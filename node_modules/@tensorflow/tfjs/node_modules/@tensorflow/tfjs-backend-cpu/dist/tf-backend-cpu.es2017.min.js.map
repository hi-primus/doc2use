{"version":3,"file":"tf-backend-cpu.es2017.min.js","sources":["../../../../tfjs-backend-cpu/src/cpu_util.ts","../../../../tfjs-backend-cpu/src/backend_cpu.ts","../../../../tfjs-backend-cpu/src/kernels/Abs.ts","../../../../tfjs-backend-cpu/src/utils/binary_impl.ts","../../../../tfjs-backend-cpu/src/kernels/Complex.ts","../../../../tfjs-backend-cpu/src/utils/zeros_impl.ts","../../../../tfjs-backend-cpu/src/kernels/Identity.ts","../../../../tfjs-backend-cpu/src/kernels/Real.ts","../../../../tfjs-backend-cpu/src/kernels/Cast.ts","../../../../tfjs-backend-cpu/src/utils/binary_utils.ts","../../../../tfjs-backend-cpu/src/kernels/Add.ts","../../../../tfjs-backend-cpu/src/kernels/Bincount_impl.ts","../../../../tfjs-backend-cpu/src/utils/unary_impl.ts","../../../../tfjs-backend-cpu/src/utils/unary_utils.ts","../../../../tfjs-backend-cpu/src/kernels/Ceil.ts","../../../../tfjs-backend-cpu/src/kernels/Concat_impl.ts","../../../../tfjs-backend-cpu/src/kernels/Equal.ts","../../../../tfjs-backend-cpu/src/kernels/Exp.ts","../../../../tfjs-backend-cpu/src/kernels/Expm1.ts","../../../../tfjs-backend-cpu/src/kernels/Floor.ts","../../../../tfjs-backend-cpu/src/kernels/FloorDiv.ts","../../../../tfjs-backend-cpu/src/kernels/GatherNd_Impl.ts","../../../../tfjs-backend-cpu/src/kernels/GatherV2_impl.ts","../../../../tfjs-backend-cpu/src/kernels/Greater.ts","../../../../tfjs-backend-cpu/src/kernels/GreaterEqual.ts","../../../../tfjs-backend-cpu/src/kernels/Less.ts","../../../../tfjs-backend-cpu/src/kernels/LessEqual.ts","../../../../tfjs-backend-cpu/src/kernels/LinSpace_impl.ts","../../../../tfjs-backend-cpu/src/kernels/Log.ts","../../../../tfjs-backend-cpu/src/kernels/Max_impl.ts","../../../../tfjs-backend-cpu/src/kernels/Maximum.ts","../../../../tfjs-backend-cpu/src/kernels/Minimum.ts","../../../../tfjs-backend-cpu/src/kernels/Multiply.ts","../../../../tfjs-backend-cpu/src/kernels/Neg.ts","../../../../tfjs-backend-cpu/src/kernels/NotEqual.ts","../../../../tfjs-backend-cpu/src/kernels/Transpose_impl.ts","../../../../tfjs-backend-cpu/src/kernels/Transpose.ts","../../../../tfjs-backend-cpu/src/kernels/Prod.ts","../../../../tfjs-backend-cpu/src/kernels/RaggedGather_impl.ts","../../../../tfjs-backend-cpu/src/kernels/RaggedRange_impl.ts","../../../../tfjs-backend-cpu/src/kernels/RaggedTensorToTensor_impl.ts","../../../../tfjs-backend-cpu/src/kernels/Range_impl.ts","../../../../tfjs-backend-cpu/src/kernels/Rsqrt.ts","../../../../tfjs-backend-cpu/src/kernels/Scatter_impl.ts","../../../../tfjs-backend-cpu/src/kernels/Sigmoid.ts","../../../../tfjs-backend-cpu/src/kernels/Slice.ts","../../../../tfjs-backend-cpu/src/kernels/SparseFillEmptyRows_impl.ts","../../../../tfjs-backend-cpu/src/kernels/SparseReshape_impl.ts","../../../../tfjs-backend-cpu/src/kernels/SparseSegmentReduction_impl.ts","../../../../tfjs-backend-cpu/src/kernels/Sqrt.ts","../../../../tfjs-backend-cpu/src/kernels/SquaredDifference.ts","../../../../tfjs-backend-cpu/src/kernels/StaticRegexReplace.ts","../../../../tfjs-backend-cpu/src/kernels/StridedSlice_impl.ts","../../../../tfjs-backend-cpu/src/kernels/StringNGrams_impl.ts","../../../../tfjs-backend-cpu/src/kernels/StringSplit_impl.ts","../../../../tfjs-backend-cpu/src/kernels/StringToHashBucketFast_impl.ts","../../../../tfjs-backend-cpu/src/kernels/Sub.ts","../../../../tfjs-backend-cpu/src/kernels/Tile_impl.ts","../../../../tfjs-backend-cpu/src/kernels/TopK_impl.ts","../../../../tfjs-backend-cpu/src/kernels/Unique_impl.ts","../../../../tfjs-backend-cpu/src/base.ts","../../../../tfjs-backend-cpu/src/kernels/Elu.ts","../../../../tfjs-backend-cpu/src/kernels/LeakyRelu.ts","../../../../tfjs-backend-cpu/src/kernels/Prelu.ts","../../../../tfjs-backend-cpu/src/kernels/Relu.ts","../../../../tfjs-backend-cpu/src/kernels/Relu6.ts","../../../../tfjs-backend-cpu/src/utils/fused_utils.ts","../../../../tfjs-backend-cpu/src/kernels/Reshape.ts","../../../../tfjs-backend-cpu/src/kernels/BatchMatMul.ts","../../../../tfjs-backend-cpu/src/kernels/_FusedMatMul.ts","../../../../tfjs-backend-cpu/src/kernels/Acos.ts","../../../../tfjs-backend-cpu/src/kernels/Acosh.ts","../../../../tfjs-backend-cpu/src/kernels/AddN.ts","../../../../tfjs-backend-cpu/src/kernels/All.ts","../../../../tfjs-backend-cpu/src/kernels/Any.ts","../../../../tfjs-backend-cpu/src/kernels/ArgMax.ts","../../../../tfjs-backend-cpu/src/kernels/ArgMin.ts","../../../../tfjs-backend-cpu/src/kernels/Asin.ts","../../../../tfjs-backend-cpu/src/kernels/Asinh.ts","../../../../tfjs-backend-cpu/src/kernels/Atan.ts","../../../../tfjs-backend-cpu/src/kernels/Atan2.ts","../../../../tfjs-backend-cpu/src/kernels/Atanh.ts","../../../../tfjs-backend-cpu/src/utils/pool_utils.ts","../../../../tfjs-backend-cpu/src/kernels/AvgPool.ts","../../../../tfjs-backend-cpu/src/kernels/AvgPool3D.ts","../../../../tfjs-backend-cpu/src/kernels/AvgPool3DGrad.ts","../../../../tfjs-backend-cpu/src/kernels/AvgPoolGrad.ts","../../../../tfjs-backend-cpu/src/kernels/BatchNorm.ts","../../../../tfjs-backend-cpu/src/kernels/BatchToSpaceND.ts","../../../../tfjs-backend-cpu/src/kernels/Bincount.ts","../../../../tfjs-backend-cpu/src/kernels/BroadcastArgs.ts","../../../../tfjs-backend-cpu/src/kernels/ClipByValue.ts","../../../../tfjs-backend-cpu/src/kernels/ComplexAbs.ts","../../../../tfjs-backend-cpu/src/kernels/Imag.ts","../../../../tfjs-backend-cpu/src/kernels/Concat.ts","../../../../tfjs-backend-cpu/src/kernels/Conv2D.ts","../../../../tfjs-backend-cpu/src/kernels/Conv2DBackpropFilter.ts","../../../../tfjs-backend-cpu/src/kernels/Conv2DBackpropInput.ts","../../../../tfjs-backend-cpu/src/kernels/Conv3D.ts","../../../../tfjs-backend-cpu/src/kernels/Conv3DBackpropFilterV2.ts","../../../../tfjs-backend-cpu/src/kernels/Conv3DBackpropInputV2.ts","../../../../tfjs-backend-cpu/src/kernels/Cos.ts","../../../../tfjs-backend-cpu/src/kernels/Cosh.ts","../../../../tfjs-backend-cpu/src/kernels/CropAndResize.ts","../../../../tfjs-backend-cpu/src/kernels/Cumprod.ts","../../../../tfjs-backend-cpu/src/kernels/Cumsum.ts","../../../../tfjs-backend-cpu/src/kernels/DenseBincount.ts","../../../../tfjs-backend-cpu/src/kernels/DepthToSpace.ts","../../../../tfjs-backend-cpu/src/kernels/DepthwiseConv2dNative.ts","../../../../tfjs-backend-cpu/src/kernels/DepthwiseConv2dNativeBackpropFilter.ts","../../../../tfjs-backend-cpu/src/kernels/DepthwiseConv2dNativeBackpropInput.ts","../../../../tfjs-backend-cpu/src/kernels/Diag.ts","../../../../tfjs-backend-cpu/src/kernels/Dilation2D.ts","../../../../tfjs-backend-cpu/src/kernels/Dilation2DBackpropFilter.ts","../../../../tfjs-backend-cpu/src/kernels/Dilation2DBackpropInput.ts","../../../../tfjs-backend-cpu/src/kernels/Sum.ts","../../../../tfjs-backend-cpu/src/kernels/Einsum.ts","../../../../tfjs-backend-cpu/src/kernels/EluGrad.ts","../../../../tfjs-backend-cpu/src/kernels/Erf.ts","../../../../tfjs-backend-cpu/src/kernels/ExpandDims.ts","../../../../tfjs-backend-cpu/src/kernels/RealDiv.ts","../../../../tfjs-backend-cpu/src/utils/fft_utils.ts","../../../../tfjs-backend-cpu/src/kernels/FFT.ts","../../../../tfjs-backend-cpu/src/kernels/Fill.ts","../../../../tfjs-backend-cpu/src/kernels/FlipLeftRight.ts","../../../../tfjs-backend-cpu/src/kernels/FusedConv2D.ts","../../../../tfjs-backend-cpu/src/kernels/FusedDepthwiseConv2D.ts","../../../../tfjs-backend-cpu/src/kernels/GatherNd.ts","../../../../tfjs-backend-cpu/src/kernels/GatherV2.ts","../../../../tfjs-backend-cpu/src/kernels/IFFT.ts","../../../../tfjs-backend-cpu/src/kernels/IsFinite.ts","../../../../tfjs-backend-cpu/src/kernels/IsInf.ts","../../../../tfjs-backend-cpu/src/kernels/IsNaN.ts","../../../../tfjs-backend-cpu/src/kernels/LinSpace.ts","../../../../tfjs-backend-cpu/src/kernels/Log1p.ts","../../../../tfjs-backend-cpu/src/kernels/LogicalAnd.ts","../../../../tfjs-backend-cpu/src/kernels/LogicalNot.ts","../../../../tfjs-backend-cpu/src/kernels/LogicalOr.ts","../../../../tfjs-backend-cpu/src/kernels/LRN.ts","../../../../tfjs-backend-cpu/src/kernels/LRNGrad.ts","../../../../tfjs-backend-cpu/src/kernels/Max.ts","../../../../tfjs-backend-cpu/src/kernels/MaxPool.ts","../../../../tfjs-backend-cpu/src/kernels/MaxPool3D.ts","../../../../tfjs-backend-cpu/src/kernels/MaxPool3DGrad.ts","../../../../tfjs-backend-cpu/src/kernels/MaxPoolGrad.ts","../../../../tfjs-backend-cpu/src/kernels/MaxPoolWithArgmax.ts","../../../../tfjs-backend-cpu/src/kernels/MaxPoolWithArgmax_impl.ts","../../../../tfjs-backend-cpu/src/kernels/Mean.ts","../../../../tfjs-backend-cpu/src/kernels/Min.ts","../../../../tfjs-backend-cpu/src/kernels/MirrorPad.ts","../../../../tfjs-backend-cpu/src/kernels/Mod.ts","../../../../tfjs-backend-cpu/src/kernels/Softmax.ts","../../../../tfjs-backend-cpu/src/kernels/Multinomial.ts","../../../../tfjs-backend-cpu/src/kernels/NonMaxSuppressionV3.ts","../../../../tfjs-backend-cpu/src/kernels/NonMaxSuppressionV4.ts","../../../../tfjs-backend-cpu/src/kernels/NonMaxSuppressionV5.ts","../../../../tfjs-backend-cpu/src/kernels/OneHot.ts","../../../../tfjs-backend-cpu/src/kernels/ZerosLike.ts","../../../../tfjs-backend-cpu/src/kernels/OnesLike.ts","../../../../tfjs-backend-cpu/src/kernels/Pack.ts","../../../../tfjs-backend-cpu/src/kernels/PadV2.ts","../../../../tfjs-backend-cpu/src/kernels/Pow.ts","../../../../tfjs-backend-cpu/src/kernels/RaggedGather.ts","../../../../tfjs-backend-cpu/src/kernels/RaggedRange.ts","../../../../tfjs-backend-cpu/src/kernels/RaggedTensorToTensor.ts","../../../../tfjs-backend-cpu/src/kernels/Range.ts","../../../../tfjs-backend-cpu/src/kernels/Reciprocal.ts","../../../../tfjs-backend-cpu/src/kernels/ResizeBilinear.ts","../../../../tfjs-backend-cpu/src/kernels/ResizeBilinearGrad.ts","../../../../tfjs-backend-cpu/src/kernels/ResizeNearestNeighbor.ts","../../../../tfjs-backend-cpu/src/kernels/ResizeNearestNeighborGrad.ts","../../../../tfjs-backend-cpu/src/kernels/Reverse.ts","../../../../tfjs-backend-cpu/src/kernels/RotateWithOffset.ts","../../../../tfjs-backend-cpu/src/kernels/Round.ts","../../../../tfjs-backend-cpu/src/kernels/ScatterNd.ts","../../../../tfjs-backend-cpu/src/kernels/SearchSorted_impl.ts","../../../../tfjs-backend-cpu/src/kernels/SearchSorted.ts","../../../../tfjs-backend-cpu/src/kernels/Select.ts","../../../../tfjs-backend-cpu/src/kernels/Selu.ts","../../../../tfjs-backend-cpu/src/kernels/Sign.ts","../../../../tfjs-backend-cpu/src/kernels/Sin.ts","../../../../tfjs-backend-cpu/src/kernels/Sinh.ts","../../../../tfjs-backend-cpu/src/kernels/Softplus.ts","../../../../tfjs-backend-cpu/src/kernels/SpaceToBatchND.ts","../../../../tfjs-backend-cpu/src/kernels/SparseFillEmptyRows.ts","../../../../tfjs-backend-cpu/src/kernels/SparseReshape.ts","../../../../tfjs-backend-cpu/src/kernels/SparseSegmentMean.ts","../../../../tfjs-backend-cpu/src/kernels/SparseSegmentSum.ts","../../../../tfjs-backend-cpu/src/kernels/SparseToDense.ts","../../../../tfjs-backend-cpu/src/kernels/SplitV.ts","../../../../tfjs-backend-cpu/src/kernels/Square.ts","../../../../tfjs-backend-cpu/src/kernels/Step.ts","../../../../tfjs-backend-cpu/src/kernels/StridedSlice.ts","../../../../tfjs-backend-cpu/src/kernels/StringNGrams.ts","../../../../tfjs-backend-cpu/src/kernels/StringSplit.ts","../../../../tfjs-backend-cpu/src/kernels/StringToHashBucketFast.ts","../../../../tfjs-backend-cpu/src/kernels/Tan.ts","../../../../tfjs-backend-cpu/src/kernels/Tanh.ts","../../../../tfjs-backend-cpu/src/kernels/TensorScatterUpdate.ts","../../../../tfjs-backend-cpu/src/kernels/Tile.ts","../../../../tfjs-backend-cpu/src/kernels/TopK.ts","../../../../tfjs-backend-cpu/src/kernels/Transform.ts","../../../../tfjs-backend-cpu/src/kernels/Unique.ts","../../../../tfjs-backend-cpu/src/kernels/Unpack.ts","../../../../tfjs-backend-cpu/src/kernels/UnsortedSegmentSum.ts","../../../../tfjs-backend-cpu/src/register_all_kernels.ts","../../../../tfjs-backend-cpu/src/version.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {TensorInfo, util} from '@tensorflow/tfjs-core';\n\nexport function assertNotComplex(\n    tensor: TensorInfo|TensorInfo[], opName: string): void {\n  if (!Array.isArray(tensor)) {\n    tensor = [tensor];\n  }\n  tensor.forEach(t => {\n    if (t != null) {\n      util.assert(\n          t.dtype !== 'complex64',\n          () => `${\n              opName} does not support complex64 tensors in the CPU backend.`);\n    }\n  });\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, BackendTimingInfo, buffer, DataStorage, DataType, engine, env, kernel_impls, KernelBackend, Rank, ShapeMap, Tensor, Tensor2D, TensorBuffer, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nconst whereImpl = kernel_impls.whereImpl;\nimport {assertNotComplex} from './cpu_util';\n\ninterface DataId {}\n\nexport interface TensorData<D extends DataType> {\n  values?: backend_util.BackendValues;\n  dtype: D;\n  // For complex numbers, the real and imaginary parts are stored as their own\n  // individual tensors, with a parent joining the two with the\n  // complexTensorInfos field.\n  complexTensorInfos?: {real: TensorInfo, imag: TensorInfo};\n  // refCount keeps track of how many tensors reference it. Used for memory\n  // management.\n  refCount: number;\n}\n\nexport class MathBackendCPU extends KernelBackend {\n  public blockSize = 48;\n\n  data: DataStorage<TensorData<DataType>>;\n  private firstUse = true;\n  private static nextDataId = 0;\n  private nextDataId(): number {\n    return MathBackendCPU.nextDataId++;\n  }\n\n  constructor() {\n    super();\n    this.data = new DataStorage(this, engine());\n  }\n\n  override write(\n      values: backend_util.BackendValues, shape: number[],\n      dtype: DataType): DataId {\n    if (this.firstUse) {\n      this.firstUse = false;\n      if (env().get('IS_NODE')) {\n        backend_util.warn(\n            '\\n============================\\n' +\n            'Hi, looks like you are running TensorFlow.js in ' +\n            'Node.js. To speed things up dramatically, install our node ' +\n            'backend, visit https://github.com/tensorflow/tfjs-node for more details. ' +\n            '\\n============================');\n      }\n    }\n    const dataId = {id: this.nextDataId()};\n\n    this.data.set(dataId, {values, dtype, refCount: 1});\n\n    return dataId;\n  }\n\n  /**\n   * Create a data bucket in cpu backend.\n   * @param shape Shape of the `TensorInfo`.\n   * @param dtype DType of the `TensorInfo`.\n   * @param values The value of the `TensorInfo` stored as a flattened array.\n   */\n  makeTensorInfo(\n      shape: number[], dtype: DataType,\n      values?: backend_util.BackendValues|string[]): TensorInfo {\n    let outId;\n    if (dtype === 'string' && values != null && values.length > 0 &&\n        util.isString(values[0])) {\n      const encodedValues =\n          (values as unknown as string[]).map(d => util.encodeString(d));\n\n      outId = this.write(encodedValues, shape, dtype);\n    } else {\n      outId = this.write(values as TypedArray, shape, dtype);\n    }\n\n    return {dataId: outId, shape, dtype};\n  }\n\n  /** Return refCount of a `TensorData`. */\n  override refCount(dataId: DataId): number {\n    if (this.data.has(dataId)) {\n      const tensorData = this.data.get(dataId);\n      return tensorData.refCount;\n    }\n    return 0;\n  }\n\n  /** Increase refCount of a `TensorData`. */\n  override incRef(dataId: DataId): void {\n    const tensorData = this.data.get(dataId);\n    tensorData.refCount++;\n  }\n\n  /** Decrease refCount of a `TensorData`. */\n  decRef(dataId: DataId): void {\n    if (this.data.has(dataId)) {\n      const tensorData = this.data.get(dataId);\n      tensorData.refCount--;\n    }\n  }\n\n  override move(\n      dataId: DataId, values: backend_util.BackendValues, shape: number[],\n      dtype: DataType, refCount: number): void {\n    this.data.set(dataId, {values, dtype, refCount});\n  }\n\n  override numDataIds(): number {\n    return this.data.numDataIds();\n  }\n\n  override async read(dataId: DataId): Promise<backend_util.BackendValues> {\n    return this.readSync(dataId);\n  }\n  override readSync(dataId: DataId): backend_util.BackendValues {\n    const {dtype, complexTensorInfos} = this.data.get(dataId);\n\n    if (dtype === 'complex64') {\n      const realValues =\n          this.readSync(complexTensorInfos.real.dataId) as Float32Array;\n      const imagValues =\n          this.readSync(complexTensorInfos.imag.dataId) as Float32Array;\n      return backend_util.mergeRealAndImagArrays(realValues, imagValues);\n    }\n    return util.convertBackendValuesAndArrayBuffer(\n        this.data.get(dataId).values, dtype);\n  }\n\n  bufferSync<R extends Rank, D extends DataType>(t: TensorInfo):\n      TensorBuffer<R, D> {\n    const data = this.readSync(t.dataId);\n    if (t.dtype === 'string') {\n      try {\n        // Decode the bytes into string.\n        const strings = (data as Uint8Array[]).map(d => util.decodeString(d));\n        return buffer(t.shape as ShapeMap[R], t.dtype, strings) as\n            TensorBuffer<R, D>;\n      } catch {\n        throw new Error('Failed to decode encoded string bytes into utf-8');\n      }\n    }\n    return buffer(t.shape as ShapeMap[R], t.dtype, data as TypedArray) as\n        TensorBuffer<R, D>;\n  }\n\n  makeOutput<T extends Tensor>(\n      values: backend_util.BackendValues, shape: number[], dtype: DataType): T {\n    return engine().makeTensorFromTensorInfo(\n               this.makeTensorInfo(shape, dtype, values), this) as T;\n  }\n\n  /**\n   * Dispose the memory if the dataId has 0 refCount. Return true if the memory\n   * is released or memory is not managed in this backend, false if memory is\n   * not cleared.\n   * @param dataId\n   * @oaram force Optional, remove the data regardless of refCount\n   */\n  override disposeData(dataId: DataId, force = false): boolean {\n    if (this.data.has(dataId)) {\n      this.data.get(dataId).refCount--;\n      if (!force && this.data.get(dataId).refCount > 0) {\n        return false;\n      }\n\n      const {complexTensorInfos} = this.data.get(dataId);\n\n      if (complexTensorInfos != null) {\n        this.disposeData(complexTensorInfos.real.dataId, true);\n        this.disposeData(complexTensorInfos.imag.dataId, true);\n      }\n\n      this.data.delete(dataId);\n    }\n    return true;\n  }\n\n  disposeIntermediateTensorInfo(tensorInfo: TensorInfo): void {\n    this.disposeData(tensorInfo.dataId);\n  }\n\n  override async time(f: () => void): Promise<BackendTimingInfo> {\n    const start = util.now();\n    f();\n    const kernelMs = util.now() - start;\n    return {kernelMs};\n  }\n\n  override memory() {\n    return {\n      // Unreliable due to automatic gc. The numbers above are cumulative.\n      unreliable: true,\n      reasons:\n          ['The reported memory is an upper bound. Due to automatic garbage ' +\n           'collection, the true allocated memory may be less.']\n    };\n  }\n\n  where(condition: Tensor): Tensor2D {\n    assertNotComplex([condition], 'where');\n\n    const condVals = this.readSync(condition.dataId) as TypedArray;\n    return whereImpl(condition.shape, condVals);\n  }\n\n  override dispose() {}\n\n  override floatPrecision(): 16|32 {\n    return 32;\n  }\n\n  /** Returns the smallest representable number.  */\n  override epsilon(): number {\n    return super.epsilon();\n  }\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Abs, AbsInputs, KernelConfig, KernelFunc, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function simpleAbsImpl(vals: TypedArray): Float32Array {\n  const resultValues = new Float32Array(vals.length);\n  for (let i = 0; i < vals.length; ++i) {\n    resultValues[i] = Math.abs(vals[i]);\n  }\n  return resultValues;\n}\n\nexport const abs = (args: {inputs: AbsInputs, backend: MathBackendCPU}) => {\n  const {x} = args.inputs;\n  const cpuBackend = args.backend;\n\n  assertNotComplex(x, 'abs');\n\n  let resultValues = new Float32Array(util.sizeFromShape(x.shape));\n  const values = cpuBackend.data.get(x.dataId).values as TypedArray;\n  resultValues = simpleAbsImpl(values);\n\n  return cpuBackend.makeOutput(resultValues, x.shape, x.dtype);\n};\n\nexport const absConfig: KernelConfig = {\n  kernelName: Abs,\n  backendName: 'cpu',\n  kernelFunc: abs as unknown as KernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, DataType, DataValues, NumericDataType, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {SimpleBinaryKernelImpl, SimpleBinaryOperation} from './binary_types';\n\n/**\n * Template that creates implementation for binary ops. Supports broadcast.\n */\nexport function createSimpleBinaryKernelImpl(op: SimpleBinaryOperation):\n    SimpleBinaryKernelImpl {\n  return (aShape: number[], bShape: number[], aVals: DataValues,\n          bVals: DataValues, dtype: DataType): [TypedArray, number[]] => {\n    const newShape = backend_util.assertAndGetBroadcastShape(aShape, bShape);\n\n    const resultRank = newShape.length;\n    const resultStrides = util.computeStrides(newShape);\n    const resultSize = util.sizeFromShape(newShape);\n\n    const result =\n        util.getTypedArrayFromDType(dtype as NumericDataType, resultSize);\n\n    const aRank = aShape.length;\n    const bRank = bShape.length;\n\n    const aStrides = util.computeStrides(aShape);\n    const bStrides = util.computeStrides(bShape);\n\n    const aBroadcastDims = backend_util.getBroadcastDims(aShape, newShape);\n    const bBroadcastDims = backend_util.getBroadcastDims(bShape, newShape);\n\n    if (aBroadcastDims.length + bBroadcastDims.length === 0) {\n      for (let i = 0; i < result.length; ++i) {\n        result[i] = op(aVals[i % aVals.length], bVals[i % bVals.length]);\n      }\n    } else {\n      for (let i = 0; i < result.length; ++i) {\n        const loc = util.indexToLoc(i, resultRank, resultStrides);\n\n        const aLoc = loc.slice(-aRank);\n        aBroadcastDims.forEach(d => aLoc[d] = 0);\n        const aIndex = util.locToIndex(aLoc, aRank, aStrides);\n\n        const bLoc = loc.slice(-bRank);\n        bBroadcastDims.forEach(d => bLoc[d] = 0);\n        const bIndex = util.locToIndex(bLoc, bRank, bStrides);\n\n        result[i] = op(aVals[aIndex], bVals[bIndex]);\n      }\n    }\n\n    return [result, newShape];\n  };\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Complex, ComplexInputs, KernelConfig, KernelFunc, TensorInfo, TypedArray} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nexport function complex(args: {inputs: ComplexInputs, backend: MathBackendCPU}):\n    TensorInfo {\n  const {inputs, backend} = args;\n  const {real, imag} = inputs;\n\n  const realVals = backend.data.get(real.dataId).values as TypedArray;\n  const imagVals = backend.data.get(imag.dataId).values as TypedArray;\n\n  const complexInfo = backend.makeTensorInfo(real.shape, 'complex64');\n\n  const complex = backend.data.get(complexInfo.dataId);\n\n  // The complex tensor owns the underlying real and imag tensorInfos, only the\n  // complex tensor tracks refCount, when complexData is disposed the\n  // underlying tensorData will be disposed.\n  complex.complexTensorInfos = {\n    real: backend.makeTensorInfo(real.shape, 'float32', realVals),\n    imag: backend.makeTensorInfo(imag.shape, 'float32', imagVals)\n  };\n\n  return complexInfo;\n}\n\nexport const complexConfig: KernelConfig = {\n  kernelName: Complex,\n  backendName: 'cpu',\n  kernelFunc: complex as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DataType, TensorInfo, util} from '@tensorflow/tfjs-core';\nimport {MathBackendCPU} from '../backend_cpu';\nimport {complex} from '../kernels/Complex';\n\n/**\n * Generates a tensorInfo with all zeros value.\n * @param backend cpu backend.\n * @param shape Shape for the zeros tensor.\n * @param dtype Optional. If set, the result has this dtype.\n */\nexport function zeros(\n    backend: MathBackendCPU, shape: number[],\n    dtype: DataType = 'float32'): TensorInfo {\n  if (dtype === 'complex64') {\n    const real = zeros(backend, shape, 'float32');\n    const imag = zeros(backend, shape, 'float32');\n\n    return complex({inputs: {real, imag}, backend});\n  }\n\n  const values = util.makeZerosTypedArray(util.sizeFromShape(shape), dtype);\n\n  return backend.makeTensorInfo(shape, dtype, values);\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Identity, IdentityInputs, KernelConfig, KernelFunc, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nexport function identity(\n    args: {inputs: IdentityInputs, backend: MathBackendCPU}): TensorInfo {\n  const {inputs, backend} = args;\n  const {x} = inputs;\n\n  backend.incRef(x.dataId);\n\n  return {dataId: x.dataId, shape: x.shape, dtype: x.dtype};\n}\n\nexport const identityConfig: KernelConfig = {\n  kernelName: Identity,\n  backendName: 'cpu',\n  kernelFunc: identity as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, Real, RealInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nexport function real(args: {inputs: RealInputs, backend: MathBackendCPU}):\n    TensorInfo {\n  const {inputs, backend} = args;\n  const {input} = inputs;\n\n  const real = backend.data.get(input.dataId).complexTensorInfos.real;\n  const realVal = backend.data.get(real.dataId).values;\n\n  // When complex tensor is disposed, its underlying parts will be disposed too.\n  // Make new tensor out of the real value of the complex. This makes sure the\n  // value is still accessible even if complex tensor is disposed.\n  return backend.makeTensorInfo(real.shape, real.dtype, realVal);\n}\n\nexport const realConfig: KernelConfig = {\n  kernelName: Real,\n  backendName: 'cpu',\n  kernelFunc: real as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {Cast, CastAttrs, CastInputs, DataType, KernelConfig, KernelFunc, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {zeros} from '../utils/zeros_impl';\n\nimport {complex} from './Complex';\nimport {identity} from './Identity';\nimport {real} from './Real';\n\nexport function castImpl(\n    values: TypedArray, shape: number[], inputType: DataType,\n    dtype: DataType): [number[], DataType, TypedArray] {\n  if (dtype === 'int32') {\n    const resultValues = Int32Array.from(values);\n    return [shape, 'int32', resultValues];\n  }\n\n  if (dtype === 'bool') {\n    // This is essentially the result of notEqual(x, 0). We avoid using\n    // kernel notEqual to avoid circular dependency, i.e. binary_utils ->\n    // cast -> notEqual -> binary_utils.\n    const zero = util.toTypedArray([0], inputType);\n\n    const [resultData, resultShape] = createSimpleBinaryKernelImpl(\n        (a, b) => (a !== b) ? 1 : 0)(shape, [], values, zero, 'bool');\n\n    return [resultShape, 'bool', resultData];\n  }\n  throw new Error(`Error in Cast: failed to cast ${inputType} to ${dtype}`);\n}\n\nexport function cast(\n    args: {inputs: CastInputs, backend: MathBackendCPU, attrs: CastAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {dtype} = attrs;\n\n  // Casting to complex64.\n  if (dtype === 'complex64') {\n    if (x.dtype === 'complex64') {\n      return identity({inputs: {x}, backend});\n    }\n\n    const zerosTensorInfo = zeros(backend, x.shape, x.dtype);\n    const floatX = cast({inputs: {x}, backend, attrs: {dtype: 'float32'}});\n\n    const result =\n        complex({inputs: {real: floatX, imag: zerosTensorInfo}, backend});\n\n    backend.disposeIntermediateTensorInfo(zerosTensorInfo);\n    backend.disposeIntermediateTensorInfo(floatX);\n\n    return result;\n  }\n\n  // Casting from complex64\n  if (x.dtype === 'complex64') {\n    const realPart = real({inputs: {input: x}, backend});\n    const result = cast({inputs: {x: realPart}, backend, attrs: {dtype}});\n\n    backend.disposeIntermediateTensorInfo(realPart);\n\n    return result;\n  }\n\n  if (!util.hasEncodingLoss(x.dtype, dtype)) {\n    // We don't change the underlying data, since we cast to higher\n    // precision.\n    const result = identity({inputs: {x}, backend});\n    return {dataId: result.dataId, shape: result.shape, dtype};\n  }\n\n  const values = backend.data.get(x.dataId).values as TypedArray;\n  const [resultShape, resultType, resultData] =\n      castImpl(values, x.shape, x.dtype, dtype);\n  return backend.makeTensorInfo(resultShape, resultType, resultData);\n}\n\nexport const castConfig: KernelConfig = {\n  kernelName: Cast,\n  backendName: 'cpu',\n  kernelFunc: cast as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, BinaryInputs, DataType, KernelFunc, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\nimport {cast} from '../kernels/Cast';\nimport {complex} from '../kernels/Complex';\n\nimport {ComplexBinaryKernelImpl, ComplexBinaryOperation, SimpleBinaryKernelImpl} from './binary_types';\n\n/**\n * Template that creates a `KernelFunc` for binary ops.\n * @param name Kernel name.\n * @param binaryKernelImpl A `SimpleBinaryKernelImpl` for the kernel.\n * @param binaryKernelComplexImpl Optional. If exists, represents a\n *     `ComplexBinaryKernelImpl` for the kernel, will be used when input dtype\n *     is `complex64`.\n * @param dtype Optional. If set, the result has this dtype. Otherwise, the\n *     result has the same dtype as the first input. This is mainly used in\n *     comparison kernels, such as Equal, Less, Greater, etc.\n */\nexport function binaryKernelFunc(\n    name: string, simpleImpl: SimpleBinaryKernelImpl,\n    complexImpl?: ComplexBinaryKernelImpl, dtype?: DataType): KernelFunc {\n  if (complexImpl == null) {\n    return ({inputs, backend}) => {\n      const {a, b} = inputs as BinaryInputs;\n      const cpuBackend = backend as MathBackendCPU;\n\n      assertNotComplex([a, b], name);\n\n      const aVals = cpuBackend.data.get(a.dataId).values as TypedArray;\n      const bVals = cpuBackend.data.get(b.dataId).values as TypedArray;\n\n      const decodedAVals = a.dtype === 'string' ?\n          // tslint:disable-next-line: no-any\n          backend_util.fromUint8ToStringArray(aVals as any as Uint8Array[]) :\n          aVals;\n      const decodedBVals = a.dtype === 'string' ?\n          // tslint:disable-next-line: no-any\n          backend_util.fromUint8ToStringArray(bVals as any as Uint8Array[]) :\n          bVals;\n      const $dtype = dtype || a.dtype;\n\n      const [resultData, resultShape] =\n          simpleImpl(a.shape, b.shape, decodedAVals, decodedBVals, $dtype);\n\n      return cpuBackend.makeTensorInfo(resultShape, $dtype, resultData);\n    };\n  }\n\n  return ({inputs, backend}) => {\n    const {a, b} = inputs as BinaryInputs;\n    const cpuBackend = backend as MathBackendCPU;\n\n    if (a.dtype === 'complex64' || b.dtype === 'complex64') {\n      const $aComplex = cast(\n          {inputs: {x: a}, backend: cpuBackend, attrs: {dtype: 'complex64'}});\n\n      const $aComplexVals = cpuBackend.data.get($aComplex.dataId);\n\n      const aReal = $aComplexVals.complexTensorInfos.real;\n      const aImag = $aComplexVals.complexTensorInfos.imag;\n\n      const aRealVals =\n          cpuBackend.data.get(aReal.dataId).values as Float32Array;\n      const aImagVals =\n          cpuBackend.data.get(aImag.dataId).values as Float32Array;\n\n      const $bComplex = cast(\n          {inputs: {x: b}, backend: cpuBackend, attrs: {dtype: 'complex64'}});\n\n      const $bComplexVals = cpuBackend.data.get($bComplex.dataId);\n\n      const bReal = $bComplexVals.complexTensorInfos.real;\n      const bImag = $bComplexVals.complexTensorInfos.imag;\n\n      const bRealVals =\n          cpuBackend.data.get(bReal.dataId).values as Float32Array;\n      const bImagVals =\n          cpuBackend.data.get(bImag.dataId).values as Float32Array;\n\n      const [resultRealData, resultImagData, resultShape] = complexImpl(\n          a.shape, b.shape, aRealVals, aImagVals, bRealVals, bImagVals);\n\n      const resultReal =\n          cpuBackend.makeTensorInfo(resultShape, 'float32', resultRealData);\n\n      const resultImag =\n          cpuBackend.makeTensorInfo(resultShape, 'float32', resultImagData);\n\n      const result = complex(\n          {inputs: {real: resultReal, imag: resultImag}, backend: cpuBackend});\n\n      cpuBackend.disposeIntermediateTensorInfo($aComplex);\n      cpuBackend.disposeIntermediateTensorInfo($bComplex);\n      cpuBackend.disposeIntermediateTensorInfo(resultReal);\n      cpuBackend.disposeIntermediateTensorInfo(resultImag);\n\n      return result;\n    } else {\n      const aVals = cpuBackend.data.get(a.dataId).values as TypedArray;\n      const bVals = cpuBackend.data.get(b.dataId).values as TypedArray;\n\n      const $dtype = dtype || a.dtype;\n\n      const [resultData, resultShape] =\n          simpleImpl(a.shape, b.shape, aVals, bVals, $dtype);\n\n      return cpuBackend.makeTensorInfo(resultShape, $dtype, resultData);\n    }\n  };\n}\n\n/**\n * Template that creates the complex type implementation for binary ops.\n * Supports broadcast.\n */\nexport function createComplexBinaryKernelImpl(op: ComplexBinaryOperation):\n    ComplexBinaryKernelImpl {\n  return (aShape: number[], bShape: number[], aRealVals: Float32Array,\n          aImagVals: Float32Array, bRealVals: Float32Array,\n          bImagVals: Float32Array): [TypedArray, TypedArray, number[]] => {\n    const resultShape = backend_util.assertAndGetBroadcastShape(aShape, bShape);\n    const resultSize = util.sizeFromShape(resultShape);\n    const resultRank = resultShape.length;\n    const resultStrides = util.computeStrides(resultShape);\n\n    const resultRealVals = util.getTypedArrayFromDType('float32', resultSize);\n    const resultImagVals = util.getTypedArrayFromDType('float32', resultSize);\n\n    const aBroadcastDims = backend_util.getBroadcastDims(aShape, resultShape);\n    const bBroadcastDims = backend_util.getBroadcastDims(bShape, resultShape);\n\n    const aVals = backend_util.mergeRealAndImagArrays(aRealVals, aImagVals);\n    const bVals = backend_util.mergeRealAndImagArrays(bRealVals, bImagVals);\n\n    const aRank = aShape.length;\n    const aStrides = util.computeStrides(aShape);\n\n    const bRank = bShape.length;\n    const bStrides = util.computeStrides(bShape);\n\n    if (aBroadcastDims.length + bBroadcastDims.length === 0) {\n      for (let i = 0; i < resultRealVals.length; i++) {\n        const aIdx = i % aVals.length;\n        const bIdx = i % bVals.length;\n\n        const result =\n            op(aVals[aIdx * 2], aVals[aIdx * 2 + 1], bVals[bIdx * 2],\n               bVals[bIdx * 2 + 1]);\n\n        resultRealVals[i] = result.real;\n        resultImagVals[i] = result.imag;\n      }\n    } else {\n      for (let i = 0; i < resultRealVals.length; i++) {\n        const loc = util.indexToLoc(i, resultRank, resultStrides);\n\n        const aLoc = loc.slice(-aRank);\n        aBroadcastDims.forEach(d => aLoc[d] = 0);\n        const aIndex = util.locToIndex(aLoc, aRank, aStrides);\n\n        const bLoc = loc.slice(-bRank);\n        bBroadcastDims.forEach(d => bLoc[d] = 0);\n        const bIndex = util.locToIndex(bLoc, bRank, bStrides);\n\n        const opResult =\n            op(aVals[aIndex * 2], aVals[aIndex * 2 + 1], bVals[bIndex * 2],\n               bVals[bIndex * 2 + 1]);\n\n        resultRealVals[i] = opResult.real;\n        resultImagVals[i] = opResult.imag;\n      }\n    }\n    return [resultRealVals, resultImagVals, resultShape];\n  };\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Add, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc, createComplexBinaryKernelImpl} from '../utils/binary_utils';\n\nexport const addImpl =\n    createSimpleBinaryKernelImpl(((a: number, b: number) => a + b));\nexport const addComplexImpl =\n    createComplexBinaryKernelImpl(((aReal, aImag, bReal, bImag) => {\n      return {real: aReal + bReal, imag: aImag + bImag};\n    }));\n\nexport const add = binaryKernelFunc(Add, addImpl, addComplexImpl);\n\nexport const addConfig: KernelConfig = {\n  kernelName: Add,\n  backendName: 'cpu',\n  kernelFunc: add\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {buffer, DataType, Rank, TensorBuffer, TypedArray, util} from '@tensorflow/tfjs-core';\n\nexport function bincountImpl(\n    xVals: TypedArray, weightsVals: TypedArray, weightsDtype: DataType,\n    weightsShape: number[], size: number): TypedArray {\n  const weightsSize = util.sizeFromShape(weightsShape);\n  const outVals = util.makeZerosTypedArray(size, weightsDtype) as TypedArray;\n\n  for (let i = 0; i < xVals.length; i++) {\n    const value = xVals[i];\n    if (value < 0) {\n      throw new Error('Input x must be non-negative!');\n    }\n\n    if (value >= size) {\n      continue;\n    }\n\n    if (weightsSize > 0) {\n      outVals[value] += weightsVals[i];\n    } else {\n      outVals[value] += 1;\n    }\n  }\n\n  return outVals;\n}\n\nexport function bincountReduceImpl<R extends Rank>(\n    xBuf: TensorBuffer<R>, weightsBuf: TensorBuffer<R>, size: number,\n    binaryOutput = false): TensorBuffer<R> {\n  const numRows = xBuf.shape[0];\n  const numCols = xBuf.shape[1];\n\n  const outBuf = buffer([numRows, size], weightsBuf.dtype);\n\n  for (let i = 0; i < numRows; i++) {\n    for (let j = 0; j < numCols; j++) {\n      const value = xBuf.get(i, j);\n      if (value < 0) {\n        throw new Error('Input x must be non-negative!');\n      }\n\n      if (value >= size) {\n        continue;\n      }\n\n      if (binaryOutput) {\n        outBuf.set(1, i, value);\n      } else {\n        if (weightsBuf.size > 0) {\n          outBuf.set(outBuf.get(i, value) + weightsBuf.get(i, j), i, value);\n        } else {\n          outBuf.set(outBuf.get(i, value) + 1, i, value);\n        }\n      }\n    }\n  }\n\n  return outBuf as TensorBuffer<R>;\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {util} from '@tensorflow/tfjs-core';\n\nimport {SimpleUnaryImpl, SimpleUnaryOperation} from './unary_types';\n\n/**\n * Template that creates implementation for unary op.\n */\nexport function createSimpleUnaryImpl<I extends number | string = number,\n  O extends number | string = number>(op: SimpleUnaryOperation<I, O>):\n    SimpleUnaryImpl<I, O> {\n  return (values, dtype, attrs) => {\n    const newValues =\n        util.getArrayFromDType(dtype, values.length);\n    for (let i = 0; i < values.length; ++i) {\n      newValues[i] = op(values[i], attrs);\n    }\n    return newValues;\n  };\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, DataTypeFor, KernelFunc, UnaryInputs} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\nimport {createSimpleUnaryImpl} from './unary_impl';\n\nimport {SimpleUnaryImpl, SimpleUnaryOperation} from './unary_types';\n\n/**\n * Template that creates a `KernelFunc` for unary ops.\n * @param name Kernel name.\n * @param op A `SimpleUnaryOperation` for the kernel.\n * @param dtype Optional. If set, the result has this dtype. Otherwise, the\n *     result has the same dtype as the input. This is mainly used in certain\n *     kernels that return bool type, such as isFinite, isInf, etc.\n */\nexport function unaryKernelFunc<I extends number | string = number,\n  O extends number | string = number>(\n  name: string, op: SimpleUnaryOperation<I, O>,\n  dtype?: DataTypeFor<O>): KernelFunc {\n\n  const impl = createSimpleUnaryImpl<I, O>(op);\n\n  return unaryKernelFuncFromImpl<I, O>(name, impl, dtype);\n}\n\n/**\n * Template that creates a `KernelFunc` for unary ops from the given\n * `SimpleUnaryImpl`..\n * @param name Kernel name.\n * @param unaryImpl A `SimpleUnaryImpl` that implements the op.\n * @param dtype Optional. If set, the result has this dtype. Otherwise, the\n *     result has the same dtype as the input. This is mainly used in certain\n *     kernels that return bool type, such as isFinite, isInf, etc.\n */\nexport function unaryKernelFuncFromImpl<I extends number | string = number,\n  O extends number | string = number>(\n  name: string, unaryImpl: SimpleUnaryImpl<I, O>,\n  dtype?: DataTypeFor<O>): KernelFunc {\n\n  return ({inputs, attrs, backend}) => {\n    const {x} = inputs as UnaryInputs;\n    assertNotComplex(x, name);\n\n    const cpuBackend = backend as MathBackendCPU;\n    const values = cpuBackend.data.get(x.dataId).values;\n    let decoded: ArrayLike<I>;\n    if (x.dtype === 'string') {\n      if (!Array.isArray(values)) {\n        throw new Error('String tensor\\'s value was not an instance of Array');\n      }\n      decoded = backend_util.fromUint8ToStringArray(values) as unknown as\n        ArrayLike<I>;\n    } else {\n      decoded = values as unknown as ArrayLike<I>;\n    }\n\n    const $dtype = dtype || x.dtype as DataTypeFor<O>;\n    const newValues = unaryImpl(decoded, $dtype, attrs);\n    return cpuBackend.makeTensorInfo(x.shape, $dtype, newValues);\n  };\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Ceil, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {createSimpleUnaryImpl} from '../utils/unary_impl';\nimport {unaryKernelFuncFromImpl} from '../utils/unary_utils';\n\nexport const ceilImpl = createSimpleUnaryImpl((xi) => Math.ceil(xi));\nexport const ceil = unaryKernelFuncFromImpl(Ceil, ceilImpl);\n\nexport const ceilConfig: KernelConfig = {\n  kernelName: Ceil,\n  backendName: 'cpu',\n  kernelFunc: ceil,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, BackendValues, DataType, TypedArray, util} from '@tensorflow/tfjs-core';\n\nexport function concatImpl(\n    inputs: Array<{vals: BackendValues, shape: number[]}>, outShape: number[],\n    dtype: DataType, simplyConcat: boolean): TypedArray|string[] {\n  const outVals = util.getArrayFromDType(dtype, util.sizeFromShape(outShape));\n\n  if (simplyConcat && dtype !== 'string') {\n    // Use built-in TypedArray.set() method for speed.\n    let offset = 0;\n    inputs.forEach(input => {\n      const size = util.sizeFromShape(input.shape);\n\n      (outVals as TypedArray).set(input.vals as TypedArray, offset);\n      offset += size;\n    });\n  } else {\n    let colOffset = 0;\n\n    inputs.forEach(input => {\n      const decodedData = dtype === 'string' ?\n          backend_util.fromUint8ToStringArray(input.vals as Uint8Array[]) :\n          input.vals as TypedArray;\n\n      let tIdx = 0;\n\n      for (let row = 0; row < input.shape[0]; ++row) {\n        const resIdx = row * outShape[1] + colOffset;\n        for (let col = 0; col < input.shape[1]; ++col) {\n          outVals[resIdx + col] = decodedData[tIdx++];\n        }\n      }\n\n      colOffset += input.shape[1];\n    });\n  }\n\n  return outVals;\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Equal, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc} from '../utils/binary_utils';\n\nexport const equalImpl =\n    createSimpleBinaryKernelImpl((a: number, b: number) => (a === b) ? 1 : 0);\nexport const equal =\n    binaryKernelFunc(Equal, equalImpl, null /* complexImpl */, 'bool');\n\nexport const equalConfig: KernelConfig = {\n  kernelName: Equal,\n  backendName: 'cpu',\n  kernelFunc: equal\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Exp, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {createSimpleUnaryImpl} from '../utils/unary_impl';\nimport {unaryKernelFuncFromImpl} from '../utils/unary_utils';\n\nexport const expImpl = createSimpleUnaryImpl((xi) => Math.exp(xi));\nexport const exp = unaryKernelFuncFromImpl(Exp, expImpl, 'float32');\n\nexport const expConfig: KernelConfig = {\n  kernelName: Exp,\n  backendName: 'cpu',\n  kernelFunc: exp,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Expm1, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {createSimpleUnaryImpl} from '../utils/unary_impl';\nimport {unaryKernelFuncFromImpl} from '../utils/unary_utils';\n\nexport const expm1Impl = createSimpleUnaryImpl((xi) => Math.expm1(xi));\nexport const expm1 = unaryKernelFuncFromImpl(Expm1, expm1Impl);\n\nexport const expm1Config: KernelConfig = {\n  kernelName: Expm1,\n  backendName: 'cpu',\n  kernelFunc: expm1,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Floor, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {createSimpleUnaryImpl} from '../utils/unary_impl';\nimport {unaryKernelFuncFromImpl} from '../utils/unary_utils';\n\nexport const floorImpl = createSimpleUnaryImpl((xi) => Math.floor(xi));\nexport const floor = unaryKernelFuncFromImpl(Floor, floorImpl);\n\nexport const floorConfig: KernelConfig = {\n  kernelName: Floor,\n  backendName: 'cpu',\n  kernelFunc: floor,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {FloorDiv, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc} from '../utils/binary_utils';\n\nexport const floorDivImpl =\n    createSimpleBinaryKernelImpl((a: number, b: number) => Math.floor(a / b));\nexport const floorDiv =\n    binaryKernelFunc(FloorDiv, floorDivImpl, null /* complexImpl */, 'int32');\n\nexport const floorDivConfig: KernelConfig = {\n  kernelName: FloorDiv,\n  backendName: 'cpu',\n  kernelFunc: floorDiv\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {buffer, DataType, Rank, TensorBuffer, TypedArray} from '@tensorflow/tfjs-core';\n\nexport function gatherNdImpl<R extends Rank>(\n    indicesData: TypedArray, paramsBuf: TensorBuffer<R>, dtype: DataType,\n    numSlices: number, sliceRank: number, sliceSize: number, strides: number[],\n    paramsShape: number[], paramsSize: number): TensorBuffer<R> {\n  const outBuf = buffer([numSlices, sliceSize], dtype);\n\n  for (let i = 0; i < numSlices; i++) {\n    const index = [];\n    let flattenIndex = 0;\n    for (let j = 0; j < sliceRank; j++) {\n      const dim = indicesData[i * sliceRank + j];\n      flattenIndex += dim * strides[j];\n      index.push(dim);\n    }\n    if (flattenIndex < 0 || flattenIndex >= paramsSize / sliceSize) {\n      throw new Error(\n          `Invalid indices: ${index} does not index into ${paramsShape}`);\n    }\n\n    for (let k = 0; k < sliceSize; k++) {\n      outBuf.values[i * sliceSize + k] =\n          paramsBuf.get(...paramsBuf.indexToLoc(flattenIndex * sliceSize + k));\n    }\n  }\n\n  return outBuf as TensorBuffer<R>;\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {buffer, DataType, Rank, TensorBuffer} from '@tensorflow/tfjs-core';\n\nexport function gatherV2Impl<R extends Rank, D extends DataType>(\n    xBuf: TensorBuffer<R, D>, indicesBuf: TensorBuffer<R, D>,\n    flattenOutputShape: number[]): TensorBuffer<R, D> {\n  const outBuf = buffer(flattenOutputShape, xBuf.dtype);\n  for (let i = 0; i < outBuf.size; ++i) {\n    const newLoc = outBuf.indexToLoc(i);\n\n    const originalLoc: number[] = newLoc.slice();\n    const batchIdx = originalLoc[0];\n    const indicesIdx = originalLoc[2];\n    const indicesIndex = indicesBuf.locToIndex([batchIdx, indicesIdx]);\n    originalLoc[2] = indicesBuf.values[indicesIndex] as number;\n\n    const originalIndex = xBuf.locToIndex(originalLoc);\n\n    if (0 <= originalIndex && originalIndex < xBuf.values.length) {\n      outBuf.values[i] = xBuf.values[originalIndex];\n    } // Else, index is out of bounds, so leave the default zero val in outBuf.\n  }\n\n  return outBuf as TensorBuffer<R, D>;\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Greater, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc} from '../utils/binary_utils';\n\nexport const greaterImpl =\n    createSimpleBinaryKernelImpl((a: number, b: number) => (a > b) ? 1 : 0);\nexport const greater =\n    binaryKernelFunc(Greater, greaterImpl, null /* complexImpl */, 'bool');\n\nexport const greaterConfig: KernelConfig = {\n  kernelName: Greater,\n  backendName: 'cpu',\n  kernelFunc: greater\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {GreaterEqual, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc} from '../utils/binary_utils';\n\nexport const greaterEqualImpl =\n    createSimpleBinaryKernelImpl((a: number, b: number) => (a >= b) ? 1 : 0);\nexport const greaterEqual = binaryKernelFunc(\n    GreaterEqual, greaterEqualImpl, null /* complexImpl */, 'bool');\n\nexport const greaterEqualConfig: KernelConfig = {\n  kernelName: GreaterEqual,\n  backendName: 'cpu',\n  kernelFunc: greaterEqual\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Less} from '@tensorflow/tfjs-core';\n\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc} from '../utils/binary_utils';\n\nexport const lessImpl =\n    createSimpleBinaryKernelImpl((a: number, b: number) => (a < b) ? 1 : 0);\nexport const less =\n    binaryKernelFunc(Less, lessImpl, null /* complexImpl */, 'bool');\n\nexport const lessConfig: KernelConfig = {\n  kernelName: Less,\n  backendName: 'cpu',\n  kernelFunc: less\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, LessEqual} from '@tensorflow/tfjs-core';\n\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc} from '../utils/binary_utils';\n\nexport const lessEqualImpl =\n    createSimpleBinaryKernelImpl((a: number, b: number) => (a <= b) ? 1 : 0);\nexport const lessEqual =\n    binaryKernelFunc(LessEqual, lessEqualImpl, null /* complexImpl */, 'bool');\n\nexport const lessEqualConfig: KernelConfig = {\n  kernelName: LessEqual,\n  backendName: 'cpu',\n  kernelFunc: lessEqual\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {TypedArray, util} from '@tensorflow/tfjs-core';\n\nexport function linSpaceImpl(\n    start: number, stop: number, num: number): TypedArray {\n  const step = (stop - start) / (num - 1);\n\n  const values = util.makeZerosTypedArray(num, 'float32');\n  values[0] = start;\n  for (let i = 1; i < values.length; i++) {\n    values[i] = values[i - 1] + step;\n  }\n\n  return values;\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Log} from '@tensorflow/tfjs-core';\n\nimport {createSimpleUnaryImpl} from '../utils/unary_impl';\nimport {unaryKernelFuncFromImpl} from '../utils/unary_utils';\n\nexport const logImpl = createSimpleUnaryImpl((xi) => Math.log(xi));\nexport const log = unaryKernelFuncFromImpl(Log, logImpl);\n\nexport const logConfig: KernelConfig = {\n  kernelName: Log,\n  backendName: 'cpu',\n  kernelFunc: log,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DataType, NumericDataType, TypedArray, util} from '@tensorflow/tfjs-core';\n\nexport function maxImpl(\n    aVals: TypedArray, reduceSize: number, outShape: number[],\n    dtype: DataType): TypedArray {\n  const vals = util.getTypedArrayFromDType(\n      dtype as NumericDataType, util.sizeFromShape(outShape));\n\n  for (let i = 0; i < vals.length; ++i) {\n    const offset = i * reduceSize;\n    let max = aVals[offset];\n    for (let j = 0; j < reduceSize; ++j) {\n      const value = aVals[offset + j];\n      if (Number.isNaN(value) ||\n          value > max) {  // comparison with NaN always return false\n        max = value;\n      }\n    }\n    vals[i] = max;\n  }\n  return vals;\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Maximum} from '@tensorflow/tfjs-core';\n\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc} from '../utils/binary_utils';\n\nexport const maximumImpl = createSimpleBinaryKernelImpl(\n    ((aValue, bValue) => Math.max(aValue as number, bValue as number)));\nexport const maximum = binaryKernelFunc(Maximum, maximumImpl);\n\nexport const maximumConfig: KernelConfig = {\n  kernelName: Maximum,\n  backendName: 'cpu',\n  kernelFunc: maximum\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Minimum} from '@tensorflow/tfjs-core';\n\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc} from '../utils/binary_utils';\n\nexport const minimumImpl = createSimpleBinaryKernelImpl(\n    ((aValue, bValue) => Math.min(aValue as number, bValue as number)));\nexport const minimum = binaryKernelFunc(Minimum, minimumImpl);\n\nexport const minimumConfig: KernelConfig = {\n  kernelName: Minimum,\n  backendName: 'cpu',\n  kernelFunc: minimum\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Multiply} from '@tensorflow/tfjs-core';\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc, createComplexBinaryKernelImpl} from '../utils/binary_utils';\n\nexport const multiplyImpl = createSimpleBinaryKernelImpl(\n    ((aValue: number, bValue: number) => aValue * bValue));\nexport const multiplyComplexImpl =\n    createComplexBinaryKernelImpl(((aReal, aImag, bReal, bImag) => {\n      return {\n        real: aReal * bReal - aImag * bImag,\n        imag: aReal * bImag + aImag * bReal\n      };\n    }));\n\nexport const multiply =\n    binaryKernelFunc(Multiply, multiplyImpl, multiplyComplexImpl);\n\nexport const multiplyConfig: KernelConfig = {\n  kernelName: Multiply,\n  backendName: 'cpu',\n  kernelFunc: multiply\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DataType, KernelConfig, KernelFunc, Neg, TensorInfo, TypedArray, UnaryInputs, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\nimport {multiplyImpl} from './Multiply';\n\nexport function negImpl(xVals: TypedArray, xShape: number[], xDtype: DataType):\n    [TypedArray, number[]] {\n  const minusOne =\n      util.createScalarValue(-1 as unknown as 'float32', xDtype) as TypedArray;\n  return multiplyImpl([], xShape, minusOne, xVals, xDtype);\n}\n\nexport function neg(args: {inputs: UnaryInputs, backend: MathBackendCPU}):\n    TensorInfo {\n  const {inputs, backend} = args;\n  const {x} = inputs;\n\n  assertNotComplex(x, 'neg');\n\n  const xVals = backend.data.get(x.dataId).values as TypedArray;\n  const [res, newShape] = negImpl(xVals, x.shape, x.dtype);\n\n  return backend.makeTensorInfo(newShape, x.dtype, res);\n}\n\nexport const negConfig: KernelConfig = {\n  kernelName: Neg,\n  backendName: 'cpu',\n  kernelFunc: neg as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, NotEqual} from '@tensorflow/tfjs-core';\n\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc} from '../utils/binary_utils';\n\nexport const notEqualImpl =\n    createSimpleBinaryKernelImpl(((a, b) => (a !== b) ? 1 : 0));\nexport const notEqual =\n    binaryKernelFunc(NotEqual, notEqualImpl, null /* complexOp */, 'bool');\n\nexport const notEqualConfig: KernelConfig = {\n  kernelName: NotEqual,\n  backendName: 'cpu',\n  kernelFunc: notEqual\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DataType, NumericDataType, TypedArray} from '@tensorflow/tfjs-core';\nimport {util} from '@tensorflow/tfjs-core';\n\nexport function transposeImpl(\n    xVals: TypedArray, xShape: number[], dtype: DataType, perm: number[],\n    newShape: number[]): TypedArray {\n  const xRank = xShape.length;\n  const xSize = util.sizeFromShape(xShape);\n  const xStrides = util.computeStrides(xShape);\n  const newStrides = util.computeStrides(newShape);\n\n  const result = util.getTypedArrayFromDType(\n      dtype as NumericDataType, util.sizeFromShape(newShape));\n\n  for (let i = 0; i < xSize; ++i) {\n    const loc = util.indexToLoc(i, xRank, xStrides);\n\n    // Permute location.\n    const newLoc: number[] = new Array(loc.length);\n    for (let i = 0; i < newLoc.length; i++) {\n      newLoc[i] = loc[perm[i]];\n    }\n\n    const newIndex = util.locToIndex(newLoc, xRank, newStrides);\n    result[newIndex] = xVals[i];\n  }\n  return result;\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, TensorInfo, Transpose, TransposeAttrs, TransposeInputs, TypedArray} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nimport {transposeImpl} from './Transpose_impl';\n\nexport function transpose(args: {\n  inputs: TransposeInputs,\n  attrs: TransposeAttrs,\n  backend: MathBackendCPU\n}): TensorInfo {\n  const {inputs, attrs, backend} = args;\n  const {x} = inputs;\n  const {perm} = attrs;\n\n  assertNotComplex(x, 'transpose');\n\n  const xRank = x.shape.length;\n\n  const newShape: number[] = new Array(xRank);\n  for (let i = 0; i < newShape.length; i++) {\n    newShape[i] = x.shape[perm[i]];\n  }\n\n  const values = backend.data.get(x.dataId).values as TypedArray;\n  const result = transposeImpl(values, x.shape, x.dtype, perm, newShape);\n\n  const dataId = backend.write(result, newShape, x.dtype);\n  return {dataId, shape: newShape, dtype: x.dtype};\n}\n\nexport const transposeConfig: KernelConfig = {\n  kernelName: Transpose,\n  backendName: 'cpu',\n  kernelFunc: transpose as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, DataType, KernelConfig, KernelFunc, Prod, ProdAttrs, ProdInputs, TensorInfo, TypedArray, upcastType, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\nimport {transpose} from './Transpose';\n\nexport function prodImpl(\n    xShape: number[], xDtype: DataType, xVals: TypedArray,\n    reductionAxes: number[]):\n    {outVals: TypedArray, outShape: number[], outDtype: DataType} {\n  const [outShape, reduceShape] =\n      backend_util.computeOutAndReduceShapes(xShape, reductionAxes);\n  const outDtype = upcastType(xDtype, 'int32');\n  const outVals = util.makeZerosTypedArray(\n                      util.sizeFromShape(outShape), outDtype) as TypedArray;\n  const reduceSize = util.sizeFromShape(reduceShape);\n\n  for (let i = 0; i < outVals.length; ++i) {\n    const offset = i * reduceSize;\n    let prod = 1;\n    for (let j = 0; j < reduceSize; ++j) {\n      prod *= xVals[offset + j];\n    }\n    outVals[i] = prod;\n  }\n\n  return {outVals, outShape, outDtype};\n}\n\nexport function prod(\n    args: {inputs: ProdInputs, backend: MathBackendCPU, attrs: ProdAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {axis, keepDims} = attrs;\n\n  assertNotComplex(x, 'prod');\n\n  const xRank = x.shape.length;\n  const axes = util.parseAxisParam(axis, x.shape);\n\n  const permutation = backend_util.getAxesPermutation(axes, xRank);\n  let reductionAxes = axes;\n  let permutedX = x;\n  const intermediateTensorInfos = [];\n  if (permutation != null) {\n    permutedX = transpose({inputs: {x}, backend, attrs: {perm: permutation}});\n    intermediateTensorInfos.push(permutedX);\n    reductionAxes = backend_util.getInnerMostAxes(reductionAxes.length, xRank);\n  }\n\n  const xVals = backend.data.get(permutedX.dataId).values as TypedArray;\n  const {outVals, outShape, outDtype} =\n      prodImpl(permutedX.shape, permutedX.dtype, xVals, reductionAxes);\n\n  let resultShape = outShape;\n  if (keepDims) {\n    resultShape = backend_util.expandShapeToKeepDim(outShape, axes);\n  }\n\n  intermediateTensorInfos.forEach(\n      t => backend.disposeIntermediateTensorInfo(t));\n\n  return backend.makeTensorInfo(resultShape, outDtype, outVals);\n}\n\nexport const prodConfig: KernelConfig = {\n  kernelName: Prod,\n  backendName: 'cpu',\n  kernelFunc: prod as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DataType, TypedArray, util} from '@tensorflow/tfjs-core';\n\nfunction validateIndices(\n    indices: TypedArray, indicesShape: number[], numParams: number) {\n  indices.forEach((index: number, i: number) => {\n    if (index < 0 || index >= numParams) {\n      const locString =\n          util.indexToLoc(\n                  i, indicesShape.length, util.computeStrides(indicesShape))\n              .join(',');\n      throw new Error(\n          `indices[${locString}] = ${index} is not in [0, ${numParams})`);\n    }\n  });\n}\n\nfunction validateSplits(\n    paramsNestedSplits: TypedArray[], numParamsDenseValues: number) {\n  // Validate\n  for (let dim = 0; dim < paramsNestedSplits.length; ++dim) {\n    const splits = paramsNestedSplits[dim];\n    const lastSplit = (dim === paramsNestedSplits.length - 1) ?\n        numParamsDenseValues :\n        paramsNestedSplits[dim + 1].length;\n    if (splits.length === 0) {\n      throw new Error('Ragged splits may not be empty');\n    }\n    if (splits[0] < 0) {\n      throw new Error('Ragged splits must be non-negative');\n    }\n    if (splits[splits.length - 1] > lastSplit) {\n      throw new Error('Ragged splits must not point past values');\n    }\n    for (let i = 1; i < splits.length; ++i) {\n      if (splits[i - 1] > splits[i]) {\n        throw new Error('Ragged splits must be sorted in ascending order');\n      }\n    }\n  }\n}\n\n// Construct the `splits` output tensors, encoded using a nested vector.\n// Also find the slices of values that need to be copied, and store them\n// in `valueSlices`.  The total number of values that will be copied (which\n// we need for allocating the output values tensor) is stored in `numValues`.\nfunction makeSplits(\n    indices: TypedArray, indicesShape: number[],\n    paramsNestedSplits: TypedArray[], numParamsDenseValues: number) {\n  const valueSlices: Array<[number, number]> = [];\n  let numValues = 0;\n\n  const numSplits = indicesShape.length - 1 + paramsNestedSplits.length;\n  const outSplits = new Array(numSplits).fill(null).map(() => [0]);\n\n  validateSplits(paramsNestedSplits, numParamsDenseValues);\n\n  // Add `splits` that come from all but the last dimension of the dense\n  // Tensor `indices`.  In particular, for each dimension D, we add a\n  // splits tensor whose values are:\n  //   range(reduceProd(splits.shape[:D]) + 1) * splits.shape[D+1]\n  // E.g., if indices.shape=[2, 3, 4] then we will add splits tensors:\n  //   [0, 3, 6]                    # length=2+1, stride=3\n  //   [0, 4, 8, 12, 16, 20, 24]    # length=2*3+1, stride=4\n  let nrows = 1;\n  for (let dim = 0; dim < indicesShape.length - 1; ++dim) {\n    nrows *= indicesShape[dim];\n    const rowLength = indicesShape[dim + 1];\n    for (let i = 1; i < nrows + 1; ++i) {\n      outSplits[dim].push(i * rowLength);\n    }\n  }\n\n  // Add `splits` that come from `paramsNestedSplits`.  Starting with the\n  // outermost ragged dimension (i.e., the first `splits` tensor), we work\n  // our way in, finding the range of values that should be copied.  As we\n  // go, we update the output `splits` for each dimension with the appropriate\n  // values.  In particular, the *lengths* of the slices from `param_splits`\n  // should be copied to generate corresponding slice lengths in the output\n  // splits.  E.g., if we are copying a ragged row with length 4, then we\n  // should add a new split point to outSplits that is 4 greater than the\n  // previous split point in outSplits.\n  for (let i = 0; i < indices.length; ++i) {\n    let start = indices[i];\n    let limit = indices[i] + 1;\n\n    // Copy splits.\n    for (let dim = 0; dim < paramsNestedSplits.length; ++dim) {\n      const splits = paramsNestedSplits[dim];\n      const outDim = dim + indicesShape.length - 1;\n      if (outDim >= 0) {\n        const outSplitsOutDim = outSplits[outDim];\n        const delta =\n            outSplitsOutDim[outSplitsOutDim.length - 1] - splits[start];\n        for (let j = start; j < limit; ++j) {\n          outSplits[outDim].push(splits[j + 1] + delta);\n        }\n      }\n      start = splits[start];\n      limit = splits[limit];\n    }\n    if (limit !== start) {\n      valueSlices.push([start, limit]);\n      numValues += limit - start;\n    }\n  }\n\n  return {outSplits, valueSlices, numValues};\n}\n\nfunction getSplits(outSplits: number[][]) {\n  const splitsOut: TypedArray[] = [];\n  for (let i = 0; i < outSplits.length; ++i) {\n    const numSplits = outSplits[i].length;\n    const splits = util.getArrayFromDType('int32', numSplits) as TypedArray;\n    splitsOut.push(splits);\n\n    outSplits[i].forEach((value, j: number) => splits[j] = value);\n  }\n\n  return splitsOut;\n}\n\nfunction computeFlatOuterDims(orig: number[], numOutDims: number) {\n  const outDims = orig.slice(0, numOutDims);\n  while (outDims.length < numOutDims) {\n    outDims.push(1);\n  }\n\n  for (let inDim = numOutDims; inDim < orig.length; inDim++) {\n    outDims[numOutDims - 1] *= orig[inDim];\n  }\n\n  return outDims;\n}\n// For each slice in `(start, limit)` in `valueSlices`, append\n// `paramsDenseValues[start,...,limit] to `values`.  `valueSize` indicates\n// the number of scalars contained in each value paramsDenseValues[i].\nfunction writeValueSlices(\n    paramsDenseValues: TypedArray, paramsDenseValuesShape: number[],\n    valueSlices: Array<[number, number]>, valueSize: number, values: TypedArray,\n    valuesShape: number[]) {\n  const denseM = computeFlatOuterDims(paramsDenseValuesShape, 2)[1];\n  const valuesM = computeFlatOuterDims(valuesShape, 2)[1];\n\n  let outPos = 0;\n  for (const slice of valueSlices) {\n    for (let i = slice[0]; i < slice[1]; ++i) {\n      for (let j = 0; j < valueSize; ++j) {\n        values[outPos * valuesM + j] = paramsDenseValues[i * denseM + j];\n      }\n      ++outPos;\n    }\n  }\n}\n\nfunction getValues(\n    paramsDenseValues: TypedArray, paramsDenseValuesShape: number[],\n    paramsDenseValuesDType: DataType, valueSlices: Array<[number, number]>,\n    numValues: number): [TypedArray, number[]] {\n  const valuesShape = paramsDenseValuesShape.slice();\n  valuesShape[0] = numValues;\n\n  const valuesOut = util.getArrayFromDType(\n                        paramsDenseValuesDType,\n                        util.sizeFromShape(valuesShape)) as TypedArray;\n\n  const numElements = paramsDenseValues.length;\n  const valueSize =\n      numElements === 0 ? 0 : (numElements / paramsDenseValuesShape[0]);\n  writeValueSlices(\n      paramsDenseValues, paramsDenseValuesShape, valueSlices, valueSize,\n      valuesOut, valuesShape);\n\n  return [valuesOut, valuesShape];\n}\nexport function raggedGatherImpl(\n    paramsNestedSplits: TypedArray[], paramsNestedSplitsShapes: number[][],\n    paramsDenseValues: TypedArray, paramsDenseValuesShape: number[],\n    paramsDenseValuesDType: DataType, indices: TypedArray,\n    indicesShape: number[],\n    outputRaggedRank: number): [TypedArray[], TypedArray, number[]] {\n  if (paramsNestedSplits.length === 0) {\n    throw new Error('paramsNestedSplits must be non empty');\n  }\n\n  if (paramsNestedSplitsShapes[0].length === 0) {\n    throw new Error('Split tensors must not be scalars');\n  }\n  const numParams = paramsNestedSplitsShapes[0][0] - 1;\n  validateIndices(indices, indicesShape, numParams);\n\n  if (paramsDenseValuesShape.length === 0) {\n    throw new Error('params.rank must be nonzero');\n  }\n  const numParamsDenseValues = paramsDenseValuesShape[0];\n\n  // Calculate the `splits`, and store the value slices that we need to\n  // copy in `valueSlices`.\n  const {outSplits, valueSlices, numValues} = makeSplits(\n      indices, indicesShape, paramsNestedSplits, numParamsDenseValues);\n\n  // Write the output tensors.\n  const outputNestedSplits = getSplits(outSplits);\n  const outputDenseValues = getValues(\n      paramsDenseValues, paramsDenseValuesShape, paramsDenseValuesDType,\n      valueSlices, numValues);\n\n  return [outputNestedSplits, outputDenseValues[0], outputDenseValues[1]];\n}\n","/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DataType, TypedArray, util} from '@tensorflow/tfjs-core';\n\nconst INT32_MAX = 2147483647;\n\nexport function raggedRangeImpl(\n    starts: TypedArray, startsShape: number[], startsDType: DataType,\n    limits: TypedArray, limitsShape: number[], deltas: TypedArray,\n    deltasShape: number[]): [TypedArray, TypedArray] {\n  // Check input tensor shapes.\n  if (startsShape.length > 1) {\n    throw new Error('starts must be a scalar or vector');\n  }\n  if (limitsShape.length > 1) {\n    throw new Error('limits must be a scalar or vector');\n  }\n  if (deltasShape.length > 1) {\n    throw new Error('deltas must be a scalar or vector');\n  }\n\n  // Determine which tensors we need to broadcast.\n  const broadcastStarts = startsShape.length === 0;\n  const broadcastLimits = limitsShape.length === 0;\n  const broadcastDeltas = deltasShape.length === 0;\n\n  // nRows (number of output rows) is the size of the non-broadcast inputs,\n  // or 1 if all inputs are scalars.\n  const inSizes: number[] = [];\n  if (!broadcastStarts) {\n    inSizes.push(startsShape[0]);\n  }\n  if (!broadcastLimits) {\n    inSizes.push(limitsShape[0]);\n  }\n  if (!broadcastDeltas) {\n    inSizes.push(deltasShape[0]);\n  }\n\n  for (let i = 1; i < inSizes.length; ++i) {\n    if (inSizes[i] !== inSizes[i - 1]) {\n      throw new Error('starts, limits, and deltas must have the same shape');\n    }\n  }\n  const nRows = inSizes.length === 0 ? 1 : inSizes[0];\n\n  // Construct the rtNestedSplits tensor.\n  const rtNestedSplits =\n      util.getArrayFromDType('int32', nRows + 1) as TypedArray;\n  rtNestedSplits[0] = 0;\n  for (let row = 0; row < nRows; ++row) {\n    const start = broadcastStarts ? starts[0] : starts[row];\n    const limit = broadcastLimits ? limits[0] : limits[row];\n    const delta = broadcastDeltas ? deltas[0] : deltas[row];\n    if (delta === 0) {\n      throw new Error('Requires delta != 0');\n    }\n    let size: number;  // The number of elements in the specified range.\n    if (((delta > 0) && (limit < start)) || ((delta < 0) && (limit > start))) {\n      size = 0;\n    } else {\n      size = Math.ceil(Math.abs((limit - start) / delta));\n\n      if (size > INT32_MAX) {\n        throw new Error(`Requires ((limit - start) / delta) <= ${INT32_MAX}`);\n      }\n    }\n    rtNestedSplits[row + 1] = rtNestedSplits[row] + size;\n  }\n\n  const nVals = rtNestedSplits[nRows];\n\n  // Construct the rtDenseValues tensor.\n  const rtDenseValues =\n      util.getArrayFromDType(startsDType, nVals) as TypedArray;\n\n  let valueIndex = 0;\n  for (let row = 0; row < nRows; ++row) {\n    const rowSize = rtNestedSplits[row + 1] - rtNestedSplits[row];\n    let value = broadcastStarts ? starts[0] : starts[row];\n    const delta = broadcastDeltas ? deltas[0] : deltas[row];\n    for (let i = 0; i < rowSize; ++i) {\n      rtDenseValues[valueIndex++] = value;\n      value += delta;\n    }\n  }\n\n  return [rtNestedSplits, rtDenseValues];\n}\n","/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, broadcastTo, DataType, reshape, tidy, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport RowPartitionType = backend_util.RowPartitionType;\n// Based on\n// https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/ragged_tensor_to_tensor_op.cc\nclass RaggedTensorToTensorOp {\n  private readonly rowPartitionTypes: RowPartitionType[];\n  private readonly raggedRank: number;\n  constructor(\n      private shape: TypedArray, private shapeShape: number[],\n      private values: TypedArray, private valuesShape: number[],\n      private valuesDType: DataType, private defaultValue: TypedArray,\n      private defaultValueShape: number[],\n      private readonly rowPartitionValues: TypedArray[],\n      private readonly rowPartitionValuesShapes: number[][],\n      rowPartitionTypeStrings: string[]) {\n    this.rowPartitionTypes =\n        backend_util.getRowPartitionTypesHelper(rowPartitionTypeStrings);\n    this.raggedRank = backend_util.getRaggedRank(this.rowPartitionTypes);\n  }\n\n  private getRowPartitionTypeByDimension(dimension: number) {\n    if (this.rowPartitionTypes[0] === RowPartitionType.FIRST_DIM_SIZE) {\n      return this.rowPartitionTypes[dimension + 1];\n    } else {\n      return this.rowPartitionTypes[dimension];\n    }\n  }\n\n  // Returns the relationship between dimension and dimension + 1.\n  private getRowPartitionTensor(dimension: number) {\n    if (this.rowPartitionTypes[0] === RowPartitionType.FIRST_DIM_SIZE) {\n      return this.rowPartitionValues[dimension + 1];\n    } else {\n      return this.rowPartitionValues[dimension];\n    }\n  }\n\n  private getMaxWidth(dimension: number) {\n    const rowPartitionTensor = this.getRowPartitionTensor(dimension - 1);\n    switch (this.getRowPartitionTypeByDimension(dimension - 1)) {\n      case RowPartitionType.VALUE_ROWIDS:\n        return RaggedTensorToTensorOp.getMaxWidthValueRowID(rowPartitionTensor);\n      case RowPartitionType.ROW_SPLITS:\n        return RaggedTensorToTensorOp.getMaxWidthRowSplit(rowPartitionTensor);\n      default:\n        throw new Error(`Cannot handle partition type ${\n            RowPartitionType[this.getRowPartitionTypeByDimension(\n                dimension - 1)]}`);\n    }\n  }\n\n  static getMaxWidthRowSplit(rowSplit: TypedArray) {\n    const tensorLength = rowSplit.length;\n    if (tensorLength === 0 || tensorLength === 1) {\n      return 0;\n    }\n    let maxWidth = 0;\n    for (let i = 0; i < tensorLength - 1; ++i) {\n      const currentWidth = rowSplit[i + 1] - rowSplit[i];\n      if (currentWidth > maxWidth) {\n        maxWidth = currentWidth;\n      }\n    }\n    return maxWidth;\n  }\n\n  static getMaxWidthValueRowID(valueRowIds: TypedArray) {\n    const indexLength = valueRowIds.length;\n    if (indexLength === 0) {\n      return 0;\n    }\n    let firstEqualIndex = 0;\n    let firstEqualIndexValue = valueRowIds[0];\n    let maxWidth = 0;\n    for (let i = 1; i < indexLength; ++i) {\n      const value = valueRowIds[i];\n      if (value !== firstEqualIndexValue) {\n        firstEqualIndexValue = value;\n        maxWidth = Math.max(i - firstEqualIndex, maxWidth);\n        firstEqualIndex = i;\n      }\n    }\n    return Math.max(indexLength - firstEqualIndex, maxWidth);\n  }\n\n  private tensorShapeFromTensor(\n      t: TypedArray, tShape: number[], isPartial = true) {\n    if (tShape.length === 0) {\n      if (t[0] === -1) {\n        return [];\n      }\n      throw new Error(\n          `The only valid scalar shape tensor is the fully unknown shape specified as -1.`);\n    }\n    // MakePartialShape/MakeShapeHelper.\n    return makeShape(t, isPartial);\n  }\n\n  private calculateOutputSize(firstDim: number) {\n    const valueShape = this.valuesShape;\n    const defaultValueShape = this.defaultValueShape;\n\n    backend_util.validateDefaultValueShape(defaultValueShape, valueShape);\n\n    const shape = this.tensorShapeFromTensor(this.shape, this.shapeShape);\n    const outputShape = backend_util.combineRaggedTensorToTensorShapes(\n        this.raggedRank, shape, valueShape);\n\n    const result = outputShape;\n\n    if (result[0] < 0) {\n      result[0] = firstDim;\n    }\n    for (let i = 1; i <= this.raggedRank; ++i) {\n      if (result[i] < 0) {\n        result[i] = this.getMaxWidth(i);\n      }\n    }\n\n    return result;\n  }\n\n  /**\n   * The outputIndex represents the index in the output tensor\n   * where the first element of a particular dimension would be written.\n   * If it is -1, it indicates that the index is out of scope.\n   * Example, given firstDimension = 10, firstDimensionOutput = 6,\n   * and outputIndexMultiplier = 100:\n   * result = [0 100 200 300 400 500 -1 -1 -1 -1]\n   * If firstDimensionOutput = 11 instead, then:\n   * result = [0 100 200 300 400 500 600 700 800 900]\n   */\n  private calculateFirstParentOutputIndex(\n      firstDimension: number, outputIndexMultiplier: number,\n      firstDimensionOutput: number) {\n    const minDimension = Math.min(firstDimension, firstDimensionOutput);\n    const result: number[] = [];\n    let currentOutputIndex = 0;\n    for (let i = 0; i < minDimension;\n         ++i, currentOutputIndex += outputIndexMultiplier) {\n      result.push(currentOutputIndex);\n    }\n    for (let i = minDimension; i < firstDimension; ++i) {\n      result.push(-1);\n    }\n    util.assert(\n        result.length === firstDimension,\n        () => 'Final length of result must be equal to firstDimension.');\n\n    return result;\n  }\n\n  private calculateOutputIndexRowSplit(\n      rowSplit: TypedArray, parentOutputIndex: number[],\n      outputIndexMultiplier: number, outputSize: number) {\n    const rowSplitSize = rowSplit.length;\n    const result: number[] = [];\n    for (let i = 0; i < rowSplitSize - 1; ++i) {\n      const rowLength = rowSplit[i + 1] - rowSplit[i];\n      let realLength = Math.min(outputSize, rowLength);\n      let parentOutputIndexCurrent = parentOutputIndex[i];\n\n      if (parentOutputIndexCurrent === -1) {\n        realLength = 0;\n      }\n      for (let j = 0; j < realLength; ++j) {\n        result.push(parentOutputIndexCurrent);\n        parentOutputIndexCurrent += outputIndexMultiplier;\n      }\n      for (let j = 0; j < rowLength - realLength; ++j) {\n        result.push(-1);\n      }\n    }\n    if (rowSplitSize > 0 && result.length !== rowSplit[rowSplitSize - 1]) {\n      throw new Error('Invalid row split size.');\n    }\n\n    return result;\n  }\n\n  // Calculate the output index of the first element of a list.\n  // The parentOutputIndex is the same computation for the previous list.\n  // -1 indicates an element or list that is out of range.\n  // The outputIndexMultiplier is the number of output indices one moves\n  // forward for each column.\n  // E.g., given:\n  // valueRowIds:[0 1 2 2 2 3 5 5 6]\n  // parentOutputIndex:[1000 1100 2000 2100 -1 3000 4000]\n  // outputIndexMultiplier: 10\n  // outputSize: 2\n  // You get:\n  // result = [1000 1100 2000 2010 -1 2100 -1 -1 3000]\n  // result[0] = parentOutputIndex[valueRowIds[0]]\n  // result[1] = parentOutputIndex[valueRowIds[1]]\n  // result[2] = parentOutputIndex[valueRowIds[2]]\n  // result[3] = parentOutputIndex[valueRowIds[2] + 10]\n  // result[4] = -1 because it is the third element the size is 2.\n  // result[5] = parentOutputIndex[valueRowIds[3]]\n  // result[6] = -1 because parentOutputIndex[valueRowIds[6]] == -1\n  // result[7] = -1 because parentOutputIndex[valueRowIds[6]] == -1\n  // result[8] = parentOutputIndex[valueRowIds[7]]\n  private calculateOutputIndexValueRowID(\n      valueRowIds: TypedArray, parentOutputIndex: number[],\n      outputIndexMultiplier: number, outputSize: number) {\n    const indexSize = valueRowIds.length;\n    const result: number[] = [];\n    if (indexSize === 0) {\n      return [];\n    }\n\n    let currentOutputColumn = 0;\n    let currentValueRowId = valueRowIds[0];\n\n    if (currentValueRowId >= parentOutputIndex.length) {\n      throw new Error(\n          `Got currentValueRowId=${currentValueRowId}, which is not less than ${\n              parentOutputIndex.length}`);\n    }\n\n    let currentOutputIndex = parentOutputIndex[currentValueRowId];\n    result.push(currentOutputIndex);\n    for (let i = 1; i < indexSize; ++i) {\n      const nextValueRowId = valueRowIds[i];\n      if (nextValueRowId === currentValueRowId) {\n        if (currentOutputIndex >= 0) {\n          ++currentOutputColumn;\n          if (currentOutputColumn < outputSize) {\n            currentOutputIndex += outputIndexMultiplier;\n          } else {\n            currentOutputIndex = -1;\n          }\n        }\n      } else {\n        currentOutputColumn = 0;\n        currentValueRowId = nextValueRowId;\n\n        if (nextValueRowId >= parentOutputIndex.length) {\n          throw new Error(\n              `Got nextValueRowId=${nextValueRowId} which is not less than ${\n                  parentOutputIndex.length}`);\n        }\n\n        currentOutputIndex = parentOutputIndex[nextValueRowId];\n      }\n      result.push(currentOutputIndex);\n    }\n\n    if (result.length !== valueRowIds.length) {\n      throw new Error('Invalid row ids.');\n    }\n\n    return result;\n  }\n\n  private calculateOutputIndex(\n      dimension: number, parentOutputIndex: number[],\n      outputIndexMultiplier: number, outputSize: number) {\n    const rowPartitionTensor = this.getRowPartitionTensor(dimension);\n    const partitionType = this.getRowPartitionTypeByDimension(dimension);\n    switch (partitionType) {\n      case RowPartitionType.VALUE_ROWIDS:\n        return this.calculateOutputIndexValueRowID(\n            rowPartitionTensor, parentOutputIndex, outputIndexMultiplier,\n            outputSize);\n      case RowPartitionType.ROW_SPLITS:\n        if (rowPartitionTensor.length - 1 > parentOutputIndex.length) {\n          throw new Error(`Row partition size is greater than output size: ${\n              rowPartitionTensor.length - 1} > ${parentOutputIndex.length}`);\n        }\n        return this.calculateOutputIndexRowSplit(\n            rowPartitionTensor, parentOutputIndex, outputIndexMultiplier,\n            outputSize);\n      default:\n        throw new Error(\n            `Unsupported partition type: ${RowPartitionType[partitionType]}`);\n    }\n  }\n\n  private getFirstDimensionSize() {\n    const firstPartitionTensor = this.rowPartitionValues[0];\n    if (this.rowPartitionTypes.length === 0) {\n      throw new Error('No row_partition_types given.');\n    }\n    const firstPartitionType = this.rowPartitionTypes[0];\n    switch (firstPartitionType) {\n      case RowPartitionType.FIRST_DIM_SIZE:\n        return firstPartitionTensor[0];\n      case RowPartitionType.VALUE_ROWIDS:\n        throw new Error('Cannot handle VALUE_ROWIDS in first dimension.');\n      case RowPartitionType.ROW_SPLITS:\n        return this.rowPartitionValuesShapes[0][0] - 1;\n      default:\n        throw new Error(\n            `Cannot handle type ${RowPartitionType[firstPartitionType]}`);\n    }\n  }\n\n  compute(): [number[], TypedArray] {\n    const firstPartitionTensor = this.rowPartitionValues[0];\n    if (firstPartitionTensor.length <= 0) {\n      throw new Error(\n          'Invalid first partition input. ' +\n          'Tensor requires at least one element.');\n    }\n    const firstDimension = this.getFirstDimensionSize();\n    const outputSize = this.calculateOutputSize(firstDimension);\n    const multiplier: number[] = new Array(this.raggedRank + 1);\n\n    multiplier[multiplier.length - 1] = 1;\n    for (let i = multiplier.length - 2; i >= 0; --i) {\n      multiplier[i] = multiplier[i + 1] * outputSize[i + 1];\n    }\n    // Full size of the tensor.\n    const outputShape: number[] = makeShape(outputSize, false);\n    const outputTensor =\n        util.getArrayFromDType(\n            this.valuesDType, util.sizeFromShape(outputShape)) as TypedArray;\n\n    const fullSize = multiplier[0] * outputSize[0];\n    if (fullSize > 0) {\n      let outputIndex = this.calculateFirstParentOutputIndex(\n          firstDimension, multiplier[0], outputSize[0]);\n      for (let i = 1; i <= this.raggedRank; ++i) {\n        const newOutputIndex = this.calculateOutputIndex(\n            i - 1, outputIndex, multiplier[i], outputSize[i]);\n        outputIndex = newOutputIndex;\n      }\n\n      this.setOutput(this.raggedRank, outputIndex, outputTensor, outputShape);\n    }\n\n    return [outputShape, outputTensor];\n  }\n  setOutput(\n      raggedRank: number, outputIndex: number[], outputTensor: TypedArray,\n      outputShape: number[]) {\n    if (outputTensor.length === 0) {\n      return;\n    }\n\n    const valuesBase = this.values;\n    const outputBase = outputTensor;\n\n    let elementShape = outputShape.slice();\n    elementShape = elementShape.slice(raggedRank + 1);\n    const valueElementSize = util.sizeFromShape(elementShape);\n    const outputIndexSize = outputIndex.length;\n\n    // Broadcast the default value to value_element_size.  (We can skip this\n    // if defaultValueTensor.size == 1, since we use fill when that's true.)\n    let defaultValue = this.defaultValue;\n    if (defaultValue.length !== valueElementSize && defaultValue.length !== 1) {\n      const srcShape = this.defaultValueShape;\n      tidy(() => {\n        const defaultValueTensor = reshape(defaultValue, srcShape);\n        const bCastDefault = broadcastTo(defaultValueTensor, elementShape);\n        defaultValue = bCastDefault.dataSync();\n      });\n    }\n\n    // Loop through the outputIndex array, finding contiguous regions that\n    // should be copied.  Once we find the end of a contiguous region, copy it\n    // and add any necessary padding (with defaultValue).\n    let srcStart = 0;  // Start of contiguous region (in values)\n    let dstStart = 0;  // Destination for contiguous region (in output)\n    let dstEnd = 0;    // Destination for contiguous region (in output)\n    for (let srcI = 0; srcI <= outputIndexSize; ++srcI) {\n      // dstI is the destination where the value at srcI should be copied.\n      let dstI = srcI < outputIndexSize ? outputIndex[srcI] : -1;\n\n      // If we're still in a contiguous region, then update dstEnd go to the\n      // next srcI.\n      if (dstI === dstEnd) {\n        ++dstEnd;\n        continue;\n      }\n\n      // We found the end of contiguous region.  This can be because we found\n      // a gap (dstI > dstEnd), or a source value that shouldn't be copied\n      // because it's out-of-bounds (dstI == -1), or the end of the tensor\n      // (dstI === -1).\n      if (dstStart < dstEnd) {\n        // Copy the contiguous region.\n        const src = valuesBase.subarray(srcStart * valueElementSize);\n        const dst = outputBase.subarray(dstStart * valueElementSize);\n        const nVals = (dstEnd - dstStart) * valueElementSize;\n        copyArray(dst, src, nVals);\n      }\n\n      // Add any necessary padding (w/ defaultValue).\n      if (srcI >= outputIndexSize) {\n        // We reached the end of values: pad to the end of output.\n        const outputSize = outputTensor.length;\n        dstI = Math.floor(outputSize / valueElementSize);\n      }\n      if (dstI > dstEnd) {\n        if (this.defaultValue.length === 1) {\n          outputBase\n              .subarray(dstEnd * valueElementSize, dstI * valueElementSize)\n              .fill(this.defaultValue[0]);\n          dstEnd = dstI;\n        } else {\n          while (dstI > dstEnd) {\n            const dst = outputBase.slice(dstEnd * valueElementSize);\n            copyArray(dst, defaultValue, valueElementSize);\n            ++dstEnd;\n          }\n        }\n      }\n\n      // Update indices.\n      if (dstI < 0) {\n        // srcI should be skipped -- leave it out of the contiguous region.\n        srcStart = srcI + 1;\n        dstStart = dstEnd;\n      } else {\n        // srcI should be copied -- include it in the contiguous region.\n        srcStart = srcI;\n        dstStart = dstEnd;\n        dstEnd = dstStart + 1;\n      }\n    }\n  }\n}\n\nfunction copyArray(dst: TypedArray, src: TypedArray, size: number) {\n  for (let i = 0; i < size; i++) {\n    dst[i] = src[i];\n  }\n}\n\nfunction makeShape(shape: number[]|TypedArray, isPartial: boolean) {\n  const out: number[] = [];\n  for (let dim of shape) {\n    if (dim < 0) {\n      if (!isPartial) {\n        throw new Error(`Dimension ${dim} must be >= 0`);\n      }\n      if (dim < -1) {\n        throw new Error(`Dimension ${dim} must be >= -1`);\n      }\n      dim = -1;\n    }\n    out.push(dim);\n  }\n\n  return out;\n}\n\nexport function raggedTensorToTensorImpl(\n    shape: TypedArray, shapesShape: number[], values: TypedArray,\n    valuesShape: number[], valuesDType: DataType, defaultValue: TypedArray,\n    defaultValueShape: number[], rowPartitionValues: TypedArray[],\n    rowPartitionValuesShapes: number[][],\n    rowPartitionTypes: string[]): [number[], TypedArray] {\n  return new RaggedTensorToTensorOp(\n             shape, shapesShape, values, valuesShape, valuesDType, defaultValue,\n             defaultValueShape, rowPartitionValues, rowPartitionValuesShapes,\n             rowPartitionTypes)\n      .compute();\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DataTypeMap, util} from '@tensorflow/tfjs-core';\n\nexport function rangeImpl(\n    start: number, stop: number, step: number,\n    dtype: 'float32'|'int32'): DataTypeMap['float32' | 'int32'] {\n  const sameStartStop = start === stop;\n  const increasingRangeNegativeStep = start < stop && step < 0;\n  const decreasingRangePositiveStep = stop < start && step > 1;\n\n  if (sameStartStop || increasingRangeNegativeStep ||\n      decreasingRangePositiveStep) {\n    return util.makeZerosTypedArray(0, dtype);\n  }\n\n  const numElements = Math.abs(Math.ceil((stop - start) / step));\n  const values = util.makeZerosTypedArray(numElements, dtype);\n\n  if (stop < start && step === 1) {\n    // Auto adjust the step's sign if it hasn't been set\n    // (or was set to 1)\n    step = -1;\n  }\n\n  values[0] = start;\n  for (let i = 1; i < values.length; i++) {\n    values[i] = values[i - 1] + step;\n  }\n  return values;\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Rsqrt} from '@tensorflow/tfjs-core';\n\nimport {createSimpleUnaryImpl} from '../utils/unary_impl';\nimport {unaryKernelFuncFromImpl} from '../utils/unary_utils';\n\nexport const rsqrtImpl = createSimpleUnaryImpl((xi) => 1 / Math.sqrt(xi));\nexport const rsqrt = unaryKernelFuncFromImpl(Rsqrt, rsqrtImpl);\n\nexport const rsqrtConfig: KernelConfig = {\n  kernelName: Rsqrt,\n  backendName: 'cpu',\n  kernelFunc: rsqrt,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {buffer, Rank, ShapeMap, TensorBuffer, TypedArray} from '@tensorflow/tfjs-core';\n\ninterface DefaultValueTypeMap {\n  bool: boolean;\n  int32: number;\n  float32: number;\n  string: string;\n}\n\nexport function\nscatterImpl<R extends Rank, D extends 'float32'|'int32'|'bool'|'string'>(\n    indices: TensorBuffer<R, 'int32'>, updates: TensorBuffer<R, D>,\n    shape: number[], outputSize: number, sliceSize: number, numUpdates: number,\n    sliceRank: number, strides: number[],\n    defaultValue: TensorBuffer<R, D>|DefaultValueTypeMap[D],\n    sumDupeIndices: boolean): TensorBuffer<R, D> {\n  const flattenShape = [outputSize / sliceSize, sliceSize];\n\n  const indicesData = indices.values as TypedArray;\n  const updatesData = updates.values;\n\n  if (outputSize === 0) {\n    return buffer(shape as ShapeMap[R], updates.dtype);\n  }\n\n  const outBuf = (defaultValue instanceof TensorBuffer) ?\n      defaultValue :\n      buffer(flattenShape, updates.dtype);\n  if (typeof defaultValue === 'string') {\n    (outBuf.values as string[]).fill(defaultValue);\n  } else if (typeof defaultValue === 'number') {\n    (outBuf.values as TypedArray).fill(defaultValue);\n  } else if (typeof defaultValue === 'boolean') {\n    (outBuf.values as TypedArray).fill(+defaultValue);\n  }\n\n  for (let i = 0; i < numUpdates; i++) {\n    const index = [];\n    let flattenIndex = 0;\n    for (let j = 0; j < sliceRank; j++) {\n      const dim = indicesData[i * sliceRank + j];\n      index.push(dim);\n      flattenIndex += dim * strides[j];\n    }\n\n    if (flattenIndex < 0 || flattenIndex >= outputSize / sliceSize) {\n      throw new Error(`Invalid indices: ${index} does not index into ${shape}`);\n    }\n\n    for (let k = 0; k < sliceSize; k++) {\n      if (sumDupeIndices) {\n        (outBuf.values as TypedArray)[flattenIndex * sliceSize + k] +=\n            (updatesData as TypedArray)[i * sliceSize + k];\n      } else {\n        outBuf.values[flattenIndex * sliceSize + k] = updates.rank === 0 ?\n            updatesData[0] :\n            updatesData[i * sliceSize + k];\n      }\n    }\n  }\n\n  return outBuf as TensorBuffer<R, D>;\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Sigmoid} from '@tensorflow/tfjs-core';\n\nimport {createSimpleUnaryImpl} from '../utils/unary_impl';\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const sigmoidImpl =\n    createSimpleUnaryImpl((xi) => 1 / (1 + Math.exp(-xi)));\nexport const sigmoid =\n    unaryKernelFunc(Sigmoid, (xi) => 1 / (1 + Math.exp(-xi)));\n\nexport const sigmoidConfig: KernelConfig = {\n  kernelName: Sigmoid,\n  backendName: 'cpu',\n  kernelFunc: sigmoid,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, BackendValues, buffer, DataType, KernelConfig, KernelFunc, Slice, slice_util, SliceAttrs, SliceInputs, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function sliceImpl(\n    vals: BackendValues, begin: number[], size: number[], shape: number[],\n    dtype: DataType): BackendValues {\n  const isContinous = slice_util.isSliceContinous(shape, begin, size);\n  const length = util.sizeFromShape(size);\n  const xStrides = util.computeStrides(shape);\n\n  if (isContinous) {\n    const flatOffset = slice_util.computeFlatOffset(begin, xStrides);\n\n    if (dtype === 'string') {\n      return (vals as Uint8Array[]).slice(flatOffset, flatOffset + length);\n    }\n\n    return (vals as TypedArray).subarray(flatOffset, flatOffset + length);\n  }\n\n  const decodedData = dtype === 'string' ?\n      backend_util.fromUint8ToStringArray(vals as Uint8Array[]) :\n      vals as TypedArray;\n\n  const inBuf = buffer(shape, dtype, decodedData);\n  const outBuf = buffer(size, dtype);\n  for (let i = 0; i < outBuf.size; ++i) {\n    const outLoc = outBuf.indexToLoc(i);\n    const inLoc = outLoc.map((idx: number, j) => idx + begin[j]);\n    outBuf.set(inBuf.get(...inLoc), ...outLoc);\n  }\n\n  if (dtype === 'string') {\n    return backend_util.fromStringArrayToUint8(outBuf.values as string[]);\n  }\n  return outBuf.values as TypedArray;\n}\n\nexport function slice(\n    args: {inputs: SliceInputs, backend: MathBackendCPU, attrs: SliceAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {begin, size} = attrs;\n\n  assertNotComplex(x, 'slice');\n\n  const [$begin, $size] = slice_util.parseSliceParams(x, begin, size);\n  slice_util.assertParamsValid(x, $begin, $size);\n\n  const vals = backend.data.get(x.dataId).values;\n  const outVals = sliceImpl(vals, $begin, $size, x.shape, x.dtype);\n  return backend.makeTensorInfo($size, x.dtype, outVals);\n}\n\nexport const sliceConfig: KernelConfig = {\n  kernelName: Slice,\n  backendName: 'cpu',\n  kernelFunc: slice as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, DataType, TypedArray, util} from '@tensorflow/tfjs-core';\n\nexport function sparseFillEmptyRowsImpl(\n    indices: TypedArray, indicesShape: number[], indicesDType: DataType,\n    values: TypedArray, valuesDType: DataType, denseShape: TypedArray,\n    defaultValue: number):\n    [TypedArray, number[], TypedArray, boolean[], number[]] {\n  const indicesCount = indicesShape[0];\n  const denseRows = denseShape[0];\n\n  const emptyRowIndicator: boolean[] = new Array(denseRows);\n  const reverseIndexMap: number[] = new Array(indicesCount);\n\n  const rank = indicesShape[1];\n\n  if (denseRows === 0) {\n    if (indicesCount !== 0) {\n      throw new Error(\n          backend_util.getSparseFillEmptyRowsIndicesDenseShapeMismatch(\n              indicesCount));\n    }\n    const outputIndices = util.getArrayFromDType(indicesDType, 0) as TypedArray;\n    const outputValues = util.getArrayFromDType(valuesDType, 0) as TypedArray;\n    return [\n      outputIndices, [0, rank], outputValues, emptyRowIndicator, reverseIndexMap\n    ];\n  }\n\n  let rowsAreOrdered = true;\n  let lastIndicesRow = 0;\n  const csrOffset: number[] = new Array(denseRows).fill(0);\n\n  for (let i = 0; i < indicesCount; ++i) {\n    // indices is a 2d tensor with shape of [N, rank]\n    const row = indices[i * rank];\n    if (row < 0) {\n      throw new Error(\n          backend_util.getSparseFillEmptyRowsNegativeIndexErrorMessage(i, row));\n    }\n    if (row >= denseRows) {\n      throw new Error(\n          backend_util.getSparseFillEmptyRowsOutOfRangeIndexErrorMessage(\n              i, row, denseRows));\n    }\n    ++csrOffset[row];\n    rowsAreOrdered = rowsAreOrdered && (row >= lastIndicesRow);\n    lastIndicesRow = row;\n  }\n\n  let allRowsFull = true;\n  for (let row = 0; row < denseRows; ++row) {\n    // csrOffset here describes the number of elements in this dense row\n    const rowEmpty = (csrOffset[row] === 0);\n    emptyRowIndicator[row] = rowEmpty;\n    allRowsFull = allRowsFull && !rowEmpty;\n    // In filled version, each row has at least one element.\n    csrOffset[row] = Math.max(csrOffset[row], 1);\n    // Update csrOffset to represent the number of elements up to and\n    // including denseRows + 1:\n    //  csrOffset[0] == #{elements of row 0}\n    //  csrOffset[1] == #{elements of row 1} + #{elements of row 0}\n    //  ..\n    //  csrOffset[i] == starting index for elements in row i + 1.\n    if (row > 0) {\n      csrOffset[row] += csrOffset[row - 1];\n    }\n  }\n\n  if (allRowsFull && rowsAreOrdered) {\n    const outputIndices: TypedArray = indices;\n    const outputValues: TypedArray = values;\n    for (let i = 0; i < indicesCount; ++i) {\n      reverseIndexMap[i] = i;\n    }\n    return [\n      outputIndices, [indicesCount, rank], outputValues, emptyRowIndicator,\n      reverseIndexMap\n    ];\n  } else {\n    const fullIndicesCount = csrOffset[denseRows - 1];\n    const outputIndices =\n        util.getArrayFromDType(indicesDType, fullIndicesCount * rank) as\n        TypedArray;\n    const outputValues =\n        util.getArrayFromDType(valuesDType, fullIndicesCount) as TypedArray;\n    const filledCount: number[] = new Array(denseRows).fill(0);\n\n    // Fill in values for rows that are not missing\n    for (let i = 0; i < indicesCount; ++i) {\n      // indices is a 2d tensor with shape of [N, rank]\n      const row = indices[i * rank];\n      const offset = filledCount[row];\n      const outputI = ((row === 0) ? 0 : csrOffset[row - 1]) + offset;\n      filledCount[row]++;  // Increment the filled count for this row.\n      for (let j = 0; j < rank; ++j) {\n        // indices and outputIndices are 2d tensors with shape of [N, rank]\n        outputIndices[outputI * rank + j] = indices[i * rank + j];\n      }\n      outputValues[outputI] = values[i];\n      // We'll need this reverse index map to backprop correctly.\n      reverseIndexMap[i] = outputI;\n    }\n\n    // Fill in values for rows that are missing\n    for (let row = 0; row < denseRows; ++row) {\n      const rowCount = filledCount[row];\n      if (rowCount === 0) {  // We haven't filled this row\n        const startingIndex = (row === 0) ? 0 : csrOffset[row - 1];\n        // Remaining index values were set to zero already.\n        // Just need to set the row index in the right location.\n        // outputIndices is a 2d tensor with shape of [N, rank]\n        outputIndices[startingIndex * rank + 0] = row;\n        for (let col = 1; col < rank; ++col) {\n          outputIndices[startingIndex * rank + col] = 0;\n        }\n        outputValues[startingIndex] = defaultValue;\n      }\n    }\n    return [\n      outputIndices, [fullIndicesCount, rank], outputValues, emptyRowIndicator,\n      reverseIndexMap\n    ];\n  }\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, DataType, TypedArray, util} from '@tensorflow/tfjs-core';\n\nexport function sparseReshapeImpl(\n    inputIndices: TypedArray, inputIndicesShape: number[], inputDType: DataType,\n    inputShape: number[],\n    targetShape: number[]): [TypedArray, number[], number[]] {\n  const denseSize = util.sizeFromShape(inputShape);\n  const nnz = inputIndicesShape[0];\n  const outputRank = targetShape.length;\n\n  // Compute the output shape. Determine product of specified dimensions, and\n  // find the index of the unspecified one.\n  const outputShape: number[] = [];\n  let product = 1;\n  let unknownIndex = -1;\n  for (let d = 0; d < outputRank; ++d) {\n    const size = targetShape[d];\n    if (size === -1) {\n      if (unknownIndex !== -1) {\n        throw new Error(\n            backend_util\n                .getSparseReshapeMultipleNegativeOneOutputDimErrorMessage(\n                    unknownIndex, d));\n      }\n      unknownIndex = d;\n      outputShape.push(1);\n    } else {\n      if (size < 0) {\n        throw new Error(\n            backend_util.getSparseReshapeNegativeOutputDimErrorMessage(\n                d, size));\n      }\n      product *= size;\n      outputShape.push(size);\n    }\n  }\n  if (unknownIndex !== -1) {\n    if (product <= 0) {\n      throw new Error(\n          backend_util.getSparseReshapeEmptyTensorZeroOutputDimErrorMessage());\n    }\n    const missing = Math.trunc(denseSize / product);\n    if (product * missing !== denseSize) {\n      throw new Error(\n          backend_util.getSparseReshapeInputOutputMultipleErrorMessage(\n              inputShape, outputShape));\n    }\n\n    outputShape[unknownIndex] = missing;\n  }\n  const outputSize = util.sizeFromShape(outputShape);\n  if (outputSize !== denseSize) {\n    throw new Error(\n        backend_util.getSparseReshapeInputOutputMismatchErrorMessage(\n            inputShape, outputShape));\n  }\n\n  const inputRank = inputShape.length;\n  const inputStrides: number[] = [];\n  if (inputRank > 0) {\n    inputStrides[inputRank - 1] = 1;\n    for (let d = inputRank - 2; d >= 0; --d) {\n      inputStrides[d] = inputStrides[d + 1] * inputShape[d + 1];\n    }\n  }\n\n  const outputStrides: number[] = [];\n  if (outputRank > 0) {\n    outputStrides[outputRank - 1] = 1;\n    for (let d = outputRank - 2; d >= 0; --d) {\n      outputStrides[d] = outputStrides[d + 1] * outputShape[d + 1];\n    }\n  }\n\n  const newIndices =\n      util.getArrayFromDType(inputDType, nnz * outputRank) as TypedArray;\n  for (let i = 0; i < nnz; ++i) {\n    let id = 0;\n    for (let j = 0; j < inputRank; ++j) {\n      // inputIndices is a 2d tensor with shape of [nnz, inputRank]\n      id += inputIndices[i * inputRank + j] * inputStrides[j];\n    }\n    for (let j = 0; j < outputRank; ++j) {\n      // newIndices is a 2d tensor with shape of [nnz, outputRank]\n      newIndices[i * outputRank + j] = Math.trunc(id / outputStrides[j]);\n      id %= outputStrides[j];\n    }\n  }\n  return [newIndices, [nnz, outputRank], outputShape];\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, DataType, TypedArray, util} from '@tensorflow/tfjs-core';\n\nexport function sparseSegmentReductionImpl(\n    input: TypedArray, inputShape: number[], inputDType: DataType,\n    indices: TypedArray, segmentIds: TypedArray, isMean = false,\n    defaultValue = 0): [TypedArray, number[]] {\n  const numIndices = indices.length;\n\n  // Flatten the array to two dimensions\n  const inputFlat: number[] = [inputShape[0], input.length / inputShape[0]];\n  const numCol = inputFlat[1];\n  // Note that the current implementation assumes that segmentIds values are\n  // sorted.\n  const lastSegmentIdPlusOne =\n      numIndices > 0 ? segmentIds[numIndices - 1] + 1 : 0;\n  const outputRows = lastSegmentIdPlusOne;\n\n  if (outputRows < 0) {\n    throw new Error(\n        backend_util.getSparseSegmentReductionNegativeSegmentIdsErrorMessage());\n  }\n\n  const outputShape = inputShape.slice();\n  outputShape[0] = outputRows;\n\n  const outputLength =\n      outputShape.reduce((product, value) => product * value, 1);\n  // Output array is initialized with the value 0 by default.\n  const output = util.getArrayFromDType(inputDType, outputLength) as TypedArray;\n\n  // Note that we do not initialize the output buffer with a default value, so\n  // we need to explicitly set missing indices to the default value.\n  if (numIndices === 0) {\n    if (outputRows > 0) {\n      output.fill(defaultValue);\n    }\n    return [output, outputShape];\n  }\n\n  if (outputRows <= 0) {\n    throw new Error(\n        backend_util.getSparseSegmentReductionNegativeSegmentIdsErrorMessage());\n  }\n\n  let start = 0, end = 1;\n  // Index from which the output is not initialized.\n  let uninitializedIndex = 0;\n  let outIndex = segmentIds[start];\n\n  while (true) {\n    // We initialize nextIndex to 0 to avoid may be uninitialized warning\n    let nextIndex = 0;\n    if (end < numIndices) {\n      nextIndex = segmentIds[end];\n      if (outIndex === nextIndex) {\n        ++end;\n        continue;\n      }\n      // We have a new segment here.  Verify that the segment ids are growing.\n      if (outIndex >= nextIndex) {\n        throw new Error(backend_util\n            .getSparseSegmentReductionNonIncreasingSegmentIdsErrorMessage());\n      }\n    }\n\n    if (outIndex < 0 || outIndex >= outputRows) {\n      throw new Error(\n          backend_util.getSparseSegmentReductionSegmentIdOutOfRangeErrorMessage(\n              outIndex, outputRows));\n    }\n\n    // If there is a gap between two indices, we need to set that gap to the\n    // default value.\n    if (outIndex > uninitializedIndex) {\n      output.fill(defaultValue, uninitializedIndex * numCol, outIndex * numCol);\n    }\n\n    for (let i = start; i < end; ++i) {\n      const index = indices[i];\n      if (index < 0 || index >= inputFlat[0]) {\n        throw new Error(\n            backend_util.getSparseSegmentReductionIndicesOutOfRangeErrorMessage(\n                i, indices[i], inputFlat[0]));\n      }\n      for (let j = 0; j < numCol; j++) {\n        output[outIndex * numCol + j] += input[index * numCol + j];\n      }\n    }\n\n    if (isMean) {\n      for (let j = 0; j < numCol; j++) {\n        output[outIndex * numCol + j] /= end - start;\n      }\n    }\n\n    start = end;\n    ++end;\n    uninitializedIndex = outIndex + 1;\n    outIndex = nextIndex;\n    if (end > numIndices) {\n      break;\n    }\n  }\n\n  // Fill the gap at the end with the default value.\n  if (uninitializedIndex < outputRows) {\n    output.fill(defaultValue, uninitializedIndex * numCol, outputRows * numCol);\n  }\n\n  return [output, outputShape];\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Sqrt} from '@tensorflow/tfjs-core';\n\nimport {createSimpleUnaryImpl} from '../utils/unary_impl';\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const sqrtImpl = createSimpleUnaryImpl((xi) => Math.sqrt(xi));\nexport const sqrt = unaryKernelFunc(Sqrt, (xi) => Math.sqrt(xi));\n\nexport const sqrtConfig: KernelConfig = {\n  kernelName: Sqrt,\n  backendName: 'cpu',\n  kernelFunc: sqrt,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, SquaredDifference} from '@tensorflow/tfjs-core';\n\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc} from '../utils/binary_utils';\n\nexport const squaredDifferenceImpl =\n    createSimpleBinaryKernelImpl(((a: number, b: number) => {\n      const diff = a - b;\n      return diff * diff;\n    }));\nexport const squaredDifference =\n    binaryKernelFunc(SquaredDifference, squaredDifferenceImpl);\n\nexport const squaredDifferenceConfig: KernelConfig = {\n  kernelName: SquaredDifference,\n  backendName: 'cpu',\n  kernelFunc: squaredDifference\n};\n","/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, StaticRegexReplace, StaticRegexReplaceAttrs} from '@tensorflow/tfjs-core';\nimport {createSimpleUnaryImpl} from '../utils/unary_impl';\nimport {unaryKernelFuncFromImpl} from '../utils/unary_utils';\n\nexport const staticRegexReplaceImpl = createSimpleUnaryImpl<string,\n  string>((x: string, attrs) => {\n    const {pattern, replaceGlobal, rewrite} =\n      attrs as unknown as StaticRegexReplaceAttrs;\n    // TODO(mattSoulanille): Don't create a regex each time.\n    return x.replace(new RegExp(pattern, replaceGlobal ? 'g' : ''), rewrite);\n});\n\nconst staticRegexReplace =\n  unaryKernelFuncFromImpl(StaticRegexReplace, staticRegexReplaceImpl);\n\nexport const staticRegexReplaceConfig: KernelConfig = {\n  kernelName: StaticRegexReplace,\n  backendName: 'cpu',\n  kernelFunc: staticRegexReplace,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {buffer, Rank, TensorBuffer} from '@tensorflow/tfjs-core';\n\nexport function stridedSliceImpl<R extends Rank>(\n    outShape: number[], xBuf: TensorBuffer<R>, strides: number[],\n    begin: number[]): TensorBuffer<R> {\n  const outBuf = buffer(outShape, xBuf.dtype);\n\n  for (let i = 0; i < outBuf.size; i++) {\n    const loc = outBuf.indexToLoc(i);\n\n    const newLoc: number[] = new Array(loc.length);\n    for (let j = 0; j < newLoc.length; j++) {\n      newLoc[j] = loc[j] * strides[j] + begin[j];\n    }\n    outBuf.set(xBuf.get(...newLoc), ...loc);\n  }\n\n  return outBuf as TensorBuffer<R>;\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {util} from '@tensorflow/tfjs-core';\n\n/**\n * The StringNGramsOp class creates ngrams from ragged string data.\n * The constructor contains all attributes related to the operation such as\n * padding widths and strings, and the compute function can be used to\n * compute the ngrams for different ragged tensor inputs.\n */\nclass StringNGramsOp {\n  private separator: Uint8Array;\n  private nGramWidths: number[];\n  private padWidth: number;\n  private leftPad: Uint8Array;\n  private rightPad: Uint8Array;\n  private preserveShort: boolean;\n\n  constructor(\n      separator: string, nGramWidths: number[], leftPad: string,\n      rightPad: string, padWidth: number, preserveShortSequences: boolean) {\n    this.separator = util.encodeString(separator);\n    this.nGramWidths = nGramWidths;\n    this.leftPad = util.encodeString(leftPad);\n    this.rightPad = util.encodeString(rightPad);\n    this.padWidth = padWidth;\n    this.preserveShort = preserveShortSequences;\n  }\n\n  private getPadWidth(nGramWidth: number) {\n    // Ngrams can be padded with either a fixed pad width or a dynamic pad\n    // width depending on the 'padWidth' arg, but in no case should the padding\n    // ever be wider than 'nGramWidth' - 1.\n    return Math.min(\n        this.padWidth < 0 ? nGramWidth - 1 : this.padWidth, nGramWidth - 1);\n  }\n\n  private getNumNGrams(length: number, nGramWidth: number) {\n    const padWidth = this.getPadWidth(nGramWidth);\n    return Math.max(0, ((length + 2 * padWidth) - nGramWidth) + 1);\n  }\n\n  private createNGrams(\n      data: Uint8Array[], splitIndex: number, output: Uint8Array[],\n      outputStartIndex: number, numNGrams: number, nGramWidth: number) {\n    for (let nGramIndex = 0; nGramIndex < numNGrams; ++nGramIndex) {\n      const padWidth = this.getPadWidth(nGramWidth);\n      const leftPadding = Math.max(0, padWidth - nGramIndex);\n      const rightPadding =\n          Math.max(0, padWidth - (numNGrams - (nGramIndex + 1)));\n      const numTokens = nGramWidth - (leftPadding + rightPadding);\n      const dataStartIndex =\n          splitIndex + (leftPadding > 0 ? 0 : nGramIndex - padWidth);\n\n      // Calculate the total expected size of the nGram so we can reserve the\n      // correct amount of space in the string.\n      let nGramSize = 0;\n      // Size of the left padding.\n      nGramSize += leftPadding * this.leftPad.length;\n      // Size of the tokens.\n      for (let n = 0; n < numTokens; ++n) {\n        nGramSize += data[dataStartIndex + n].length;\n      }\n      // Size of the right padding.\n      nGramSize += rightPadding * this.rightPad.length;\n      // Size of the separators.\n      const numSeparators = leftPadding + rightPadding + numTokens - 1;\n      nGramSize += numSeparators * this.separator.length;\n\n      // Build the nGram.\n      output[outputStartIndex + nGramIndex] = new Uint8Array(nGramSize);\n      const nGram = output[outputStartIndex + nGramIndex];\n\n      let nextNGramIndex = 0;\n      const appendToNGram = (str: Uint8Array) =>\n          str.forEach((value) => nGram[nextNGramIndex++] = value);\n\n      for (let n = 0; n < leftPadding; ++n) {\n        appendToNGram(this.leftPad);\n        appendToNGram(this.separator);\n      }\n      // Only output first numTokens - 1 pairs of data and separator\n      for (let n = 0; n < numTokens - 1; ++n) {\n        appendToNGram(data[dataStartIndex + n]);\n        appendToNGram(this.separator);\n      }\n      // Handle case when there are no tokens or no right padding as these\n      // can result in consecutive separators.\n      if (numTokens > 0) {\n        // If we have tokens, then output last and then pair each separator\n        // with the right padding that follows, to ensure nGram ends either with\n        // the token or with the right pad.\n        appendToNGram(data[dataStartIndex + numTokens - 1]);\n        for (let n = 0; n < rightPadding; ++n) {\n          appendToNGram(this.separator);\n          appendToNGram(this.rightPad);\n        }\n      } else {\n        // If we don't have tokens, then the last item inserted into the nGram\n        // has been the separator from the left padding loop above. Hence,\n        // output right pad and separator and make sure to finish with a\n        // padding, not a separator.\n        for (let n = 0; n < rightPadding - 1; ++n) {\n          appendToNGram(this.rightPad);\n          appendToNGram(this.separator);\n        }\n        appendToNGram(this.rightPad);\n      }\n    }\n  }\n\n  // Data and splits together form the definition of the ragged tensor,\n  // where data is 1 dimensional and contains the values of the tensor\n  // and splits denotes the indices at which each row starts.\n  public compute(data: Uint8Array[], splits: Int32Array):\n      [Uint8Array[], Int32Array] {\n    // Validate that the splits are valid indices into data, only if there are\n    // splits specified.\n    const inputDataSize = data.length;\n    const splitsSize = splits.length;\n    if (splitsSize > 0) {\n      let prevSplit = splits[0];\n      if (prevSplit !== 0) {\n        throw new Error(`First split value must be 0, got ${prevSplit}`);\n      }\n      for (let i = 1; i < splitsSize; ++i) {\n        let validSplits = splits[i] >= prevSplit;\n        validSplits = validSplits && (splits[i] <= inputDataSize);\n        if (!validSplits) {\n          throw new Error(`Invalid split value ${splits[i]}, must be in [${\n              prevSplit}, ${inputDataSize}]`);\n        }\n        prevSplit = splits[i];\n      }\n      if (prevSplit !== inputDataSize) {\n        throw new Error(`Last split value must be data size. Expected ${\n            inputDataSize}, got ${prevSplit}`);\n      }\n    }\n\n    const numBatchItems = splitsSize - 1;\n    const nGramsSplits = util.getArrayFromDType('int32', splitsSize);\n    // If there is no data or size, return an empty ragged tensor.\n    if (inputDataSize === 0 || splitsSize === 0) {\n      const empty: Uint8Array[] = new Array(inputDataSize);\n      for (let i = 0; i <= numBatchItems; ++i) {\n        nGramsSplits[i] = 0;\n      }\n      return [empty, nGramsSplits];\n    }\n\n    nGramsSplits[0] = 0;\n    for (let i = 1; i <= numBatchItems; ++i) {\n      const length = splits[i] - splits[i - 1];\n      let numNGrams = 0;\n      this.nGramWidths.forEach((nGramWidth) => {\n        numNGrams += this.getNumNGrams(length, nGramWidth);\n      });\n      if (this.preserveShort && length > 0 && numNGrams === 0) {\n        numNGrams = 1;\n      }\n      nGramsSplits[i] = nGramsSplits[i - 1] + numNGrams;\n    }\n\n    const nGrams: Uint8Array[] = new Array(nGramsSplits[numBatchItems]);\n\n    for (let i = 0; i < numBatchItems; ++i) {\n      const splitIndex = splits[i];\n      let outputStartIdx = nGramsSplits[i];\n      this.nGramWidths.forEach((nGramWidth) => {\n        const length = splits[i + 1] - splits[i];\n        const numNGrams = this.getNumNGrams(length, nGramWidth);\n        this.createNGrams(\n            data, splitIndex, nGrams, outputStartIdx, numNGrams, nGramWidth);\n        outputStartIdx += numNGrams;\n      });\n      // If we're preserving short sequences, check to see if no sequence was\n      // generated by comparing the current output start idx to the original\n      // one (nGramSplitsdata). If no ngrams were generated, then they will\n      // be equal (since we increment outputStartIdx by numNGrams every\n      // time we create a set of ngrams.)\n      if (this.preserveShort && outputStartIdx === nGramsSplits[i]) {\n        const dataLength = splits[i + 1] - splits[i];\n        // One legitimate reason to not have any ngrams when this.preserveShort\n        // is true is if the sequence itself is empty. In that case, move on.\n        if (dataLength === 0) {\n          continue;\n        }\n        // We don't have to worry about dynamic padding sizes here: if padding\n        // was dynamic, every sequence would have had sufficient padding to\n        // generate at least one nGram.\n        const nGramWidth = dataLength + 2 * this.padWidth;\n        const numNGrams = 1;\n        this.createNGrams(\n            data, splitIndex, nGrams, outputStartIdx, numNGrams, nGramWidth);\n      }\n    }\n    return [nGrams, nGramsSplits];\n  }\n}\n\nexport function stringNGramsImpl(\n    data: Uint8Array[], dataSplits: Int32Array, separator: string,\n    nGramWidths: number[], leftPad: string, rightPad: string, padWidth: number,\n    preserveShortSequences: boolean): [Uint8Array[], Int32Array] {\n  return new StringNGramsOp(\n             separator, nGramWidths, leftPad, rightPad, padWidth,\n             preserveShortSequences)\n      .compute(data, dataSplits);\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {TypedArray, util} from '@tensorflow/tfjs-core';\n\nfunction split(\n    str: Uint8Array, delimiters: Uint8Array, skipEmpty: boolean,\n    result: Uint8Array[]): void {\n  if (!str.length) {\n    return;\n  }\n  // When the delimiter is empty, the input is split into individual characters.\n  if (delimiters.length === 0) {\n    for (let i = 0; i < str.length; ++i) {\n      result.push(str.subarray(i, i + 1));\n    }\n    return;\n  }\n  // When there is one delimiter, the input is split only at that delimiter.\n  if (delimiters.length === 1) {\n    const delimiter = delimiters[0];\n    let f = str.indexOf(delimiter);\n    while (f !== -1) {\n      const token = str.subarray(0, f);\n      if (!skipEmpty || token.length !== 0) {\n        result.push(token);\n      }\n      str = str.subarray(f + 1);\n      f = str.indexOf(delimiter);\n    }\n    if (!skipEmpty || str.length !== 0) {\n      result.push(str);\n    }\n    return;\n  }\n  // When there are multiple delimiters, the input is split at every instance\n  // one of the delimiters appears.\n  let tokenStart = 0;\n  for (let i = 0; i < str.length + 1; i++) {\n    if ((i === str.length) || (delimiters.indexOf(str[i]) !== -1)) {\n      const token = str.subarray(tokenStart, i);\n      if (!skipEmpty || token.length !== 0) {\n        result.push(token);\n      }\n      tokenStart = i + 1;\n    }\n  }\n}\n\nexport function stringSplitImpl(\n    input: Uint8Array[], delimiter: Uint8Array,\n    skipEmpty: boolean): [TypedArray, Uint8Array[], [number, number]] {\n  const batchSize = input.length;\n\n  // Empty delimiter means split the input character by character.\n  const tokens: Uint8Array[] = [];\n\n  let outputSize = 0;\n  let maxNumEntries = 0;\n  const numIndices: number[] = new Array(batchSize);\n  for (let i = 0; i < batchSize; ++i) {\n    const prevTokensLength = tokens.length;\n    split(input[i], delimiter, skipEmpty, tokens);\n    const nEntries = tokens.length - prevTokensLength;\n    numIndices[i] = nEntries;\n    outputSize += nEntries;\n    maxNumEntries = Math.max(maxNumEntries, nEntries);\n  }\n\n  const indices = util.getArrayFromDType('int32', outputSize * 2) as TypedArray;\n  const values: Uint8Array[] = new Array(outputSize);\n  const shape: [number, number] = [batchSize, maxNumEntries];\n\n  let c = 0;\n  for (let i = 0; i < batchSize; ++i) {\n    for (let j = 0; j < numIndices[i]; ++j) {\n      // indices is a 2d tensor with shape of [outputSize, 2]\n      indices[c * 2] = i;\n      indices[c * 2 + 1] = j;\n      values[c] = tokens[c];\n      ++c;\n    }\n  }\n\n  return [indices, values, shape];\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {TypedArray, util} from '@tensorflow/tfjs-core';\n\nexport function stringToHashBucketFastImpl(\n    input: Uint8Array[], numBuckets: number): TypedArray {\n  const output = util.getArrayFromDType('int32', input.length) as TypedArray;\n\n  for (let i = 0; i < input.length; ++i) {\n    output[i] =\n        util.fingerPrint64(input[i]).modulo(numBuckets).getLowBitsUnsigned();\n  }\n\n  return output;\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Sub} from '@tensorflow/tfjs-core';\n\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc, createComplexBinaryKernelImpl} from '../utils/binary_utils';\n\nexport const subImpl = createSimpleBinaryKernelImpl(\n    ((aValue: number, bValue: number) => aValue - bValue));\nexport const subComplexImpl =\n    createComplexBinaryKernelImpl(((aReal, aImag, bReal, bImag) => {\n      return {real: aReal - bReal, imag: aImag - bImag};\n    }));\nexport const sub = binaryKernelFunc(Sub, subImpl, subComplexImpl);\n\nexport const subConfig: KernelConfig = {\n  kernelName: Sub,\n  backendName: 'cpu',\n  kernelFunc: sub\n};\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {buffer, DataType, Rank, TensorBuffer} from '@tensorflow/tfjs-core';\n\n/**\n * An implementation of the tile kernel shared between webgl and cpu for string\n * tensors only.\n */\n\nexport function tileImpl<R extends Rank>(\n    xBuf: TensorBuffer<R, DataType>,\n    reps: number[]): TensorBuffer<R, DataType> {\n  const newShape: number[] = new Array(xBuf.rank);\n  for (let i = 0; i < newShape.length; i++) {\n    newShape[i] = xBuf.shape[i] * reps[i];\n  }\n  const result = buffer(newShape, xBuf.dtype);\n  for (let i = 0; i < result.values.length; ++i) {\n    const newLoc = result.indexToLoc(i);\n\n    const originalLoc: number[] = new Array(xBuf.rank);\n    for (let j = 0; j < originalLoc.length; j++) {\n      originalLoc[j] = newLoc[j] % xBuf.shape[j];\n    }\n\n    const originalIndex = xBuf.locToIndex(originalLoc);\n\n    result.values[i] = xBuf.values[originalIndex];\n  }\n  return result as TensorBuffer<R, DataType>;\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n/** An implementation of the TopK kernel shared between webgl and cpu. */\n\nimport {buffer, NumericDataType, Rank, ShapeMap, Tensor, TensorBuffer, TypedArray, util} from '@tensorflow/tfjs-core';\n\ntype Pair = {\n  value: number,\n  index: number\n};\n\nconst comparePair = (a: Pair, b: Pair) => {\n  const valueDiff = b.value - a.value;\n  return valueDiff === 0 ? a.index - b.index : valueDiff;\n};\n\n/**\n * Partitions array where all elements smaller than the (k+1) smallest element\n * are found to the left of it, and all larger to the right of it.\n * Based on the Floyd-Rivest Algorithm, ref:\n * https://en.wikipedia.org/wiki/Floyd%E2%80%93Rivest_algorithm\n * @param array: Array to partition\n * @param left: Left index for the interval\n * @param right: Right index for the interval\n * @param k: Desired index value, where array[k] is the (k+1)th smallest element\n *           when left = 0\n */\nfunction select(array: Pair[], k: number, left = 0, right = array.length - 1) {\n  while (right > left) {\n    // Use select recursively to sample a smaller set of size s\n    // the arbitrary constants 600 and 0.5 are used in the original\n    // version to minimize execution time.\n    if (right - left > 600) {\n      const n = right - left + 1;\n      const i = k - left + 1;\n      const z = Math.log(n);\n      const s = 0.5 * Math.exp(2 * z / 3);\n      const sd = 0.5 * Math.sqrt(z * s * (n - s) / n) * Math.sign(i - n / 2);\n      const newLeft = Math.max(left, Math.floor(k - i * s / n + sd));\n      const newRight = Math.min(right, Math.floor(k + (n - i) * s / n + sd));\n      select(array, k, newLeft, newRight);\n    }\n    // partition the elements between left and right around t\n    const t = array[k];\n    let i = left;\n    let j = right;\n\n    util.swap(array, left, k);\n\n    if (comparePair(array[right], t) > 0) {\n      util.swap(array, left, right);\n    }\n    while (i < j) {\n      util.swap(array, i, j);\n      i++;\n      j--;\n      while (comparePair(array[i], t) < 0) {\n        i = i + 1;\n      }\n      while (comparePair(array[j], t) > 0) {\n        j = j - 1;\n      }\n    }\n    if (comparePair(array[left], t) === 0) {\n      util.swap(array, left, j);\n    } else {\n      j = j + 1;\n      util.swap(array, j, right);\n    }\n    // Adjust left and right towards the boundaries of the subset\n    // containing the (k - left + 1)th smallest element.\n    if (j <= k) {\n      left = j + 1;\n    }\n    if (k <= j) {\n      right = j - 1;\n    }\n  }\n}\n\nexport function topKImpl<T extends Tensor, R extends Rank>(\n    x: TypedArray, xShape: number[], xDtype: NumericDataType, k: number,\n    sorted: boolean):\n    [TensorBuffer<R, NumericDataType>, TensorBuffer<R, 'int32'>] {\n  // Reshape into a 2d tensor [batch, lastDim] and compute topk along lastDim.\n  const lastDim = xShape[xShape.length - 1];\n  const [batch, size] = [x.length / lastDim, lastDim];\n  const allTopKVals = util.getTypedArrayFromDType(xDtype, batch * k);\n  const allTopKIndices = util.getTypedArrayFromDType('int32', batch * k);\n\n  for (let b = 0; b < batch; b++) {\n    const offset = b * size;\n    const vals = x.subarray(offset, offset + size);\n\n    let valAndInd: Pair[] = new Array(vals.length);\n    vals.forEach(\n        (value: number, index: number) => valAndInd[index] = {value, index});\n\n    if (k < valAndInd.length) {\n      select(valAndInd, k);\n      valAndInd = valAndInd.slice(0, k);\n    }\n\n    if (sorted) {\n      valAndInd.sort(comparePair);\n    }\n    \n    const outOffset = b * k;\n    const topKVals = allTopKVals.subarray(outOffset, outOffset + k);\n    const topKIndices = allTopKIndices.subarray(outOffset, outOffset + k);\n    for (let i = 0; i < k; i++) {\n      topKVals[i] = valAndInd[i].value;\n      topKIndices[i] = valAndInd[i].index;\n    }\n  }\n  // Reshape back to the original input shape, except that the last\n  // dimension is k.\n  const outputShape = xShape.slice();\n  outputShape[outputShape.length - 1] = k;\n\n  return [\n    buffer(outputShape as ShapeMap[R], xDtype, allTopKVals),\n    buffer(outputShape as ShapeMap[R], 'int32', allTopKIndices)\n  ];\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {BackendValues, DataType, TensorBuffer, TypedArray, util} from '@tensorflow/tfjs-core';\n\nexport function uniqueImpl(\n    values: BackendValues, axis: number, shape: number[], dtype: DataType): {\n  outputValues: BackendValues,\n  outputShape: number[],\n  indices: BackendValues\n} {\n  // Normalize and validate axis.\n  const $axis = util.parseAxisParam(axis, shape)[0];\n\n  // Calculate the new shape that is suitable for extracting data along the\n  // given axis.\n  //\n  // The rank is 3.\n  // The size of the 1st dimension is the size of all the axes < the given axis.\n  // The size of the 2nd dimension is the same as the size of the given axis.\n  // The size of the 3rd dimension is the size of all the axes > the given axis.\n  //\n  // For example, for a 4D tensor with shape=[2, 3, 5, 4] and axis=2, the\n  // newShape would be: [2*3, 5, 4].\n  //\n  // Note that this is not the final output shape. This will be the shape for an\n  // intermediate TensorBuffer (see inputBuffer below) to allow us to extract\n  // values along the given axis. To demonstrate how it works, consider the\n  // following example:\n  //\n  // Input: a 3D tensor, with shape [1, 2, 3]\n  // [\n  //   [\n  //      [1,2,3],\n  //      [4,5,6]\n  //   ]\n  // ]\n  // Axis: 2 (the last axis).\n  // Along axis 2, we expect to extract 3 tensors: [1,4], [2,5], [3,6].\n  //\n  // For this example, newShape would be: [2, 3, 1], where 2 is calculated from\n  // 1*2. The re-shaped data would look like:\n  //\n  // [\n  //   [\n  //     [1], [2], [3]\n  //   ],\n  //   [\n  //     [4], [5], [6]\n  //   ]\n  // ]\n  //\n  // Then, we can construct a 3-level nested loop by the following dimension\n  // order to extract the values along the axis (dimension1):\n  // i: dimension1       // 0,1,2 (newShape[1])\n  //   m: dimension0     // 0,1   (newShape[0])\n  //     n: dimension2   // 0     (newShape[2])\n  //\n  //                       m, i, n\n  //                      ---------\n  // Iteration 0: data at [0, 0, 0] => \"1\"\n  // Iteration 1: data at [1, 0, 0] => \"4\"\n  // We got [1,4].\n  // Iteration 2: data at [0, 1, 0] => \"2\"\n  // Iteration 3: data at [1, 1, 0] => \"5\"\n  // We got [2,5].\n  // Iteration 4: data at [0, 2, 0] => \"3\"\n  // Iteration 5: data at [1, 2, 0] => \"6\"\n  // We got [3,6].\n  const newShape = [1, shape[0], 1];\n  for (let i = 0; i < $axis; i++) {\n    newShape[0] *= shape[i];\n  }\n  newShape[1] = shape[$axis];\n  for (let i = $axis + 1; i < shape.length; i++) {\n    newShape[2] *= shape[i];\n  }\n\n  // A map from unique elements (their string representations) to their values\n  // in \"indices\" (below).\n  const uniqueElements = new Map<string, number>();\n  // The indices of each unique element in the original tensor along the given\n  // axis. It is 1D and has the same size as the given axis.\n  const indices = new Int32Array(shape[$axis]);\n  // Create a buffer so we can easily extract value at a given location.\n  const inputBuffer = new TensorBuffer(newShape, dtype, values as TypedArray);\n  // The indices along the given axis that have unique elements. This is a\n  // de-duped version of \"indices\" above.\n  const uniqueIndices: number[] = [];\n  const is1DTensor = newShape[0] === 1 && newShape[2] === 1;\n  for (let i = 0; i < shape[$axis]; i++) {\n    // Extract values along the axis.\n    let element: string;\n    if (is1DTensor) {\n      // Fast path for 1D tensor input.\n      element = values[i].toString();\n    } else {\n      const axisValues = [];\n      for (let m = 0; m < newShape[0]; m++) {\n        for (let n = 0; n < newShape[2]; n++) {\n          axisValues.push(inputBuffer.get(m, i, n));\n        }\n      }\n      element = axisValues.join(',');\n    }\n\n    // Dedup and update various indices.\n    const existingIndex = uniqueElements.get(element);\n    if (existingIndex != null) {\n      indices[i] = existingIndex;\n    } else {\n      const uniqueIndex = uniqueElements.size;\n      uniqueElements.set(element, uniqueIndex);\n      indices[i] = uniqueIndex;\n      uniqueIndices.push(i);\n    }\n  }\n\n  // Now we know where each of the unique elements are located along the axis\n  // (uniqueIndices). Extract them from input buffer and store them in the\n  // output buffer.\n  const outputTmpShape = newShape.slice();\n  outputTmpShape[1] = uniqueElements.size;\n  const outputBuffer = new TensorBuffer(outputTmpShape, dtype);\n  uniqueIndices.forEach((uniqueElementIndex, i) => {\n    for (let m = 0; m < newShape[0]; m++) {\n      for (let n = 0; n < newShape[2]; n++) {\n        outputBuffer.set(inputBuffer.get(m, uniqueElementIndex, n), m, i, n);\n      }\n    }\n  });\n\n  // The output shape can be calculated from the input shape with the size of\n  // the given axis replaced by the number of unique elements along that axis.\n  const outputShape = shape.slice();\n  outputShape[$axis] = outputTmpShape[1];\n\n  return {\n    outputValues: outputBuffer.values as BackendValues,\n    outputShape,\n    indices,\n  };\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n/*\n * base.ts contains all the exports from tfjs-backend-cpu\n * without auto-kernel registration\n */\nimport {registerBackend} from '@tensorflow/tfjs-core';\nimport {MathBackendCPU} from './backend_cpu';\nimport * as shared from './shared';\n\nexport {MathBackendCPU} from './backend_cpu';\nexport {version as version_cpu} from './version';\nexport {shared};\n\n// Side effects for default initialization of MathBackendCPU\nregisterBackend('cpu', () => new MathBackendCPU(), 1 /* priority */);\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Elu, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const elu =\n    unaryKernelFunc(Elu, (xi) => xi >= 0 ? xi : (Math.exp(xi) - 1));\n\nexport const eluConfig: KernelConfig = {\n  kernelName: Elu,\n  backendName: 'cpu',\n  kernelFunc: elu,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, LeakyRelu, LeakyReluAttrs, LeakyReluInputs, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function leakyRelu(args: {\n  inputs: LeakyReluInputs,\n  backend: MathBackendCPU,\n  attrs: LeakyReluAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {alpha} = attrs;\n\n  assertNotComplex([x], 'leakyRelu');\n\n  const xSize = util.sizeFromShape(x.shape);\n  const xVals = backend.data.get(x.dataId).values as TypedArray;\n  const outVals = util.getTypedArrayFromDType('float32', xSize);\n\n  for (let i = 0; i < xVals.length; i++) {\n    outVals[i] = xVals[i] < 0 ? alpha * xVals[i] : xVals[i];\n  }\n\n  return backend.makeTensorInfo(x.shape, 'float32', outVals);\n}\n\nexport const leakyReluConfig: KernelConfig = {\n  kernelName: LeakyRelu,\n  backendName: 'cpu',\n  kernelFunc: leakyRelu as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Prelu, PreluInputs, TensorInfo, TypedArray} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\n\nconst preluImpl = createSimpleBinaryKernelImpl(\n    (xValue: number, aValue: number) => xValue < 0 ? aValue * xValue : xValue);\n\nexport function prelu(args: {inputs: PreluInputs, backend: MathBackendCPU}):\n    TensorInfo {\n  const {inputs, backend} = args;\n  const {x, alpha} = inputs;\n\n  assertNotComplex([x, alpha], 'prelu');\n\n  const aVals = backend.data.get(x.dataId).values as TypedArray;\n  const bVals = backend.data.get(alpha.dataId).values as TypedArray;\n\n  const [resultData, resultShape] =\n      preluImpl(x.shape, alpha.shape, aVals, bVals, 'float32');\n\n  return backend.makeTensorInfo(resultShape, 'float32', resultData);\n}\n\nexport const preluConfig: KernelConfig = {\n  kernelName: Prelu,\n  backendName: 'cpu',\n  kernelFunc: prelu,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Relu} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const relu = unaryKernelFunc(Relu, (xi) => Math.max(0, xi));\n\nexport const reluConfig: KernelConfig = {\n  kernelName: Relu,\n  backendName: 'cpu',\n  kernelFunc: relu,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Relu6} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const relu6 =\n    unaryKernelFunc(Relu6, (xi) => Math.min(Math.max(0, xi), 6));\n\nexport const relu6Config: KernelConfig = {\n  kernelName: Relu6,\n  backendName: 'cpu',\n  kernelFunc: relu6,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {_FusedMatMul, _FusedMatMulAttrs, _FusedMatMulInputs, backend_util, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {elu} from '../kernels/Elu';\nimport {identity} from '../kernels/Identity';\nimport {leakyRelu} from '../kernels/LeakyRelu';\nimport {prelu} from '../kernels/Prelu';\nimport {relu} from '../kernels/Relu';\nimport {relu6} from '../kernels/Relu6';\nimport {sigmoid} from '../kernels/Sigmoid';\n\nexport function applyActivation(\n    backend: MathBackendCPU, x: TensorInfo, activation: backend_util.Activation,\n    preluActivationWeights?: TensorInfo, leakyreluAlpha?: number): TensorInfo {\n  if (activation === 'linear') {\n    return identity({inputs: {x}, backend});\n  } else if (activation === 'relu') {\n    return relu({inputs: {x}, backend}) as TensorInfo;\n  } else if (activation === 'elu') {\n    return elu({inputs: {x}, backend}) as TensorInfo;\n  } else if (activation === 'relu6') {\n    return relu6({inputs: {x}, backend}) as TensorInfo;\n  } else if (activation === 'prelu') {\n    return prelu({inputs: {x, alpha: preluActivationWeights}, backend});\n  } else if (activation === 'leakyrelu') {\n    return leakyRelu({inputs: {x}, backend, attrs: {alpha: leakyreluAlpha}});\n  } else if (activation === 'sigmoid') {\n    return sigmoid({inputs: {x}, backend}) as TensorInfo;\n  }\n  throw new Error(\n      `Activation ${activation} has not been implemented for the CPU backend.`);\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, Reshape, ReshapeAttrs, ReshapeInputs, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nexport function reshape(\n    args:\n        {inputs: ReshapeInputs, backend: MathBackendCPU, attrs: ReshapeAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {shape} = attrs;\n\n  const xSize = util.sizeFromShape(x.shape);\n  const $shape = util.inferFromImplicitShape(shape, xSize);\n  const $xSize = util.sizeFromShape($shape);\n\n  util.assert(\n      xSize === $xSize,\n      () => `The new shape (${$shape}) has ${$xSize} elements and the old ` +\n          `shape (${x.shape}) has ${xSize} elements. The new shape and old ` +\n          `shape must have the same number of elements.`);\n\n  backend.incRef(x.dataId);\n\n  const xData = backend.data.get(x.dataId);\n\n  if (xData.complexTensorInfos != null) {\n    const real = xData.complexTensorInfos.real;\n    const imag = xData.complexTensorInfos.imag;\n\n    real.shape = $shape;\n    imag.shape = $shape;\n  }\n\n  return {dataId: x.dataId, shape: $shape, dtype: x.dtype};\n}\n\nexport const reshapeConfig: KernelConfig = {\n  kernelName: Reshape,\n  backendName: 'cpu',\n  kernelFunc: reshape as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {BatchMatMul, BatchMatMulAttrs, BatchMatMulInputs, broadcast_util, buffer, KernelConfig, KernelFunc, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nimport {reshape} from './Reshape';\n\nexport function batchMatMul(args: {\n  inputs: BatchMatMulInputs,\n  attrs: BatchMatMulAttrs,\n  backend: MathBackendCPU\n}) {\n  const {inputs, backend, attrs} = args;\n  const {a, b} = inputs;\n  const {transposeA, transposeB} = attrs;\n\n  assertNotComplex([a, b], 'matMul');\n\n  const aRank = a.shape.length;\n  const bRank = b.shape.length;\n\n  const innerShapeA = transposeA ? a.shape[aRank - 2] : a.shape[aRank - 1];\n  const innerShapeB = transposeB ? b.shape[bRank - 1] : b.shape[bRank - 2];\n\n  const outerShapeA = transposeA ? a.shape[aRank - 1] : a.shape[aRank - 2];\n  const outerShapeB = transposeB ? b.shape[bRank - 2] : b.shape[bRank - 1];\n\n  const outerDimsA = a.shape.slice(0, -2);\n  const outerDimsB = b.shape.slice(0, -2);\n\n  const batchDimA = util.sizeFromShape(outerDimsA);\n  const batchDimB = util.sizeFromShape(outerDimsB);\n\n  const outShapeOuterDims = broadcast_util.assertAndGetBroadcastShape(\n      a.shape.slice(0, -2), b.shape.slice(0, -2));\n  const outShape = outShapeOuterDims.concat([outerShapeA, outerShapeB]);\n\n  util.assert(\n      innerShapeA === innerShapeB,\n      () => `Error in matMul: inner shapes (${innerShapeA}) and (` +\n          `${innerShapeB}) of Tensors with shapes ${a.shape} and ` +\n          `${b.shape} and transposeA=${transposeA}` +\n          ` and transposeB=${transposeB} must match.`);\n\n  const a3dShape = transposeA ? [batchDimA, innerShapeA, outerShapeA] :\n                                [batchDimA, outerShapeA, innerShapeA];\n  const b3dShape = transposeB ? [batchDimB, outerShapeB, innerShapeB] :\n                                [batchDimB, innerShapeB, outerShapeB];\n\n  // The rest of the implementation is designed to operate on rank-3 tensors\n  const a3d = reshape({inputs: {x: a}, backend, attrs: {shape: a3dShape}});\n  const b3d = reshape({inputs: {x: b}, backend, attrs: {shape: b3dShape}});\n\n  const sharedDim = transposeA ? a3d.shape[1] : a3d.shape[2];\n  const leftDim = transposeA ? a3d.shape[2] : a3d.shape[1];\n  const rightDim = transposeB ? b3d.shape[1] : b3d.shape[2];\n  const batchDim = Math.max(batchDimA, batchDimB);\n\n  const a3dValues = backend.data.get(a3d.dataId).values as TypedArray;\n  const b3dValues = backend.data.get(b3d.dataId).values as TypedArray;\n\n  const a3dStrides = util.computeStrides(a3d.shape);\n  const b3dStrides = util.computeStrides(b3d.shape);\n\n  const [aBatch, aOuterStep, aInnerStep] = transposeA ?\n      [a3dStrides[0], 1, a3dStrides[1]] :\n      [a3dStrides[0], a3dStrides[1], 1];\n  const [bInnerStep, bOuterStep, bBatch] = transposeB ?\n      [1, b3dStrides[1], b3dStrides[0]] :\n      [b3dStrides[1], 1, b3dStrides[0]];\n\n  const size = leftDim * rightDim;\n  const result = buffer([batchDim, leftDim, rightDim], a3d.dtype);\n\n  const resVals = result.values as TypedArray;\n  const blockSize = backend.blockSize;\n\n  for (let bi = 0; bi < batchDim; bi++) {\n    const batchIndexA = bi % batchDimA;\n    const batchIndexB = bi % batchDimB;\n    for (let i0 = 0; i0 < leftDim; i0 += blockSize) {\n      // for when blockSize doesn't evenly divide the input\n      const iBlock = Math.min(i0 + blockSize, leftDim);\n      for (let j0 = 0; j0 < rightDim; j0 += blockSize) {\n        const jBlock = Math.min(j0 + blockSize, rightDim);\n        for (let k0 = 0; k0 < sharedDim; k0 += blockSize) {\n          const kBlock = Math.min(k0 + blockSize, sharedDim);\n\n          for (let i = i0; i < iBlock; i++) {\n            for (let j = j0; j < jBlock; j++) {\n              let sum = 0.0;\n\n              for (let k = k0; k < kBlock; k++) {\n                const aVal =\n                    // tslint:disable-next-line: max-line-length\n                    a3dValues[batchIndexA * aBatch + i * aOuterStep + k * aInnerStep];\n                const bVal =\n                    // tslint:disable-next-line: max-line-length\n                    b3dValues[k * bInnerStep + j * bOuterStep + batchIndexB * bBatch];\n                sum += aVal * bVal;\n              }\n              resVals[bi * size + (i * rightDim + j)] += sum;\n            }\n          }\n        }\n      }\n    }\n  }\n\n  backend.disposeIntermediateTensorInfo(a3d);\n  backend.disposeIntermediateTensorInfo(b3d);\n\n  // set correct shape on output.\n  return backend.makeTensorInfo(\n      outShape, result.dtype, result.values as TypedArray);\n}\n\nexport const batchMatMulConfig: KernelConfig = {\n  kernelName: BatchMatMul,\n  backendName: 'cpu',\n  kernelFunc: batchMatMul as unknown as KernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {_FusedMatMul, _FusedMatMulAttrs, _FusedMatMulInputs, KernelConfig, KernelFunc, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {applyActivation} from '../utils/fused_utils';\n\nimport {add} from './Add';\nimport {batchMatMul} from './BatchMatMul';\n\nexport function _fusedMatMul(args: {\n  inputs: _FusedMatMulInputs,\n  attrs: _FusedMatMulAttrs,\n  backend: MathBackendCPU\n}) {\n  const {inputs, backend, attrs} = args;\n  const {a, b, bias, preluActivationWeights} = inputs;\n  const {transposeA, transposeB, activation, leakyreluAlpha} = attrs;\n\n  let current;\n  let addRes;\n  let activationRes;\n\n  const intermediates: TensorInfo[] = [];\n\n  const matMulRes =\n      batchMatMul({inputs: {a, b}, attrs: {transposeA, transposeB}, backend});\n  current = matMulRes;\n\n  if (bias) {\n    addRes = add({inputs: {a: current, b: bias}, backend}) as TensorInfo;\n    intermediates.push(current);\n    current = addRes;\n  }\n  if (activation) {\n    activationRes = applyActivation(\n        backend, current, activation, preluActivationWeights, leakyreluAlpha);\n    intermediates.push(current);\n    current = activationRes;\n  }\n\n  for (const i of intermediates) {\n    backend.disposeIntermediateTensorInfo(i);\n  }\n\n  return current;\n}\n\nexport const _fusedMatMulConfig: KernelConfig = {\n  kernelName: _FusedMatMul,\n  backendName: 'cpu',\n  kernelFunc: _fusedMatMul as unknown as KernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Acos, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const acos = unaryKernelFunc(Acos, (xi) => Math.acos(xi));\n\nexport const acosConfig: KernelConfig = {\n  kernelName: Acos,\n  backendName: 'cpu',\n  kernelFunc: acos,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Acosh, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const acosh = unaryKernelFunc(Acosh, (xi) => Math.acosh(xi));\n\nexport const acoshConfig: KernelConfig = {\n  kernelName: Acosh,\n  backendName: 'cpu',\n  kernelFunc: acosh,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {AddN, AddNInputs, buffer, KernelConfig, KernelFunc, Tensor, TensorInfo, TypedArray} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function addN(args: {inputs: AddNInputs, backend: MathBackendCPU}):\n    TensorInfo {\n  const {inputs, backend} = args;\n  const tensors = inputs as Tensor[];\n\n  assertNotComplex(inputs, 'addN');\n\n  const vals =\n      tensors.map(t => backend.data.get(t.dataId).values as TypedArray);\n  const outBuf = buffer(tensors[0].shape, tensors[0].dtype as 'float32');\n  const outVals = outBuf.values;\n  for (let i = 0; i < tensors.length; i++) {\n    const currVals = vals[i];\n    for (let j = 0; j < outVals.length; j++) {\n      outVals[j] += currVals[j];\n    }\n  }\n\n  return backend.makeTensorInfo(outBuf.shape, outBuf.dtype, outBuf.values);\n}\n\nexport const addNConfig: KernelConfig = {\n  kernelName: AddN,\n  backendName: 'cpu',\n  kernelFunc: addN as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {All, AllAttrs, AllInputs, backend_util, KernelConfig, KernelFunc, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\nimport {reshape} from './Reshape';\nimport {transpose} from './Transpose';\n\nexport function all(\n    args: {inputs: AllInputs, backend: MathBackendCPU, attrs: AllAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {axis, keepDims} = attrs;\n\n  assertNotComplex(x, 'all');\n\n  const origAxes = util.parseAxisParam(axis, x.shape);\n  let axes = origAxes;\n  const permutedAxes = backend_util.getAxesPermutation(axes, x.shape.length);\n  let $x = x;\n  if (permutedAxes != null) {\n    $x = transpose({inputs: {x}, backend, attrs: {perm: permutedAxes}});\n    axes = backend_util.getInnerMostAxes(axes.length, x.shape.length);\n  }\n\n  backend_util.assertAxesAreInnerMostDims('all', axes, $x.shape.length);\n  const [outShape, reduceShape] =\n      backend_util.computeOutAndReduceShapes($x.shape, axes);\n  const reduceSize = util.sizeFromShape(reduceShape);\n  const vals = util.makeZerosTypedArray(util.sizeFromShape(outShape), $x.dtype);\n\n  const aVals = backend.data.get($x.dataId).values as TypedArray;\n  for (let i = 0; i < vals.length; ++i) {\n    const offset = i * reduceSize;\n    let all = aVals[offset];\n    for (let j = 0; j < reduceSize; ++j) {\n      const value = aVals[offset + j];\n      all = all && value;\n    }\n    vals[i] = all;\n  }\n\n  if (permutedAxes != null) {\n    backend.disposeIntermediateTensorInfo($x);\n  }\n\n  const result = backend.makeTensorInfo(outShape, $x.dtype, vals);\n\n  if (keepDims) {\n    const expandedShape = backend_util.expandShapeToKeepDim(outShape, origAxes);\n    const reshapedResult =\n        reshape({inputs: {x: result}, backend, attrs: {shape: expandedShape}});\n\n    backend.disposeIntermediateTensorInfo(result);\n\n    return reshapedResult;\n  }\n\n  return result;\n}\n\nexport const allConfig: KernelConfig = {\n  kernelName: All,\n  backendName: 'cpu',\n  kernelFunc: all as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Any, AnyAttrs, AnyInputs, backend_util, KernelConfig, KernelFunc, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\nimport {reshape} from './Reshape';\nimport {transpose} from './Transpose';\n\nexport function any(\n    args: {inputs: AnyInputs, backend: MathBackendCPU, attrs: AnyAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {axis, keepDims} = attrs;\n\n  assertNotComplex(x, 'any');\n\n  const origAxes = util.parseAxisParam(axis, x.shape);\n  let axes = origAxes;\n  const permutedAxes = backend_util.getAxesPermutation(axes, x.shape.length);\n  let $x = x;\n  if (permutedAxes != null) {\n    $x = transpose({inputs: {x}, backend, attrs: {perm: permutedAxes}});\n    axes = backend_util.getInnerMostAxes(axes.length, x.shape.length);\n  }\n\n  backend_util.assertAxesAreInnerMostDims('any', axes, $x.shape.length);\n  const [outShape, reduceShape] =\n      backend_util.computeOutAndReduceShapes($x.shape, axes);\n  const reduceSize = util.sizeFromShape(reduceShape);\n  const vals = util.makeZerosTypedArray(util.sizeFromShape(outShape), $x.dtype);\n\n  const aVals = backend.data.get($x.dataId).values as TypedArray;\n  for (let i = 0; i < vals.length; ++i) {\n    const offset = i * reduceSize;\n    let anyVal = aVals[offset];\n    for (let j = 0; j < reduceSize; ++j) {\n      const value = aVals[offset + j];\n      anyVal = anyVal || value;\n    }\n    vals[i] = anyVal;\n  }\n\n  if (permutedAxes != null) {\n    backend.disposeIntermediateTensorInfo($x);\n  }\n\n  const result = backend.makeTensorInfo(outShape, $x.dtype, vals);\n\n  if (keepDims) {\n    const expandedShape = backend_util.expandShapeToKeepDim(outShape, origAxes);\n    const reshapedResult =\n        reshape({inputs: {x: result}, backend, attrs: {shape: expandedShape}});\n\n    backend.disposeIntermediateTensorInfo(result);\n\n    return reshapedResult;\n  }\n\n  return result;\n}\n\nexport const anyConfig: KernelConfig = {\n  kernelName: Any,\n  backendName: 'cpu',\n  kernelFunc: any as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ArgMax, ArgMaxAttrs, ArgMaxInputs, backend_util, KernelConfig, KernelFunc, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\nimport {transpose} from './Transpose';\n\nexport function argMax(\n    args: {inputs: ArgMaxInputs, backend: MathBackendCPU, attrs: ArgMaxAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {axis} = attrs;\n\n  assertNotComplex(x, 'argMax');\n\n  let axes = util.parseAxisParam(axis, x.shape);\n  const permutedAxes = backend_util.getAxesPermutation(axes, x.shape.length);\n  let $x = x;\n  const intermediateTensorInfos = [];\n  if (permutedAxes != null) {\n    $x = transpose({inputs: {x}, backend, attrs: {perm: permutedAxes}});\n    intermediateTensorInfos.push($x);\n    axes = backend_util.getInnerMostAxes(axes.length, $x.shape.length);\n  }\n\n  axes = [axes[0]];\n  backend_util.assertAxesAreInnerMostDims('argMax', axes, $x.shape.length);\n  const [outShape, reduceShape] =\n      backend_util.computeOutAndReduceShapes($x.shape, axes);\n\n  const outSize = util.sizeFromShape(outShape);\n  const vals = util.makeZerosTypedArray(outSize, 'int32');\n  const reduceSize = util.sizeFromShape(reduceShape);\n\n  const aVals = backend.data.get($x.dataId).values as TypedArray;\n  for (let i = 0; i < vals.length; ++i) {\n    const offset = i * reduceSize;\n    let max = aVals[offset];\n    let maxIndex = 0;\n    for (let j = 0; j < reduceSize; ++j) {\n      const value = aVals[offset + j];\n      if (value > max) {\n        max = value;\n        maxIndex = j;\n      }\n    }\n    vals[i] = maxIndex;\n  }\n\n  intermediateTensorInfos.forEach(\n      t => backend.disposeIntermediateTensorInfo(t));\n\n  return backend.makeTensorInfo(outShape, 'int32', vals);\n}\n\nexport const argMaxConfig: KernelConfig = {\n  kernelName: ArgMax,\n  backendName: 'cpu',\n  kernelFunc: argMax as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ArgMin, ArgMinAttrs, ArgMinInputs, backend_util, KernelConfig, KernelFunc, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\nimport {transpose} from './Transpose';\n\nexport function argMin(\n    args: {inputs: ArgMinInputs, backend: MathBackendCPU, attrs: ArgMinAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {axis} = attrs;\n\n  assertNotComplex(x, 'argMin');\n\n  let axes = util.parseAxisParam(axis, x.shape);\n  const permutedAxes = backend_util.getAxesPermutation(axes, x.shape.length);\n  let $x = x;\n  const intermediateTensorInfos = [];\n  if (permutedAxes != null) {\n    $x = transpose({inputs: {x}, backend, attrs: {perm: permutedAxes}});\n    intermediateTensorInfos.push($x);\n    axes = backend_util.getInnerMostAxes(axes.length, $x.shape.length);\n  }\n\n  axes = [axes[0]];\n  backend_util.assertAxesAreInnerMostDims('argMin', axes, $x.shape.length);\n  const [outShape, reduceShape] =\n      backend_util.computeOutAndReduceShapes($x.shape, axes);\n\n  const outSize = util.sizeFromShape(outShape);\n  const vals = util.makeZerosTypedArray(outSize, 'int32');\n  const reduceSize = util.sizeFromShape(reduceShape);\n\n  const aVals = backend.data.get($x.dataId).values as TypedArray;\n  for (let i = 0; i < vals.length; ++i) {\n    const offset = i * reduceSize;\n    let min = aVals[offset];\n    let minIndex = 0;\n    for (let j = 0; j < reduceSize; ++j) {\n      const value = aVals[offset + j];\n      if (value < min) {\n        min = value;\n        minIndex = j;\n      }\n    }\n    vals[i] = minIndex;\n  }\n\n  intermediateTensorInfos.forEach(\n      t => backend.disposeIntermediateTensorInfo(t));\n\n  return backend.makeTensorInfo(outShape, 'int32', vals);\n}\n\nexport const argMinConfig: KernelConfig = {\n  kernelName: ArgMin,\n  backendName: 'cpu',\n  kernelFunc: argMin as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Asin, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const asin = unaryKernelFunc(Asin, (xi) => Math.asin(xi));\n\nexport const asinConfig: KernelConfig = {\n  kernelName: Asin,\n  backendName: 'cpu',\n  kernelFunc: asin,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Asinh, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const asinh = unaryKernelFunc(Asinh, (xi) => Math.asinh(xi));\n\nexport const asinhConfig: KernelConfig = {\n  kernelName: Asinh,\n  backendName: 'cpu',\n  kernelFunc: asinh,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Atan, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const atan = unaryKernelFunc(Atan, (xi) => Math.atan(xi));\n\nexport const atanConfig: KernelConfig = {\n  kernelName: Atan,\n  backendName: 'cpu',\n  kernelFunc: atan,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Atan2, KernelConfig} from '@tensorflow/tfjs-core';\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc} from '../utils/binary_utils';\n\nexport const atan2Impl = createSimpleBinaryKernelImpl(\n    (aValue, bValue) => Math.atan2(aValue as number, bValue as number));\n\nexport const atan2 = binaryKernelFunc(Atan2, atan2Impl);\n\nexport const atan2Config: KernelConfig = {\n  kernelName: Atan2,\n  backendName: 'cpu',\n  kernelFunc: atan2,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Atanh, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const atanh = unaryKernelFunc(Atanh, (xi) => Math.atanh(xi));\n\nexport const atanhConfig: KernelConfig = {\n  kernelName: Atanh,\n  backendName: 'cpu',\n  kernelFunc: atanh,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, buffer, DataType, Rank, TensorBuffer, TypedArray} from '@tensorflow/tfjs-core';\n\nexport function pool(\n    xValues: TypedArray, xShape: number[], dtype: DataType, strides: number[],\n    convInfo: backend_util.Conv2DInfo,\n    poolType: 'max'|'avg'): TensorBuffer<Rank, DataType> {\n  const strideHeight = convInfo.strideHeight;\n  const strideWidth = convInfo.strideWidth;\n  const dilationHeight = convInfo.dilationHeight;\n  const dilationWidth = convInfo.dilationWidth;\n  const effectiveFilterHeight = convInfo.effectiveFilterHeight;\n  const effectiveFilterWidth = convInfo.effectiveFilterWidth;\n  const padTop = convInfo.padInfo.top;\n  const padLeft = convInfo.padInfo.left;\n\n  const initialValue =\n      (poolType === 'max' ? Number.NEGATIVE_INFINITY :\n                            Number.POSITIVE_INFINITY);\n\n  const output = buffer(convInfo.outShape, dtype);\n  const outputVals = output.values;\n\n  const outputBatchStrides =\n      convInfo.outShape[1] * convInfo.outShape[2] * convInfo.outShape[3];\n  const outputRowStrides = convInfo.outShape[2] * convInfo.outShape[3];\n  const outputColStrides = convInfo.outShape[3];\n\n  for (let b = 0; b < convInfo.batchSize; ++b) {\n    const outputBatchOffset = b * outputBatchStrides;\n    const inputBatchOffset = b * strides[0];\n    for (let d = 0; d < convInfo.inChannels; ++d) {\n      for (let yR = 0; yR < convInfo.outHeight; ++yR) {\n        const xRCorner = yR * strideHeight - padTop;\n        const xRMin = Math.max(0, xRCorner);\n        const xRMax =\n            Math.min(convInfo.inHeight, effectiveFilterHeight + xRCorner);\n        const outputRowOffset = outputBatchOffset + yR * outputRowStrides;\n        for (let yC = 0; yC < convInfo.outWidth; ++yC) {\n          const xCCorner = yC * strideWidth - padLeft;\n          const xCMin = Math.max(0, xCCorner);\n          const xCMax =\n              Math.min(convInfo.inWidth, effectiveFilterWidth + xCCorner);\n          let minMaxValue = initialValue;\n          let avgValue = 0;\n          let count = 0;\n          for (let xR = xRMin; xR < xRMax; xR += dilationHeight) {\n            const xROffset = inputBatchOffset + xR * strides[1];\n            for (let xC = xCMin; xC < xCMax; xC += dilationWidth) {\n              const xCOffset = xROffset + xC * strides[2];\n              const pixel = xValues[xCOffset + d];\n              if ((poolType === 'max' && pixel > minMaxValue)) {\n                minMaxValue = pixel;\n              } else if (poolType === 'avg') {\n                avgValue += pixel;\n                count++;\n              }\n            }\n            if (isNaN(minMaxValue)) {\n              break;\n            }\n          }\n          const outputOffset = outputRowOffset + yC * outputColStrides + d;\n          outputVals[outputOffset] =\n              poolType === 'avg' ? avgValue / count : minMaxValue;\n        }\n      }\n    }\n  }\n  return output;\n}\n\nexport function maxPoolPositions(\n    xValues: TypedArray, xShape: number[], dtype: DataType,\n    convInfo: backend_util.Conv2DInfo, flattenPositions = false,\n    includeBatchInIndex = false): TensorBuffer<Rank, 'int32'> {\n  const maxPositions = buffer(convInfo.outShape, 'int32');\n  const strideHeight = convInfo.strideHeight;\n  const strideWidth = convInfo.strideWidth;\n  const dilationHeight = convInfo.dilationHeight;\n  const dilationWidth = convInfo.dilationWidth;\n  const effectiveFilterHeight = convInfo.effectiveFilterHeight;\n  const effectiveFilterWidth = convInfo.effectiveFilterWidth;\n  const padTop = convInfo.padInfo.top;\n  const padLeft = convInfo.padInfo.left;\n\n  const xBuf = buffer(xShape, dtype, xValues);\n  for (let b = 0; b < convInfo.batchSize; ++b) {\n    for (let d = 0; d < convInfo.inChannels; ++d) {\n      for (let yR = 0; yR < convInfo.outHeight; ++yR) {\n        const xRCorner = yR * strideHeight - padTop;\n        let xRMin = xRCorner;\n        while (xRMin < 0) {\n          xRMin += dilationHeight;\n        }\n        // const xRMin = Math.max(0, xRCorner);\n        const xRMax =\n            Math.min(convInfo.inHeight, effectiveFilterHeight + xRCorner);\n        for (let yC = 0; yC < convInfo.outWidth; ++yC) {\n          const xCCorner = yC * strideWidth - padLeft;\n          let xCMin = xCCorner;\n          while (xCMin < 0) {\n            xCMin += dilationWidth;\n          }\n          const xCMax =\n              Math.min(convInfo.inWidth, effectiveFilterWidth + xCCorner);\n          let maxValue = Number.NEGATIVE_INFINITY;\n          let maxPosition = -1;\n\n          for (let xR = xRMin; xR < xRMax; xR += dilationHeight) {\n            const wR = xR - xRCorner;\n            for (let xC = xCMin; xC < xCMax; xC += dilationWidth) {\n              const wC = xC - xCCorner;\n              // For some reason, disable-next-line is not working\n              // TODO(mattsoulanille): Remove this when switching to TS5.\n              /* tslint:disable: no-unnecessary-type-assertion */\n              const pixel = xBuf.get(b, xR, xC, d) as number;\n              if (pixel > maxValue) {\n                maxValue = pixel as number;\n                if (flattenPositions) {\n                  maxPosition = includeBatchInIndex ?\n                      ((b * convInfo.inHeight + xR) * convInfo.inWidth + xC) *\n                              convInfo.inChannels +\n                          d :\n                      (xR * convInfo.inWidth + xC) * convInfo.inChannels + d;\n                } else {\n                  maxPosition = wR * effectiveFilterWidth + wC;\n                }\n              }\n            }\n          }\n          maxPositions.set(maxPosition, b, yR, yC, d);\n        }\n      }\n    }\n  }\n  return maxPositions;\n}\n\nexport function pool3d(\n    xValues: TypedArray, xShape: number[], dtype: DataType, strides: number[],\n    convInfo: backend_util.Conv3DInfo,\n    poolType: 'max'|'avg'): TensorBuffer<Rank, DataType> {\n  const strideDepth = convInfo.strideDepth;\n  const strideHeight = convInfo.strideHeight;\n  const strideWidth = convInfo.strideWidth;\n  const dilationDepth = convInfo.dilationDepth;\n  const dilationHeight = convInfo.dilationHeight;\n  const dilationWidth = convInfo.dilationWidth;\n  const effectiveFilterDepth = convInfo.effectiveFilterDepth;\n  const effectiveFilterHeight = convInfo.effectiveFilterHeight;\n  const effectiveFilterWidth = convInfo.effectiveFilterWidth;\n  const padFront = convInfo.padInfo.front;\n  const padTop = convInfo.padInfo.top;\n  const padLeft = convInfo.padInfo.left;\n\n  const initialValue =\n      (poolType === 'max' ? Number.NEGATIVE_INFINITY :\n                            Number.POSITIVE_INFINITY);\n\n  const output = buffer(convInfo.outShape, dtype);\n  const outputVals = output.values;\n\n  const outputBatchStrides = convInfo.outShape[1] * convInfo.outShape[2] *\n      convInfo.outShape[3] * convInfo.outShape[4];\n  const outputDepthStrides =\n      convInfo.outShape[2] * convInfo.outShape[3] * convInfo.outShape[4];\n  const outputRowStrides = convInfo.outShape[3] * convInfo.outShape[4];\n  const outputColStrides = convInfo.outShape[4];\n\n  for (let batch = 0; batch < convInfo.batchSize; ++batch) {\n    const outputBatchOffset = batch * outputBatchStrides;\n    const inputBatchOffset = batch * strides[0];\n    for (let channel = 0; channel < convInfo.inChannels; ++channel) {\n      for (let yDepth = 0; yDepth < convInfo.outDepth; ++yDepth) {\n        const xDepthCorner = yDepth * strideDepth - padFront;\n        let xDepthMin = xDepthCorner;\n        while (xDepthMin < 0) {\n          xDepthMin += dilationDepth;\n        }\n        const xDepthMax =\n            Math.min(convInfo.inDepth, effectiveFilterDepth + xDepthCorner);\n        const outputDepthOffset =\n            outputBatchOffset + yDepth * outputDepthStrides;\n        for (let yRow = 0; yRow < convInfo.outHeight; ++yRow) {\n          const xRowCorner = yRow * strideHeight - padTop;\n          let xRowMin = xRowCorner;\n          while (xRowMin < 0) {\n            xRowMin += dilationHeight;\n          }\n          const xRowMax =\n              Math.min(convInfo.inHeight, effectiveFilterHeight + xRowCorner);\n          const outputRowOffset = outputDepthOffset + yRow * outputRowStrides;\n          for (let yCol = 0; yCol < convInfo.outWidth; ++yCol) {\n            const xColCorner = yCol * strideWidth - padLeft;\n            let xColMin = xColCorner;\n            while (xColMin < 0) {\n              xColMin += dilationWidth;\n            }\n            const xColMax =\n                Math.min(convInfo.inWidth, effectiveFilterWidth + xColCorner);\n            // Shader code begins\n            const outputColOffset = outputRowOffset + yCol * outputColStrides;\n            let minMaxValue = initialValue;\n            let avgValue = 0;\n            let count = 0;\n            for (let xDepth = xDepthMin; xDepth < xDepthMax;\n                 xDepth += dilationDepth) {\n              const xDepthOffset = inputBatchOffset + xDepth * strides[1];\n              for (let xRow = xRowMin; xRow < xRowMax; xRow += dilationHeight) {\n                const xRowOffset = xDepthOffset + xRow * strides[2];\n                for (let xCol = xColMin; xCol < xColMax;\n                     xCol += dilationWidth) {\n                  const xColOffset = xRowOffset + xCol * strides[3];\n                  const pixel = xValues[xColOffset + channel];\n                  if ((poolType === 'max' && pixel > minMaxValue)) {\n                    minMaxValue = pixel;\n                  } else if (poolType === 'avg') {\n                    avgValue += pixel;\n                    count++;\n                  }\n                  if (isNaN(minMaxValue)) {\n                    break;\n                  }\n                }\n                if (isNaN(minMaxValue)) {\n                  break;\n                }\n              }\n              if (isNaN(minMaxValue)) {\n                break;\n              }\n            }\n            const outputOffset = outputColOffset + channel;\n            outputVals[outputOffset] = poolType === 'avg' ?\n                avgValue / Math.max(count, 1) :\n                minMaxValue;\n          }\n        }\n      }\n    }\n  }\n\n  return output;\n}\n\nexport function maxPool3dPositions(\n    xBuf: TensorBuffer<Rank, DataType>,\n    convInfo: backend_util.Conv3DInfo): TensorBuffer<Rank, DataType> {\n  const maxPositions = buffer(convInfo.outShape, 'int32');\n  const strideDepth = convInfo.strideDepth;\n  const strideHeight = convInfo.strideHeight;\n  const strideWidth = convInfo.strideWidth;\n  const dilationDepth = convInfo.dilationDepth;\n  const dilationHeight = convInfo.dilationHeight;\n  const dilationWidth = convInfo.dilationWidth;\n  const effectiveFilterDepth = convInfo.effectiveFilterDepth;\n  const effectiveFilterHeight = convInfo.effectiveFilterHeight;\n  const effectiveFilterWidth = convInfo.effectiveFilterWidth;\n  const padFront = convInfo.padInfo.front;\n  const padTop = convInfo.padInfo.top;\n  const padLeft = convInfo.padInfo.left;\n\n  for (let batch = 0; batch < convInfo.batchSize; ++batch) {\n    for (let channel = 0; channel < convInfo.inChannels; ++channel) {\n      for (let yDepth = 0; yDepth < convInfo.outDepth; ++yDepth) {\n        const xDepthCorner = yDepth * strideDepth - padFront;\n        let xDepthMin = xDepthCorner;\n        while (xDepthMin < 0) {\n          xDepthMin += dilationDepth;\n        }\n        const xDepthMax =\n            Math.min(convInfo.inDepth, effectiveFilterDepth + xDepthCorner);\n        for (let yRow = 0; yRow < convInfo.outHeight; ++yRow) {\n          const xRowCorner = yRow * strideHeight - padTop;\n          let xRowMin = xRowCorner;\n          while (xRowMin < 0) {\n            xRowMin += dilationHeight;\n          }\n          const xRowMax =\n              Math.min(convInfo.inHeight, effectiveFilterHeight + xRowCorner);\n          for (let yCol = 0; yCol < convInfo.outWidth; ++yCol) {\n            const xColCorner = yCol * strideWidth - padLeft;\n            let xColMin = xColCorner;\n            while (xColMin < 0) {\n              xColMin += dilationWidth;\n            }\n            const xColMax =\n                Math.min(convInfo.inWidth, effectiveFilterWidth + xColCorner);\n\n            // Shader code begins\n            let maxValue = Number.NEGATIVE_INFINITY;\n            let maxPosition = -1;\n\n            for (let xDepth = xDepthMin; xDepth < xDepthMax;\n                 xDepth += dilationDepth) {\n              const wDepth = xDepth - xDepthCorner;\n              for (let xRow = xRowMin; xRow < xRowMax; xRow += dilationHeight) {\n                const wRow = xRow - xRowCorner;\n                for (let xCol = xColMin; xCol < xColMax;\n                     xCol += dilationWidth) {\n                  const wCol = xCol - xColCorner;\n                  const pixel = xBuf.get(batch, xDepth, xRow, xCol,\n                                         channel) as number;\n                  if (pixel >= maxValue) {\n                    maxValue = pixel as number;\n                    maxPosition =\n                        wDepth * effectiveFilterHeight * effectiveFilterWidth +\n                        wRow * effectiveFilterHeight + wCol;\n                  }\n                }\n              }\n            }\n\n            maxPositions.set(maxPosition, batch, yDepth, yRow, yCol, channel);\n          }\n        }\n      }\n    }\n  }\n\n  return maxPositions;\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {AvgPool, AvgPoolAttrs, AvgPoolInputs, backend_util, KernelConfig, KernelFunc, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\nimport {pool} from '../utils/pool_utils';\nimport {identity} from './Identity';\n\nexport function avgPool(\n    args:\n        {inputs: AvgPoolInputs, backend: MathBackendCPU, attrs: AvgPoolAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  assertNotComplex(x, 'avgPool');\n  const {filterSize, strides, pad, dimRoundingMode} = attrs;\n  const dilations = 1;\n\n  util.assert(\n      backend_util.eitherStridesOrDilationsAreOne(strides, dilations),\n      () => 'Error in avgPool: Either strides or dilations must be 1. ' +\n          `Got strides ${strides} and dilations '${dilations}'`);\n\n  const convInfo = backend_util.computePool2DInfo(\n      x.shape as [number, number, number, number], filterSize, strides,\n      dilations, pad, dimRoundingMode);\n  let res: TensorInfo;\n\n  if (convInfo.filterWidth === 1 && convInfo.filterHeight === 1 &&\n      util.arraysEqual(convInfo.inShape, convInfo.outShape)) {\n    res = identity({inputs: {x}, backend});\n  } else {\n    const xValues = backend.data.get(x.dataId).values as TypedArray;\n    const strides = util.computeStrides(x.shape);\n    const buffer = pool(xValues, x.shape, x.dtype, strides, convInfo, 'avg');\n    res = backend.makeTensorInfo(\n        convInfo.outShape, x.dtype, buffer.values as TypedArray);\n  }\n  return res;\n}\n\nexport const avgPoolConfig: KernelConfig = {\n  kernelName: AvgPool,\n  backendName: 'cpu',\n  kernelFunc: avgPool as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {AvgPool3D, AvgPool3DAttrs, AvgPool3DInputs, backend_util, KernelConfig, KernelFunc, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\nimport {pool3d} from '../utils/pool_utils';\n\nexport function avgPool3D(args: {\n  inputs: AvgPool3DInputs,\n  backend: MathBackendCPU,\n  attrs: AvgPool3DAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {filterSize, strides, pad, dimRoundingMode, dataFormat} = attrs;\n\n  assertNotComplex(x, 'avgPool3d');\n\n  const convInfo = backend_util.computePool3DInfo(\n      x.shape as [number, number, number, number, number], filterSize, strides,\n      1 /* dilations */, pad, dimRoundingMode, dataFormat);\n\n  const xValues = backend.data.get(x.dataId).values as TypedArray;\n  const outBuf = pool3d(\n      xValues, x.shape, x.dtype, util.computeStrides(x.shape), convInfo, 'avg');\n\n  return backend.makeTensorInfo(outBuf.shape, 'float32', outBuf.values);\n}\n\nexport const avgPool3DConfig: KernelConfig = {\n  kernelName: AvgPool3D,\n  backendName: 'cpu',\n  kernelFunc: avgPool3D as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {AvgPool3DGrad, AvgPool3DGradAttrs, AvgPool3DGradInputs, backend_util, buffer, KernelConfig, KernelFunc, Rank, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function avgPool3DGrad(args: {\n  inputs: AvgPool3DGradInputs,\n  backend: MathBackendCPU,\n  attrs: AvgPool3DGradAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {dy, input} = inputs;\n  const {filterSize, strides, pad, dimRoundingMode} = attrs;\n\n  assertNotComplex([dy, input], 'avgPool3DGrad');\n\n  const convInfo = backend_util.computePool3DInfo(\n      input.shape as [number, number, number, number, number], filterSize,\n      strides, 1 /* dilations */, pad, dimRoundingMode);\n\n  const strideDepth = convInfo.strideDepth;\n  const strideHeight = convInfo.strideHeight;\n  const strideWidth = convInfo.strideWidth;\n  const filterDepth = convInfo.filterDepth;\n  const filterHeight = convInfo.filterHeight;\n  const filterWidth = convInfo.filterWidth;\n  const dilationDepth = convInfo.dilationDepth;\n  const dilationHeight = convInfo.dilationHeight;\n  const dilationWidth = convInfo.dilationWidth;\n  const effectiveFilterDepth = convInfo.effectiveFilterDepth;\n  const effectiveFilterHeight = convInfo.effectiveFilterHeight;\n  const effectiveFilterWidth = convInfo.effectiveFilterWidth;\n  const padFront = effectiveFilterDepth - 1 - convInfo.padInfo.front;\n  const padLeft = effectiveFilterWidth - 1 - convInfo.padInfo.left;\n  const padTop = effectiveFilterHeight - 1 - convInfo.padInfo.top;\n  const dx = buffer(input.shape, 'float32');\n\n  const avgMultiplier = 1 / (filterDepth * filterHeight * filterWidth);\n\n  const dyBuf = backend.bufferSync<Rank, 'float32'>(dy);\n\n  for (let batch = 0; batch < convInfo.batchSize; ++batch) {\n    for (let channel = 0; channel < convInfo.inChannels; ++channel) {\n      for (let dxDepth = 0; dxDepth < convInfo.inDepth; ++dxDepth) {\n        for (let dxRow = 0; dxRow < convInfo.inHeight; ++dxRow) {\n          for (let dxCol = 0; dxCol < convInfo.inWidth; ++dxCol) {\n            // Shader code begins.\n            const dyDepthCorner = dxDepth - padFront;\n            const dyRowCorner = dxRow - padTop;\n            const dyColCorner = dxCol - padLeft;\n            let dotProd = 0;\n            for (let wDepth = 0; wDepth < effectiveFilterDepth;\n                 wDepth += dilationDepth) {\n              const dyDepth = (dyDepthCorner + wDepth) / strideDepth;\n              if (dyDepth < 0 || dyDepth >= convInfo.outDepth ||\n                  Math.floor(dyDepth) !== dyDepth) {\n                continue;\n              }\n              for (let wRow = 0; wRow < effectiveFilterHeight;\n                   wRow += dilationHeight) {\n                const dyRow = (dyRowCorner + wRow) / strideHeight;\n                if (dyRow < 0 || dyRow >= convInfo.outHeight ||\n                    Math.floor(dyRow) !== dyRow) {\n                  continue;\n                }\n                for (let wCol = 0; wCol < effectiveFilterWidth;\n                     wCol += dilationWidth) {\n                  const dyCol = (dyColCorner + wCol) / strideWidth;\n                  if (dyCol < 0 || dyCol >= convInfo.outWidth ||\n                      Math.floor(dyCol) !== dyCol) {\n                    continue;\n                  }\n\n                  const pixel =\n                      dyBuf.get(batch, dyDepth, dyRow, dyCol, channel);\n                  dotProd += pixel;\n                }\n              }\n            }\n            dx.set(\n                dotProd * avgMultiplier, batch, dxDepth, dxRow, dxCol, channel);\n          }\n        }\n      }\n    }\n  }\n\n  return backend.makeTensorInfo(dx.shape, dx.dtype, dx.values);\n}\n\nexport const avgPool3DGradConfig: KernelConfig = {\n  kernelName: AvgPool3DGrad,\n  backendName: 'cpu',\n  kernelFunc: avgPool3DGrad as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {AvgPoolGrad, AvgPoolGradAttrs, AvgPoolGradInputs, backend_util, buffer, KernelConfig, KernelFunc, Rank, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function avgPoolGrad(args: {\n  inputs: AvgPoolGradInputs,\n  backend: MathBackendCPU,\n  attrs: AvgPoolGradAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {dy, input} = inputs;\n  const x = input;\n  assertNotComplex([dy, input], 'avgPoolGrad');\n  const {filterSize, strides, pad} = attrs;\n\n  const convInfo = backend_util.computePool2DInfo(\n      x.shape as [number, number, number, number], filterSize, strides,\n      1 /* dilations */, pad);\n  const strideHeight = convInfo.strideHeight;\n  const strideWidth = convInfo.strideWidth;\n  const filterHeight = convInfo.filterHeight;\n  const filterWidth = convInfo.filterWidth;\n  const dilationHeight = convInfo.dilationHeight;\n  const dilationWidth = convInfo.dilationWidth;\n  const effectiveFilterHeight = convInfo.effectiveFilterHeight;\n  const effectiveFilterWidth = convInfo.effectiveFilterWidth;\n  const padLeft = effectiveFilterWidth - 1 - convInfo.padInfo.left;\n  const padTop = effectiveFilterHeight - 1 - convInfo.padInfo.top;\n  const dx =\n      buffer<Rank.R4>(x.shape as [number, number, number, number], 'float32');\n\n  const avgMultiplier = 1 / (filterHeight * filterWidth);\n\n  const dyData = backend.data.get(dy.dataId).values as Float32Array;\n  const dyBuf = buffer<Rank.R4>(\n      dy.shape as [number, number, number, number], 'float32', dyData);\n\n  for (let b = 0; b < convInfo.batchSize; ++b) {\n    for (let d = 0; d < convInfo.inChannels; ++d) {\n      for (let dxR = 0; dxR < convInfo.inHeight; ++dxR) {\n        for (let dxC = 0; dxC < convInfo.inWidth; ++dxC) {\n          // Shader code begins.\n          const dyRCorner = dxR - padTop;\n          const dyCCorner = dxC - padLeft;\n          let dotProd = 0;\n          for (let wR = 0; wR < effectiveFilterHeight; wR += dilationHeight) {\n            const dyR = (dyRCorner + wR) / strideHeight;\n            if (dyR < 0 || dyR >= convInfo.outHeight ||\n                Math.floor(dyR) !== dyR) {\n              continue;\n            }\n            for (let wC = 0; wC < effectiveFilterWidth; wC += dilationWidth) {\n              const dyC = (dyCCorner + wC) / strideWidth;\n              if (dyC < 0 || dyC >= convInfo.outWidth ||\n                  Math.floor(dyC) !== dyC) {\n                continue;\n              }\n\n              const pixel = dyBuf.get(b, dyR, dyC, d);\n              dotProd += pixel;\n            }\n          }\n          dx.set(dotProd * avgMultiplier, b, dxR, dxC, d);\n        }\n      }\n    }\n  }\n  return backend.makeTensorInfo(dx.shape, dx.dtype, dx.values);\n}\n\nexport const avgPoolGradConfig: KernelConfig = {\n  kernelName: AvgPoolGrad,\n  backendName: 'cpu',\n  kernelFunc: avgPoolGrad as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {FusedBatchNorm, FusedBatchNormAttrs, FusedBatchNormInputs, KernelConfig, KernelFunc, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function batchNorm(args: {\n  inputs: FusedBatchNormInputs,\n  backend: MathBackendCPU,\n  attrs: FusedBatchNormAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x, scale, offset, mean, variance} = inputs;\n\n  util.assert(\n      mean.shape.length === variance.shape.length,\n      () => 'Batch normalization gradient requires mean and variance to have ' +\n          'equal ranks.');\n  util.assert(\n      offset == null || mean.shape.length === offset.shape.length,\n      () => 'Batch normalization gradient requires mean and offset to have ' +\n          'equal ranks.');\n  util.assert(\n      scale == null || mean.shape.length === scale.shape.length,\n      () => 'Batch normalization gradient requires mean and scale to have ' +\n          'equal ranks.');\n\n  assertNotComplex([x, mean, variance, scale, offset], 'batchNorm');\n\n  let {varianceEpsilon} = attrs;\n  if (varianceEpsilon == null) {\n    varianceEpsilon = 0.001;\n  }\n\n  const xVals = backend.data.get(x.dataId).values as TypedArray;\n  const mVals = backend.data.get(mean.dataId).values as TypedArray;\n  const varVals = backend.data.get(variance.dataId).values as TypedArray;\n  const sVals = scale ? backend.data.get(scale.dataId).values as TypedArray :\n                        new Float32Array([1]);\n  const offVals = offset ?\n      backend.data.get(offset.dataId).values as TypedArray :\n      new Float32Array([0]);\n  const outVals = new Float32Array(xVals.length);\n\n  const offValsLength = offVals.length;\n  const sValsLength = sVals.length;\n  const varValsLength = varVals.length;\n  const mValsLength = mVals.length;\n\n  let offi = 0;\n  let mi = 0;\n  let si = 0;\n  let vi = 0;\n  for (let i = 0; i < xVals.length; ++i) {\n    outVals[i] = offVals[offi++] +\n        (xVals[i] - mVals[mi++]) * sVals[si++] /\n            Math.sqrt(varVals[vi++] + varianceEpsilon);\n    if (offi >= offValsLength) {\n      offi = 0;\n    }\n    if (mi >= mValsLength) {\n      mi = 0;\n    }\n    if (si >= sValsLength) {\n      si = 0;\n    }\n    if (vi >= varValsLength) {\n      vi = 0;\n    }\n  }\n  return backend.makeTensorInfo(x.shape, x.dtype, outVals);\n}\n\nexport const batchNormConfig: KernelConfig = {\n  kernelName: FusedBatchNorm,\n  backendName: 'cpu',\n  kernelFunc: batchNorm as unknown as KernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, BatchToSpaceND, BatchToSpaceNDAttrs, BatchToSpaceNDInputs, KernelConfig, KernelFunc, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\nimport {reshape} from './Reshape';\nimport {slice} from './Slice';\nimport {transpose} from './Transpose';\n\nexport function batchToSpaceND(args: {\n  inputs: BatchToSpaceNDInputs,\n  backend: MathBackendCPU,\n  attrs: BatchToSpaceNDAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {blockShape, crops} = attrs;\n\n  assertNotComplex([x], 'batchToSpaceND');\n\n  const prod = blockShape.reduce((a, b) => a * b);\n\n  const reshaped = backend_util.getReshaped(x.shape, blockShape, prod);\n  const permuted = backend_util.getPermuted(reshaped.length, blockShape.length);\n  const reshapedPermuted =\n      backend_util.getReshapedPermuted(x.shape, blockShape, prod);\n  const sliceBeginCoords =\n      backend_util.getSliceBeginCoords(crops, blockShape.length);\n  const sliceSize =\n      backend_util.getSliceSize(reshapedPermuted, crops, blockShape.length);\n\n  const xReshaped = reshape({inputs: {x}, backend, attrs: {shape: reshaped}});\n  const xTransposed =\n      transpose({inputs: {x: xReshaped}, backend, attrs: {perm: permuted}});\n  const xTransposedReshaped = reshape(\n      {inputs: {x: xTransposed}, backend, attrs: {shape: reshapedPermuted}});\n  const result = slice({\n    inputs: {x: xTransposedReshaped},\n    backend,\n    attrs: {begin: sliceBeginCoords, size: sliceSize}\n  });\n\n  backend.disposeIntermediateTensorInfo(xReshaped);\n  backend.disposeIntermediateTensorInfo(xTransposed);\n  backend.disposeIntermediateTensorInfo(xTransposedReshaped);\n\n  return result;\n}\n\nexport const batchToSpaceNDConfig: KernelConfig = {\n  kernelName: BatchToSpaceND,\n  backendName: 'cpu',\n  kernelFunc: batchToSpaceND as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Bincount, BincountAttrs, BincountInputs, KernelConfig, KernelFunc, TensorInfo, TypedArray} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {bincountImpl} from './Bincount_impl';\n\nexport function bincount(args: {\n  inputs: BincountInputs,\n  backend: MathBackendCPU,\n  attrs: BincountAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x, weights} = inputs;\n  const {size} = attrs;\n\n  const xVals = backend.data.get(x.dataId).values as TypedArray;\n  const weightsVals = backend.data.get(weights.dataId).values as TypedArray;\n\n  const outVals =\n      bincountImpl(xVals, weightsVals, weights.dtype, weights.shape, size);\n\n  return backend.makeTensorInfo([size], weights.dtype, outVals);\n}\n\nexport const bincountConfig: KernelConfig = {\n  kernelName: Bincount,\n  backendName: 'cpu',\n  kernelFunc: bincount as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, BroadcastArgs, BroadcastArgsInputs, KernelConfig, TensorInfo, TypedArray} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nexport function broadcastArgs(args: {\n  inputs: BroadcastArgsInputs,\n  backend: MathBackendCPU,\n}): TensorInfo {\n  const {inputs, backend} = args;\n  const {s0, s1} = inputs;\n\n  const s0Vals = backend.data.get(s0.dataId).values as TypedArray;\n  const s1Vals = backend.data.get(s1.dataId).values as TypedArray;\n\n  const broadcastShape = backend_util.assertAndGetBroadcastShape(\n      Array.from(s0Vals), Array.from(s1Vals));\n\n  return backend.makeTensorInfo(\n      [broadcastShape.length], 'int32', Int32Array.from(broadcastShape));\n}\n\nexport const broadcastArgsConfig: KernelConfig = {\n  kernelName: BroadcastArgs,\n  backendName: 'cpu',\n  kernelFunc: broadcastArgs\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ClipByValue, ClipByValueAttrs, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const clipByValue = unaryKernelFunc(ClipByValue, (xi, attrs) => {\n  const clipAttrs = attrs as unknown as ClipByValueAttrs;\n  if (xi > clipAttrs.clipValueMax) {\n    return clipAttrs.clipValueMax;\n  }\n  return xi < clipAttrs.clipValueMin ? clipAttrs.clipValueMin : xi;\n});\n\nexport const clipByValueConfig: KernelConfig = {\n  kernelName: ClipByValue,\n  backendName: 'cpu',\n  kernelFunc: clipByValue,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ComplexAbs, ComplexAbsInputs, KernelConfig, KernelFunc, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nexport const complexAbs =\n    (args: {inputs: ComplexAbsInputs, backend: MathBackendCPU}) => {\n      const {x} = args.inputs;\n      const cpuBackend = args.backend;\n      const resultValues = new Float32Array(util.sizeFromShape(x.shape));\n      const complexVals = cpuBackend.data.get(x.dataId);\n      const real = complexVals.complexTensorInfos.real;\n      const imag = complexVals.complexTensorInfos.imag;\n      const realVals = cpuBackend.data.get(real.dataId).values as Float32Array;\n      const imagVals = cpuBackend.data.get(imag.dataId).values as Float32Array;\n      for (let i = 0; i < realVals.length; i++) {\n        const real = realVals[i];\n        const imag = imagVals[i];\n        resultValues[i] = Math.hypot(real, imag);\n      }\n\n      return cpuBackend.makeOutput(resultValues, x.shape, 'float32');\n    };\n\nexport const complexAbsConfig: KernelConfig = {\n  kernelName: ComplexAbs,\n  backendName: 'cpu',\n  kernelFunc: complexAbs as unknown as KernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Imag, ImagInputs, KernelConfig, KernelFunc, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nexport function imag(args: {inputs: ImagInputs, backend: MathBackendCPU}):\n    TensorInfo {\n  const {inputs, backend} = args;\n  const {input} = inputs;\n\n  const imag = backend.data.get(input.dataId).complexTensorInfos.imag;\n  const imagVal = backend.data.get(imag.dataId).values;\n\n  // When complex tensor is disposed, its underlying parts will be disposed too.\n  // Make new tensor out of the imag value of the complex. This makes sure the\n  // value is still accessible even if complex tensor is disposed.\n  return backend.makeTensorInfo(imag.shape, imag.dtype, imagVal);\n}\n\nexport const imagConfig: KernelConfig = {\n  kernelName: Imag,\n  backendName: 'cpu',\n  kernelFunc: imag as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Concat, ConcatAttrs, ConcatInputs, KernelConfig, KernelFunc, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nimport {complex} from './Complex';\nimport {concatImpl} from './Concat_impl';\nimport {identity} from './Identity';\nimport {imag} from './Imag';\nimport {real} from './Real';\nimport {reshape} from './Reshape';\n\nexport function concat(\n    args: {inputs: ConcatInputs, backend: MathBackendCPU, attrs: ConcatAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {axis} = attrs;\n\n  const $axis = util.parseAxisParam(axis, inputs[0].shape)[0];\n\n  const shapes = inputs.map(t => t.shape);\n  backend_util.assertParamsConsistent(shapes, $axis);\n\n  let outShape = backend_util.computeOutShape(inputs.map(t => t.shape), $axis);\n\n  if (util.sizeFromShape(outShape) === 0) {\n    return backend.makeTensorInfo(outShape, inputs[0].dtype, []);\n  }\n\n  // Keep only non-empty tensors (ignore tensors with 0 in their shape).\n  const $inputs = inputs.filter(t => util.sizeFromShape(t.shape) > 0);\n  if ($inputs.length === 1) {\n    return identity({inputs: {x: $inputs[0]}, backend});\n  }\n\n  if ($inputs[0].dtype === 'complex64') {\n    const reals = $inputs.map((t) => real({inputs: {input: t}, backend}));\n    const imags = $inputs.map((t) => imag({inputs: {input: t}, backend}));\n\n    const realConcated = concat({inputs: reals, backend, attrs: {axis: $axis}});\n    const imagConcated = concat({inputs: imags, backend, attrs: {axis: $axis}});\n\n    const result =\n        complex({inputs: {real: realConcated, imag: imagConcated}, backend});\n\n    reals.forEach(r => backend.disposeIntermediateTensorInfo(r));\n    imags.forEach(i => backend.disposeIntermediateTensorInfo(i));\n    backend.disposeIntermediateTensorInfo(realConcated);\n    backend.disposeIntermediateTensorInfo(imagConcated);\n\n    return result;\n  }\n\n  // Any concat of n-dimensional tensors across any axis can be reduced to\n  // a concatenation of two-dimensional tensors across the axis 1 by first\n  // partitioning the axes of the original tensors into those less than the\n  // axis to be concatenated and the rest. Then reshape the tensors\n  // into a two-dimensional tensor by collapsing these two sets of axes and\n  // concatenate the resulting matrices across the axis 1, finally reshaping\n  // the result to have the proper shape.\n  const inputs2D = $inputs.map(t => {\n    const innerSize = util.sizeFromShape(t.shape.slice($axis));\n    const shape = [-1, innerSize];\n    return reshape({inputs: {x: t}, backend, attrs: {shape}});\n  });\n\n  const inputsValShapes = inputs2D.map(t => {\n    return {vals: backend.data.get(t.dataId).values, shape: t.shape};\n  });\n\n  // Concats 2d tensors along axis=1.\n  outShape =\n      backend_util.computeOutShape(inputs2D.map(t => t.shape), 1 /* axis */);\n  const simplyConcat = inputs2D[0].shape[0] === 1;\n  const outVals =\n      concatImpl(inputsValShapes, outShape, inputs[0].dtype, simplyConcat);\n\n  const finalOutShape =\n      backend_util.computeOutShape($inputs.map(t => t.shape), $axis);\n\n  const outInfo =\n      backend.makeTensorInfo(finalOutShape, inputs[0].dtype, outVals);\n\n  inputs2D.forEach(t => backend.disposeIntermediateTensorInfo(t));\n\n  return outInfo;\n}\n\nexport const concatConfig: KernelConfig = {\n  kernelName: Concat,\n  backendName: 'cpu',\n  kernelFunc: concat as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Conv2D, Conv2DAttrs, Conv2DInputs, KernelConfig, KernelFunc, TensorBuffer, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function conv2D(\n    args: {inputs: Conv2DInputs, backend: MathBackendCPU, attrs: Conv2DAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x, filter} = inputs;\n  const {strides, pad, dataFormat, dilations, dimRoundingMode} = attrs;\n\n  assertNotComplex([x, filter], 'conv2d');\n\n  const $dataFormat = backend_util.convertConv2DDataFormat(dataFormat);\n  const convInfo = backend_util.computeConv2DInfo(\n      x.shape as [number, number, number, number],\n      filter.shape as [number, number, number, number], strides, dilations, pad,\n      dimRoundingMode, false /* depthwise */, $dataFormat);\n\n  const filterHeight = convInfo.filterHeight;\n  const filterWidth = convInfo.filterWidth;\n  const dilationHeight = convInfo.dilationHeight;\n  const dilationWidth = convInfo.dilationWidth;\n  const padLeft = convInfo.padInfo.left;\n  const padTop = convInfo.padInfo.top;\n  const isChannelsLast = convInfo.dataFormat === 'channelsLast';\n\n  const y = new TensorBuffer(convInfo.outShape, x.dtype as 'float32');\n\n  const xStrides = util.computeStrides(x.shape);\n  const filterStrides = util.computeStrides(filter.shape);\n\n  const xBatchStride = xStrides[0];\n  const xRowStride = isChannelsLast ? xStrides[1] : xStrides[2];\n  const xColStride = isChannelsLast ? xStrides[2] : 1;\n  const xChannelStride = isChannelsLast ? 1 : xStrides[1];\n  const yBatchStride = y.strides[0];\n  const yRowStride = isChannelsLast ? y.strides[1] : y.strides[2];\n  const yColStride = isChannelsLast ? y.strides[2] : 1;\n  const yChannelStride = isChannelsLast ? 1 : y.strides[1];\n\n  const xVals = backend.data.get(x.dataId).values as TypedArray;\n  const wVals = backend.data.get(filter.dataId).values as TypedArray;\n  const yVals = y.values;\n\n  for (let b = 0; b < convInfo.batchSize; ++b) {\n    const xOffset1 = b * xBatchStride;\n    const yOffset1 = b * yBatchStride;\n    for (let yR = 0; yR < convInfo.outHeight; ++yR) {\n      const yOffset2 = yOffset1 + yR * yRowStride;\n      const xRCorner = yR * convInfo.strideHeight - padTop;\n      for (let wR = 0; wR < filterHeight; ++wR) {\n        const xR = xRCorner + wR * dilationHeight;\n        if (xR < 0 || xR >= convInfo.inHeight) {\n          continue;\n        }\n        const wOffset1 = wR * filterStrides[0];\n        const xOffset2 = xOffset1 + xR * xRowStride;\n        for (let yC = 0; yC < convInfo.outWidth; ++yC) {\n          const yOffset3 = yOffset2 + yC * yColStride;\n          const xCCorner = yC * convInfo.strideWidth - padLeft;\n          for (let wC = 0; wC < filterWidth; ++wC) {\n            const xC = xCCorner + wC * dilationWidth;\n            if (xC < 0 || xC >= convInfo.inWidth) {\n              continue;\n            }\n            const wOffset2 = wOffset1 + wC * filterStrides[1];\n            const xOffset3 = xOffset2 + xC * xColStride;\n            let wOffset3 = wOffset2;\n            for (let d1 = 0; d1 < convInfo.inChannels; ++d1) {\n              const xVal = xVals[xOffset3 + d1 * xChannelStride];\n              for (let d2 = 0; d2 < convInfo.outChannels; ++d2) {\n                yVals[yOffset3 + d2 * yChannelStride] +=\n                    xVal * wVals[wOffset3 + d2];\n              }\n              wOffset3 += convInfo.outChannels;\n            }\n          }\n        }\n      }\n    }\n  }\n\n  return backend.makeTensorInfo(y.shape, y.dtype, yVals);\n}\n\nexport const conv2DConfig: KernelConfig = {\n  kernelName: Conv2D,\n  backendName: 'cpu',\n  kernelFunc: conv2D as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Conv2DBackpropFilter, Conv2DBackpropFilterAttrs, Conv2DBackpropFilterInputs, KernelConfig, KernelFunc, TensorBuffer, TensorInfo, TypedArray} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function conv2DBackpropFilter(args: {\n  inputs: Conv2DBackpropFilterInputs,\n  backend: MathBackendCPU,\n  attrs: Conv2DBackpropFilterAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x, dy} = inputs;\n  const {strides, pad, dataFormat, dimRoundingMode, filterShape} = attrs;\n\n  assertNotComplex([x, dy], 'conv2dBackpropFilter');\n\n  const $dataFormat = backend_util.convertConv2DDataFormat(dataFormat);\n  const convInfo = backend_util.computeConv2DInfo(\n      x.shape as [number, number, number, number], filterShape, strides,\n      1 /* dilations */, pad, dimRoundingMode, false /* depthwise */,\n      $dataFormat);\n\n  const {strideHeight, strideWidth, filterHeight, filterWidth} = convInfo;\n  const isChannelsLast = convInfo.dataFormat === 'channelsLast';\n  const dW = new TensorBuffer(convInfo.filterShape, 'float32');\n\n  const leftPad = convInfo.padInfo.left;\n  const topPad = convInfo.padInfo.top;\n  const xVals = backend.data.get(x.dataId).values as TypedArray;\n  const dyVals = backend.data.get(dy.dataId).values as TypedArray;\n\n  const xBuf = new TensorBuffer(x.shape, x.dtype, xVals);\n  const dyBuf = new TensorBuffer(dy.shape, dy.dtype, dyVals);\n\n  for (let wR = 0; wR < filterHeight; ++wR) {\n    const yRMin = Math.max(0, Math.ceil((topPad - wR) / strideHeight));\n    const yRMax = Math.min(\n        convInfo.outHeight, (convInfo.inHeight + topPad - wR) / strideHeight);\n\n    for (let wC = 0; wC < filterWidth; ++wC) {\n      const yCMin = Math.max(0, Math.ceil((leftPad - wC) / strideWidth));\n      const yCMax = Math.min(\n          convInfo.outWidth, (convInfo.inWidth + leftPad - wC) / strideWidth);\n\n      for (let d1 = 0; d1 < convInfo.inChannels; ++d1) {\n        for (let d2 = 0; d2 < convInfo.outChannels; ++d2) {\n          let dotProd = 0;\n          for (let b = 0; b < convInfo.batchSize; ++b) {\n            for (let yR = yRMin; yR < yRMax; ++yR) {\n              const xR = wR + yR * strideHeight - topPad;\n              for (let yC = yCMin; yC < yCMax; ++yC) {\n                const xC = wC + yC * strideWidth - leftPad;\n                if (isChannelsLast) {\n                  dotProd += (xBuf.get(b, xR, xC, d1) as number) *\n                      (dyBuf.get(b, yR, yC, d2) as number);\n                } else {\n                  dotProd += (xBuf.get(b, d1, xR, xC) as number) *\n                      (dyBuf.get(b, d2, yR, yC) as number);\n                }\n              }\n            }\n          }\n          dW.set(dotProd, wR, wC, d1, d2);\n        }\n      }\n    }\n  }\n\n  return backend.makeTensorInfo(dW.shape, dW.dtype, dW.values);\n}\n\nexport const conv2DBackpropFilterConfig: KernelConfig = {\n  kernelName: Conv2DBackpropFilter,\n  backendName: 'cpu',\n  kernelFunc: conv2DBackpropFilter as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Conv2DBackpropInput, Conv2DBackpropInputAttrs, Conv2DBackpropInputInputs, KernelConfig, KernelFunc, TensorBuffer, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function conv2DBackpropInput(args: {\n  inputs: Conv2DBackpropInputInputs,\n  backend: MathBackendCPU,\n  attrs: Conv2DBackpropInputAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {dy, filter} = inputs;\n  const {inputShape, strides, pad, dataFormat, dimRoundingMode} = attrs;\n\n  assertNotComplex([dy, filter], 'conv2dBackpropInput');\n\n  const filterStrides = util.computeStrides(filter.shape);\n  const dyStrides = util.computeStrides(dy.shape);\n\n  let $dataFormat = backend_util.convertConv2DDataFormat(dataFormat);\n  const convInfo = backend_util.computeConv2DInfo(\n      inputShape, filter.shape as [number, number, number, number], strides,\n      1 /* dilations */, pad, dimRoundingMode, false, $dataFormat);\n\n  const dx = new TensorBuffer(convInfo.inShape, 'float32');\n  const dxValues = dx.values;\n  const dyValues = backend.data.get(dy.dataId).values as TypedArray;\n  const fltValues = backend.data.get(filter.dataId).values as TypedArray;\n  const [fltS0, fltS1, fltS2] = filterStrides;\n  const {\n    batchSize,\n    filterHeight,\n    filterWidth,\n    inChannels,\n    inHeight,\n    inWidth,\n    outChannels,\n    outHeight,\n    outWidth,\n    strideHeight,\n    strideWidth\n  } = convInfo;\n  $dataFormat = convInfo.dataFormat;\n  const topPad = filterHeight - 1 - convInfo.padInfo.top;\n  const leftPad = filterWidth - 1 - convInfo.padInfo.left;\n\n  const isChannelsLast = $dataFormat === 'channelsLast';\n  const xBatchStride = dx.strides[0];\n  const xRowStride = isChannelsLast ? dx.strides[1] : dx.strides[2];\n  const xColStride = isChannelsLast ? dx.strides[2] : 1;\n  const xChannelStride = isChannelsLast ? 1 : dx.strides[1];\n  const yBatchStride = dyStrides[0];\n  const yRowStride = isChannelsLast ? dyStrides[1] : dyStrides[2];\n  const yColStride = isChannelsLast ? dyStrides[2] : 1;\n  const yChannelStride = isChannelsLast ? 1 : dyStrides[1];\n\n  for (let b = 0; b < batchSize; ++b) {\n    for (let d1 = 0; d1 < inChannels; ++d1) {\n      for (let xR = 0; xR < inHeight; ++xR) {\n        const xRCorner = xR - topPad;\n        const xRMin = Math.max(0, Math.ceil(xRCorner / strideHeight));\n        const yRMax =\n            Math.min(outHeight, (filterHeight + xRCorner) / strideHeight);\n\n        for (let xC = 0; xC < inWidth; ++xC) {\n          const xCCorner = xC - leftPad;\n          const xCMin = Math.max(0, Math.ceil(xCCorner / strideWidth));\n          const yCMax =\n              Math.min(outWidth, (filterWidth + xCCorner) / strideWidth);\n\n          let dotProd = 0;\n          for (let yR = xRMin; yR < yRMax; ++yR) {\n            const wR = yR * strideHeight - xRCorner;\n\n            for (let yC = xCMin; yC < yCMax; ++yC) {\n              const wC = yC * strideWidth - xCCorner;\n              const dyOffset =\n                  yBatchStride * b + yRowStride * yR + yColStride * yC;\n              const fltOffset = fltS0 * (filterHeight - 1 - wR) +\n                  fltS1 * (filterWidth - 1 - wC) + fltS2 * d1;\n\n              for (let d2 = 0; d2 < outChannels; ++d2) {\n                const pixel = dyValues[dyOffset + yChannelStride * d2];\n                const weight = fltValues[fltOffset + d2];\n                dotProd += pixel * weight;\n              }\n            }\n          }\n          const dxOffset = xBatchStride * b + xRowStride * xR +\n              xColStride * xC + xChannelStride * d1;\n          dxValues[dxOffset] = dotProd;\n        }\n      }\n    }\n  }\n\n  return backend.makeTensorInfo(dx.shape, dx.dtype, dx.values);\n}\n\nexport const conv2DBackpropInputConfig: KernelConfig = {\n  kernelName: Conv2DBackpropInput,\n  backendName: 'cpu',\n  kernelFunc: conv2DBackpropInput as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Conv3D, Conv3DAttrs, Conv3DInputs, KernelConfig, KernelFunc, TensorBuffer, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function conv3D(\n    args: {inputs: Conv3DInputs, backend: MathBackendCPU, attrs: Conv3DAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x, filter} = inputs;\n  const {strides, pad, dilations} = attrs;\n\n  assertNotComplex([x, filter], 'conv3d');\n\n  const convInfo = backend_util.computeConv3DInfo(\n      x.shape as [number, number, number, number, number],\n      filter.shape as [number, number, number, number, number], strides,\n      dilations, pad);\n\n  const {\n    filterDepth,\n    filterHeight,\n    filterWidth,\n    dilationDepth,\n    dilationHeight,\n    dilationWidth,\n    padInfo\n  } = convInfo;\n  const padFront = padInfo.front;\n  const padLeft = padInfo.left;\n  const padTop = padInfo.top;\n  const y = new TensorBuffer(convInfo.outShape, x.dtype as 'float32');\n\n  const xVals = backend.data.get(x.dataId).values as TypedArray;\n  const wVals = backend.data.get(filter.dataId).values as TypedArray;\n  const yVals = y.values;\n\n  const xStrides = util.computeStrides(x.shape);\n  const filterStrides = util.computeStrides(filter.shape);\n\n  for (let b = 0; b < convInfo.batchSize; ++b) {\n    const xOffset1 = b * xStrides[0];\n    const yOffset1 = b * y.strides[0];\n    for (let yF = 0; yF < convInfo.outDepth; ++yF) {\n      const yOffset2 = yOffset1 + yF * y.strides[1];\n      const xFCorner = yF * convInfo.strideDepth - padFront;\n      for (let wF = 0; wF < filterDepth; ++wF) {\n        const xF = xFCorner + wF * dilationDepth;\n        if (xF < 0 || xF >= convInfo.inDepth) {\n          continue;\n        }\n        const wOffset1 = wF * filterStrides[0];\n        const xOffset2 = xOffset1 + xF * xStrides[1];\n\n        for (let yR = 0; yR < convInfo.outHeight; ++yR) {\n          const yOffset3 = yOffset2 + yR * y.strides[2];\n          const xRCorner = yR * convInfo.strideHeight - padTop;\n          for (let wR = 0; wR < filterHeight; ++wR) {\n            const xR = xRCorner + wR * dilationHeight;\n            if (xR < 0 || xR >= convInfo.inHeight) {\n              continue;\n            }\n            const wOffset2 = wOffset1 + wR * filterStrides[1];\n            const xOffset3 = xOffset2 + xR * xStrides[2];\n            for (let yC = 0; yC < convInfo.outWidth; ++yC) {\n              const yOffset4 = yOffset3 + yC * convInfo.outChannels;\n              const xCCorner = yC * convInfo.strideWidth - padLeft;\n              for (let wC = 0; wC < filterWidth; ++wC) {\n                const xC = xCCorner + wC * dilationWidth;\n                if (xC < 0 || xC >= convInfo.inWidth) {\n                  continue;\n                }\n                const wOffset3 = wOffset2 + wC * filterStrides[2];\n                const xOffset4 = xOffset3 + xC * convInfo.inChannels;\n                let wOffset4 = wOffset3;\n                for (let d1 = 0; d1 < convInfo.inChannels; ++d1) {\n                  const xVal = xVals[xOffset4 + d1];\n                  for (let d2 = 0; d2 < convInfo.outChannels; ++d2) {\n                    yVals[yOffset4 + d2] += xVal * wVals[wOffset4 + d2];\n                  }\n                  wOffset4 += convInfo.outChannels;\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n  }\n\n  return backend.makeTensorInfo(y.shape, y.dtype, y.values);\n}\n\nexport const conv3DConfig: KernelConfig = {\n  kernelName: Conv3D,\n  backendName: 'cpu',\n  kernelFunc: conv3D as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Conv3DBackpropFilterV2, Conv3DBackpropFilterV2Attrs, Conv3DBackpropFilterV2Inputs, KernelConfig, KernelFunc, TensorBuffer, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function conv3DBackpropFilterV2(args: {\n  inputs: Conv3DBackpropFilterV2Inputs,\n  backend: MathBackendCPU,\n  attrs: Conv3DBackpropFilterV2Attrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x, dy} = inputs;\n  const {strides, pad, filterShape} = attrs;\n\n  assertNotComplex([x, dy], 'conv3dBackpropFilterV2');\n\n  const xStrides = util.computeStrides(x.shape);\n  const dyStrides = util.computeStrides(dy.shape);\n\n  const convInfo = backend_util.computeConv3DInfo(\n      x.shape as [number, number, number, number, number], filterShape, strides,\n      1 /* dilations */, pad);\n\n  const strideDepth = convInfo.strideDepth;\n  const strideHeight = convInfo.strideHeight;\n  const strideWidth = convInfo.strideWidth;\n  const filterDepth = convInfo.filterDepth;\n  const filterHeight = convInfo.filterHeight;\n  const filterWidth = convInfo.filterWidth;\n\n  const dw = new TensorBuffer(convInfo.filterShape, 'float32');\n  const dwValues = dw.values;\n  const [dwS0, dwS1, dwS2, dwS3] = dw.strides;\n  const dyValues = backend.data.get(dy.dataId).values as TypedArray;\n  const [dyS0, dyS1, dyS2, dyS3] = dyStrides;\n  const xValues = backend.data.get(x.dataId).values as TypedArray;\n  const [xS0, xS1, xS2, xS3] = xStrides;\n\n  const frontPad = convInfo.padInfo.front;\n  const leftPad = convInfo.padInfo.left;\n  const topPad = convInfo.padInfo.top;\n\n  for (let wF = 0; wF < filterDepth; ++wF) {\n    const yFMin = Math.max(0, Math.ceil((frontPad - wF) / strideDepth));\n    const yFMax = Math.min(\n        convInfo.outDepth, (convInfo.inDepth + frontPad - wF) / strideDepth);\n    const wOffset1 = wF * dwS0;\n\n    for (let wR = 0; wR < filterHeight; ++wR) {\n      const yRMin = Math.max(0, Math.ceil((topPad - wR) / strideHeight));\n      const yRMax = Math.min(\n          convInfo.outHeight, (convInfo.inHeight + topPad - wR) / strideHeight);\n      const wOffset2 = wR * dwS1 + wOffset1;\n\n      for (let wC = 0; wC < filterWidth; ++wC) {\n        const yCMin = Math.max(0, Math.ceil((leftPad - wC) / strideWidth));\n        const yCMax = Math.min(\n            convInfo.outWidth, (convInfo.inWidth + leftPad - wC) / strideWidth);\n        const wOffset3 = wC * dwS2 + wOffset2;\n\n        for (let d1 = 0; d1 < convInfo.inChannels; ++d1) {\n          const wOffset4 = d1 * dwS3 + wOffset3;\n\n          for (let d2 = 0; d2 < convInfo.outChannels; ++d2) {\n            let dotProd = 0;\n            for (let b = 0; b < convInfo.batchSize; ++b) {\n              const xOffset1 = b * xS0;\n              const yOffset1 = b * dyS0;\n\n              for (let yF = yFMin; yF < yFMax; ++yF) {\n                const xF = wF + yF * strideDepth - frontPad;\n                const xOffset2 = xF * xS1 + xOffset1;\n                const yOffset2 = yF * dyS1 + yOffset1;\n\n                for (let yR = yRMin; yR < yRMax; ++yR) {\n                  const xR = wR + yR * strideHeight - topPad;\n                  const xOffset3 = xR * xS2 + xOffset2;\n                  const yOffset3 = yR * dyS2 + yOffset2;\n\n                  for (let yC = yCMin; yC < yCMax; ++yC) {\n                    const xC = wC + yC * strideWidth - leftPad;\n                    const xOffset4 = xC * xS3 + xOffset3;\n                    const yOffset4 = yC * dyS3 + yOffset3;\n\n                    dotProd += xValues[xOffset4 + d1] * dyValues[yOffset4 + d2];\n                  }\n                }\n              }\n            }\n            dwValues[wOffset4 + d2] = dotProd;\n          }\n        }\n      }\n    }\n  }\n\n  return backend.makeTensorInfo(dw.shape, dw.dtype, dw.values);\n}\n\nexport const conv3DBackpropFilterV2Config: KernelConfig = {\n  kernelName: Conv3DBackpropFilterV2,\n  backendName: 'cpu',\n  kernelFunc: conv3DBackpropFilterV2 as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Conv3DBackpropInputV2, Conv3DBackpropInputV2Attrs, Conv3DBackpropInputV2Inputs, KernelConfig, KernelFunc, TensorBuffer, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function conv3DBackpropInputV2(args: {\n  inputs: Conv3DBackpropInputV2Inputs,\n  backend: MathBackendCPU,\n  attrs: Conv3DBackpropInputV2Attrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {dy, filter} = inputs;\n  const {pad, strides, inputShape} = attrs;\n\n  assertNotComplex([dy], 'conv3dBackpropInputV2');\n\n  const dyStrides = util.computeStrides(dy.shape);\n  const filterStrides = util.computeStrides(filter.shape);\n\n  const convInfo = backend_util.computeConv3DInfo(\n      inputShape, filter.shape as [number, number, number, number, number],\n      strides, 1 /* dilations */, pad);\n\n  const dx = new TensorBuffer(convInfo.inShape, 'float32');\n  const dxValues = dx.values;\n  const [dxS0, dxS1, dxS2, dxS3] = dx.strides;\n  const dyValues = backend.data.get(dy.dataId).values as TypedArray;\n  const [dyS0, dyS1, dyS2, dyS3] = dyStrides;\n  const fltValues = backend.data.get(filter.dataId).values as TypedArray;\n  const [fltS0, fltS1, fltS2, fltS3] = filterStrides;\n  const {\n    batchSize,\n    filterDepth,\n    filterHeight,\n    filterWidth,\n    inChannels,\n    inDepth,\n    inHeight,\n    inWidth,\n    outChannels,\n    outDepth,\n    outHeight,\n    outWidth,\n    strideDepth,\n    strideHeight,\n    strideWidth\n  } = convInfo;\n  const frontPad = filterDepth - 1 - convInfo.padInfo.front;\n  const topPad = filterHeight - 1 - convInfo.padInfo.top;\n  const leftPad = filterWidth - 1 - convInfo.padInfo.left;\n\n  for (let b = 0; b < batchSize; ++b) {\n    for (let d1 = 0; d1 < inChannels; ++d1) {\n      // Frames of depth\n      for (let xF = 0; xF < inDepth; ++xF) {\n        const xFCorner = xF - frontPad;\n        const xFMin = Math.max(0, Math.ceil(xFCorner / strideDepth));\n        const yFMax =\n            Math.min(outDepth, (filterDepth + xFCorner) / strideDepth);\n\n        // Rows as per standard 2d matrix notation\n        for (let xR = 0; xR < inHeight; ++xR) {\n          const xRCorner = xR - topPad;\n          const xRMin = Math.max(0, Math.ceil(xRCorner / strideHeight));\n          const yRMax =\n              Math.min(outHeight, (filterHeight + xRCorner) / strideHeight);\n          // Columns as per standard 2d matrix notation\n          for (let xC = 0; xC < inWidth; ++xC) {\n            const xCCorner = xC - leftPad;\n            const xCMin = Math.max(0, Math.ceil(xCCorner / strideWidth));\n            const yCMax =\n                Math.min(outWidth, (filterWidth + xCCorner) / strideWidth);\n\n            let dotProd = 0;\n            for (let yF = xFMin; yF < yFMax; ++yF) {\n              const wF = yF * strideDepth - xFCorner;\n\n              for (let yR = xRMin; yR < yRMax; ++yR) {\n                const wR = yR * strideHeight - xRCorner;\n\n                for (let yC = xCMin; yC < yCMax; ++yC) {\n                  const wC = yC * strideWidth - xCCorner;\n                  const dyOffset = dyS0 * b + dyS1 * yF + dyS2 * yR + dyS3 * yC;\n                  const fltOffset = fltS0 * (filterDepth - 1 - wF) +\n                      fltS1 * (filterHeight - 1 - wR) +\n                      fltS2 * (filterWidth - 1 - wC) + fltS3 * d1;\n\n                  for (let d2 = 0; d2 < outChannels; ++d2) {\n                    const pixel = dyValues[dyOffset + d2];\n                    const weight = fltValues[fltOffset + d2];\n                    dotProd += pixel * weight;\n                  }\n                }\n              }\n            }\n            dxValues[dxS0 * b + dxS1 * xF + dxS2 * xR + dxS3 * xC + d1] =\n                dotProd;\n          }\n        }\n      }\n    }\n  }\n\n  return backend.makeTensorInfo(dx.shape, dx.dtype, dx.values);\n}\n\nexport const conv3DBackpropInputV2Config: KernelConfig = {\n  kernelName: Conv3DBackpropInputV2,\n  backendName: 'cpu',\n  kernelFunc: conv3DBackpropInputV2 as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Cos, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const cos = unaryKernelFunc(Cos, (xi) => Math.cos(xi));\n\nexport const cosConfig: KernelConfig = {\n  kernelName: Cos,\n  backendName: 'cpu',\n  kernelFunc: cos,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Cosh, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const cosh = unaryKernelFunc(Cosh, (xi) => Math.cosh(xi));\n\nexport const coshConfig: KernelConfig = {\n  kernelName: Cosh,\n  backendName: 'cpu',\n  kernelFunc: cosh,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {buffer, CropAndResize, CropAndResizeAttrs, CropAndResizeInputs, KernelConfig, KernelFunc, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nexport function cropAndResize(args: {\n  inputs: CropAndResizeInputs,\n  backend: MathBackendCPU,\n  attrs: CropAndResizeAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {image, boxes, boxInd} = inputs;\n  const {cropSize, method, extrapolationValue} = attrs;\n\n  const [batch, imageHeight, imageWidth, numChannels] = image.shape;\n  const numBoxes = boxes.shape[0];\n\n  const [cropHeight, cropWidth] = cropSize;\n  const output =\n      buffer([numBoxes, cropHeight, cropWidth, numChannels], 'float32');\n\n  const boxVals = backend.data.get(boxes.dataId).values as TypedArray;\n  const boxIndVals = backend.data.get(boxInd.dataId).values as TypedArray;\n  const imageVals = backend.data.get(image.dataId).values as TypedArray;\n\n  const inStride =\n      util.computeStrides(image.shape);  // to calculate flat indexes into image\n  const outStride = util.computeStrides(\n      output.shape);  // to calculate flat indexes into output\n\n  // Reference implementation\n  // tslint:disable-next-line:max-line-length\n  // https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/crop_and_resize_op.cc\n  for (let b = 0; b < numBoxes; b++) {\n    const startInd = b * 4;\n    const y1 = boxVals[startInd];\n    const x1 = boxVals[startInd + 1];\n    const y2 = boxVals[startInd + 2];\n    const x2 = boxVals[startInd + 3];\n\n    const bInd: number = boxIndVals[b];\n    if (bInd >= batch) {\n      continue;\n    }\n\n    const heightScale =\n        (cropHeight > 1) ? (y2 - y1) * (imageHeight - 1) / (cropHeight - 1) : 0;\n    const widthScale =\n        (cropWidth > 1) ? (x2 - x1) * (imageWidth - 1) / (cropWidth - 1) : 0;\n\n    for (let y = 0; y < cropHeight; y++) {\n      const yInd: number = (cropHeight > 1) ?\n          y1 * (imageHeight - 1) + y * (heightScale) :\n          0.5 * (y1 + y2) * (imageHeight - 1);\n\n      if (yInd < 0 || yInd > imageHeight - 1) {\n        for (let x = 0; x < cropWidth; x++) {\n          for (let c = 0; c < numChannels; c++) {\n            const ind =\n                c + x * outStride[2] + y * outStride[1] + b * outStride[0];\n            output.values[ind] = extrapolationValue;\n          }\n        }\n        continue;\n      }\n\n      if (method === 'bilinear') {\n        const topInd = Math.floor(yInd);\n        const bottomInd = Math.ceil(yInd);\n        const yLerp = yInd - topInd;\n\n        for (let x = 0; x < cropWidth; x++) {\n          const xInd = (cropWidth > 1) ?\n              x1 * (imageWidth - 1) + x * widthScale :\n              0.5 * (x1 + x2) * (imageWidth - 1);\n\n          if (xInd < 0 || xInd > imageWidth - 1) {\n            for (let c = 0; c < numChannels; c++) {\n              const ind =\n                  c + x * outStride[2] + y * outStride[1] + b * outStride[0];\n              output.values[ind] = extrapolationValue;\n            }\n            continue;\n          }\n\n          const leftInd = Math.floor(xInd);\n          const rightInd = Math.ceil(xInd);\n          const xLerp = xInd - leftInd;\n\n          for (let c = 0; c < numChannels; c++) {\n            let ind = c + leftInd * inStride[2] + topInd * inStride[1] +\n                bInd * inStride[0];\n            const topLeft = imageVals[ind];\n\n            ind = c + rightInd * inStride[2] + topInd * inStride[1] +\n                bInd * inStride[0];\n            const topRight = imageVals[ind];\n\n            ind = c + leftInd * inStride[2] + bottomInd * inStride[1] +\n                bInd * inStride[0];\n            const bottomLeft = imageVals[ind];\n\n            ind = c + rightInd * inStride[2] + bottomInd * inStride[1] +\n                bInd * inStride[0];\n            const bottomRight = imageVals[ind];\n\n            const top = topLeft + (topRight - topLeft) * xLerp;\n            const bottom = bottomLeft + (bottomRight - bottomLeft) * xLerp;\n\n            ind = c + x * outStride[2] + y * outStride[1] + b * outStride[0];\n            output.values[ind] = top + ((bottom - top) * yLerp);\n          }\n        }\n      } else {  // method == \"nearest\"\n        for (let x = 0; x < cropWidth; ++x) {\n          const xInd = (cropWidth > 1) ?\n              x1 * (imageWidth - 1) + x * widthScale :\n              0.5 * (x1 + x2) * (imageWidth - 1);\n\n          if (xInd < 0 || xInd > imageWidth - 1) {\n            for (let c = 0; c < numChannels; c++) {\n              const ind =\n                  c + x * outStride[2] + y * outStride[1] + b * outStride[0];\n              output.values[ind] = extrapolationValue;\n            }\n            continue;\n          }\n\n          const closestX = Math.round(xInd);\n          const closestY = Math.round(yInd);\n          for (let c = 0; c < numChannels; c++) {\n            const inInd = c + closestX * inStride[2] + closestY * inStride[1] +\n                bInd * inStride[0];\n            const outInd =\n                c + x * outStride[2] + y * outStride[1] + b * outStride[0];\n            output.values[outInd] = imageVals[inInd];\n          }\n        }\n      }\n    }\n  }\n\n  return backend.makeTensorInfo(output.shape, output.dtype, output.values);\n}\n\nexport const cropAndResizeConfig: KernelConfig = {\n  kernelName: CropAndResize,\n  backendName: 'cpu',\n  kernelFunc: cropAndResize as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Cumprod, CumprodAttrs, CumprodInputs, KernelConfig, KernelFunc, TensorInfo, TypedArray, upcastType, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\nimport {transpose} from './Transpose';\n\nexport function cumprod(\n    args: {inputs: CumprodInputs, backend: MathBackendCPU,\n           attrs: CumprodAttrs}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {axis, exclusive, reverse} = attrs;\n\n  assertNotComplex(x, 'cumprod');\n\n  const permutation = backend_util.getAxesPermutation([axis], x.shape.length);\n  let $x = x;\n  if (permutation != null) {\n    $x = transpose({inputs: {x}, backend, attrs: {perm: permutation}});\n  }\n  const permutedAxis = backend_util.getInnerMostAxes(1, x.shape.length)[0];\n\n  if (permutedAxis !== $x.shape.length - 1) {\n    throw new Error(\n        `backend.cumprod in CPU expects an inner-most ` +\n        `axis=${$x.shape.length - 1} but got axis=${permutedAxis}`);\n  }\n\n  const resultDtype = upcastType($x.dtype, 'int32');\n  const vals = util.makeOnesTypedArray(\n                   util.sizeFromShape($x.shape), resultDtype) as TypedArray;\n\n  const aVals = backend.data.get($x.dataId).values as TypedArray;\n  const finalDim = $x.shape[$x.shape.length - 1];\n  const indexAdjuster = reverse ?\n      (i: number, j: number) => i + finalDim - j - 1 :\n      (i: number, j: number) => i + j;\n  for (let i = 0; i < aVals.length; i += finalDim) {\n    for (let j = 0; j < finalDim; j++) {\n      const idx = indexAdjuster(i, j);\n      if (j === 0) {\n        vals[idx] = exclusive ? 1 : aVals[idx];\n      } else {\n        const prevIdx = indexAdjuster(i, j - 1);\n        vals[idx] = exclusive ? aVals[prevIdx] * vals[prevIdx] :\n                                aVals[idx] * vals[prevIdx];\n      }\n    }\n  }\n\n  const result = backend.makeTensorInfo($x.shape, resultDtype, vals);\n\n  if (permutation != null) {\n    const reversePermutation = backend_util.getUndoAxesPermutation(permutation);\n    const reverseTransposedResult = transpose(\n        {inputs: {x: result}, backend, attrs: {perm: reversePermutation}});\n\n    backend.disposeIntermediateTensorInfo(result);\n    backend.disposeIntermediateTensorInfo($x);\n\n    return reverseTransposedResult;\n  }\n\n  return result;\n}\n\nexport const cumprodConfig: KernelConfig = {\n  kernelName: Cumprod,\n  backendName: 'cpu',\n  kernelFunc: cumprod as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Cumsum, CumsumAttrs, CumsumInputs, KernelConfig, KernelFunc, TensorInfo, TypedArray, upcastType, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\nimport {transpose} from './Transpose';\n\nexport function cumsum(\n    args: {inputs: CumsumInputs, backend: MathBackendCPU, attrs: CumsumAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {axis, exclusive, reverse} = attrs;\n\n  assertNotComplex(x, 'cumsum');\n\n  const permutation = backend_util.getAxesPermutation([axis], x.shape.length);\n  let $x = x;\n  if (permutation != null) {\n    $x = transpose({inputs: {x}, backend, attrs: {perm: permutation}});\n  }\n  const permutedAxis = backend_util.getInnerMostAxes(1, x.shape.length)[0];\n\n  if (permutedAxis !== $x.shape.length - 1) {\n    throw new Error(\n        `backend.cumsum in CPU expects an inner-most ` +\n        `axis=${$x.shape.length - 1} but got axis=${permutedAxis}`);\n  }\n\n  const resultDtype = upcastType($x.dtype, 'int32');\n  const vals = util.makeZerosTypedArray(\n                   util.sizeFromShape($x.shape), resultDtype) as TypedArray;\n\n  const aVals = backend.data.get($x.dataId).values as TypedArray;\n  const finalDim = $x.shape[$x.shape.length - 1];\n  const indexAdjuster = reverse ?\n      (i: number, j: number) => i + finalDim - j - 1 :\n      (i: number, j: number) => i + j;\n  for (let i = 0; i < aVals.length; i += finalDim) {\n    for (let j = 0; j < finalDim; j++) {\n      const idx = indexAdjuster(i, j);\n      if (j === 0) {\n        vals[idx] = exclusive ? 0 : aVals[idx];\n      } else {\n        const prevIdx = indexAdjuster(i, j - 1);\n        vals[idx] = exclusive ? aVals[prevIdx] + vals[prevIdx] :\n                                aVals[idx] + vals[prevIdx];\n      }\n    }\n  }\n\n  const result = backend.makeTensorInfo($x.shape, resultDtype, vals);\n\n  if (permutation != null) {\n    const reversePermutation = backend_util.getUndoAxesPermutation(permutation);\n    const reverseTransposedResult = transpose(\n        {inputs: {x: result}, backend, attrs: {perm: reversePermutation}});\n\n    backend.disposeIntermediateTensorInfo(result);\n    backend.disposeIntermediateTensorInfo($x);\n\n    return reverseTransposedResult;\n  }\n\n  return result;\n}\n\nexport const cumsumConfig: KernelConfig = {\n  kernelName: Cumsum,\n  backendName: 'cpu',\n  kernelFunc: cumsum as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DenseBincount, DenseBincountAttrs, DenseBincountInputs, KernelConfig, KernelFunc, Rank, TensorInfo, TypedArray} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {bincountImpl, bincountReduceImpl} from './Bincount_impl';\n\nexport function denseBincount(args: {\n  inputs: DenseBincountInputs,\n  backend: MathBackendCPU,\n  attrs: DenseBincountAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x, weights} = inputs;\n  const {size, binaryOutput} = attrs;\n\n  if (x.shape.length === 1) {\n    const xVals = backend.data.get(x.dataId).values as TypedArray;\n    const weightsVals = backend.data.get(weights.dataId).values as TypedArray;\n\n    const outVals =\n        bincountImpl(xVals, weightsVals, weights.dtype, weights.shape, size);\n\n    return backend.makeTensorInfo([size], weights.dtype, outVals);\n  } else if (x.shape.length === 2) {\n    const xBuf = backend.bufferSync<Rank, 'float32'>(x);\n    const weightsBuf = backend.bufferSync<Rank, 'float32'>(weights);\n\n    const outBuf = bincountReduceImpl(xBuf, weightsBuf, size, binaryOutput);\n\n    return backend.makeTensorInfo(outBuf.shape, weights.dtype, outBuf.values);\n  }\n\n  throw new Error(\n      `Error in denseBincount: input must be at most rank 2, but got rank` +\n      `${x.shape.length}.`);\n}\n\nexport const denseBincountConfig: KernelConfig = {\n  kernelName: DenseBincount,\n  backendName: 'cpu',\n  kernelFunc: denseBincount as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DepthToSpace, DepthToSpaceAttrs, DepthToSpaceInputs, KernelConfig, KernelFunc, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nexport function depthToSpace(args: {\n  inputs: DepthToSpaceInputs,\n  backend: MathBackendCPU,\n  attrs: DepthToSpaceAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {blockSize, dataFormat} = attrs;\n\n  util.assert(\n      dataFormat === 'NHWC',\n      () => `Only NHWC dataFormat supported on CPU for depthToSpace. Got ${\n          dataFormat}`);\n\n  const batchSize = x.shape[0];\n  const inputHeight = x.shape[1];\n  const inputWidth = x.shape[2];\n  const inputDepth = x.shape[3];\n\n  const outputHeight = inputHeight * blockSize;\n  const outputWidth = inputWidth * blockSize;\n  const outputDepth = inputDepth / (blockSize * blockSize);\n\n  const xValues = backend.data.get(x.dataId).values as TypedArray;\n  const result =\n      new Float32Array(batchSize * outputHeight * outputWidth * outputDepth);\n\n  let outputIdx = 0;\n  for (let b = 0; b < batchSize; ++b) {\n    for (let h = 0; h < outputHeight; ++h) {\n      const inH = Math.floor(h / blockSize);\n      const offsetH = (h % blockSize);\n      for (let w = 0; w < outputWidth; ++w) {\n        const inW = Math.floor(w / blockSize);\n        const offsetW = (w % blockSize);\n        const offsetD = (offsetH * blockSize + offsetW) * outputDepth;\n        for (let d = 0; d < outputDepth; ++d) {\n          const inD = d + offsetD;\n          const inputIdx =\n              inD + inputDepth * (inW + inputWidth * (inH + inputHeight * b));\n          result[outputIdx++] = xValues[inputIdx];\n        }\n      }\n    }\n  }\n\n  return backend.makeTensorInfo(\n      [batchSize, outputHeight, outputWidth, outputDepth], x.dtype, result);\n}\n\nexport const depthToSpaceConfig: KernelConfig = {\n  kernelName: DepthToSpace,\n  backendName: 'cpu',\n  kernelFunc: depthToSpace as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, DepthwiseConv2dNative, DepthwiseConv2dNativeAttrs, DepthwiseConv2dNativeInputs, KernelConfig, KernelFunc, TensorBuffer, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function depthwiseConv2dNative(args: {\n  inputs: DepthwiseConv2dNativeInputs,\n  backend: MathBackendCPU,\n  attrs: DepthwiseConv2dNativeAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x, filter} = inputs;\n  const {strides, pad, dilations, dimRoundingMode} = attrs;\n\n  assertNotComplex([x, filter], 'depthwiseConv2DNative');\n\n  const xStrides = util.computeStrides(x.shape);\n  const filterStrides = util.computeStrides(filter.shape);\n\n  let $dilations = dilations;\n  if ($dilations == null) {\n    $dilations = [1, 1];\n  }\n\n  util.assert(\n      backend_util.eitherStridesOrDilationsAreOne(strides, $dilations),\n      () => 'Error in depthwiseConv2d: Either strides or dilations must be ' +\n          `1. Got strides ${strides} and dilations '${$dilations}'`);\n\n  const convInfo = backend_util.computeConv2DInfo(\n      x.shape as [number, number, number, number],\n      filter.shape as [number, number, number, number], strides, $dilations,\n      pad, dimRoundingMode, true /* depthwise */);\n\n  const {filterHeight, filterWidth, dilationHeight, dilationWidth, padInfo} =\n      convInfo;\n  const padLeft = padInfo.left;\n  const padTop = padInfo.top;\n  const chMul = convInfo.outChannels / convInfo.inChannels;\n  const y = new TensorBuffer(convInfo.outShape, x.dtype as 'float32');\n  const xVals = backend.data.get(x.dataId).values as TypedArray;\n  const wVals = backend.data.get(filter.dataId).values as TypedArray;\n  const yVals = y.values;\n\n  for (let b = 0; b < convInfo.batchSize; ++b) {\n    const xOffset1 = b * xStrides[0];\n    const yOffset1 = b * y.strides[0];\n    for (let yR = 0; yR < convInfo.outHeight; ++yR) {\n      const yOffset2 = yOffset1 + yR * y.strides[1];\n      const xRCorner = yR * convInfo.strideHeight - padTop;\n      for (let wR = 0; wR < filterHeight; ++wR) {\n        const xR = xRCorner + wR * dilationHeight;\n        if (xR < 0 || xR >= convInfo.inHeight) {\n          continue;\n        }\n        const wOffset1 = wR * filterStrides[0];\n        const xOffset2 = xOffset1 + xR * xStrides[1];\n        for (let yC = 0; yC < convInfo.outWidth; ++yC) {\n          const yOffset3 = yOffset2 + yC * y.strides[2];\n          const xCCorner = yC * convInfo.strideWidth - padLeft;\n          for (let wC = 0; wC < filterWidth; ++wC) {\n            const xC = xCCorner + wC * dilationWidth;\n            if (xC < 0 || xC >= convInfo.inWidth) {\n              continue;\n            }\n            const wOffset2 = wOffset1 + wC * filterStrides[1];\n            const xOffset3 = xOffset2 + xC * convInfo.inChannels;\n            let yOffset4 = yOffset3;\n            let wOffset3 = wOffset2;\n            for (let d1 = 0; d1 < convInfo.inChannels; ++d1) {\n              const xVal = xVals[xOffset3 + d1];\n              for (let q = 0; q < chMul; ++q) {\n                yVals[yOffset4 + q] += xVal * wVals[wOffset3 + q];\n              }\n              yOffset4 += chMul;\n              wOffset3 += chMul;\n            }\n          }\n        }\n      }\n    }\n  }\n\n  return backend.makeTensorInfo(y.shape, y.dtype, y.values);\n}\n\nexport const depthwiseConv2dNativeConfig: KernelConfig = {\n  kernelName: DepthwiseConv2dNative,\n  backendName: 'cpu',\n  kernelFunc: depthwiseConv2dNative as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, DepthwiseConv2dNativeBackpropFilter, DepthwiseConv2dNativeBackpropFilterAttrs, DepthwiseConv2dNativeBackpropFilterInputs, KernelConfig, KernelFunc, TensorBuffer, TensorInfo, TypedArray} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function depthwiseConv2dNativeBackpropFilter(args: {\n  inputs: DepthwiseConv2dNativeBackpropFilterInputs,\n  backend: MathBackendCPU,\n  attrs: DepthwiseConv2dNativeBackpropFilterAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x, dy} = inputs;\n  const {strides, dilations, pad, dimRoundingMode, filterShape} = attrs;\n\n  assertNotComplex([x, dy], 'depthwiseConv2dNativeBackpropFilter');\n\n  const convInfo = backend_util.computeConv2DInfo(\n      x.shape as [number, number, number, number], filterShape, strides,\n      dilations, pad, dimRoundingMode, true /* depthwise */);\n\n  const {strideHeight, strideWidth, filterHeight, filterWidth} = convInfo;\n\n  const dW = new TensorBuffer(convInfo.filterShape, 'float32');\n\n  const leftPad = convInfo.padInfo.left;\n  const topPad = convInfo.padInfo.top;\n  const chMul = convInfo.outChannels / convInfo.inChannels;\n\n  const xVals = backend.data.get(x.dataId).values as TypedArray;\n  const xBuf = new TensorBuffer(x.shape, x.dtype, xVals);\n  const dyVals = backend.data.get(dy.dataId).values as TypedArray;\n  const dyBuf = new TensorBuffer(dy.shape, dy.dtype, dyVals);\n  for (let wR = 0; wR < filterHeight; ++wR) {\n    const yRMin = Math.max(0, Math.ceil((topPad - wR) / strideHeight));\n    const yRMax = Math.min(\n        convInfo.outHeight, (convInfo.inHeight + topPad - wR) / strideHeight);\n\n    for (let wC = 0; wC < filterWidth; ++wC) {\n      const yCMin = Math.max(0, Math.ceil((leftPad - wC) / strideWidth));\n      const yCMax = Math.min(\n          convInfo.outWidth, (convInfo.inWidth + leftPad - wC) / strideWidth);\n\n      for (let d2 = 0; d2 < convInfo.outChannels; ++d2) {\n        const d1 = Math.trunc(d2 / chMul);\n        const dm = d2 % chMul;\n\n        let dotProd = 0;\n        for (let b = 0; b < convInfo.batchSize; ++b) {\n          for (let yR = yRMin; yR < yRMax; ++yR) {\n            const xR = wR + yR * strideHeight - topPad;\n            for (let yC = yCMin; yC < yCMax; ++yC) {\n              const xC = wC + yC * strideWidth - leftPad;\n              dotProd += (xBuf.get(b, xR, xC, d1) as number) *\n                  (dyBuf.get(b, yR, yC, d2) as number);\n            }\n          }\n        }\n        dW.set(dotProd, wR, wC, d1, dm);\n      }\n    }\n  }\n\n  return backend.makeTensorInfo(dW.shape, dW.dtype, dW.values);\n}\n\nexport const depthwiseConv2dNativeBackpropFilterConfig: KernelConfig = {\n  kernelName: DepthwiseConv2dNativeBackpropFilter,\n  backendName: 'cpu',\n  kernelFunc: depthwiseConv2dNativeBackpropFilter as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, DepthwiseConv2dNativeBackpropInput, DepthwiseConv2dNativeBackpropInputAttrs, DepthwiseConv2dNativeBackpropInputInputs, KernelConfig, KernelFunc, TensorBuffer, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function depthwiseConv2dNativeBackpropInput(args: {\n  inputs: DepthwiseConv2dNativeBackpropInputInputs,\n  backend: MathBackendCPU,\n  attrs: DepthwiseConv2dNativeBackpropInputAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {dy, filter} = inputs;\n  const {strides, dilations, pad, dimRoundingMode, inputShape} = attrs;\n\n  assertNotComplex([dy, filter], 'depthwiseConv2DNativeBackpropInput');\n\n  const dyStrides = util.computeStrides(dy.shape);\n  const filterStrides = util.computeStrides(filter.shape);\n\n  const convInfo = backend_util.computeConv2DInfo(\n      inputShape, filter.shape as [number, number, number, number], strides,\n      dilations, pad, dimRoundingMode, true /* depthwise */);\n\n  const dx = new TensorBuffer(convInfo.inShape, 'float32');\n  const dxValues = dx.values;\n  const [dxS0, dxS1, dxS2] = dx.strides;\n  const dyValues = backend.data.get(dy.dataId).values as TypedArray;\n  const [dyS0, dyS1, dyS2] = dyStrides;\n  const fltValues = backend.data.get(filter.dataId).values as TypedArray;\n  const [fltS0, fltS1, fltS2] = filterStrides;\n  const {\n    batchSize,\n    filterHeight,\n    filterWidth,\n    inChannels,\n    inHeight,\n    inWidth,\n    outChannels,\n    outHeight,\n    outWidth,\n    strideHeight,\n    strideWidth\n  } = convInfo;\n  const topPad = filterHeight - 1 - convInfo.padInfo.top;\n  const leftPad = filterWidth - 1 - convInfo.padInfo.left;\n  const chMul = outChannels / inChannels;\n\n  for (let b = 0; b < batchSize; ++b) {\n    for (let d1 = 0; d1 < inChannels; ++d1) {\n      for (let xR = 0; xR < inHeight; ++xR) {\n        const xRCorner = xR - topPad;\n        const xRMin = Math.max(0, Math.ceil(xRCorner / strideHeight));\n        const yRMax =\n            Math.min(outHeight, (filterHeight + xRCorner) / strideHeight);\n\n        for (let xC = 0; xC < inWidth; ++xC) {\n          const xCCorner = xC - leftPad;\n          const xCMin = Math.max(0, Math.ceil(xCCorner / strideWidth));\n          const yCMax =\n              Math.min(outWidth, (filterWidth + xCCorner) / strideWidth);\n\n          let dotProd = 0;\n          for (let yR = xRMin; yR < yRMax; ++yR) {\n            const wR = yR * strideHeight - xRCorner;\n\n            for (let yC = xCMin; yC < yCMax; ++yC) {\n              const wC = yC * strideWidth - xCCorner;\n              const dyOffset = dyS0 * b + dyS1 * yR + dyS2 * yC;\n              const fltOffset = fltS0 * (filterHeight - 1 - wR) +\n                  fltS1 * (filterWidth - 1 - wC) + fltS2 * d1;\n\n              for (let dm = 0; dm < chMul; ++dm) {\n                const d2 = d1 * chMul + dm;\n                const pixel = dyValues[dyOffset + d2];\n                const weight = fltValues[fltOffset + dm];\n                dotProd += pixel * weight;\n              }\n            }\n          }\n          dxValues[dxS0 * b + dxS1 * xR + dxS2 * xC + d1] = dotProd;\n        }\n      }\n    }\n  }\n\n  return backend.makeTensorInfo(dx.shape, dx.dtype, dx.values);\n}\n\nexport const depthwiseConv2dNativeBackpropInputConfig: KernelConfig = {\n  kernelName: DepthwiseConv2dNativeBackpropInput,\n  backendName: 'cpu',\n  kernelFunc: depthwiseConv2dNativeBackpropInput as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {buffer, Diag, DiagInputs, KernelConfig, KernelFunc, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nexport function diag(args: {inputs: DiagInputs, backend: MathBackendCPU}):\n    TensorInfo {\n  const {inputs, backend} = args;\n  const {x} = inputs;\n\n  const xSize = util.sizeFromShape(x.shape);\n\n  const xVals = backend.data.get(x.dataId).values as TypedArray;\n  const outBuf = buffer([xSize, xSize], x.dtype);\n  const vals = outBuf.values;\n  for (let i = 0; i < xVals.length; i++) {\n    vals[i * xSize + i] = xVals[i];\n  }\n\n  const outShape = [...x.shape, ...x.shape];\n\n  return backend.makeTensorInfo(outShape, outBuf.dtype, outBuf.values);\n}\n\nexport const diagConfig: KernelConfig = {\n  kernelName: Diag,\n  backendName: 'cpu',\n  kernelFunc: diag as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Dilation2D, Dilation2DAttrs, Dilation2DInputs, KernelConfig, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nexport const dilation2DConfig: KernelConfig = {\n  kernelName: Dilation2D,\n  backendName: 'cpu',\n  kernelFunc: ({inputs, backend, attrs}) => {\n    const {x, filter} = inputs as Dilation2DInputs;\n    const {strides, pad, dilations} = attrs as unknown as Dilation2DAttrs;\n    const cpuBackend = backend as MathBackendCPU;\n\n    const xVals = cpuBackend.data.get(x.dataId).values as TypedArray;\n    const xRank = x.shape.length;\n\n    const filterVals = cpuBackend.data.get(filter.dataId).values as TypedArray;\n    const filterRank = filter.shape.length;\n\n    const {\n      batchSize,\n      inHeight,\n      inWidth,\n      inChannels,\n      outHeight,\n      outWidth,\n      padInfo,\n      strideHeight,\n      strideWidth,\n      filterHeight,\n      filterWidth,\n      dilationHeight,\n      dilationWidth,\n      outShape\n    } =\n        backend_util.computeDilation2DInfo(\n            x.shape as [number, number, number, number],\n            filter.shape as [number, number, number], strides, pad,\n            'NHWC' /* dataFormat */, dilations);\n\n    const outSize = util.sizeFromShape(outShape);\n    const outRank = outShape.length;\n    const outputVals = util.getArrayFromDType(x.dtype, outSize);\n\n    // Upsampling the input by fill in `dilation size - 1` values between each\n    // input value.\n    // This implementation follows the TF c++ implementation:\n    // https://github.com/tensorflow/tensorflow/blob/d9a3a849edc198e90172bc58eb293de457f9d986/tensorflow/core/kernels/dilation_ops.cc\n    for (let b = 0; b < batchSize; ++b) {\n      for (let hOut = 0; hOut < outHeight; ++hOut) {\n        const hBeg = hOut * strideHeight - padInfo.top;\n        for (let wOut = 0; wOut < outWidth; ++wOut) {\n          const wBeg = wOut * strideWidth - padInfo.left;\n          for (let d = 0; d < inChannels; ++d) {\n            let curVal = Number.MIN_SAFE_INTEGER;\n            for (let h = 0; h < filterHeight; ++h) {\n              const hIn = hBeg + h * dilationHeight;\n              if (hIn >= 0 && hIn < inHeight) {\n                for (let w = 0; w < filterWidth; ++w) {\n                  const wIn = wBeg + w * dilationWidth;\n                  if (wIn >= 0 && wIn < inWidth) {\n                    const xIndex = util.locToIndex(\n                        [b, hIn, wIn, d], xRank, util.computeStrides(x.shape));\n                    const filterIndex = util.locToIndex(\n                        [h, w, d], filterRank,\n                        util.computeStrides(filter.shape));\n                    const val = xVals[xIndex] + filterVals[filterIndex];\n                    if (val > curVal) {\n                      curVal = val;\n                    }\n                  }\n                }\n              }\n            }\n            const outputIndex = util.locToIndex(\n                [b, hOut, wOut, d], outRank, util.computeStrides(outShape));\n            outputVals[outputIndex] = curVal;\n          }\n        }\n      }\n    }\n\n    const dataId = cpuBackend.write(\n        util.toTypedArray(outputVals, x.dtype), outShape, x.dtype);\n\n    return {dataId, shape: outShape, dtype: x.dtype};\n  }\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Dilation2DAttrs, Dilation2DBackpropFilter, Tensor3D, Tensor4D, TypedArray, util} from '@tensorflow/tfjs-core';\nimport {KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nexport const dilation2DBackpropFilterConfig: KernelConfig = {\n  kernelName: Dilation2DBackpropFilter,\n  backendName: 'cpu',\n  kernelFunc: ({inputs, backend, attrs}) => {\n    const {x, filter, dy} =\n        inputs as {x: Tensor4D, filter: Tensor3D, dy: Tensor4D};\n    const {strides, pad, dilations} = attrs as unknown as Dilation2DAttrs;\n    const cpuBackend = backend as MathBackendCPU;\n\n    const $x =\n        util.toNestedArray(\n            x.shape, cpuBackend.data.get(x.dataId).values as TypedArray) as\n        number[][][][];\n\n    const $filter = util.toNestedArray(\n                        filter.shape,\n                        cpuBackend.data.get(filter.dataId).values as\n                            TypedArray) as number[][][];\n\n    const {\n      batchSize,\n      inHeight,\n      inWidth,\n      inChannels,\n      outHeight,\n      outWidth,\n      padInfo,\n      strideHeight,\n      strideWidth,\n      filterHeight,\n      filterWidth,\n      dilationHeight,\n      dilationWidth,\n      outShape\n    } =\n        backend_util.computeDilation2DInfo(\n            x.shape as [number, number, number, number],\n            filter.shape as [number, number, number], strides, pad,\n            'NHWC' /* dataFormat */, dilations);\n\n    util.assert(\n        dy.rank === outShape.length,\n        () => `Error in ${Dilation2DBackpropFilter}, dy ` +\n            `must have the same rank as output ${outShape.length}, but got ` +\n            `${dy.rank}`);\n\n    const $dy =\n        util.toNestedArray(\n            outShape, cpuBackend.data.get(dy.dataId).values as TypedArray) as\n        number[][][][];\n\n    // The computed filter gradients has the same dimensions as the filter:\n    // [filterHeight, filterWidth, depth]\n    const gradients = util.makeZerosNestedTypedArray(\n                          filter.shape, filter.dtype) as number[][][];\n\n    // In the case of multiple argmax branches, we only back-propagate along the\n    // last branch, i.e., the one with largest value of `h * filter_cols + w`,\n    // similarly to the max-pooling backward routines.\n    // This implementation follows the TF c++ implementation:\n    // https://github.com/tensorflow/tensorflow/blob/d9a3a849edc198e90172bc58eb293de457f9d986/tensorflow/core/kernels/dilation_ops.cc\n    for (let b = 0; b < batchSize; ++b) {\n      for (let hOut = 0; hOut < outHeight; ++hOut) {\n        const hBeg = hOut * strideHeight - padInfo.top;\n        for (let wOut = 0; wOut < outWidth; ++wOut) {\n          const wBeg = wOut * strideWidth - padInfo.left;\n          for (let d = 0; d < inChannels; ++d) {\n            let curVal = Number.MIN_SAFE_INTEGER;\n            let hMax = 0;\n            let wMax = 0;\n            for (let h = 0; h < filterHeight; ++h) {\n              const hIn = hBeg + h * dilationHeight;\n              if (hIn >= 0 && hIn < inHeight) {\n                for (let w = 0; w < filterWidth; ++w) {\n                  const wIn = wBeg + w * dilationWidth;\n                  if (wIn >= 0 && wIn < inWidth) {\n                    const val = $x[b][hIn][wIn][d] + $filter[h][w][d];\n                    if (val > curVal) {\n                      curVal = val;\n                      hMax = h;\n                      wMax = w;\n                    }\n                  }\n                }\n              }\n            }\n            gradients[hMax][wMax][d] += $dy[b][hOut][wOut][d];\n          }\n        }\n      }\n    }\n\n    const dataId = cpuBackend.write(\n        util.toTypedArray(gradients, x.dtype), filter.shape, filter.dtype);\n\n    return {dataId, shape: filter.shape, dtype: filter.dtype};\n  }\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Dilation2DAttrs, Dilation2DBackpropInput, Tensor3D, Tensor4D, TypedArray, util} from '@tensorflow/tfjs-core';\nimport {KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nexport const dilation2DBackpropInputConfig: KernelConfig = {\n  kernelName: Dilation2DBackpropInput,\n  backendName: 'cpu',\n  kernelFunc: ({inputs, backend, attrs}) => {\n    const {x, filter, dy} =\n        inputs as {x: Tensor4D, filter: Tensor3D, dy: Tensor4D};\n    const {strides, pad, dilations} = attrs as unknown as Dilation2DAttrs;\n    const cpuBackend = backend as MathBackendCPU;\n\n    const $x =\n        util.toNestedArray(\n            x.shape, cpuBackend.data.get(x.dataId).values as TypedArray) as\n        number[][][][];\n\n    const $filter = util.toNestedArray(\n                        filter.shape,\n                        cpuBackend.data.get(filter.dataId).values as\n                            TypedArray) as number[][][];\n\n    const {\n      batchSize,\n      inHeight,\n      inWidth,\n      inChannels,\n      outHeight,\n      outWidth,\n      padInfo,\n      strideHeight,\n      strideWidth,\n      filterHeight,\n      filterWidth,\n      dilationHeight,\n      dilationWidth,\n      outShape\n    } =\n        backend_util.computeDilation2DInfo(\n            x.shape as [number, number, number, number],\n            filter.shape as [number, number, number], strides, pad,\n            'NHWC' /* dataFormat */, dilations);\n\n    util.assert(\n        dy.rank === outShape.length,\n        () => `Error in ${Dilation2DBackpropInput}, dy ` +\n            `must have the same rank as output ${outShape.length}, but got ` +\n            `${dy.rank}`);\n\n    const $dy =\n        util.toNestedArray(\n            outShape, cpuBackend.data.get(dy.dataId).values as TypedArray) as\n        number[][][][];\n\n    // The computed gradients has the same dimensions as the input:\n    // [batch, inputHeight, inputCols, inChannel]\n    const gradients =\n        util.makeZerosNestedTypedArray(x.shape, x.dtype) as number[][][][];\n\n    // In the case of multiple argmax branches, we only back-propagate along the\n    // last branch, i.e., the one with largest value of `h * filter_cols + w`,\n    // similarly to the max-pooling backward routines.\n    // This implementation follows the TF c++ implementation:\n    // https://github.com/tensorflow/tensorflow/blob/d9a3a849edc198e90172bc58eb293de457f9d986/tensorflow/core/kernels/dilation_ops.cc\n    for (let b = 0; b < batchSize; ++b) {\n      for (let hOut = 0; hOut < outHeight; ++hOut) {\n        const hBeg = hOut * strideHeight - padInfo.top;\n        for (let wOut = 0; wOut < outWidth; ++wOut) {\n          const wBeg = wOut * strideWidth - padInfo.left;\n          for (let d = 0; d < inChannels; ++d) {\n            let curVal = Number.MIN_SAFE_INTEGER;\n            let hInMax = (hBeg < 0) ? 0 : hBeg;\n            let wInMax = (wBeg < 0) ? 0 : wBeg;\n            for (let h = 0; h < filterHeight; ++h) {\n              const hIn = hBeg + h * dilationHeight;\n              if (hIn >= 0 && hIn < inHeight) {\n                for (let w = 0; w < filterWidth; ++w) {\n                  const wIn = wBeg + w * dilationWidth;\n                  if (wIn >= 0 && wIn < inWidth) {\n                    const val = $x[b][hIn][wIn][d] + $filter[h][w][d];\n                    if (val > curVal) {\n                      curVal = val;\n                      hInMax = hIn;\n                      wInMax = wIn;\n                    }\n                  }\n                }\n              }\n            }\n            gradients[b][hInMax][wInMax][d] += $dy[b][hOut][wOut][d];\n          }\n        }\n      }\n    }\n\n    const dataId = cpuBackend.write(\n        util.toTypedArray(gradients, x.dtype), x.shape, x.dtype);\n\n    return {dataId, shape: x.shape, dtype: x.dtype};\n  }\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, KernelConfig, KernelFunc, Sum, SumAttrs, SumInputs, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\nimport {zeros} from '../utils/zeros_impl';\nimport {cast} from './Cast';\nimport {identity} from './Identity';\nimport {reshape} from './Reshape';\nimport {transpose} from './Transpose';\n\nexport function sum(\n    args: {inputs: SumInputs, backend: MathBackendCPU, attrs: SumAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {axis, keepDims} = attrs;\n\n  assertNotComplex(x, 'sum');\n\n  let $x;\n  if (x.dtype === 'bool') {\n    $x = cast({inputs: {x}, backend, attrs: {dtype: 'int32'}});\n  } else {\n    $x = identity({inputs: {x}, backend});\n  }\n\n  const xRank = $x.shape.length;\n  const axes = util.parseAxisParam(axis, $x.shape);\n  const permutation = backend_util.getAxesPermutation(axes, xRank);\n\n  let reductionAxes = axes;\n  let permutedX = $x;\n  if (permutation != null) {\n    permutedX =\n        transpose({inputs: {x: $x}, backend, attrs: {perm: permutation}});\n    reductionAxes = backend_util.getInnerMostAxes(reductionAxes.length, xRank);\n  }\n\n  backend_util.assertAxesAreInnerMostDims(\n      'sum', reductionAxes, permutedX.shape.length);\n\n  const [outShape, reduceShape] =\n      backend_util.computeOutAndReduceShapes(permutedX.shape, reductionAxes);\n  const resultDtype = backend_util.upcastType(permutedX.dtype, 'int32');\n  let result = zeros(backend, outShape, resultDtype);\n  const reduceSize = util.sizeFromShape(reduceShape);\n  const vals = backend.data.get(result.dataId).values as TypedArray;\n\n  const aVals = backend.data.get(permutedX.dataId).values as TypedArray;\n  for (let i = 0; i < vals.length; ++i) {\n    const offset = i * reduceSize;\n    let sum = 0;\n    for (let j = 0; j < reduceSize; ++j) {\n      sum += aVals[offset + j];\n    }\n    vals[i] = sum;\n  }\n\n  if (keepDims) {\n    const newShape = backend_util.expandShapeToKeepDim(result.shape, axes);\n    const oldResult = result;\n    result = reshape({inputs: {x: result}, backend, attrs: {shape: newShape}});\n    backend.disposeIntermediateTensorInfo(oldResult);\n  }\n\n  backend.disposeIntermediateTensorInfo($x);\n\n  if (permutation != null) {\n    backend.disposeIntermediateTensorInfo(permutedX);\n  }\n\n  return result;\n}\n\nexport const sumConfig: KernelConfig = {\n  kernelName: Sum,\n  backendName: 'cpu',\n  kernelFunc: sum as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Einsum, EinsumAttrs, EinsumInputs, KernelConfig, KernelFunc, Tensor, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nimport {multiply} from './Multiply';\nimport {reshape} from './Reshape';\nimport {sum} from './Sum';\nimport {transpose} from './Transpose';\n\nexport function einsum(\n    args: {inputs: EinsumInputs, backend: MathBackendCPU, attrs: EinsumAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {equation} = attrs;\n  const tensors = inputs as Tensor[];\n\n  const {allDims, summedDims, idDims} =\n      backend_util.decodeEinsumEquation(equation, tensors.length);\n  backend_util.checkEinsumDimSizes(allDims.length, idDims, tensors);\n  const {path, steps} = backend_util.getEinsumComputePath(summedDims, idDims);\n\n  const nSteps = steps.length;\n  let out: TensorInfo|null = null;\n  let numDimsRemaining = allDims.length;\n  const tensorsToDispose: TensorInfo[] = [];\n  for (let i = 0; i < nSteps; ++i) {\n    for (const idTerm of steps[i]) {\n      const {permutationIndices: perm, expandDims: dimsToExpand} =\n          backend_util.getEinsumPermutation(numDimsRemaining, idDims[idTerm]);\n      let x: TensorInfo;\n      if (backend_util.isIdentityPermutation(perm)) {\n        x = tensors[idTerm];\n      } else {\n        x = transpose({inputs: {x: tensors[idTerm]}, backend, attrs: {perm}});\n        tensorsToDispose.push(x);\n      }\n      const targetShape: number[] = x.shape.slice();\n      for (let k = 0; k < dimsToExpand.length; ++k) {\n        targetShape.splice(dimsToExpand[k], 0, 1);\n      }\n\n      if (!util.arraysEqual(x.shape, targetShape)) {\n        x = reshape({inputs: {x}, backend, attrs: {shape: targetShape}});\n        tensorsToDispose.push(x);\n      }\n      if (out === null) {\n        out = x;\n      } else {\n        // tslint:disable-next-line: no-unnecessary-type-assertion\n        out = multiply({inputs: {a: x, b: out}, backend}) as TensorInfo;\n        tensorsToDispose.push(out);\n      }\n    }\n    if (i < nSteps - 1) {\n      if (path[i] >= 0) {\n        out = sum({\n          inputs: {x: out},\n          backend,\n          attrs: {\n            axis: path[i] - (allDims.length - numDimsRemaining),\n            keepDims: false\n          }\n        });\n        tensorsToDispose.push(out);\n      }\n      numDimsRemaining--;\n    }\n  }\n\n  // Clean up intermediate tensors.\n  for (const tensorInfo of tensorsToDispose) {\n    if (tensorInfo === out) {\n      continue;\n    }\n    backend.disposeIntermediateTensorInfo(tensorInfo);\n  }\n\n  return out;\n}\n\nexport const einsumConfig: KernelConfig = {\n  kernelName: Einsum,\n  backendName: 'cpu',\n  kernelFunc: einsum as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {EluGrad, EluGradInputs, KernelConfig, KernelFunc, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function eluGrad(args: {inputs: EluGradInputs, backend: MathBackendCPU}):\n    TensorInfo {\n  const {inputs, backend} = args;\n  const {dy, y} = inputs;\n\n  assertNotComplex([dy, y], 'eluGrad');\n\n  const resultValues = new Float32Array(util.sizeFromShape(y.shape));\n  const values = backend.data.get(y.dataId).values as TypedArray;\n  const dyValues = backend.data.get(dy.dataId).values as TypedArray;\n  for (let i = 0; i < values.length; ++i) {\n    const v = values[i];\n    if (v >= 0) {\n      resultValues[i] = dyValues[i];\n    } else {\n      resultValues[i] = dyValues[i] * (v + 1);\n    }\n  }\n\n  return backend.makeTensorInfo(y.shape, 'float32', resultValues);\n}\n\nexport const eluGradConfig: KernelConfig = {\n  kernelName: EluGrad,\n  backendName: 'cpu',\n  kernelFunc: eluGrad as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Erf, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nconst p = backend_util.ERF_P;\nconst a1 = backend_util.ERF_A1;\nconst a2 = backend_util.ERF_A2;\nconst a3 = backend_util.ERF_A3;\nconst a4 = backend_util.ERF_A4;\nconst a5 = backend_util.ERF_A5;\n\nexport const erf = unaryKernelFunc(\n    Erf,\n    (xi) => {\n      const sign = Math.sign(xi);\n      const v = Math.abs(xi);\n      const t = 1.0 / (1.0 + p * v);\n      return sign *\n          (1.0 -\n           (((((a5 * t + a4) * t) + a3) * t + a2) * t + a1) * t *\n               Math.exp(-v * v));\n    },\n);\n\nexport const erfConfig: KernelConfig = {\n  kernelName: Erf,\n  backendName: 'cpu',\n  kernelFunc: erf,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ExpandDims, ExpandDimsAttrs, ExpandDimsInputs, KernelConfig, KernelFunc, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {reshape} from './Reshape';\n\nexport function expandDims(args: {\n  inputs: ExpandDimsInputs,\n  backend: MathBackendCPU,\n  attrs: ExpandDimsAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {input} = inputs;\n  const {dim} = attrs;\n\n  const inputRank = input.shape.length;\n  const newShape = input.shape.slice();\n  let $dim = dim;\n  if (dim < 0) {\n    // Negative value is counted from the tail of rank.\n    util.assert(\n        -(inputRank + 1) <= dim,\n        () => `Axis must be in the interval [${- (inputRank + 1)}, ${\n            inputRank}]`);\n    $dim = inputRank + dim + 1;\n  }\n  newShape.splice($dim, 0, 1);\n\n  return reshape({inputs: {x: input}, backend, attrs: {shape: newShape}});\n}\n\nexport const expandDimsConfig: KernelConfig = {\n  kernelName: ExpandDims,\n  backendName: 'cpu',\n  kernelFunc: expandDims as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, RealDiv} from '@tensorflow/tfjs-core';\n\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc} from '../utils/binary_utils';\n\nexport const realDivImpl =\n    createSimpleBinaryKernelImpl((a: number, b: number) => a / b);\nexport const div = binaryKernelFunc(RealDiv, realDivImpl);\n\nexport const realDivConfig: KernelConfig = {\n  kernelName: RealDiv,\n  backendName: 'cpu',\n  kernelFunc: div\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Tensor, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {add} from '../kernels/Add';\nimport {complex} from '../kernels/Complex';\nimport {concat} from '../kernels/Concat';\nimport {identity} from '../kernels/Identity';\nimport {imag} from '../kernels/Imag';\nimport {multiply} from '../kernels/Multiply';\nimport {real} from '../kernels/Real';\nimport {realDivConfig} from '../kernels/RealDiv';\nimport {slice} from '../kernels/Slice';\nimport {sub} from '../kernels/Sub';\n\n/**\n * Calculate FFT of inner most elements of batch tensor.\n */\nexport function fftBatch(\n    input: TensorInfo, inverse: boolean,\n    cpuBackend: MathBackendCPU): TensorInfo {\n  const inputShape = input.shape;\n  const batch = inputShape[0];\n  const innerDim = inputShape[1];\n\n  const inputVals = cpuBackend.data.get(input.dataId);\n\n  const real2D = inputVals.complexTensorInfos.real;\n  const imag2D = inputVals.complexTensorInfos.imag;\n\n  // Collects real and imaginary values separately.\n  const resultShape = [batch, innerDim];\n  const resultSize = util.sizeFromShape(resultShape);\n  const resultReal = util.getTypedArrayFromDType('float32', resultSize);\n  const resultImag = util.getTypedArrayFromDType('float32', resultSize);\n\n  for (let b = 0; b < batch; b++) {\n    // TODO: Support slice ops for complex type.\n    const r = slice({\n      inputs: {x: real2D},\n      backend: cpuBackend,\n      attrs: {begin: [b, 0], size: [1, innerDim]}\n    });\n    const i = slice({\n      inputs: {x: imag2D},\n      backend: cpuBackend,\n      attrs: {begin: [b, 0], size: [1, innerDim]}\n    });\n\n    const input = complex({inputs: {real: r, imag: i}, backend: cpuBackend});\n\n    // Run FFT by batch element.\n    const {real, imag} = fftImpl(input, inverse, cpuBackend);\n    const res = backend_util.mergeRealAndImagArrays(real, imag);\n\n    for (let d = 0; d < innerDim; d++) {\n      const c = backend_util.getComplexWithIndex(res, d);\n      resultReal[b * innerDim + d] = c.real;\n      resultImag[b * innerDim + d] = c.imag;\n    }\n\n    cpuBackend.disposeIntermediateTensorInfo(r);\n    cpuBackend.disposeIntermediateTensorInfo(i);\n    cpuBackend.disposeIntermediateTensorInfo(input);\n  }\n\n  const $realInfo: TensorInfo =\n      cpuBackend.makeTensorInfo(resultShape, 'float32', resultReal);\n  const $imagInfo: TensorInfo =\n      cpuBackend.makeTensorInfo(resultShape, 'float32', resultImag);\n\n  const result = complex(\n      {inputs: {real: $realInfo, imag: $imagInfo}, backend: cpuBackend});\n\n  cpuBackend.disposeIntermediateTensorInfo($realInfo);\n  cpuBackend.disposeIntermediateTensorInfo($imagInfo);\n\n  return result;\n}\n\nexport function fftImpl(\n    input: TensorInfo, inverse: boolean,\n    cpuBackend: MathBackendCPU): {real: Float32Array, imag: Float32Array} {\n  const inputSize = util.sizeFromShape(input.shape);\n\n  const inputVals = cpuBackend.data.get(input.dataId);\n\n  const realVals =\n      cpuBackend.data.get(inputVals.complexTensorInfos.real.dataId).values as\n      Float32Array;\n\n  const imagVals =\n      cpuBackend.data.get(inputVals.complexTensorInfos.imag.dataId).values as\n      Float32Array;\n\n  if (isExponentOf2(inputSize)) {\n    const result =\n        fftRadix2(realVals, imagVals, inputSize, inverse, cpuBackend);\n\n    const resultShape = [input.shape[0], input.shape[1]];\n\n    if (inverse) {\n      const realInfo: TensorInfo =\n          cpuBackend.makeTensorInfo(resultShape, 'float32', result.real);\n      const imagInfo: TensorInfo =\n          cpuBackend.makeTensorInfo(resultShape, 'float32', result.imag);\n\n      const sizeInfo: TensorInfo = cpuBackend.makeTensorInfo(\n          [], 'float32',\n          util.createScalarValue(inputSize as unknown as 'float32', 'float32'));\n      const sizeInfoCopy =\n          identity({inputs: {x: sizeInfo}, backend: cpuBackend});\n\n      const divRealInfo =\n          realDivConfig.kernelFunc(\n              {inputs: {a: realInfo, b: sizeInfo}, backend: cpuBackend}) as\n          TensorInfo;\n      const divImagInfo =\n          realDivConfig.kernelFunc(\n              {inputs: {a: imagInfo, b: sizeInfoCopy}, backend: cpuBackend}) as\n          TensorInfo;\n\n      const divRealVals =\n          cpuBackend.data.get(divRealInfo.dataId).values as Float32Array;\n      const divImagVals =\n          cpuBackend.data.get(divImagInfo.dataId).values as Float32Array;\n\n      cpuBackend.disposeIntermediateTensorInfo(realInfo);\n      cpuBackend.disposeIntermediateTensorInfo(imagInfo);\n      cpuBackend.disposeIntermediateTensorInfo(sizeInfo);\n      cpuBackend.disposeIntermediateTensorInfo(sizeInfoCopy);\n      cpuBackend.disposeIntermediateTensorInfo(divRealInfo);\n      cpuBackend.disposeIntermediateTensorInfo(divImagInfo);\n\n      return {real: divRealVals, imag: divImagVals};\n    }\n\n    return result;\n  } else {\n    const data = backend_util.mergeRealAndImagArrays(realVals, imagVals);\n\n    const rawOutput =\n        fourierTransformByMatmul(data, inputSize, inverse) as Float32Array;\n\n    return backend_util.splitRealAndImagArrays(rawOutput);\n  }\n}\n\nfunction isExponentOf2(size: number): boolean {\n  return (size & size - 1) === 0;\n}\n\n// FFT using Cooley-Tukey algorithm on radix 2 dimensional input.\nfunction fftRadix2(\n    realVals: Float32Array, imagVals: Float32Array, size: number,\n    inverse: boolean,\n    cpuBackend: MathBackendCPU): {real: Float32Array, imag: Float32Array} {\n  if (size === 1) {\n    return {real: realVals, imag: imagVals};\n  }\n\n  const data = backend_util.mergeRealAndImagArrays(realVals, imagVals);\n\n  const half = size / 2;\n\n  const evenComplex = backend_util.complexWithEvenIndex(data);\n\n  const evenRealVals = evenComplex.real;\n  const evenImagVals = evenComplex.imag;\n\n  const evenShape = [evenRealVals.length];\n\n  const evenRealInfo =\n      cpuBackend.makeTensorInfo(evenShape, 'float32', evenRealVals);\n  const evenImagInfo =\n      cpuBackend.makeTensorInfo(evenShape, 'float32', evenImagVals);\n\n  const evenTensorInfo = complex(\n      {inputs: {real: evenRealInfo, imag: evenImagInfo}, backend: cpuBackend});\n\n  const oddComplex = backend_util.complexWithOddIndex(data);\n\n  const oddRealVals = oddComplex.real;\n  const oddImagVals = oddComplex.imag;\n\n  const oddShape = [oddRealVals.length];\n\n  const oddRealInfo =\n      cpuBackend.makeTensorInfo(oddShape, 'float32', oddRealVals);\n  const oddImagInfo =\n      cpuBackend.makeTensorInfo(oddShape, 'float32', oddImagVals);\n\n  const oddTensorInfo = complex(\n      {inputs: {real: oddRealInfo, imag: oddImagInfo}, backend: cpuBackend});\n\n  // Recursive call for half part of original input.\n  const $evenComplex =\n      fftRadix2(evenRealVals, evenImagVals, half, inverse, cpuBackend);\n\n  const $evenRealVals = $evenComplex.real;\n  const $evenImagVals = $evenComplex.imag;\n\n  const $evenShape = [$evenRealVals.length];\n\n  const $evenRealInfo =\n      cpuBackend.makeTensorInfo($evenShape, 'float32', $evenRealVals);\n  const $evenImagInfo =\n      cpuBackend.makeTensorInfo($evenShape, 'float32', $evenImagVals);\n\n  const $evenTensorInfo = complex({\n    inputs: {real: $evenRealInfo, imag: $evenImagInfo},\n    backend: cpuBackend\n  });\n\n  const $oddComplex =\n      fftRadix2(oddRealVals, oddImagVals, half, inverse, cpuBackend);\n\n  const $oddRealVals = $oddComplex.real;\n  const $oddImagVals = $oddComplex.imag;\n\n  const $oddShape = [$oddRealVals.length];\n\n  const $oddRealInfo =\n      cpuBackend.makeTensorInfo($oddShape, 'float32', $oddRealVals);\n  const $oddImagInfo =\n      cpuBackend.makeTensorInfo($oddShape, 'float32', $oddImagVals);\n\n  const $oddTensorInfo = complex(\n      {inputs: {real: $oddRealInfo, imag: $oddImagInfo}, backend: cpuBackend});\n\n  const e = backend_util.exponents(size, inverse);\n  const eShape = [e.real.length];\n\n  const eRealInfo = cpuBackend.makeTensorInfo(eShape, 'float32', e.real);\n  const eImagInfo = cpuBackend.makeTensorInfo(eShape, 'float32', e.imag);\n\n  const complexInfo = complex(\n      {inputs: {real: eRealInfo, imag: eImagInfo}, backend: cpuBackend});\n\n  const exponentInfo =\n      multiply(\n          {inputs: {a: complexInfo, b: $oddTensorInfo}, backend: cpuBackend}) as\n      TensorInfo;\n\n  const addPart = add({\n                    inputs: {a: $evenTensorInfo, b: exponentInfo},\n                    backend: cpuBackend\n                  }) as TensorInfo;\n  const subPart = sub({\n                    inputs: {a: $evenTensorInfo, b: exponentInfo},\n                    backend: cpuBackend\n                  }) as TensorInfo;\n\n  const addPartReal = real({inputs: {input: addPart}, backend: cpuBackend});\n  const subPartReal = real({inputs: {input: subPart}, backend: cpuBackend});\n\n  const addPartImag = imag({inputs: {input: addPart}, backend: cpuBackend});\n  const subPartImag = imag({inputs: {input: subPart}, backend: cpuBackend});\n\n  const $real = concat({\n    inputs: [addPartReal as Tensor, subPartReal as Tensor],\n    backend: cpuBackend,\n    attrs: {axis: 0}\n  });\n  const $imag = concat({\n    inputs: [addPartImag as Tensor, subPartImag as Tensor],\n    backend: cpuBackend,\n    attrs: {axis: 0}\n  });\n\n  const $realVals = cpuBackend.data.get($real.dataId).values as Float32Array;\n  const $imagVals = cpuBackend.data.get($imag.dataId).values as Float32Array;\n\n  cpuBackend.disposeIntermediateTensorInfo(evenRealInfo);\n  cpuBackend.disposeIntermediateTensorInfo(evenImagInfo);\n  cpuBackend.disposeIntermediateTensorInfo(evenTensorInfo);\n  cpuBackend.disposeIntermediateTensorInfo(oddRealInfo);\n  cpuBackend.disposeIntermediateTensorInfo(oddImagInfo);\n  cpuBackend.disposeIntermediateTensorInfo(oddTensorInfo);\n  cpuBackend.disposeIntermediateTensorInfo($evenRealInfo);\n  cpuBackend.disposeIntermediateTensorInfo($evenImagInfo);\n  cpuBackend.disposeIntermediateTensorInfo($evenTensorInfo);\n  cpuBackend.disposeIntermediateTensorInfo($oddRealInfo);\n  cpuBackend.disposeIntermediateTensorInfo($oddImagInfo);\n  cpuBackend.disposeIntermediateTensorInfo($oddTensorInfo);\n  cpuBackend.disposeIntermediateTensorInfo(eRealInfo);\n  cpuBackend.disposeIntermediateTensorInfo(eImagInfo);\n  cpuBackend.disposeIntermediateTensorInfo(complexInfo);\n  cpuBackend.disposeIntermediateTensorInfo(exponentInfo);\n  cpuBackend.disposeIntermediateTensorInfo(addPart);\n  cpuBackend.disposeIntermediateTensorInfo(subPart);\n  cpuBackend.disposeIntermediateTensorInfo(addPartReal);\n  cpuBackend.disposeIntermediateTensorInfo(addPartImag);\n  cpuBackend.disposeIntermediateTensorInfo(subPartReal);\n  cpuBackend.disposeIntermediateTensorInfo(subPartImag);\n  cpuBackend.disposeIntermediateTensorInfo($real);\n  cpuBackend.disposeIntermediateTensorInfo($imag);\n\n  return {real: $realVals, imag: $imagVals};\n}\n\n// Calculate fourier transform by multplying sinusoid matrix.\nfunction fourierTransformByMatmul(\n    data: TypedArray, size: number, inverse: boolean): TypedArray {\n  const ret = new Float32Array(size * 2);\n  // TODO: Use matmul instead once it supports complex64 type.\n  for (let r = 0; r < size; r++) {\n    let real = 0.0;\n    let imag = 0.0;\n    for (let c = 0; c < size; c++) {\n      const e = backend_util.exponent(r * c, size, inverse);\n      const term = backend_util.getComplexWithIndex(data as Float32Array, c);\n      real += term.real * e.real - term.imag * e.imag;\n      imag += term.real * e.imag + term.imag * e.real;\n    }\n    if (inverse) {\n      real /= size;\n      imag /= size;\n    }\n    backend_util.assignToTypedArray(ret, real, imag, r);\n  }\n  return ret;\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {FFT, FFTInputs, KernelConfig, KernelFunc, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {fftBatch} from '../utils/fft_utils';\nimport {reshape} from './Reshape';\n\nexport function fft(args: {inputs: FFTInputs, backend: MathBackendCPU}):\n    TensorInfo {\n  const {inputs, backend} = args;\n  const {input} = inputs;\n\n  const inputSize = util.sizeFromShape(input.shape);\n\n  // Collapse all outer dimensions to a single batch dimension.\n  const innerDimensionSize = input.shape[input.shape.length - 1];\n  const batch = inputSize / innerDimensionSize;\n\n  const input2D = reshape({\n    inputs: {x: input},\n    backend,\n    attrs: {shape: [batch, innerDimensionSize]}\n  });\n\n  const result = fftBatch(input2D, false, backend);\n\n  const resultReshaped =\n      reshape({inputs: {x: result}, backend, attrs: {shape: input.shape}});\n\n  backend.disposeIntermediateTensorInfo(input2D);\n  backend.disposeIntermediateTensorInfo(result);\n\n  return resultReshaped;\n}\n\nexport const fftConfig: KernelConfig = {\n  kernelName: FFT,\n  backendName: 'cpu',\n  kernelFunc: fft as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DataType, DataValues, Fill, FillAttrs, KernelConfig, KernelFunc, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nexport function fill(args: {backend: MathBackendCPU, attrs: FillAttrs}):\n    TensorInfo {\n  const {backend, attrs} = args;\n  const {shape, value, dtype} = attrs;\n\n  const $dtype = dtype || util.inferDtype(value);\n  const values = util.getArrayFromDType($dtype, util.sizeFromShape(shape));\n  fillValues(values, value, $dtype);\n\n  return backend.makeTensorInfo(shape, $dtype, values);\n}\n\nexport const fillConfig: KernelConfig = {\n  kernelName: Fill,\n  backendName: 'cpu',\n  kernelFunc: fill as unknown as KernelFunc\n};\n\nfunction fillValues(\n    values: DataValues, value: string|number, dtype: DataType): void {\n  if (dtype === 'string') {\n    (values as string[]).fill(value as string);\n  } else {\n    (values as TypedArray).fill(value as number);\n  }\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, NumericDataType, TypedArray} from '@tensorflow/tfjs-core';\nimport {FlipLeftRight, FlipLeftRightInputs, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nexport const flipLeftRightConfig: KernelConfig = {\n  kernelName: FlipLeftRight,\n  backendName: 'cpu',\n  kernelFunc: ({inputs, attrs, backend}) => {\n    const {image} = inputs as FlipLeftRightInputs;\n    const cpuBackend = backend as MathBackendCPU;\n\n    const output = util.getTypedArrayFromDType(\n        image.dtype as NumericDataType, util.sizeFromShape(image.shape));\n    const [batch, imageHeight, imageWidth, numChannels] = image.shape;\n\n    const imageVals = cpuBackend.data.get(image.dataId).values as TypedArray;\n\n    for (let batchIdx = 0; batchIdx < batch; batchIdx++) {\n      const batchOffset = batchIdx * imageWidth * imageHeight * numChannels;\n\n      for (let row = 0; row < imageHeight; row++) {\n        const rowOffset = row * (imageWidth * numChannels);\n\n        for (let col = 0; col < imageWidth; col++) {\n          const colOffset = col * numChannels;\n\n          for (let channel = 0; channel < numChannels; channel++) {\n            const coordX = Math.round(imageWidth - col - 1);\n            const outIdx = batchOffset + rowOffset + colOffset + channel;\n\n            let outputValue = imageVals[outIdx];\n            // If the coordinate position falls within the image boundaries...\n            if (coordX >= 0 && coordX < imageWidth) {\n              // set the output to the image value at the coordinate position.\n              const rotatedColOffset = coordX * numChannels;\n              const imageIdx =\n                  batchOffset + rowOffset + rotatedColOffset + channel;\n              outputValue = imageVals[imageIdx];\n            }\n            output[outIdx] = outputValue;\n          }\n        }\n      }\n    }\n\n    const dataId = cpuBackend.write(output, image.shape, image.dtype);\n    return {dataId, shape: image.shape, dtype: image.dtype};\n  }\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {FusedConv2D, FusedConv2DAttrs, FusedConv2DInputs, KernelConfig, KernelFunc, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {applyActivation} from '../utils/fused_utils';\nimport {add} from './Add';\nimport {conv2D} from './Conv2D';\nimport {reshape} from './Reshape';\n\nexport function fusedConv2D(args: {\n  inputs: FusedConv2DInputs,\n  backend: MathBackendCPU,\n  attrs: FusedConv2DAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x, filter, bias, preluActivationWeights} = inputs;\n  const {\n    strides,\n    pad,\n    dataFormat,\n    dilations,\n    dimRoundingMode,\n    activation,\n    leakyreluAlpha\n  } = attrs;\n\n  let result = conv2D({\n    inputs: {x, filter},\n    backend,\n    attrs: {strides, pad, dataFormat, dilations, dimRoundingMode}\n  });\n\n  if (bias) {\n    const resultOld = result;\n    // For NCHW format, if bias is a 1-D tensor, it is supposed to be aligned\n    // to the channel of the conv2d's result; if the bias is a scalar, the\n    // bias_add is computed as if the bias was broadcasted to the shape of the\n    // conv2d's result.\n    if (dataFormat === 'NCHW' && bias.shape.length === 1 &&\n        bias.shape[0] !== 1) {\n      const reshapedBias = reshape(\n          {inputs: {x: bias}, backend, attrs: {shape: [bias.shape[0], 1, 1]}});\n      result =\n          add({inputs: {a: result, b: reshapedBias}, backend}) as TensorInfo;\n      backend.disposeIntermediateTensorInfo(reshapedBias);\n    } else {\n      // This condition handles NHWC and NCHW (scalar case). The only other case\n      // for NCHW (1D case) is handled above.\n      result = add({inputs: {a: result, b: bias}, backend}) as TensorInfo;\n    }\n    backend.disposeIntermediateTensorInfo(resultOld);\n  }\n\n  if (activation) {\n    const resultOld = result;\n    // For NCHW format, if PReLu activation weights is a 1-D tensor, it is\n    // supposed to be aligned with the channel of the conv2d's result. For other\n    // cases, whether NCHW or NHWC data format, the conv2d result is\n    // already aligned with the activation weights.\n    if (dataFormat === 'NCHW' && activation === 'prelu' &&\n        preluActivationWeights.shape.length === 1 &&\n        preluActivationWeights.shape[0] !== 1) {\n      const reshapedAlpha = reshape({\n        inputs: {x: preluActivationWeights},\n        backend,\n        attrs: {shape: [preluActivationWeights.shape[0], 1, 1]}\n      });\n      result = applyActivation(\n          backend, result, activation, reshapedAlpha, leakyreluAlpha);\n      backend.disposeIntermediateTensorInfo(reshapedAlpha);\n    } else {\n      result = applyActivation(\n          backend, result, activation, preluActivationWeights, leakyreluAlpha);\n    }\n    backend.disposeIntermediateTensorInfo(resultOld);\n  }\n\n  return result;\n}\n\nexport const fusedConv2DConfig: KernelConfig = {\n  kernelName: FusedConv2D,\n  backendName: 'cpu',\n  kernelFunc: fusedConv2D as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {FusedDepthwiseConv2D, FusedDepthwiseConv2DAttrs, FusedDepthwiseConv2DInputs, KernelConfig, KernelFunc, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {applyActivation} from '../utils/fused_utils';\nimport {add} from './Add';\nimport {depthwiseConv2dNative} from './DepthwiseConv2dNative';\n\nexport function fusedDepthwiseConv2D(args: {\n  inputs: FusedDepthwiseConv2DInputs,\n  backend: MathBackendCPU,\n  attrs: FusedDepthwiseConv2DAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x, filter, bias, preluActivationWeights} = inputs;\n  const {\n    strides,\n    pad,\n    dataFormat,\n    dilations,\n    dimRoundingMode,\n    activation,\n    leakyreluAlpha\n  } = attrs;\n\n  let result = depthwiseConv2dNative({\n    inputs: {x, filter},\n    backend,\n    attrs: {strides, pad, dataFormat, dilations, dimRoundingMode}\n  });\n\n  if (bias) {\n    const oldResult = result;\n    result = add({inputs: {a: result, b: bias}, backend}) as TensorInfo;\n    backend.disposeIntermediateTensorInfo(oldResult);\n  }\n  if (activation) {\n    const oldResult = result;\n    result = applyActivation(\n        backend, result, activation, preluActivationWeights, leakyreluAlpha);\n    backend.disposeIntermediateTensorInfo(oldResult);\n  }\n\n  return result;\n}\n\nexport const fusedDepthwiseConv2DConfig: KernelConfig = {\n  kernelName: FusedDepthwiseConv2D,\n  backendName: 'cpu',\n  kernelFunc: fusedDepthwiseConv2D as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, GatherNd, GatherNdInputs, KernelConfig, KernelFunc, Rank, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nimport {gatherNdImpl} from './GatherNd_Impl';\n\nexport function gatherNd(\n    args: {inputs: GatherNdInputs, backend: MathBackendCPU}): TensorInfo {\n  const {inputs, backend} = args;\n  const {params, indices} = inputs;\n\n  const paramsSize = util.sizeFromShape(params.shape);\n\n  const indicesShape = indices.shape;\n  const sliceRank = indicesShape[indicesShape.length - 1];\n\n  const [resultShape, numSlices, sliceSize, strides] =\n      backend_util.prepareAndValidate(params, indices);\n  if (numSlices === 0) {\n    return backend.makeTensorInfo(resultShape, params.dtype, []);\n  }\n\n  const indicesData = backend.data.get(indices.dataId).values as TypedArray;\n  const paramsBuf = backend.bufferSync<Rank, 'float32'>(params);\n  const outBuf = gatherNdImpl(\n      indicesData, paramsBuf, params.dtype, numSlices, sliceRank, sliceSize,\n      strides, params.shape, paramsSize);\n\n  return backend.makeTensorInfo(resultShape, params.dtype, outBuf.values);\n}\n\nexport const gatherNdConfig: KernelConfig = {\n  kernelName: GatherNd,\n  backendName: 'cpu',\n  kernelFunc: gatherNd as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, GatherV2, GatherV2Attrs, GatherV2Inputs, KernelConfig, KernelFunc, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\nimport {gatherV2Impl} from './GatherV2_impl';\nimport {reshape} from './Reshape';\n\nexport function gatherV2(args: {\n  inputs: GatherV2Inputs,\n  backend: MathBackendCPU,\n  attrs: GatherV2Attrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x, indices} = inputs;\n  const {axis, batchDims} = attrs;\n\n  assertNotComplex([x, indices], 'gatherV2');\n\n  // Throw error when any index is out of bound.\n  const parsedAxis = util.parseAxisParam(axis, x.shape)[0];\n  const indicesVals = backend.data.get(indices.dataId).values as TypedArray;\n  const axisDim = x.shape[parsedAxis];\n  for (let i = 0; i < indicesVals.length; ++i) {\n    const index = indicesVals[i];\n    util.assert(\n        index <= axisDim - 1 && index >= 0,\n        () =>\n            `GatherV2: the index value ${index} is not in [0, ${axisDim - 1}]`);\n  }\n\n  let $batchDims = batchDims;\n\n  if (batchDims == null) {\n    $batchDims = 0;\n  }\n\n  const indicesSize = util.sizeFromShape(indices.shape);\n\n  const shapeInfo = backend_util.segment_util.collectGatherOpShapeInfo(\n      x, indices, parsedAxis, $batchDims);\n\n  const flattenX = reshape({\n    inputs: {x},\n    backend,\n    attrs: {\n      shape: [\n        shapeInfo.batchSize, shapeInfo.outerSize, shapeInfo.dimSize,\n        shapeInfo.sliceSize\n      ]\n    }\n  });\n\n  const flattenIndex = reshape({\n    inputs: {x: indices},\n    backend,\n    attrs: {shape: [shapeInfo.batchSize, indicesSize / shapeInfo.batchSize]}\n  });\n\n  const flattenOutputShape = [\n    shapeInfo.batchSize, shapeInfo.outerSize, indicesSize / shapeInfo.batchSize,\n    shapeInfo.sliceSize\n  ];\n\n  const indicesBuf = backend.bufferSync(flattenIndex);\n  const xBuf = backend.bufferSync(flattenX);\n  const outBuf = gatherV2Impl(xBuf, indicesBuf, flattenOutputShape);\n\n  backend.disposeIntermediateTensorInfo(flattenX);\n  backend.disposeIntermediateTensorInfo(flattenIndex);\n\n  return backend.makeTensorInfo(\n      shapeInfo.outputShape, outBuf.dtype, outBuf.values);\n}\n\nexport const gatherV2Config: KernelConfig = {\n  kernelName: GatherV2,\n  backendName: 'cpu',\n  kernelFunc: gatherV2 as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {IFFT, IFFTInputs, KernelConfig, KernelFunc, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {fftBatch} from '../utils/fft_utils';\nimport {reshape} from './Reshape';\n\nexport function ifft(args: {inputs: IFFTInputs, backend: MathBackendCPU}):\n    TensorInfo {\n  const {inputs, backend} = args;\n  const {input} = inputs;\n\n  const inputSize = util.sizeFromShape(input.shape);\n\n  // Collapse all outer dimensions to a single batch dimension.\n  const innerDimensionSize = input.shape[input.shape.length - 1];\n  const batch = inputSize / innerDimensionSize;\n\n  const input2D = reshape({\n    inputs: {x: input},\n    backend,\n    attrs: {shape: [batch, innerDimensionSize]}\n  });\n\n  const result = fftBatch(input2D, true, backend);\n\n  const resultReshaped =\n      reshape({inputs: {x: result}, backend, attrs: {shape: input.shape}});\n\n  backend.disposeIntermediateTensorInfo(input2D);\n  backend.disposeIntermediateTensorInfo(result);\n\n  return resultReshaped;\n}\n\nexport const ifftConfig: KernelConfig = {\n  kernelName: IFFT,\n  backendName: 'cpu',\n  kernelFunc: ifft as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {IsFinite, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const isFinite =\n    unaryKernelFunc(IsFinite, (xi) => Number.isFinite(xi) ? 1 : 0, 'bool');\n\nexport const isFiniteConfig: KernelConfig = {\n  kernelName: IsFinite,\n  backendName: 'cpu',\n  kernelFunc: isFinite,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {IsInf, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const isInf =\n    unaryKernelFunc(IsInf, (xi) => Math.abs(xi) === Infinity ? 1 : 0, 'bool');\n\nexport const isInfConfig: KernelConfig = {\n  kernelName: IsInf,\n  backendName: 'cpu',\n  kernelFunc: isInf,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {IsNan, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const isNaN =\n    unaryKernelFunc(IsNan, (xi) => Number.isNaN(xi) ? 1 : 0, 'bool');\n\nexport const isNaNConfig: KernelConfig = {\n  kernelName: IsNan,\n  backendName: 'cpu',\n  kernelFunc: isNaN,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, LinSpace, LinSpaceAttrs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {linSpaceImpl} from './LinSpace_impl';\n\nexport function linSpace(args: {backend: MathBackendCPU, attrs: LinSpaceAttrs}):\n    TensorInfo {\n  const {backend, attrs} = args;\n  const {start, stop, num} = attrs;\n\n  const outVals = linSpaceImpl(start, stop, num);\n\n  return backend.makeTensorInfo([outVals.length], 'float32', outVals);\n}\n\nexport const linSpaceConfig: KernelConfig = {\n  kernelName: LinSpace,\n  backendName: 'cpu',\n  kernelFunc: linSpace as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Log1p} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const log1p = unaryKernelFunc(Log1p, (xi) => Math.log1p(xi));\n\nexport const log1pConfig: KernelConfig = {\n  kernelName: Log1p,\n  backendName: 'cpu',\n  kernelFunc: log1p,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, LogicalAnd} from '@tensorflow/tfjs-core';\n\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc} from '../utils/binary_utils';\n\nexport const logicalAndImpl =\n    createSimpleBinaryKernelImpl((a: number, b: number) => a && b);\nexport const logicalAnd = binaryKernelFunc(\n    LogicalAnd, logicalAndImpl, null /* complexImpl */, 'bool');\n\nexport const logicalAndConfig: KernelConfig = {\n  kernelName: LogicalAnd,\n  backendName: 'cpu',\n  kernelFunc: logicalAnd\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, LogicalNot} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const logicalNot =\n    unaryKernelFunc(LogicalNot, (xi) => xi ? 0 : 1, 'bool');\n\nexport const logicalNotConfig: KernelConfig = {\n  kernelName: LogicalNot,\n  backendName: 'cpu',\n  kernelFunc: logicalNot,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, LogicalOr} from '@tensorflow/tfjs-core';\n\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc} from '../utils/binary_utils';\n\nexport const logicalOrImpl =\n    createSimpleBinaryKernelImpl((a: number, b: number) => a || b);\nexport const logicalOr =\n    binaryKernelFunc(LogicalOr, logicalOrImpl, null /* complexImpl */, 'bool');\n\nexport const logicalOrConfig: KernelConfig = {\n  kernelName: LogicalOr,\n  backendName: 'cpu',\n  kernelFunc: logicalOr\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, LRN, LRNAttrs, LRNInputs, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function lRN(\n    args: {inputs: LRNInputs, backend: MathBackendCPU, attrs: LRNAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {depthRadius, bias, alpha, beta} = attrs;\n\n  assertNotComplex(x, 'LRN');\n\n  const channels = x.shape[3];\n  const maxD = channels - 1;\n  const xValues = backend.data.get(x.dataId).values as TypedArray;\n  const size = util.sizeFromShape(x.shape);\n  const result = new Float32Array(size);\n\n  function sumAcrossChannels(offset: number) {\n    const currentChannel = offset % channels;\n    let beginSumOffset =\n        offset - currentChannel + Math.max(0, currentChannel - depthRadius);\n    const endSumOffset =\n        offset - currentChannel + Math.min(currentChannel + depthRadius, maxD);\n\n    let sum = 0.0;\n    for (; beginSumOffset <= endSumOffset; beginSumOffset++) {\n      const z = xValues[beginSumOffset];\n      sum += z * z;\n    }\n    return sum;\n  }\n\n  for (let offset = 0; offset < size; offset++) {\n    const sum = sumAcrossChannels(offset);\n    const val = xValues[offset] * Math.pow(bias + alpha * sum, -beta);\n    result[offset] = val;\n  }\n\n  return backend.makeTensorInfo(x.shape, x.dtype, result);\n}\n\n// tslint:disable-next-line: variable-name\nexport const LRNConfig: KernelConfig = {\n  kernelName: LRN,\n  backendName: 'cpu',\n  kernelFunc: lRN as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, LRNGrad, LRNGradAttrs, LRNGradInputs, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function lRNGrad(\n    args:\n        {inputs: LRNGradInputs, backend: MathBackendCPU, attrs: LRNGradAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x, y, dy} = inputs;\n  const {depthRadius, bias, alpha, beta} = attrs;\n\n  assertNotComplex(dy, 'LRNGrad');\n\n  const dySize = util.sizeFromShape(dy.shape);\n\n  const channels = dy.shape[3];\n  const dyValues = backend.data.get(dy.dataId).values as TypedArray;\n  const xValues = backend.data.get(x.dataId).values as TypedArray;\n  const yValues = backend.data.get(y.dataId).values as TypedArray;\n  const result = new Float32Array(dySize);\n  const size = dySize;\n\n  for (let offset = 0; offset < size; offset++) {\n    const currentChannel = offset % channels;\n    const depthBegin =\n        (offset - currentChannel) + Math.max(0, currentChannel - depthRadius);\n    const depthEnd = (offset - currentChannel) +\n        Math.min(channels, currentChannel + depthRadius + 1);\n\n    let norm = 0;\n    for (let k = depthBegin; k < depthEnd; k++) {\n      norm += Math.pow(xValues[k], 2);\n    }\n    norm = alpha * norm + bias;\n\n    for (let k = depthBegin; k < depthEnd; k++) {\n      let dyi = -2 * alpha * beta * xValues[k] * yValues[offset] / norm;\n      if (offset === k) {\n        dyi += Math.pow(norm, -beta);\n      }\n      dyi *= dyValues[offset];\n      result[k] += dyi;\n    }\n  }\n\n  return backend.makeTensorInfo(dy.shape, x.dtype, result);\n}\n\n// tslint:disable-next-line: variable-name\nexport const LRNGradConfig: KernelConfig = {\n  kernelName: LRNGrad,\n  backendName: 'cpu',\n  kernelFunc: lRNGrad as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelFunc, Max, MaxAttrs, MaxInputs, TensorInfo} from '@tensorflow/tfjs-core';\nimport {backend_util, KernelConfig} from '@tensorflow/tfjs-core';\nimport {TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nimport {maxImpl} from './Max_impl';\nimport {transposeImpl} from './Transpose_impl';\n\nexport function max(\n    args: {inputs: MaxInputs, backend: MathBackendCPU, attrs: MaxAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {reductionIndices, keepDims} = attrs;\n  const cpuBackend = backend;\n  let xShape = x.shape;\n  const xRank = xShape.length;\n\n  const origAxes = util.parseAxisParam(reductionIndices, xShape);\n  let axes = origAxes;\n  const permutedAxes = backend_util.getAxesPermutation(axes, xRank);\n  let xVals = cpuBackend.data.get(x.dataId).values as TypedArray;\n  if (permutedAxes != null) {\n    const newShape: number[] = new Array(xRank);\n    for (let i = 0; i < newShape.length; i++) {\n      newShape[i] = xShape[permutedAxes[i]];\n    }\n\n    xVals = transposeImpl(xVals, xShape, x.dtype, permutedAxes, newShape);\n    axes = backend_util.getInnerMostAxes(axes.length, xRank);\n\n    xShape = newShape;\n  }\n\n  assertNotComplex(x, 'max');\n  backend_util.assertAxesAreInnerMostDims('max', axes, xRank);\n  const [maxOutShape, reduceShape] =\n      backend_util.computeOutAndReduceShapes(xShape, axes);\n\n  const reduceSize = util.sizeFromShape(reduceShape);\n\n  const result = maxImpl(xVals, reduceSize, maxOutShape, x.dtype);\n  const dataId = cpuBackend.write(result, maxOutShape, x.dtype);\n\n  let outShape = maxOutShape;\n  if (keepDims) {\n    // reshape\n    const newShape = backend_util.expandShapeToKeepDim(maxOutShape, origAxes);\n    outShape = newShape;\n  }\n\n  return {dataId, shape: outShape, dtype: x.dtype};\n}\n\nexport const maxConfig: KernelConfig = {\n  kernelName: Max,\n  backendName: 'cpu',\n  kernelFunc: max as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {backend_util, KernelConfig, KernelFunc, MaxPool, MaxPoolAttrs, MaxPoolInputs, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\nimport {pool} from '../utils/pool_utils';\nimport {identity} from './Identity';\n\nexport function maxPool(\n    args:\n        {inputs: MaxPoolInputs, backend: MathBackendCPU, attrs: MaxPoolAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  assertNotComplex(x, 'maxPool');\n  const {filterSize, strides, pad, dimRoundingMode} = attrs;\n  const dilations = 1;\n\n  util.assert(\n      backend_util.eitherStridesOrDilationsAreOne(strides, dilations),\n      () => 'Error in maxPool: Either strides or dilations must be 1. ' +\n          `Got strides ${strides} and dilations '${dilations}'`);\n\n  const convInfo = backend_util.computePool2DInfo(\n      x.shape as [number, number, number, number], filterSize, strides,\n      dilations, pad, dimRoundingMode);\n  let res: TensorInfo;\n\n  if (convInfo.filterWidth === 1 && convInfo.filterHeight === 1 &&\n      util.arraysEqual(convInfo.inShape, convInfo.outShape)) {\n    res = identity({inputs: {x}, backend});\n  } else {\n    const xValues = backend.data.get(x.dataId).values as TypedArray;\n    const strides = util.computeStrides(x.shape);\n    const buffer = pool(xValues, x.shape, x.dtype, strides, convInfo, 'max');\n    res = backend.makeTensorInfo(\n        convInfo.outShape, x.dtype, buffer.values as TypedArray);\n  }\n  return res;\n}\n\nexport const maxPoolConfig: KernelConfig = {\n  kernelName: MaxPool,\n  backendName: 'cpu',\n  kernelFunc: maxPool as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, KernelConfig, KernelFunc, MaxPool3D, MaxPool3DAttrs, MaxPool3DInputs, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\nimport {pool3d} from '../utils/pool_utils';\n\nexport function maxPool3D(args: {\n  inputs: MaxPool3DInputs,\n  backend: MathBackendCPU,\n  attrs: MaxPool3DAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {filterSize, strides, pad, dimRoundingMode, dataFormat} = attrs;\n\n  assertNotComplex(x, 'maxPool3d');\n\n  const convInfo = backend_util.computePool3DInfo(\n      x.shape as [number, number, number, number, number], filterSize, strides,\n      1 /* dilations */, pad, dimRoundingMode, dataFormat);\n\n  const xValues = backend.data.get(x.dataId).values as TypedArray;\n  const outBuf = pool3d(\n      xValues, x.shape, x.dtype, util.computeStrides(x.shape), convInfo, 'max');\n\n  return backend.makeTensorInfo(outBuf.shape, 'float32', outBuf.values);\n}\n\nexport const maxPool3DConfig: KernelConfig = {\n  kernelName: MaxPool3D,\n  backendName: 'cpu',\n  kernelFunc: maxPool3D as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, buffer, KernelConfig, KernelFunc, MaxPool3DGrad, MaxPool3DGradAttrs, MaxPool3DGradInputs, Rank, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\nimport {maxPool3dPositions} from '../utils/pool_utils';\n\nexport function maxPool3DGrad(args: {\n  inputs: MaxPool3DGradInputs,\n  backend: MathBackendCPU,\n  attrs: MaxPool3DGradAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {dy, input} = inputs;\n  const {filterSize, strides, pad, dimRoundingMode} = attrs;\n\n  assertNotComplex([dy, input], 'maxPool3DGrad');\n\n  const convInfo = backend_util.computePool3DInfo(\n      input.shape as [number, number, number, number, number], filterSize,\n      strides, 1 /* dilations */, pad, dimRoundingMode);\n\n  const inputBuf = backend.bufferSync(input);\n  const maxPosBuf = maxPool3dPositions(inputBuf, convInfo);\n  const strideDepth = convInfo.strideDepth;\n  const strideHeight = convInfo.strideHeight;\n  const strideWidth = convInfo.strideWidth;\n  const dilationDepth = convInfo.dilationDepth;\n  const dilationHeight = convInfo.dilationHeight;\n  const dilationWidth = convInfo.dilationWidth;\n  const effectiveFilterDepth = convInfo.effectiveFilterDepth;\n  const effectiveFilterHeight = convInfo.effectiveFilterHeight;\n  const effectiveFilterWidth = convInfo.effectiveFilterWidth;\n  const padFront = effectiveFilterDepth - 1 - convInfo.padInfo.front;\n  const padLeft = effectiveFilterWidth - 1 - convInfo.padInfo.left;\n  const padTop = effectiveFilterHeight - 1 - convInfo.padInfo.top;\n  const dx = buffer(input.shape, 'float32');\n\n  const dyBuf = backend.bufferSync<Rank, 'float32'>(dy);\n\n  for (let batch = 0; batch < convInfo.batchSize; ++batch) {\n    for (let channel = 0; channel < convInfo.inChannels; ++channel) {\n      for (let dxDepth = 0; dxDepth < convInfo.inDepth; ++dxDepth) {\n        for (let dxRow = 0; dxRow < convInfo.inHeight; ++dxRow) {\n          for (let dxCol = 0; dxCol < convInfo.inWidth; ++dxCol) {\n            // Shader code begins\n            const dyDepthCorner = dxDepth - padFront;\n            const dyRowCorner = dxRow - padTop;\n            const dyColCorner = dxCol - padLeft;\n            let dotProd = 0;\n            for (let wDepth = 0; wDepth < effectiveFilterDepth;\n                 wDepth += dilationDepth) {\n              const dyDepth = (dyDepthCorner + wDepth) / strideDepth;\n              if (dyDepth < 0 || dyDepth >= convInfo.outDepth ||\n                  Math.floor(dyDepth) !== dyDepth) {\n                continue;\n              }\n              for (let wRow = 0; wRow < effectiveFilterHeight;\n                   wRow += dilationHeight) {\n                const dyRow = (dyRowCorner + wRow) / strideHeight;\n                if (dyRow < 0 || dyRow >= convInfo.outHeight ||\n                    Math.floor(dyRow) !== dyRow) {\n                  continue;\n                }\n                for (let wCol = 0; wCol < effectiveFilterWidth;\n                     wCol += dilationWidth) {\n                  const dyCol = (dyColCorner + wCol) / strideWidth;\n                  if (dyCol < 0 || dyCol >= convInfo.outWidth ||\n                      Math.floor(dyCol) !== dyCol) {\n                    continue;\n                  }\n\n                  const maxPos = effectiveFilterDepth * effectiveFilterHeight *\n                          effectiveFilterWidth -\n                      1 -\n                      (maxPosBuf.get(batch, dyDepth, dyRow, dyCol, channel) as\n                       number);\n                  const curPos =\n                      wDepth * effectiveFilterHeight * effectiveFilterWidth +\n                      wRow * effectiveFilterWidth + wCol;\n\n                  const mask = maxPos === curPos ? 1 : 0;\n                  if (mask === 0) {\n                    continue;\n                  }\n\n                  const pixel =\n                      dyBuf.get(batch, dyDepth, dyRow, dyCol, channel);\n                  dotProd += pixel * mask;\n                }\n              }\n            }\n            dx.set(dotProd, batch, dxDepth, dxRow, dxCol, channel);\n          }\n        }\n      }\n    }\n  }\n\n  return backend.makeTensorInfo(dx.shape, dx.dtype, dx.values);\n}\n\nexport const maxPool3DGradConfig: KernelConfig = {\n  kernelName: MaxPool3DGrad,\n  backendName: 'cpu',\n  kernelFunc: maxPool3DGrad as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {backend_util, buffer, KernelConfig, KernelFunc, MaxPoolGrad, MaxPoolGradAttrs, MaxPoolGradInputs, Rank, TensorInfo, TypedArray} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\nimport {maxPoolPositions} from '../utils/pool_utils';\n\nexport function maxPoolGrad(args: {\n  inputs: MaxPoolGradInputs,\n  backend: MathBackendCPU,\n  attrs: MaxPoolGradAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {dy, input, output} = inputs;\n  const x = input;\n  assertNotComplex([input, output], 'maxPoolGrad');\n  const {filterSize, strides, pad, dimRoundingMode} = attrs;\n\n  const convInfo = backend_util.computePool2DInfo(\n      x.shape as [number, number, number, number], filterSize, strides,\n      1 /* dilations */, pad, dimRoundingMode);\n  const xValues = backend.data.get(x.dataId).values as TypedArray;\n  const maxPosBuf = buffer(\n      convInfo.outShape, x.dtype,\n      maxPoolPositions(xValues, x.shape, x.dtype, convInfo).values);\n  const strideHeight = convInfo.strideHeight;\n  const strideWidth = convInfo.strideWidth;\n  const dilationHeight = convInfo.dilationHeight;\n  const dilationWidth = convInfo.dilationWidth;\n  const effectiveFilterHeight = convInfo.effectiveFilterHeight;\n  const effectiveFilterWidth = convInfo.effectiveFilterWidth;\n  const padLeft = effectiveFilterWidth - 1 - convInfo.padInfo.left;\n  const padTop = effectiveFilterHeight - 1 - convInfo.padInfo.top;\n  const dx =\n      buffer<Rank.R4>(x.shape as [number, number, number, number], 'float32');\n\n  const dyData = backend.data.get(dy.dataId).values as Float32Array;\n  const dyBuf = buffer<Rank.R4>(\n      dy.shape as [number, number, number, number], 'float32', dyData);\n\n  for (let b = 0; b < convInfo.batchSize; ++b) {\n    for (let d = 0; d < convInfo.inChannels; ++d) {\n      for (let dxR = 0; dxR < convInfo.inHeight; ++dxR) {\n        for (let dxC = 0; dxC < convInfo.inWidth; ++dxC) {\n          // Shader code begins.\n          const dyRCorner = dxR - padTop;\n          const dyCCorner = dxC - padLeft;\n          let dotProd = 0;\n          for (let wR = 0; wR < effectiveFilterHeight; wR += dilationHeight) {\n            const dyR = (dyRCorner + wR) / strideHeight;\n            if (dyR < 0 || dyR >= convInfo.outHeight ||\n                Math.floor(dyR) !== dyR) {\n              continue;\n            }\n            for (let wC = 0; wC < effectiveFilterWidth; wC += dilationWidth) {\n              const dyC = (dyCCorner + wC) / strideWidth;\n              if (dyC < 0 || dyC >= convInfo.outWidth ||\n                  Math.floor(dyC) !== dyC) {\n                continue;\n              }\n              const maxPos = effectiveFilterHeight * effectiveFilterWidth - 1 -\n                  (maxPosBuf.get(b, dyR, dyC, d) as number);\n              const curPos = wR * effectiveFilterWidth + wC;\n\n              const mask = maxPos === curPos ? 1 : 0;\n              if (mask === 0) {\n                continue;\n              }\n\n              const pixel = dyBuf.get(b, dyR, dyC, d);\n              dotProd += pixel * mask;\n            }\n          }\n          dx.set(dotProd, b, dxR, dxC, d);\n        }\n      }\n    }\n  }\n  return backend.makeTensorInfo(dx.shape, dx.dtype, dx.values);\n}\n\nexport const maxPoolGradConfig: KernelConfig = {\n  kernelName: MaxPoolGrad,\n  backendName: 'cpu',\n  kernelFunc: maxPoolGrad as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {MaxPoolWithArgmax, MaxPoolWithArgmaxAttrs, MaxPoolWithArgmaxInputs} from '@tensorflow/tfjs-core';\nimport {backend_util, KernelConfig, TypedArray} from '@tensorflow/tfjs-core';\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nimport {maxPoolWithArgmaxImpl} from './MaxPoolWithArgmax_impl';\n\nexport const maxPoolWithArgmaxConfig: KernelConfig = {\n  kernelName: MaxPoolWithArgmax,\n  backendName: 'cpu',\n  kernelFunc: ({inputs, attrs, backend}) => {\n    const {x} = inputs as MaxPoolWithArgmaxInputs;\n    const {filterSize, strides, pad, includeBatchInIndex} =\n        attrs as unknown as MaxPoolWithArgmaxAttrs;\n    const cpuBackend = backend as MathBackendCPU;\n    assertNotComplex(x, 'MaxPoolWithArgmax');\n\n    const values = cpuBackend.data.get(x.dataId).values as TypedArray;\n    const convInfo = backend_util.computePool2DInfo(\n        x.shape as [number, number, number, number], filterSize, strides,\n        [1, 1], pad);\n    const [pooled, indexes] = maxPoolWithArgmaxImpl(\n        values, x.shape, x.dtype, includeBatchInIndex, convInfo);\n\n    const pooledDataId =\n        cpuBackend.write(pooled as Float32Array, convInfo.outShape, x.dtype);\n    const indexesDataId =\n        cpuBackend.write(indexes as Int32Array, convInfo.outShape, x.dtype);\n    return [\n      {dataId: pooledDataId, shape: convInfo.outShape, dtype: x.dtype},\n      {dataId: indexesDataId, shape: convInfo.outShape, dtype: 'int32'}\n    ];\n  }\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {backend_util, DataType, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {maxPoolPositions, pool} from '../utils/pool_utils';\nexport function maxPoolWithArgmaxImpl(\n    xValues: TypedArray, xShape: number[], dtype: DataType,\n    includeBatchInIndex: boolean, convInfo: backend_util.Conv2DInfo) {\n  const strides = util.computeStrides(xShape);\n  const maxPools = pool(xValues, xShape, dtype, strides, convInfo, 'max');\n  const maxPositions = maxPoolPositions(\n      xValues, xShape, dtype, convInfo, true, includeBatchInIndex);\n\n  return [maxPools.values, maxPositions.values];\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, KernelConfig, KernelFunc, Mean, MeanAttrs, MeanInputs, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {cast} from './Cast';\nimport {div} from './RealDiv';\nimport {sum} from './Sum';\n\nexport function mean(\n    args: {inputs: MeanInputs, backend: MathBackendCPU, attrs: MeanAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {axis, keepDims} = attrs;\n\n  const axes = util.parseAxisParam(axis, x.shape);\n  const shapes = backend_util.computeOutAndReduceShapes(x.shape, axes);\n  const reduceShape = shapes[1];\n  const reduceSize = util.sizeFromShape(reduceShape);\n  const toDispose = [];\n  const reduceSizeScalar =\n      backend.makeTensorInfo([], 'float32', new Float32Array([reduceSize]));\n  toDispose.push(reduceSizeScalar);\n\n  const $x = cast({inputs: {x}, backend, attrs: {dtype: 'float32'}});\n  toDispose.push($x);\n\n  const res =\n      div({inputs: {a: $x, b: reduceSizeScalar}, backend}) as TensorInfo;\n  toDispose.push(res);\n\n  const result = sum({inputs: {x: res}, backend, attrs: {axis, keepDims}});\n\n  toDispose.forEach(t => backend.disposeIntermediateTensorInfo(t));\n\n  return result;\n}\n\nexport const meanConfig: KernelConfig = {\n  kernelName: Mean,\n  backendName: 'cpu',\n  kernelFunc: mean as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, KernelConfig, KernelFunc, Min, MinAttrs, MinInputs, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\nimport {reshape} from './Reshape';\nimport {transpose} from './Transpose';\n\nexport function min(\n    args: {inputs: MinInputs, backend: MathBackendCPU, attrs: MinAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {axis, keepDims} = attrs;\n\n  assertNotComplex(x, 'min');\n\n  const origAxes = util.parseAxisParam(axis, x.shape);\n  let axes = origAxes;\n  const permutedAxes = backend_util.getAxesPermutation(axes, x.shape.length);\n  let $x = x;\n  if (permutedAxes != null) {\n    $x = transpose({inputs: {x}, backend, attrs: {perm: permutedAxes}});\n    axes = backend_util.getInnerMostAxes(axes.length, x.shape.length);\n  }\n\n  backend_util.assertAxesAreInnerMostDims('min', axes, $x.shape.length);\n  const [outShape, reduceShape] =\n      backend_util.computeOutAndReduceShapes($x.shape, axes);\n  const reduceSize = util.sizeFromShape(reduceShape);\n  const vals = util.makeZerosTypedArray(util.sizeFromShape(outShape), $x.dtype);\n\n  const aVals = backend.data.get($x.dataId).values as TypedArray;\n  for (let i = 0; i < vals.length; ++i) {\n    const offset = i * reduceSize;\n    let min = aVals[offset];\n    for (let j = 0; j < reduceSize; ++j) {\n      const value = aVals[offset + j];\n      if (Number.isNaN(value) ||\n          value < min) {  // comparison with NaN always return false\n        min = value;\n      }\n    }\n    vals[i] = min;\n  }\n\n  if (permutedAxes != null) {\n    backend.disposeIntermediateTensorInfo($x);\n  }\n\n  const result = backend.makeTensorInfo(outShape, $x.dtype, vals);\n\n  if (keepDims) {\n    const expandedShape = backend_util.expandShapeToKeepDim(outShape, origAxes);\n    const reshapedResult =\n        reshape({inputs: {x: result}, backend, attrs: {shape: expandedShape}});\n\n    backend.disposeIntermediateTensorInfo(result);\n\n    return reshapedResult;\n  }\n\n  return result;\n}\n\nexport const minConfig: KernelConfig = {\n  kernelName: Min,\n  backendName: 'cpu',\n  kernelFunc: min as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, MirrorPad, MirrorPadAttrs, MirrorPadInputs, NumericDataType, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function mirrorPad(args: {\n  inputs: MirrorPadInputs,\n  backend: MathBackendCPU,\n  attrs: MirrorPadAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {paddings, mode} = attrs;\n\n  assertNotComplex(x, 'mirrorPad');\n\n  const outShape = paddings.map(\n      (p, i) => p[0] /* beforePad */ + x.shape[i] + p[1] /* afterPad */);\n\n  const start = paddings.map(p => p[0]);\n  const end = paddings.map((p, i) => p[0] + x.shape[i]);\n  const offset = mode === 'reflect' ? 0 : 1;\n\n  const xVals = backend.data.get(x.dataId).values as TypedArray;\n  const xRank = x.shape.length;\n  const xStrides = util.computeStrides(x.shape);\n\n  const resultSize = util.sizeFromShape(outShape);\n  const resultRank = outShape.length;\n  const resultStrides = util.computeStrides(outShape);\n  const resVals =\n      util.getTypedArrayFromDType(x.dtype as NumericDataType, resultSize);\n\n  for (let i = 0; i < resultSize; i++) {\n    let coords = util.indexToLoc(i, resultRank, resultStrides);\n    for (let i = 0; i < resultRank; i++) {\n      if (coords[i] < start[i]) {\n        coords[i] = start[i] * 2 - coords[i] - offset;\n      } else if (coords[i] >= end[i]) {\n        coords[i] = (end[i] - 1) * 2 - coords[i] + offset;\n      }\n    }\n    coords = coords.map((c, i) => c - start[i]);\n\n    const inIndex = util.locToIndex(coords, xRank, xStrides);\n\n    resVals[i] = xVals[inIndex];\n  }\n\n  const outId = backend.write(resVals, outShape, x.dtype);\n\n  return {dataId: outId, shape: outShape, dtype: x.dtype};\n}\n\nexport const mirrorPadConfig: KernelConfig = {\n  kernelName: MirrorPad,\n  backendName: 'cpu',\n  kernelFunc: mirrorPad as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Mod} from '@tensorflow/tfjs-core';\n\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc} from '../utils/binary_utils';\n\nexport const modImpl =\n    createSimpleBinaryKernelImpl(((aValue: number, bValue: number) => {\n      const rem = aValue % bValue;\n      if ((aValue < 0 && bValue < 0) || (aValue >= 0 && bValue >= 0)) {\n        return rem;\n      } else {\n        return (rem + bValue) % bValue;\n      }\n    }));\n\nexport const mod = binaryKernelFunc(Mod, modImpl);\n\nexport const modConfig: KernelConfig = {\n  kernelName: Mod,\n  backendName: 'cpu',\n  kernelFunc: mod\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, KernelConfig, KernelFunc, Softmax, SoftmaxAttrs, SoftmaxInputs, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nimport {exp} from './Exp';\nimport {max} from './Max';\nimport {div} from './RealDiv';\nimport {reshape} from './Reshape';\nimport {sub} from './Sub';\nimport {sum} from './Sum';\n\nexport function softmax(\n    args:\n        {inputs: SoftmaxInputs, backend: MathBackendCPU, attrs: SoftmaxAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {logits} = inputs;\n  const {dim} = attrs;\n\n  const logitsRank = logits.shape.length;\n\n  let $dim = dim;\n  if ($dim === -1) {\n    $dim = logitsRank - 1;\n  }\n  if ($dim !== logitsRank - 1) {\n    throw Error(\n        'Softmax along a non-last dimension is not yet supported. ' +\n        `Logits was rank ${logitsRank} and dim was ${$dim}`);\n  }\n\n  const axes = util.parseAxisParam([$dim], logits.shape);\n  const maxLogit = max({\n    inputs: {x: logits},\n    backend,\n    attrs: {reductionIndices: axes, keepDims: false}\n  });\n  const expandedShape = backend_util.expandShapeToKeepDim(maxLogit.shape, axes);\n\n  const maxLogitReshaped =\n      reshape({inputs: {x: maxLogit}, backend, attrs: {shape: expandedShape}});\n  const a =\n      sub({inputs: {a: logits, b: maxLogitReshaped}, backend}) as TensorInfo;\n  const b = exp({inputs: {x: a}, backend}) as TensorInfo;\n  const sumExp =\n      sum({inputs: {x: b}, backend, attrs: {axis: axes, keepDims: false}});\n  const sumReshaped =\n      reshape({inputs: {x: sumExp}, backend, attrs: {shape: expandedShape}});\n\n  const result = div({inputs: {a: b, b: sumReshaped}, backend}) as TensorInfo;\n\n  backend.disposeIntermediateTensorInfo(maxLogit);\n  backend.disposeIntermediateTensorInfo(maxLogitReshaped);\n  backend.disposeIntermediateTensorInfo(a);\n  backend.disposeIntermediateTensorInfo(b);\n  backend.disposeIntermediateTensorInfo(sumExp);\n  backend.disposeIntermediateTensorInfo(sumReshaped);\n\n  return result;\n}\n\nexport const softmaxConfig: KernelConfig = {\n  kernelName: Softmax,\n  backendName: 'cpu',\n  kernelFunc: softmax as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, Multinomial, MultinomialAttrs, MultinomialInputs, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\nimport * as seedrandom from 'seedrandom';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nimport {softmax} from './Softmax';\n\nexport function multinomial(args: {\n  inputs: MultinomialInputs,\n  backend: MathBackendCPU,\n  attrs: MultinomialAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {logits} = inputs;\n  const {numSamples, seed, normalized} = attrs;\n\n  assertNotComplex(logits, 'multinomial');\n\n  const probabilities = normalized ?\n      logits :\n      softmax({inputs: {logits}, backend, attrs: {dim: -1}});\n\n  const batchSize = probabilities.shape[0];\n  const numEvents = probabilities.shape[1];\n  const probVals = backend.data.get(probabilities.dataId).values as TypedArray;\n  const resShape = [batchSize, numSamples];\n  const resVals =\n      util.makeZerosTypedArray(util.sizeFromShape(resShape), 'int32');\n\n  for (let b = 0; b < batchSize; ++b) {\n    const offset = b * numEvents;\n    // The cdf won't include the last event. It will be implicit if no other\n    // event happened.\n    const cdf = new Float32Array(numEvents - 1);\n    cdf[0] = probVals[offset];\n    for (let event = 1; event < cdf.length; ++event) {\n      cdf[event] = cdf[event - 1] + probVals[offset + event];\n    }\n\n    const random = seedrandom.alea(seed.toString());\n    const outOffset = b * numSamples;\n    for (let sampleId = 0; sampleId < numSamples; ++sampleId) {\n      const r = random();\n\n      // Assume last event happened by default.\n      resVals[outOffset + sampleId] = cdf.length;\n\n      for (let event = 0; event < cdf.length; event++) {\n        if (r < cdf[event]) {\n          resVals[outOffset + sampleId] = event;\n          break;\n        }\n      }\n    }\n  }\n\n  if (!normalized) {\n    backend.disposeIntermediateTensorInfo(probabilities);\n  }\n\n  return backend.makeTensorInfo(resShape, 'int32', resVals);\n}\n\nexport const multinomialConfig: KernelConfig = {\n  kernelName: Multinomial,\n  backendName: 'cpu',\n  kernelFunc: multinomial as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {kernel_impls, KernelConfig, KernelFunc, NonMaxSuppressionV3, NonMaxSuppressionV3Attrs, NonMaxSuppressionV3Inputs, TensorInfo, TypedArray} from '@tensorflow/tfjs-core';\n\nconst nonMaxSuppressionV3Impl = kernel_impls.nonMaxSuppressionV3Impl;\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function nonMaxSuppressionV3(args: {\n  inputs: NonMaxSuppressionV3Inputs,\n  backend: MathBackendCPU,\n  attrs: NonMaxSuppressionV3Attrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {boxes, scores} = inputs;\n  const {maxOutputSize, iouThreshold, scoreThreshold} = attrs;\n\n  assertNotComplex(boxes, 'NonMaxSuppression');\n\n  const boxesVals = backend.data.get(boxes.dataId).values as TypedArray;\n  const scoresVals = backend.data.get(scores.dataId).values as TypedArray;\n\n  const {selectedIndices} = nonMaxSuppressionV3Impl(\n      boxesVals, scoresVals, maxOutputSize, iouThreshold, scoreThreshold);\n\n  return backend.makeTensorInfo(\n      [selectedIndices.length], 'int32', new Int32Array(selectedIndices));\n}\n\nexport const nonMaxSuppressionV3Config: KernelConfig = {\n  kernelName: NonMaxSuppressionV3,\n  backendName: 'cpu',\n  kernelFunc: nonMaxSuppressionV3 as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {kernel_impls, KernelConfig, KernelFunc, NonMaxSuppressionV4, NonMaxSuppressionV4Attrs, NonMaxSuppressionV4Inputs, TensorInfo, TypedArray} from '@tensorflow/tfjs-core';\n\nconst nonMaxSuppressionV4Impl = kernel_impls.nonMaxSuppressionV4Impl;\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function nonMaxSuppressionV4(args: {\n  inputs: NonMaxSuppressionV4Inputs,\n  backend: MathBackendCPU,\n  attrs: NonMaxSuppressionV4Attrs\n}): [TensorInfo, TensorInfo] {\n  const {inputs, backend, attrs} = args;\n  const {boxes, scores} = inputs;\n  const {maxOutputSize, iouThreshold, scoreThreshold, padToMaxOutputSize} =\n      attrs;\n\n  assertNotComplex(boxes, 'NonMaxSuppressionPadded');\n\n  const boxesVals = backend.data.get(boxes.dataId).values as TypedArray;\n  const scoresVals = backend.data.get(scores.dataId).values as TypedArray;\n\n  const {selectedIndices, validOutputs} = nonMaxSuppressionV4Impl(\n      boxesVals, scoresVals, maxOutputSize, iouThreshold, scoreThreshold,\n      padToMaxOutputSize);\n\n  return [\n    backend.makeTensorInfo(\n        [selectedIndices.length], 'int32', new Int32Array(selectedIndices)),\n    backend.makeTensorInfo([], 'int32', new Int32Array([validOutputs]))\n  ];\n}\nexport const nonMaxSuppressionV4Config: KernelConfig = {\n  kernelName: NonMaxSuppressionV4,\n  backendName: 'cpu',\n  kernelFunc: nonMaxSuppressionV4 as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {kernel_impls, KernelConfig, KernelFunc, NonMaxSuppressionV5, NonMaxSuppressionV5Attrs, NonMaxSuppressionV5Inputs, TensorInfo, TypedArray} from '@tensorflow/tfjs-core';\n\nconst nonMaxSuppressionV5Impl = kernel_impls.nonMaxSuppressionV5Impl;\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function nonMaxSuppressionV5(args: {\n  inputs: NonMaxSuppressionV5Inputs,\n  backend: MathBackendCPU,\n  attrs: NonMaxSuppressionV5Attrs\n}): [TensorInfo, TensorInfo] {\n  const {inputs, backend, attrs} = args;\n  const {boxes, scores} = inputs;\n  const {maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma} = attrs;\n\n  assertNotComplex(boxes, 'NonMaxSuppressionWithScore');\n\n  const boxesVals = backend.data.get(boxes.dataId).values as TypedArray;\n  const scoresVals = backend.data.get(scores.dataId).values as TypedArray;\n\n  const maxOutputSizeVal = maxOutputSize;\n  const iouThresholdVal = iouThreshold;\n  const scoreThresholdVal = scoreThreshold;\n  const softNmsSigmaVal = softNmsSigma;\n\n  const {selectedIndices, selectedScores} = nonMaxSuppressionV5Impl(\n      boxesVals, scoresVals, maxOutputSizeVal, iouThresholdVal,\n      scoreThresholdVal, softNmsSigmaVal);\n\n  return [\n    backend.makeTensorInfo(\n        [selectedIndices.length], 'int32', new Int32Array(selectedIndices)),\n    backend.makeTensorInfo(\n        [selectedScores.length], 'float32', new Float32Array(selectedScores))\n  ];\n}\n\nexport const nonMaxSuppressionV5Config: KernelConfig = {\n  kernelName: NonMaxSuppressionV5,\n  backendName: 'cpu',\n  kernelFunc: nonMaxSuppressionV5 as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, OneHot, OneHotAttrs, OneHotInputs, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function oneHot(\n    args: {inputs: OneHotInputs, backend: MathBackendCPU, attrs: OneHotAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {indices} = inputs;\n  const {dtype, depth, onValue, offValue} = attrs;\n\n  assertNotComplex(indices, 'oneHot');\n\n  const indicesSize = util.sizeFromShape(indices.shape);\n\n  const res = new Float32Array(indicesSize * depth);\n  res.fill(offValue);\n  const indicesVal = backend.data.get(indices.dataId).values as TypedArray;\n\n  for (let event = 0; event < indicesSize; ++event) {\n    if (indicesVal[event] >= 0 && indicesVal[event] < depth) {\n      res[event * depth + indicesVal[event]] = onValue;\n    }\n  }\n\n  return backend.makeTensorInfo([...indices.shape, depth], dtype, res);\n}\n\nexport const oneHotConfig: KernelConfig = {\n  kernelName: OneHot,\n  backendName: 'cpu',\n  kernelFunc: oneHot as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, TensorInfo, ZerosLike, ZerosLikeInputs} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nimport {complex} from './Complex';\nimport {fill} from './Fill';\nimport {imag} from './Imag';\nimport {real} from './Real';\n\nexport function zerosLike(\n    args: {inputs: ZerosLikeInputs, backend: MathBackendCPU}): TensorInfo {\n  const {inputs, backend} = args;\n  const {x} = inputs;\n\n  if (x.dtype === 'string') {\n    throw new Error('zerosLike is not supported for string tensors');\n  } else if (x.dtype === 'complex64') {\n    const realPart = real({inputs: {input: x}, backend});\n    const r = zerosLike({inputs: {x: realPart}, backend});\n    const imagPart = imag({inputs: {input: x}, backend});\n    const i = zerosLike({inputs: {x: imagPart}, backend});\n\n    const result = complex({inputs: {real: r, imag: i}, backend});\n\n    backend.disposeIntermediateTensorInfo(realPart);\n    backend.disposeIntermediateTensorInfo(r);\n    backend.disposeIntermediateTensorInfo(imagPart);\n    backend.disposeIntermediateTensorInfo(i);\n\n    return result;\n  } else {\n    return fill({backend, attrs: {shape: x.shape, value: 0, dtype: x.dtype}});\n  }\n}\n\nexport const zerosLikeConfig: KernelConfig = {\n  kernelName: ZerosLike,\n  backendName: 'cpu',\n  kernelFunc: zerosLike as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, OnesLike, OnesLikeInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {complex} from './Complex';\nimport {fill} from './Fill';\nimport {imag} from './Imag';\nimport {real} from './Real';\nimport {zerosLike} from './ZerosLike';\n\nexport function onesLike(\n    args: {inputs: OnesLikeInputs, backend: MathBackendCPU}): TensorInfo {\n  const {inputs, backend} = args;\n  const {x} = inputs;\n\n  if (x.dtype === 'string') {\n    throw new Error('onesLike is not supported for string tensors');\n  } else if (x.dtype === 'complex64') {\n    const realPart = real({inputs: {input: x}, backend});\n    const r = onesLike({inputs: {x: realPart}, backend});\n    const imagPart = imag({inputs: {input: x}, backend});\n    const i = zerosLike({inputs: {x: imagPart}, backend});\n\n    const result = complex({inputs: {real: r, imag: i}, backend});\n\n    backend.disposeIntermediateTensorInfo(realPart);\n    backend.disposeIntermediateTensorInfo(r);\n    backend.disposeIntermediateTensorInfo(imagPart);\n    backend.disposeIntermediateTensorInfo(i);\n\n    return result;\n  } else {\n    return fill({backend, attrs: {shape: x.shape, value: 1, dtype: x.dtype}});\n  }\n}\n\nexport const onesLikeConfig: KernelConfig = {\n  kernelName: OnesLike,\n  backendName: 'cpu',\n  kernelFunc: onesLike as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, Pack, PackAttrs, PackInputs, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {concat} from './Concat';\nimport {expandDims} from './ExpandDims';\n\nexport function pack(\n    args: {inputs: PackInputs, backend: MathBackendCPU, attrs: PackAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {axis} = attrs;\n\n  if (inputs.length === 1) {\n    return expandDims(\n        {inputs: {input: inputs[0]}, backend, attrs: {dim: axis}});\n  }\n\n  const shape = inputs[0].shape;\n  const dtype = inputs[0].dtype;\n\n  inputs.forEach(t => {\n    util.assertShapesMatch(\n        shape, t.shape,\n        'All tensors passed to stack must have matching shapes');\n    util.assert(\n        dtype === t.dtype,\n        () => 'All tensors passed to stack must have matching dtypes');\n  });\n\n  const intermediateTensorInfos: TensorInfo[] = [];\n  const expandedTensors = inputs.map(t => {\n    const expandedT =\n        expandDims({inputs: {input: t}, backend, attrs: {dim: axis}});\n    intermediateTensorInfos.push(expandedT);\n    return expandedT;\n  });\n\n  const result = concat({inputs: expandedTensors, backend, attrs: {axis}});\n\n  intermediateTensorInfos.forEach(\n      t => backend.disposeIntermediateTensorInfo(t));\n\n  return result;\n}\n\nexport const packConfig: KernelConfig = {\n  kernelName: Pack,\n  backendName: 'cpu',\n  kernelFunc: pack as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, NumericDataType, PadV2, PadV2Attrs, PadV2Inputs, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function padV2(\n    args: {inputs: PadV2Inputs, backend: MathBackendCPU, attrs: PadV2Attrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {paddings, constantValue} = attrs;\n\n  assertNotComplex(x, 'pad');\n\n  const outShape = paddings.map(\n      (p, i) => p[0] /* beforePad */ + x.shape[i] + p[1] /* afterPad */);\n\n  const start = paddings.map(p => p[0]);\n\n  const xVals = backend.data.get(x.dataId).values as TypedArray;\n  const xSize = util.sizeFromShape(x.shape);\n  const xRank = x.shape.length;\n  const xStrides = util.computeStrides(x.shape);\n\n  const resultSize = util.sizeFromShape(outShape);\n  const resultRank = outShape.length;\n  const resultStrides = util.computeStrides(outShape);\n  const resVals =\n      util.getTypedArrayFromDType(x.dtype as NumericDataType, resultSize);\n\n  if (constantValue !== 0) {\n    resVals.fill(constantValue);\n  }\n\n  for (let i = 0; i < xSize; i++) {\n    const coords = util.indexToLoc(i, xRank, xStrides);\n    const outCoords = coords.map((c, i) => c + start[i]);\n    const outIndex = util.locToIndex(outCoords, resultRank, resultStrides);\n\n    resVals[outIndex] = xVals[i];\n  }\n\n  const outId = backend.write(resVals, outShape, x.dtype);\n\n  return {dataId: outId, shape: outShape, dtype: x.dtype};\n}\n\nexport const padV2Config: KernelConfig = {\n  kernelName: PadV2,\n  backendName: 'cpu',\n  kernelFunc: padV2 as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Pow} from '@tensorflow/tfjs-core';\n\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc} from '../utils/binary_utils';\n\nexport const powImpl =\n    createSimpleBinaryKernelImpl((a: number, b: number) => Math.pow(a, b));\nexport const pow = binaryKernelFunc(Pow, powImpl);\n\nexport const powConfig: KernelConfig = {\n  kernelName: Pow,\n  backendName: 'cpu',\n  kernelFunc: pow\n};\n","/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, RaggedGather, RaggedGatherAttrs, RaggedGatherInputs, TensorInfo, TypedArray} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nimport {raggedGatherImpl} from './RaggedGather_impl';\n\nexport function raggedGather(args: {\n  inputs: RaggedGatherInputs,\n  backend: MathBackendCPU,\n  attrs: RaggedGatherAttrs\n}): TensorInfo[] {\n  const {inputs, backend, attrs} = args;\n  const {paramsNestedSplits, paramsDenseValues, indices} = inputs;\n  const {outputRaggedRank} = attrs;\n\n  const $paramsNestedSplits = paramsNestedSplits.map(\n      t => backend.data.get(t.dataId).values as TypedArray);\n  const $paramsNestedSplitsShapes = paramsNestedSplits.map(t => t.shape);\n  const $paramsDenseValues =\n      backend.data.get(paramsDenseValues.dataId).values as TypedArray;\n  const $indices = backend.data.get(indices.dataId).values as TypedArray;\n\n  const [outputNestedSplits, outputDenseValues, outputDenseValuesShape] =\n      raggedGatherImpl(\n          $paramsNestedSplits, $paramsNestedSplitsShapes, $paramsDenseValues,\n          paramsDenseValues.shape, paramsDenseValues.dtype, $indices,\n          indices.shape, outputRaggedRank);\n\n  const outputNestedSplitsTensors = outputNestedSplits.map(\n      (splits) => backend.makeTensorInfo([splits.length], 'int32', splits));\n\n  const outputDenseValuesTensor = backend.makeTensorInfo(\n      outputDenseValuesShape, paramsDenseValues.dtype, outputDenseValues);\n\n  return outputNestedSplitsTensors.concat([outputDenseValuesTensor]);\n}\n\nexport const raggedGatherConfig: KernelConfig = {\n  kernelName: RaggedGather,\n  backendName: 'cpu',\n  kernelFunc: raggedGather as unknown as KernelFunc,\n};\n","/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, RaggedRange, RaggedRangeInputs, TensorInfo, TypedArray} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nimport {raggedRangeImpl} from './RaggedRange_impl';\n\nexport function raggedRange(\n    args: {inputs: RaggedRangeInputs, backend: MathBackendCPU}):\n    [TensorInfo, TensorInfo] {\n  const {inputs, backend} = args;\n  const {starts, limits, deltas} = inputs;\n\n  const $starts = backend.data.get(starts.dataId).values as TypedArray;\n  const $limits = backend.data.get(limits.dataId).values as TypedArray;\n  const $deltas = backend.data.get(deltas.dataId).values as TypedArray;\n\n  const [rtNestedSplitsData, rtDenseValuesData] = raggedRangeImpl(\n      $starts, starts.shape, starts.dtype, $limits, limits.shape, $deltas,\n      deltas.shape);\n\n  const rtNestedSplits = backend.makeTensorInfo(\n      [rtNestedSplitsData.length], 'int32', rtNestedSplitsData);\n  const rtDenseValues = backend.makeTensorInfo(\n      [rtDenseValuesData.length], starts.dtype, rtDenseValuesData);\n\n  return [rtNestedSplits, rtDenseValues];\n}\n\nexport const raggedRangeConfig: KernelConfig = {\n  kernelName: RaggedRange,\n  backendName: 'cpu',\n  kernelFunc: raggedRange as unknown as KernelFunc,\n};\n","/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, RaggedTensorToTensor, RaggedTensorToTensorAttrs, RaggedTensorToTensorInputs, TensorInfo, TypedArray} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nimport {raggedTensorToTensorImpl} from './RaggedTensorToTensor_impl';\n\nexport function raggedTensorToTensor(args: {\n  inputs: RaggedTensorToTensorInputs,\n  backend: MathBackendCPU,\n  attrs: RaggedTensorToTensorAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {shape, values, defaultValue, rowPartitionTensors} = inputs;\n  const {rowPartitionTypes} = attrs;\n\n  const $shape = backend.data.get(shape.dataId).values as TypedArray;\n  const $values = backend.data.get(values.dataId).values as TypedArray;\n  const $defaultValue =\n      backend.data.get(defaultValue.dataId).values as TypedArray;\n  const $rowPartitionValues = rowPartitionTensors.map(\n      t => backend.data.get(t.dataId).values as TypedArray);\n  const rowPartitionValuesShapes = rowPartitionTensors.map(t => t.shape);\n\n  const [outputShape, output] = raggedTensorToTensorImpl(\n      $shape, shape.shape, $values, values.shape, values.dtype, $defaultValue,\n      defaultValue.shape, $rowPartitionValues, rowPartitionValuesShapes,\n      rowPartitionTypes);\n  return backend.makeTensorInfo(outputShape, values.dtype, output);\n}\n\nexport const raggedTensorToTensorConfig: KernelConfig = {\n  kernelName: RaggedTensorToTensor,\n  backendName: 'cpu',\n  kernelFunc: raggedTensorToTensor as unknown as KernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, Range, RangeAttrs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {rangeImpl} from './Range_impl';\n\nexport function range(args: {backend: MathBackendCPU, attrs: RangeAttrs}):\n    TensorInfo {\n  const {backend, attrs} = args;\n  const {start, stop, dtype, step} = attrs;\n\n  const values = rangeImpl(start, stop, step, dtype);\n  return backend.makeTensorInfo([values.length], dtype, values);\n}\n\nexport const rangeConfig: KernelConfig = {\n  kernelName: Range,\n  backendName: 'cpu',\n  kernelFunc: range as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Reciprocal} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const reciprocal = unaryKernelFunc(Reciprocal, (xi) => 1 / xi);\n\nexport const reciprocalConfig: KernelConfig = {\n  kernelName: Reciprocal,\n  backendName: 'cpu',\n  kernelFunc: reciprocal,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, ResizeBilinear, ResizeBilinearAttrs, ResizeBilinearInputs, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function resizeBilinear(args: {\n  inputs: ResizeBilinearInputs,\n  backend: MathBackendCPU,\n  attrs: ResizeBilinearAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {images} = inputs;\n  const {alignCorners, halfPixelCenters, size} = attrs;\n\n  assertNotComplex(images, 'resizeBilinear');\n\n  const imagesStrides = util.computeStrides(images.shape);\n  const [newHeight, newWidth] = size;\n\n  const [batch, oldHeight, oldWidth, numChannels] = images.shape;\n  const xValues = backend.data.get(images.dataId).values as TypedArray;\n  const result = new Float32Array(\n      util.sizeFromShape([batch, newHeight, newWidth, numChannels]));\n\n  const effectiveInputSize: [number, number] = [\n    (alignCorners && newHeight > 1) ? oldHeight - 1 : oldHeight,\n    (alignCorners && newWidth > 1) ? oldWidth - 1 : oldWidth\n  ];\n\n  const effectiveOutputSize: [number, number] = [\n    (alignCorners && newHeight > 1) ? newHeight - 1 : newHeight,\n    (alignCorners && newWidth > 1) ? newWidth - 1 : newWidth\n  ];\n  let outputIdx = 0;\n  const effectiveRowSizeRatio = effectiveInputSize[0] / effectiveOutputSize[0];\n  const effectiveColSizeRatio = effectiveInputSize[1] / effectiveOutputSize[1];\n  for (let b = 0; b < batch; b++) {\n    for (let r = 0; r < newHeight; r++) {\n      let sourceFracRow: number;\n      if (halfPixelCenters) {\n        sourceFracRow = effectiveRowSizeRatio * (r + 0.5) - 0.5;\n      } else {\n        sourceFracRow = effectiveRowSizeRatio * r;\n      }\n\n      const sourceRowFloor = Math.max(0, Math.floor(sourceFracRow));\n      const rowFrac = sourceFracRow - sourceRowFloor;\n      const sourceRowCeil = Math.min(oldHeight - 1, Math.ceil(sourceFracRow));\n      const topRowOffset =\n          b * imagesStrides[0] + sourceRowFloor * imagesStrides[1];\n      const botRowOffset =\n          b * imagesStrides[0] + sourceRowCeil * imagesStrides[1];\n      for (let c = 0; c < newWidth; c++) {\n        let sourceFracCol: number;\n        if (halfPixelCenters) {\n          sourceFracCol = effectiveColSizeRatio * (c + 0.5) - 0.5;\n        } else {\n          sourceFracCol = effectiveColSizeRatio * c;\n        }\n        const sourceColFloor = Math.max(0, Math.floor(sourceFracCol));\n        const colFrac = sourceFracCol - sourceColFloor;\n        const sourceColCeil = Math.min(oldWidth - 1, Math.ceil(sourceFracCol));\n        const topLeftOffest = topRowOffset + sourceColFloor * imagesStrides[2];\n        const botLeftOffset = botRowOffset + sourceColFloor * imagesStrides[2];\n        const topRightOffset = topRowOffset + sourceColCeil * imagesStrides[2];\n        const botRightOffest = botRowOffset + sourceColCeil * imagesStrides[2];\n        for (let d = 0; d < numChannels; d++) {\n          // Begin shader.\n\n          // Compute the fractional index of the source.\n          const topLeft = xValues[topLeftOffest + d];\n          const bottomLeft = xValues[botLeftOffset + d];\n          const topRight = xValues[topRightOffset + d];\n          const bottomRight = xValues[botRightOffest + d];\n\n          const top = topLeft + (topRight - topLeft) * colFrac;\n          const bottom = bottomLeft + (bottomRight - bottomLeft) * colFrac;\n          const newValue = top + (bottom - top) * rowFrac;\n\n          result[outputIdx++] = newValue;\n        }\n      }\n    }\n  }\n\n  return backend.makeTensorInfo(\n      [batch, newHeight, newWidth, numChannels], 'float32', result);\n}\n\nexport const resizeBilinearConfig: KernelConfig = {\n  kernelName: ResizeBilinear,\n  backendName: 'cpu',\n  kernelFunc: resizeBilinear as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, ResizeBilinearGrad, ResizeBilinearGradAttrs, ResizeBilinearGradInputs, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function resizeBilinearGrad(args: {\n  inputs: ResizeBilinearGradInputs,\n  backend: MathBackendCPU,\n  attrs: ResizeBilinearGradAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {images, dy} = inputs;\n  const {alignCorners} = attrs;\n\n  assertNotComplex([dy, images], 'resizeBilinearGrad');\n\n  const imagesStrides = util.computeStrides(images.shape);\n\n  const [batch, xHeight, xWidth, depth] = images.shape;\n  const [, yHeight, yWidth] = dy.shape;\n\n  const output = new Float32Array(batch * xHeight * xWidth * depth);\n\n  // In the backwards pass, we want to find the pixels that were generated\n  // for each pixel in the input image the forward pass and add the\n  // corresponding coefficient from dy to the gradient (with some\n  // interpolation).\n\n  const effectiveXSize: [number, number] = [\n    (alignCorners && yHeight > 1) ? xHeight - 1 : xHeight,\n    (alignCorners && yWidth > 1) ? xWidth - 1 : xWidth\n  ];\n\n  const effectiveYSize: [number, number] = [\n    (alignCorners && yHeight > 1) ? yHeight - 1 : yHeight,\n    (alignCorners && yWidth > 1) ? yWidth - 1 : yWidth\n  ];\n\n  const heightScale = effectiveXSize[0] / effectiveYSize[0];\n  const widthScale = effectiveXSize[1] / effectiveYSize[1];\n\n  // Reference implementation\n  // tslint:disable-next-line:max-line-length\n  // https://github.com/tensorflow/tensorflow/blob/3039375c86a5bbc9610c7725dcaa95d635f87ba2/tensorflow/core/kernels/resize_bilinear_op.cc#L275\n  const dyValues = backend.data.get(dy.dataId).values as TypedArray;\n  let offset = 0;\n  for (let b = 0; b < batch; b++) {\n    const bOffset = b * imagesStrides[0];\n    for (let r = 0; r < yHeight; r++) {\n      const dxR = r * heightScale;\n      const topDxRIndex = Math.floor(dxR);\n      const bottomDxRIndex = Math.min(Math.ceil(dxR), xHeight - 1);\n\n      const topDxROffset = bOffset + topDxRIndex * imagesStrides[1];\n      const bottomDxROffset = bOffset + bottomDxRIndex * imagesStrides[1];\n\n      const dxRLerp = dxR - topDxRIndex;\n      const inverseDxRLerp = 1.0 - dxRLerp;\n      for (let c = 0; c < yWidth; c++) {\n        const dxC = c * widthScale;\n        const leftDxCIndex = Math.floor(dxC);\n        const rightDxCIndex = Math.min(Math.ceil(dxC), xWidth - 1);\n        const dxCLerp = dxC - leftDxCIndex;\n        const inverseDxCLerp = 1.0 - dxCLerp;\n\n        const topLeftRCOffset = topDxROffset + leftDxCIndex * imagesStrides[2];\n        const topRightRCOffset =\n            topDxROffset + rightDxCIndex * imagesStrides[2];\n        const bottomLeftRCOffset =\n            bottomDxROffset + leftDxCIndex * imagesStrides[2];\n        const bottomRightRCOffset =\n            bottomDxROffset + rightDxCIndex * imagesStrides[2];\n\n        const inverseDxRLerpTimesInverseDxCLerp =\n            inverseDxRLerp * inverseDxCLerp;\n        const inverseDxRLerpTimesDxCLerp = inverseDxRLerp * dxCLerp;\n        const dxRLerpTimesInverseDxCLerp = dxRLerp * inverseDxCLerp;\n        const dxRLerpTimesDxCLerp = dxRLerp * dxCLerp;\n        for (let d = 0; d < depth; d++) {\n          const dyVal = dyValues[offset++];\n          output[topLeftRCOffset + d] +=\n              dyVal * inverseDxRLerpTimesInverseDxCLerp;\n          output[topRightRCOffset + d] += dyVal * inverseDxRLerpTimesDxCLerp;\n          output[bottomLeftRCOffset + d] += dyVal * dxRLerpTimesInverseDxCLerp;\n          output[bottomRightRCOffset + d] += dyVal * dxRLerpTimesDxCLerp;\n        }\n      }\n    }\n  }\n\n  return backend.makeTensorInfo(\n      [batch, xWidth, xHeight, depth], 'float32', output);\n}\n\nexport const resizeBilinearGradConfig: KernelConfig = {\n  kernelName: ResizeBilinearGrad,\n  backendName: 'cpu',\n  kernelFunc: resizeBilinearGrad as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, ResizeNearestNeighbor, ResizeNearestNeighborAttrs, ResizeNearestNeighborInputs, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function resizeNearestNeighbor(args: {\n  inputs: ResizeNearestNeighborInputs,\n  backend: MathBackendCPU,\n  attrs: ResizeNearestNeighborAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {images} = inputs;\n  const {alignCorners, halfPixelCenters, size} = attrs;\n\n  assertNotComplex(images, 'resizeNearestNeighbor');\n\n  const imagesStrides = util.computeStrides(images.shape);\n  const [newHeight, newWidth] = size;\n\n  const [batch, oldHeight, oldWidth, numChannels] = images.shape;\n  const xValues = backend.data.get(images.dataId).values as TypedArray;\n  const output = new Float32Array(batch * newHeight * newWidth * numChannels);\n\n  const effectiveInputSize: [number, number] = [\n    (alignCorners && newHeight > 1) ? oldHeight - 1 : oldHeight,\n    (alignCorners && newWidth > 1) ? oldWidth - 1 : oldWidth\n  ];\n\n  const effectiveOutputSize: [number, number] = [\n    (alignCorners && newHeight > 1) ? newHeight - 1 : newHeight,\n    (alignCorners && newWidth > 1) ? newWidth - 1 : newWidth\n  ];\n\n  const effectiveRowSizeRatio = effectiveInputSize[0] / effectiveOutputSize[0];\n  const effectiveColSizeRatio = effectiveInputSize[1] / effectiveOutputSize[1];\n\n  let outputOffset = 0;\n  for (let b = 0; b < batch; b++) {\n    const batchOffset = b * imagesStrides[0];\n    for (let r = 0; r < newHeight; r++) {\n      const sourceFracRow = halfPixelCenters ?\n          effectiveRowSizeRatio * (r + 0.5) :\n          effectiveRowSizeRatio * r;\n      let sourceNearestRow = Math.min(\n          oldHeight - 1,\n          alignCorners ? Math.round(sourceFracRow) : Math.floor(sourceFracRow));\n      if (halfPixelCenters) {\n        sourceNearestRow = Math.max(0, sourceNearestRow);\n      }\n      const rowOffset = batchOffset + sourceNearestRow * imagesStrides[1];\n      for (let c = 0; c < newWidth; c++) {\n        const sourceFracCol = halfPixelCenters ?\n            effectiveColSizeRatio * (c + 0.5) :\n            effectiveColSizeRatio * c;\n        let sourceNearestCol = Math.min(\n            oldWidth - 1,\n            alignCorners ? Math.round(sourceFracCol) :\n                           Math.floor(sourceFracCol));\n        if (halfPixelCenters) {\n          sourceNearestCol = Math.max(0, sourceNearestCol);\n        }\n        const colOffset = rowOffset + sourceNearestCol * imagesStrides[2];\n        for (let d = 0; d < numChannels; d++) {\n          // Begin shader.\n          // Compute the fractional index of the source.\n          const newVal = xValues[colOffset + d];\n          output[outputOffset++] = newVal;\n        }\n      }\n    }\n  }\n\n  return backend.makeTensorInfo(\n      [batch, newHeight, newWidth, numChannels], images.dtype, output);\n}\n\nexport const resizeNearestNeighborConfig: KernelConfig = {\n  kernelName: ResizeNearestNeighbor,\n  backendName: 'cpu',\n  kernelFunc: resizeNearestNeighbor as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, ResizeNearestNeighborGrad, ResizeNearestNeighborGradAttrs, ResizeNearestNeighborGradInputs, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function resizeNearestNeighborGrad(args: {\n  inputs: ResizeNearestNeighborGradInputs,\n  backend: MathBackendCPU,\n  attrs: ResizeNearestNeighborGradAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {images, dy} = inputs;\n  const {alignCorners} = attrs;\n\n  assertNotComplex([dy, images], 'resizeNearestNeighborGrad');\n\n  const imagesStrides = util.computeStrides(images.shape);\n  const dyStrides = util.computeStrides(dy.shape);\n  const [batch, xHeight, xWidth, depth] = images.shape;\n  const [, yHeight, yWidth] = dy.shape;\n\n  const output = new Float32Array(batch * xHeight * xWidth * depth);\n  const dyValues = backend.data.get(dy.dataId).values as TypedArray;\n\n  // In the backwards pass, we want to find the pixels that were generated\n  // for each pixel in the input image the forward pass\n\n  const effectiveXSize: [number, number] = [\n    (alignCorners && yHeight > 1) ? xHeight - 1 : xHeight,\n    (alignCorners && yWidth > 1) ? xWidth - 1 : xWidth\n  ];\n\n  const effectiveYSize: [number, number] = [\n    (alignCorners && yHeight > 1) ? yHeight - 1 : yHeight,\n    (alignCorners && yWidth > 1) ? yWidth - 1 : yWidth\n  ];\n\n  const heightScale = effectiveXSize[0] / effectiveYSize[0];\n  const widthScale = effectiveXSize[1] / effectiveYSize[1];\n\n  const invHeightScale = 1 / heightScale;\n  const invWidthScale = 1 / widthScale;\n\n  // This defines the size of the window of values around a particular\n  // index in dy that we want to search for contributions to dx.\n  const winHeight = (Math.ceil(invHeightScale) * 2) + 2;\n  const winWidth = (Math.ceil(invWidthScale) * 2) + 2;\n\n  // Loop over the output space.\n  for (let b = 0; b < batch; b++) {\n    const batchOffset = b * imagesStrides[0];\n    for (let r = 0; r < xHeight; r++) {\n      const rowOffset = batchOffset + r * imagesStrides[1];\n\n      // Compute bounds for where in dy we will look\n      const startRLerp = Math.floor(r * invHeightScale);\n      const startDyR = Math.floor(startRLerp - (winHeight / 2));\n      for (let c = 0; c < xWidth; c++) {\n        const colOffset = rowOffset + c * imagesStrides[2];\n\n        // Compute bounds for where in dy we will look\n        const startCLerp = Math.floor(c * invWidthScale);\n        const startDyC = Math.floor(startCLerp - (winWidth / 2));\n\n        for (let d = 0; d < depth; d++) {\n          let accum = 0;\n          // loop over dy\n\n          for (let dyRIndex = 0; dyRIndex < winHeight; dyRIndex++) {\n            const dyR = dyRIndex + startDyR;\n            // Guard against the window exceeding the bounds of dy\n            if (dyR < 0 || dyR >= yHeight) {\n              continue;\n            }\n\n            const dyROffset = batchOffset + dyR * dyStrides[1];\n            const sourceFracRow = dyR * heightScale;\n            const sourceNearestRow = Math.min(\n                xHeight - 1,\n                alignCorners ? Math.round(sourceFracRow) :\n                               Math.floor(sourceFracRow));\n            if (r !== sourceNearestRow) {\n              continue;\n            }\n            for (let dyCIndex = 0; dyCIndex < winWidth; dyCIndex++) {\n              const dyC = dyCIndex + startDyC;\n              // Guard against the window exceeding the bounds of dy\n              if (dyC < 0 || dyC >= yWidth) {\n                continue;\n              }\n\n              const dyCOffset = dyROffset + dyC * dyStrides[2];\n              const sourceFracCol = dyC * widthScale;\n              const sourceNearestCol = Math.min(\n                  xWidth - 1,\n                  alignCorners ? Math.round(sourceFracCol) :\n                                 Math.floor(sourceFracCol));\n\n              if (c === sourceNearestCol) {\n                accum += dyValues[dyCOffset + d];\n              }\n            }\n          }\n          output[colOffset + d] = accum;\n        }\n      }\n    }\n  }\n\n  return backend.makeTensorInfo(images.shape, images.dtype, output);\n}\n\nexport const resizeNearestNeighborGradConfig: KernelConfig = {\n  kernelName: ResizeNearestNeighborGrad,\n  backendName: 'cpu',\n  kernelFunc: resizeNearestNeighborGrad as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, Reverse, ReverseAttrs, ReverseInputs, TensorBuffer, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\nimport {identity} from './Identity';\n\nexport function reverse(\n    args:\n        {inputs: ReverseInputs, backend: MathBackendCPU, attrs: ReverseAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {dims} = attrs;\n\n  assertNotComplex(x, 'reverse');\n\n  const xRank = x.shape.length;\n\n  const $dims = util.parseAxisParam(dims, x.shape);\n  if (xRank === 0) {\n    return identity({inputs: {x}, backend});\n  }\n\n  const outBuf = new TensorBuffer(x.shape, x.dtype);\n  const xBuf = backend.bufferSync(x);\n\n  for (let i = 0; i < outBuf.size; i++) {\n    const outLoc = outBuf.indexToLoc(i);\n    const inLoc = outLoc.slice();\n    $dims.forEach(d => inLoc[d] = x.shape[d] - 1 - inLoc[d]);\n    outBuf.set(xBuf.get(...inLoc), ...outLoc);\n  }\n\n  return backend.makeTensorInfo(outBuf.shape, outBuf.dtype, outBuf.values);\n}\n\nexport const reverseConfig: KernelConfig = {\n  kernelName: Reverse,\n  backendName: 'cpu',\n  kernelFunc: reverse as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, NumericDataType, TypedArray} from '@tensorflow/tfjs-core';\nimport {backend_util, RotateWithOffset, RotateWithOffsetAttrs, RotateWithOffsetInputs, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nexport const rotateWithOffsetConfig: KernelConfig = {\n  kernelName: RotateWithOffset,\n  backendName: 'cpu',\n  kernelFunc: ({inputs, attrs, backend}) => {\n    const {image} = inputs as RotateWithOffsetInputs;\n    const {radians, fillValue, center} =\n      attrs as unknown as RotateWithOffsetAttrs;\n    const cpuBackend = backend as MathBackendCPU;\n\n    const output = util.getTypedArrayFromDType(\n        image.dtype as NumericDataType, util.sizeFromShape(image.shape));\n    const [batch, imageHeight, imageWidth, numChannels] = image.shape;\n\n    const [centerX, centerY] =\n        backend_util.getImageCenter(center, imageHeight, imageWidth);\n    const fullOpacityValue = 255;\n\n    const sinFactor = Math.sin(radians);\n    const cosFactor = Math.cos(radians);\n    const imageVals = cpuBackend.data.get(image.dataId).values as TypedArray;\n\n    for (let batchIdx = 0; batchIdx < batch; batchIdx++) {\n      const batchOffset = batchIdx * imageWidth * imageHeight * numChannels;\n\n      for (let row = 0; row < imageHeight; row++) {\n        const rowOffset = row * (imageWidth * numChannels);\n\n        for (let col = 0; col < imageWidth; col++) {\n          const colOffset = col * numChannels;\n\n          for (let channel = 0; channel < numChannels; channel++) {\n            const coords = [batch, row, col, channel];\n\n            const x = coords[2];\n            const y = coords[1];\n\n            // coordX/coordY are the result of rotating and translating x/y.\n            let coordX = (x - centerX) * cosFactor - (y - centerY) * sinFactor;\n            let coordY = (x - centerX) * sinFactor + (y - centerY) * cosFactor;\n            coordX = Math.round(coordX + centerX);\n            coordY = Math.round(coordY + centerY);\n\n            let outputValue = fillValue;\n            if (typeof fillValue !== 'number') {\n              if (channel === 3) {\n                outputValue = fullOpacityValue;\n              } else {\n                outputValue = fillValue[channel];\n              }\n            }\n\n            // If the coordinate position falls within the image boundaries...\n            if (coordX >= 0 && coordX < imageWidth && coordY >= 0 &&\n                coordY < imageHeight) {\n              // set the output to the image value at the coordinate position.\n              const rotatedRowOffset = coordY * (imageWidth * numChannels);\n              const rotatedColOffset = coordX * numChannels;\n              const imageIdx =\n                  batchOffset + rotatedRowOffset + rotatedColOffset + channel;\n              outputValue = imageVals[imageIdx];\n            }\n\n            const outIdx = batchOffset + rowOffset + colOffset + channel;\n            output[outIdx] = outputValue as number;\n          }\n        }\n      }\n    }\n\n    const dataId = cpuBackend.write(output, image.shape, image.dtype);\n    return {dataId, shape: image.shape, dtype: image.dtype};\n  }\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Round} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const round = unaryKernelFunc(Round, (xi) => {\n  // The algorithm is based on banker's rounding.\n  const base = Math.floor(xi);\n  if (xi - base < 0.5) {\n    return Math.floor(xi);\n  } else if (xi - base > 0.5) {\n    return Math.ceil(xi);\n  } else {\n    if (base % 2.0 === 0.0) {\n      return base;\n    } else {\n      return base + 1.0;\n    }\n  }\n});\n\nexport const roundConfig: KernelConfig = {\n  kernelName: Round,\n  backendName: 'cpu',\n  kernelFunc: round,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, KernelConfig, KernelFunc, Rank, ScatterNd, ScatterNdAttrs, ScatterNdInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {scatterImpl} from './Scatter_impl';\n\nexport function scatterNd(args: {\n  inputs: ScatterNdInputs,\n  backend: MathBackendCPU,\n  attrs: ScatterNdAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {indices, updates} = inputs;\n  const {shape} = attrs;\n\n  const {sliceRank, numUpdates, sliceSize, strides, outputSize} =\n      backend_util.calculateShapes(updates, indices, shape);\n  const sumDupeIndices = true;\n\n  const indicesBuf = backend.bufferSync<Rank, 'int32'>(indices);\n  const updatesBuf = backend.bufferSync<Rank, 'int32'|'float32'>(updates);\n\n  const outBuf = scatterImpl(\n      indicesBuf, updatesBuf, shape, outputSize, sliceSize, numUpdates,\n      sliceRank, strides, 0 /* defaultValue */, sumDupeIndices);\n\n  return backend.makeTensorInfo(shape, outBuf.dtype, outBuf.values);\n}\n\nexport const scatterNdConfig: KernelConfig = {\n  kernelName: ScatterNd,\n  backendName: 'cpu',\n  kernelFunc: scatterNd as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {TypedArray, util} from '@tensorflow/tfjs-core';\n\nfunction lowerBound(array: TypedArray, value: number) {\n  let left = 0;\n  let right = array.length;\n  let mid = 0;\n  while (left < right) {\n    mid = Math.floor((left + right) / 2);\n    if (array[mid] < value) {\n      left = mid + 1;\n    } else {\n      right = mid;\n    }\n  }\n  return right;\n}\n\nfunction upperBound(array: TypedArray, value: number) {\n  let left = 0;\n  let right = array.length;\n  let mid = 0;\n  while (left < right) {\n    mid = Math.floor((left + right) / 2);\n    if (array[mid] <= value) {\n      left = mid + 1;\n    } else {\n      right = mid;\n    }\n  }\n  return right;\n}\n\nexport function searchSortedImpl(\n    sortedInputs: TypedArray, values: TypedArray, batchSize: number,\n    numInputs: number, numValues: number, side: 'left'|'right'): TypedArray {\n  const output =\n      util.getArrayFromDType('int32', batchSize * numValues) as TypedArray;\n  for (let b = 0; b < batchSize; ++b) {\n    const sortedInputsSlice =\n        sortedInputs.slice(b * numInputs, (b + 1) * numInputs);\n    const outputOffset = b * numValues;\n    for (let i = 0; i < numValues; ++i) {\n      output[outputOffset + i] = side === 'left' ?\n          lowerBound(sortedInputsSlice, values[i + outputOffset]) :\n          upperBound(sortedInputsSlice, values[i + outputOffset]);\n    }\n  }\n  return output;\n}\n","/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, SearchSorted, SearchSortedAttrs, SearchSortedInputs, TensorInfo, TypedArray} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nimport {searchSortedImpl} from './SearchSorted_impl';\n\nexport function searchSorted(args: {\n  inputs: SearchSortedInputs,\n  backend: MathBackendCPU,\n  attrs: SearchSortedAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {sortedSequence, values} = inputs;\n  const {side} = attrs;\n\n  const $sortedSequence =\n      backend.data.get(sortedSequence.dataId).values as TypedArray;\n  const $values = backend.data.get(values.dataId).values as TypedArray;\n\n  const output = searchSortedImpl(\n      $sortedSequence, $values, sortedSequence.shape[0],\n      sortedSequence.shape[1], values.shape[1], side);\n  return backend.makeTensorInfo(values.shape, 'int32', output);\n}\n\nexport const searchSortedConfig: KernelConfig = {\n  kernelName: SearchSorted,\n  backendName: 'cpu',\n  kernelFunc: searchSorted as unknown as KernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, Select, SelectInputs, TensorInfo, TypedArray, upcastType, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function select(args: {inputs: SelectInputs, backend: MathBackendCPU}):\n    TensorInfo {\n  const {inputs, backend} = args;\n  const {condition, t, e} = inputs;\n\n  assertNotComplex([condition, t, e], 'select');\n  const conditionRank = condition.shape.length;\n\n  const values = backend.data.get(condition.dataId).values as TypedArray;\n  const tValues = backend.data.get(t.dataId).values as TypedArray;\n  const eValues = backend.data.get(e.dataId).values as TypedArray;\n  const resultDtype = upcastType(t.dtype, e.dtype);\n  const newValues =\n      util.makeZerosTypedArray(util.sizeFromShape(t.shape), resultDtype);\n\n  let index = 0;\n  const offset =\n      conditionRank === 0 || conditionRank > 1 || t.shape.length === 1 ?\n      1 :\n      util.sizeFromShape(t.shape.slice(1));\n\n  for (let i = 0; i < values.length; i++) {\n    for (let j = 0; j < offset; j++) {\n      if (values[i] === 1) {\n        newValues[index++] = tValues[i];\n      } else {\n        newValues[index++] = eValues[i];\n      }\n    }\n  }\n\n  return backend.makeTensorInfo(t.shape, resultDtype, newValues);\n}\n\nexport const selectConfig: KernelConfig = {\n  kernelName: Select,\n  backendName: 'cpu',\n  kernelFunc: select as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, KernelConfig, Selu} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nconst scaleAlpha = backend_util.SELU_SCALEALPHA;\nconst scale = backend_util.SELU_SCALE;\n\nexport const selu = unaryKernelFunc(Selu, (xi) => {\n  if (xi >= 0) {\n    return scale * xi;\n  } else {\n    return scaleAlpha * (Math.exp(xi) - 1);\n  }\n});\n\nexport const seluConfig: KernelConfig = {\n  kernelName: Selu,\n  backendName: 'cpu',\n  kernelFunc: selu,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Sign} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const sign = unaryKernelFunc(Sign, (xi) => {\n  if (xi < 0) {\n    return -1;\n  } else if (xi > 0) {\n    return 1;\n  } else {\n    return 0;\n  }\n});\n\nexport const signConfig: KernelConfig = {\n  kernelName: Sign,\n  backendName: 'cpu',\n  kernelFunc: sign,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Sin} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const sin = unaryKernelFunc(Sin, (xi) => Math.sin(xi));\n\nexport const sinConfig: KernelConfig = {\n  kernelName: Sin,\n  backendName: 'cpu',\n  kernelFunc: sin,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Sinh} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const sinh = unaryKernelFunc(Sinh, (xi) => Math.sinh(xi));\n\nexport const sinhConfig: KernelConfig = {\n  kernelName: Sinh,\n  backendName: 'cpu',\n  kernelFunc: sinh,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Softplus} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\n// mirrors the implementation of tf.nn.softplus: https://goo.gl/vkcvwX\n\n// epsilon is the difference between 1.0 and the next representable float.\n// For a single precision 32 bit float this should be 2^-23, see:\n// https://math.byu.edu/~schow/work/IEEEFloatingPoint.htm\nconst epsilon = 1.1920928955078125e-7;\nconst threshold = Math.log(epsilon) + 2.0;\n\nexport const softplus = unaryKernelFunc(Softplus, (xi) => {\n  // Value above which exp(x) may overflow, but softplus(x) == x\n  // is within machine epsilon.\n  const tooLarge = xi > -threshold;\n\n  // Value below which exp(x) may underflow, but softplus(x) == exp(x)\n  // is within machine epsilon.\n  const tooSmall = xi < threshold;\n\n  const expX = Math.exp(xi);\n  let result;\n\n  if (tooSmall) {\n    result = expX;\n  } else if (tooLarge) {\n    result = xi;\n  } else {\n    result = Math.log(1.0 + expX);\n  }\n  return result;\n});\n\nexport const softplusConfig: KernelConfig = {\n  kernelName: Softplus,\n  backendName: 'cpu',\n  kernelFunc: softplus,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, KernelConfig, KernelFunc, ReshapeAttrs, ReshapeInputs, SpaceToBatchND, SpaceToBatchNDAttrs, SpaceToBatchNDInputs, TensorInfo, TransposeAttrs, TransposeInputs, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nimport {padV2Config} from './PadV2';\nimport {reshape} from './Reshape';\nimport {transpose} from './Transpose';\n\nexport function spaceToBatchND(args: {\n  inputs: SpaceToBatchNDInputs,\n  backend: MathBackendCPU,\n  attrs: SpaceToBatchNDAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {blockShape, paddings} = attrs;\n\n  assertNotComplex([x], 'spaceToBatchND');\n\n  const prod = util.sizeFromShape(blockShape);\n\n  const completePaddings: Array<[number, number]> = [[0, 0]];\n  completePaddings.push(...(paddings as Array<[number, number]>));\n\n  for (let i = 1 + blockShape.length; i < x.shape.length; ++i) {\n    completePaddings.push([0, 0]);\n  }\n\n  const paddedX = padV2Config.kernelFunc({\n    inputs: {x},\n    backend,\n    attrs: {paddings: completePaddings, constantValue: 0}\n  }) as TensorInfo;\n\n  const reshapedPaddedShape =\n      backend_util.getReshaped(paddedX.shape, blockShape, prod, false);\n\n  const permutedReshapedPaddedPermutation = backend_util.getPermuted(\n      reshapedPaddedShape.length, blockShape.length, false);\n\n  const flattenShape =\n      backend_util.getReshapedPermuted(paddedX.shape, blockShape, prod, false);\n\n  const reshapeInputs: ReshapeInputs = {x: paddedX};\n  const reshapeAttrs: ReshapeAttrs = {shape: reshapedPaddedShape};\n  const paddedXReshaped =\n      reshape({inputs: reshapeInputs, backend, attrs: reshapeAttrs});\n\n  const transposeInputs: TransposeInputs = {x: paddedXReshaped};\n  const transposeAttrs:\n      TransposeAttrs = {perm: permutedReshapedPaddedPermutation};\n  const paddedXT =\n      transpose({inputs: transposeInputs, backend, attrs: transposeAttrs});\n\n  const resultReshapeInputs: ReshapeInputs = {x: paddedXT};\n  const resultReshapeAttrs: ReshapeAttrs = {shape: flattenShape};\n  const result = reshape(\n      {inputs: resultReshapeInputs, backend, attrs: resultReshapeAttrs});\n\n  backend.disposeIntermediateTensorInfo(paddedX);\n  backend.disposeIntermediateTensorInfo(paddedXReshaped);\n  backend.disposeIntermediateTensorInfo(paddedXT);\n\n  return result;\n}\n\nexport const spaceToBatchNDConfig: KernelConfig = {\n  kernelName: SpaceToBatchND,\n  backendName: 'cpu',\n  kernelFunc: spaceToBatchND as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, SparseFillEmptyRows, SparseFillEmptyRowsInputs, TensorInfo, TypedArray} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nimport {sparseFillEmptyRowsImpl} from './SparseFillEmptyRows_impl';\n\nexport function sparseFillEmptyRows(args: {\n  inputs: SparseFillEmptyRowsInputs,\n  backend: MathBackendCPU\n}): [TensorInfo, TensorInfo, TensorInfo, TensorInfo] {\n  const {inputs, backend} = args;\n  const {indices, values, denseShape, defaultValue} = inputs;\n  if (denseShape.shape.length !== 1) {\n    throw new Error(`Dense shape must be a vector, saw:\n        ${denseShape.shape}`);\n  }\n  if (indices.shape.length !== 2) {\n    throw new Error(`Indices must be a matrix, saw:\n        ${indices.shape}`);\n  }\n  if (values.shape.length !== 1) {\n    throw new Error(`Values must be a vector, saw:\n        ${values.shape}`);\n  }\n  if (defaultValue.shape.length !== 0) {\n    throw new Error(`Default value must be a scalar, saw:\n        ${defaultValue.shape}`);\n  }\n\n  const $indices = backend.data.get(indices.dataId).values as TypedArray;\n  const $values = backend.data.get(values.dataId).values as TypedArray;\n  const $denseShape = backend.data.get(denseShape.dataId).values as TypedArray;\n  const $defaultValue =\n      backend.data.get(defaultValue.dataId).values[0] as number;\n\n  const [outputIndices, outputIndicesShape, outputValues,\n         emptyRowIndicator, reverseIndexMap] =\n      sparseFillEmptyRowsImpl(\n          $indices, indices.shape, indices.dtype, $values, values.dtype,\n          $denseShape, $defaultValue);\n  return [\n    backend.makeTensorInfo(outputIndicesShape, indices.dtype, outputIndices),\n    backend.makeTensorInfo(\n        [outputIndicesShape[0]], values.dtype, outputValues),\n    backend.makeTensorInfo(\n        [emptyRowIndicator.length], 'bool',\n        new Uint8Array(\n            emptyRowIndicator.map((value: boolean) => Number(value)))),\n    backend.makeTensorInfo(\n        [reverseIndexMap.length], indices.dtype,\n        new Int32Array(reverseIndexMap)),\n  ];\n}\n\nexport const sparseFillEmptyRowsConfig: KernelConfig = {\n  kernelName: SparseFillEmptyRows,\n  backendName: 'cpu',\n  kernelFunc: sparseFillEmptyRows as unknown as KernelFunc,\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, SparseReshape, SparseReshapeInputs, TensorInfo, TypedArray} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nimport {sparseReshapeImpl} from './SparseReshape_impl';\n\nexport function sparseReshape(\n    args: {inputs: SparseReshapeInputs, backend: MathBackendCPU}):\n    [TensorInfo, TensorInfo] {\n  const {inputs, backend} = args;\n  const {inputIndices, inputShape, newShape} = inputs;\n  if (inputIndices.shape.length !== 2) {\n    throw new Error(`Input indices should be a matrix but received shape\n        ${inputIndices.shape}`);\n  }\n  if (inputShape.shape.length !== 1) {\n    throw new Error(`Input shape should be a vector but received shape\n        ${inputShape.shape}`);\n  }\n\n  if (newShape.shape.length !== 1) {\n    throw new Error(\n        `Target shape should be a vector but received shape ${newShape.shape}`);\n  }\n\n  const $inputShape =\n      Array.from(backend.data.get(inputShape.dataId).values as TypedArray);\n  const $inputIndices =\n      backend.data.get(inputIndices.dataId).values as TypedArray;\n  const targetShape =\n      Array.from(backend.data.get(newShape.dataId).values as TypedArray);\n\n  const [newIndices, indicesShape, outputShape] = sparseReshapeImpl(\n      $inputIndices, inputIndices.shape, inputIndices.dtype, $inputShape,\n      targetShape);\n  return [\n    backend.makeTensorInfo(indicesShape, inputIndices.dtype, newIndices),\n    backend.makeTensorInfo(\n        [outputShape.length], newShape.dtype, new Int32Array(outputShape)),\n  ];\n}\n\nexport const sparseReshapeConfig: KernelConfig = {\n  kernelName: SparseReshape,\n  backendName: 'cpu',\n  kernelFunc: sparseReshape,\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, SparseSegmentMean, SparseSegmentMeanInputs, TensorInfo, TypedArray} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nimport {sparseSegmentReductionImpl} from './SparseSegmentReduction_impl';\n\nexport function sparseSegmentMean(\n    args: {inputs: SparseSegmentMeanInputs, backend: MathBackendCPU}):\n    TensorInfo {\n  const {inputs, backend} = args;\n  const {data, indices, segmentIds} = inputs;\n  if (data.shape.length < 1) {\n    throw new Error(\n        `Data should be at least 1 dimensional but received scalar`);\n  }\n  if (indices.shape.length !== 1) {\n    throw new Error(`Indices should be a vector but received shape\n          ${indices.shape}`);\n  }\n  if (segmentIds.shape.length !== 1) {\n    throw new Error(`Segment ids should be a vector but received shape\n          ${segmentIds.shape}`);\n  }\n  if (indices.shape[0] !== segmentIds.shape[0]) {\n    throw new Error(`segmentIds and indices should have same size.`);\n  }\n\n  const $data = backend.data.get(data.dataId).values as TypedArray;\n  const $indices = backend.data.get(indices.dataId).values as TypedArray;\n  const $segmentIds = backend.data.get(segmentIds.dataId).values as TypedArray;\n\n  const [outputData, outputDataShape] = sparseSegmentReductionImpl(\n      $data, data.shape, data.dtype, $indices, $segmentIds, true);\n  return backend.makeTensorInfo(outputDataShape, data.dtype, outputData);\n}\n\nexport const sparseSegmentMeanConfig: KernelConfig = {\n  kernelName: SparseSegmentMean,\n  backendName: 'cpu',\n  kernelFunc: sparseSegmentMean,\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, SparseSegmentSum, SparseSegmentSumInputs, TensorInfo, TypedArray} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nimport {sparseSegmentReductionImpl} from './SparseSegmentReduction_impl';\n\nexport function sparseSegmentSum(\n    args: {inputs: SparseSegmentSumInputs, backend: MathBackendCPU}):\n    TensorInfo {\n  const {inputs, backend} = args;\n  const {data, indices, segmentIds} = inputs;\n  if (data.shape.length < 1) {\n    throw new Error(\n        `Data should be at least 1 dimensional but received scalar`);\n  }\n  if (indices.shape.length !== 1) {\n    throw new Error(`Indices should be a vector but received shape\n         ${indices.shape}`);\n  }\n  if (segmentIds.shape.length !== 1) {\n    throw new Error(`Segment ids should be a vector but received shape\n         ${segmentIds.shape}`);\n  }\n  if (indices.shape[0] !== segmentIds.shape[0]) {\n    throw new Error(`segmentIds and indices should have same size.`);\n  }\n\n  const $data = backend.data.get(data.dataId).values as TypedArray;\n  const $indices = backend.data.get(indices.dataId).values as TypedArray;\n  const $segmentIds = backend.data.get(segmentIds.dataId).values as TypedArray;\n\n  const [outputData, outputDataShape] = sparseSegmentReductionImpl(\n      $data, data.shape, data.dtype, $indices, $segmentIds);\n  return backend.makeTensorInfo(outputDataShape, data.dtype, outputData);\n}\n\nexport const sparseSegmentSumConfig: KernelConfig = {\n  kernelName: SparseSegmentSum,\n  backendName: 'cpu',\n  kernelFunc: sparseSegmentSum,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, KernelConfig, KernelFunc, Rank, SparseToDense, SparseToDenseAttrs, SparseToDenseInputs, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {scatterImpl} from './Scatter_impl';\n\nexport function sparseToDense(args: {\n  inputs: SparseToDenseInputs,\n  backend: MathBackendCPU,\n  attrs: SparseToDenseAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {sparseIndices, sparseValues, defaultValue} = inputs;\n  const {outputShape} = attrs;\n\n  const {sliceRank, numUpdates, sliceSize, strides, outputSize} =\n      backend_util.calculateShapes(sparseValues, sparseIndices, outputShape);\n  const sumDupeIndices = false;\n\n  const indicesBuf = backend.bufferSync<Rank, 'int32'>(sparseIndices);\n\n  let outBuf;\n  switch (sparseValues.dtype) {\n    case 'bool': {\n      const updatesBuf = backend.bufferSync<Rank, 'bool'>(sparseValues);\n      const $defaultValue =\n          Boolean(backend.data.get(defaultValue.dataId).values[0]);\n      outBuf = scatterImpl(\n          indicesBuf, updatesBuf, outputShape, outputSize, sliceSize,\n          numUpdates, sliceRank, strides, $defaultValue, sumDupeIndices);\n      break;\n    }\n    case 'float32': {\n      const updatesBuf = backend.bufferSync<Rank, 'float32'>(sparseValues);\n      const $defaultValue =\n          backend.data.get(defaultValue.dataId).values[0] as number;\n      outBuf = scatterImpl(\n          indicesBuf, updatesBuf, outputShape, outputSize, sliceSize,\n          numUpdates, sliceRank, strides, $defaultValue, sumDupeIndices);\n      break;\n    }\n    case 'int32': {\n      const updatesBuf = backend.bufferSync<Rank, 'int32'>(sparseValues);\n      const $defaultValue =\n          backend.data.get(defaultValue.dataId).values[0] as number;\n      outBuf = scatterImpl(\n          indicesBuf, updatesBuf, outputShape, outputSize, sliceSize,\n          numUpdates, sliceRank, strides, $defaultValue, sumDupeIndices);\n      break;\n    }\n    case 'string': {\n      const updatesBuf = backend.bufferSync<Rank, 'string'>(sparseValues);\n      const $defaultValue = util.decodeString(\n          backend.data.get(defaultValue.dataId).values[0] as Uint8Array);\n      outBuf = scatterImpl(\n          indicesBuf, updatesBuf, outputShape, outputSize, sliceSize,\n          numUpdates, sliceRank, strides, $defaultValue, sumDupeIndices);\n      break;\n    }\n    default:\n      throw new Error(`Unsupported type ${sparseValues.dtype}`);\n  }\n  return backend.makeTensorInfo(outputShape, outBuf.dtype, outBuf.values);\n}\n\nexport const sparseToDenseConfig: KernelConfig = {\n  kernelName: SparseToDense,\n  backendName: 'cpu',\n  kernelFunc: sparseToDense as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, SplitVAttrs, SplitVInputs} from '@tensorflow/tfjs-core';\nimport {KernelConfig, KernelFunc, SplitV, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {slice} from './Slice';\n\nexport function splitV(\n    args: {inputs: SplitVInputs, backend: MathBackendCPU, attrs: SplitVAttrs}):\n    TensorInfo[] {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {numOrSizeSplits, axis} = attrs;\n\n  const $axis = util.parseAxisParam(axis, x.shape)[0];\n  const splitSizes = backend_util.prepareSplitSize(x, numOrSizeSplits, $axis);\n\n  const begin = new Array(x.shape.length).fill(0);\n  const size = x.shape.slice();\n  return splitSizes.map(s => {\n    const sliceSize = [...size];\n    sliceSize[$axis] = s;\n    const sliceT =\n        slice({inputs: {x}, backend, attrs: {begin, size: sliceSize}});\n    begin[$axis] += s;\n    return sliceT;\n  });\n}\n\nexport const splitVConfig: KernelConfig = {\n  kernelName: SplitV,\n  backendName: 'cpu',\n  kernelFunc: splitV as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Square, SquareInputs} from '@tensorflow/tfjs-core';\nimport {KernelConfig} from '@tensorflow/tfjs-core';\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport const squareConfig: KernelConfig = {\n  kernelName: Square,\n  backendName: 'cpu',\n  kernelFunc: ({inputs, backend}) => {\n    const {x} = inputs as SquareInputs;\n    const cpuBackend = backend as MathBackendCPU;\n    assertNotComplex(x, 'square');\n\n    const values = cpuBackend.data.get(x.dataId).values as Float32Array;\n    const newValues = new Float32Array(values.length);\n    for (let i = 0; i < values.length; ++i) {\n      const value = values[i];\n      newValues[i] = value * value;\n    }\n    const dataId = cpuBackend.write(newValues, x.shape, x.dtype);\n    return {dataId, shape: x.shape, dtype: x.dtype};\n  }\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Step, StepAttrs} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const step = unaryKernelFunc(Step, (xi, attrs) => {\n  const stepAttrs = attrs as unknown as StepAttrs;\n  if (isNaN(xi)) {\n    return NaN;\n  } else {\n    return xi > 0 ? 1 : stepAttrs.alpha;\n  }\n});\n\nexport const stepConfig: KernelConfig = {\n  kernelName: Step,\n  backendName: 'cpu',\n  kernelFunc: step,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, Rank, slice_util, StridedSlice, StridedSliceAttrs, StridedSliceInputs, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\nimport {reshape} from './Reshape';\nimport {slice} from './Slice';\nimport {stridedSliceImpl} from './StridedSlice_impl';\n\nexport function stridedSlice(args: {\n  inputs: StridedSliceInputs,\n  backend: MathBackendCPU,\n  attrs: StridedSliceAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {\n    begin,\n    end,\n    strides,\n    beginMask,\n    endMask,\n    ellipsisMask,\n    newAxisMask,\n    shrinkAxisMask\n  } = attrs;\n\n  assertNotComplex(x, 'stridedSlice');\n\n  const {\n    finalShapeSparse,\n    finalShape,\n    isIdentity,\n    sliceDim0,\n    isSimpleSlice,\n    begin: $begin,\n    end: $end,\n    strides: $strides\n  } =\n      slice_util.sliceInfo(\n          x.shape, begin, end, strides, beginMask, endMask, ellipsisMask,\n          newAxisMask, shrinkAxisMask);\n\n  let result;\n\n  // ref:\n  // https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/strided_slice_op.cc\n  if (isIdentity) {\n    // Optimization #1, slice is a no-op plus reshape\n    result = reshape({inputs: {x}, backend, attrs: {shape: finalShape}});\n  } else if (sliceDim0 || isSimpleSlice) {\n    // Optimization #2, slice is memory contiguous (only occurs in dim 0)\n    util.assert(\n        x.shape.length >= 1,\n        () => `Input must have rank at least 1, got: ${x.shape.length}`);\n\n    const size = slice_util.computeOutShape($begin, $end, $strides);\n    // To tolerate begin[0] > end[0] (a 0-output slice), we min(begin, end).\n    const sliced = slice({inputs: {x}, backend, attrs: {begin: $begin, size}});\n    result =\n        reshape({inputs: {x: sliced}, backend, attrs: {shape: finalShape}});\n    backend.disposeIntermediateTensorInfo(sliced);\n  } else {\n    const xBuf = backend.bufferSync<Rank, 'float32'>(x);\n    const outBuf = stridedSliceImpl(finalShapeSparse, xBuf, $strides, $begin);\n\n    result = backend.makeTensorInfo(finalShape, outBuf.dtype, outBuf.values);\n  }\n\n  return result;\n}\n\nexport const stridedSliceConfig: KernelConfig = {\n  kernelName: StridedSlice,\n  backendName: 'cpu',\n  kernelFunc: stridedSlice as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, StringNGrams, StringNGramsAttrs, StringNGramsInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nimport {stringNGramsImpl} from './StringNGrams_impl';\n\nexport function stringNGrams(args: {\n  inputs: StringNGramsInputs,\n  backend: MathBackendCPU,\n  attrs: StringNGramsAttrs\n}): [TensorInfo, TensorInfo] {\n  const {inputs, backend, attrs} = args;\n  const {\n    separator,\n    nGramWidths,\n    leftPad,\n    rightPad,\n    padWidth,\n    preserveShortSequences\n  } = attrs;\n  const {data, dataSplits} = inputs;\n  const $data = backend.data.get(data.dataId).values as Uint8Array[];\n  const $dataSplits = backend.data.get(dataSplits.dataId).values as Int32Array;\n\n  const [nGrams, nGramsSplits] = stringNGramsImpl(\n      $data, $dataSplits, separator, nGramWidths, leftPad, rightPad, padWidth,\n      preserveShortSequences);\n  return [\n    backend.makeTensorInfo([nGrams.length], 'string', nGrams),\n    backend.makeTensorInfo(dataSplits.shape, 'int32', nGramsSplits),\n  ];\n}\n\nexport const stringNGramsConfig: KernelConfig = {\n  kernelName: StringNGrams,\n  backendName: 'cpu',\n  kernelFunc: stringNGrams as unknown as KernelFunc,\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, StringSplit, StringSplitAttrs, StringSplitInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nimport {stringSplitImpl} from './StringSplit_impl';\n\nexport function stringSplit(args: {\n  inputs: StringSplitInputs,\n  backend: MathBackendCPU,\n  attrs: StringSplitAttrs\n}): [TensorInfo, TensorInfo, TensorInfo] {\n  const {inputs, backend, attrs} = args;\n  const {skipEmpty} = attrs;\n  const {input, delimiter} = inputs;\n\n  if (input.dtype !== 'string') {\n    throw new Error('Input must be of datatype string');\n  }\n  if (input.shape.length !== 1) {\n    throw new Error(`Input must be a vector, got shape: ${input.shape}`);\n  }\n  if (delimiter.shape.length !== 0) {\n    throw new Error(\n        `Delimiter must be a scalar, got shape: ${delimiter.shape}`);\n  }\n\n  const $input = backend.data.get(input.dataId).values as Uint8Array[];\n  const $delimiter = backend.data.get(delimiter.dataId).values[0] as Uint8Array;\n\n  const [indices, values, shape] =\n      stringSplitImpl($input, $delimiter, skipEmpty);\n  const outputSize = values.length;\n  return [\n    backend.makeTensorInfo([outputSize, 2], 'int32', indices),\n    backend.makeTensorInfo([outputSize], 'string', values),\n    backend.makeTensorInfo([2], 'int32', new Int32Array(shape))\n  ];\n}\n\nexport const stringSplitConfig: KernelConfig = {\n  kernelName: StringSplit,\n  backendName: 'cpu',\n  kernelFunc: stringSplit as unknown as KernelFunc,\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, StringToHashBucketFast, StringToHashBucketFastAttrs, StringToHashBucketFastInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nimport {stringToHashBucketFastImpl} from './StringToHashBucketFast_impl';\n\nexport function stringToHashBucketFast(args: {\n  inputs: StringToHashBucketFastInputs,\n  backend: MathBackendCPU,\n  attrs: StringToHashBucketFastAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {numBuckets} = attrs;\n  const {input} = inputs;\n\n  if (input.dtype !== 'string') {\n    throw new Error('Input must be of datatype string');\n  }\n  if (numBuckets <= 0) {\n    throw new Error(`Number of buckets must be at least 1`);\n  }\n\n  const $input = backend.data.get(input.dataId).values as Uint8Array[];\n\n  const output = stringToHashBucketFastImpl($input, numBuckets);\n  return backend.makeTensorInfo(input.shape, 'int32', output);\n}\n\nexport const stringToHashBucketFastConfig: KernelConfig = {\n  kernelName: StringToHashBucketFast,\n  backendName: 'cpu',\n  kernelFunc: stringToHashBucketFast as unknown as KernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Tan} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const tan = unaryKernelFunc(Tan, (xi) => Math.tan(xi));\n\nexport const tanConfig: KernelConfig = {\n  kernelName: Tan,\n  backendName: 'cpu',\n  kernelFunc: tan,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Tanh} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const tanh = unaryKernelFunc(Tanh, (xi) => Math.tanh(xi));\n\nexport const tanhConfig: KernelConfig = {\n  kernelName: Tanh,\n  backendName: 'cpu',\n  kernelFunc: tanh,\n};\n","/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, KernelConfig, KernelFunc, Rank, TensorInfo, TensorScatterUpdate, TensorScatterUpdateAttrs, TensorScatterUpdateInputs} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nimport {scatterImpl} from './Scatter_impl';\n\nexport function tensorScatterUpdate(args: {\n  inputs: TensorScatterUpdateInputs,\n  backend: MathBackendCPU,\n  attrs: TensorScatterUpdateAttrs\n}): TensorInfo {\n  const {inputs, backend} = args;\n  const {tensor, indices, updates} = inputs;\n\n  const {sliceRank, numUpdates, sliceSize, strides, outputSize} =\n      backend_util.calculateShapes(updates, indices, tensor.shape);\n  const sumDupeIndices = false;\n\n  const indicesBuf = backend.bufferSync<Rank, 'int32'>(indices);\n  const updatesBuf = backend.bufferSync<Rank, 'int32'|'float32'>(updates);\n  const tensorBuf = backend.bufferSync<Rank, 'int32'|'float32'>(tensor);\n  const outBuf = scatterImpl(\n      indicesBuf, updatesBuf, tensor.shape, outputSize, sliceSize, numUpdates,\n      sliceRank, strides, tensorBuf, sumDupeIndices);\n  return backend.makeTensorInfo(tensor.shape, outBuf.dtype, outBuf.values);\n}\n\nexport const tensorScatterUpdateConfig: KernelConfig = {\n  kernelName: TensorScatterUpdate,\n  backendName: 'cpu',\n  kernelFunc: tensorScatterUpdate as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, TensorInfo, Tile, TileAttrs, TileInputs} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\nimport {tileImpl} from './Tile_impl';\n\nexport function tile(\n    args: {inputs: TileInputs, backend: MathBackendCPU, attrs: TileAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {reps} = attrs;\n\n  assertNotComplex(x, 'tile');\n  const outBuf = tileImpl(backend.bufferSync(x), reps);\n\n  return backend.makeTensorInfo(outBuf.shape, outBuf.dtype, outBuf.values);\n}\n\nexport const tileConfig: KernelConfig = {\n  kernelName: Tile,\n  backendName: 'cpu',\n  kernelFunc: tile as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, NumericDataType, TensorInfo, TopK, TopKAttrs, TopKInputs, TypedArray} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\nimport {topKImpl} from './TopK_impl';\n\nexport function topK(\n    args: {inputs: TopKInputs, backend: MathBackendCPU, attrs: TopKAttrs}):\n    [TensorInfo, TensorInfo] {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {k, sorted} = attrs;\n\n  assertNotComplex(x, 'topk');\n\n  const xVals = backend.data.get(x.dataId).values as TypedArray;\n  const [allTopKVals, allTopKIndices] =\n      topKImpl(xVals, x.shape, x.dtype as NumericDataType, k, sorted);\n\n  return [\n    backend.makeTensorInfo(\n        allTopKVals.shape, allTopKVals.dtype, allTopKVals.values),\n    backend.makeTensorInfo(\n        allTopKIndices.shape, allTopKIndices.dtype, allTopKIndices.values)\n  ];\n}\n\nexport const topKConfig: KernelConfig = {\n  kernelName: TopK,\n  backendName: 'cpu',\n  kernelFunc: topK as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, NumericDataType, TensorInfo, Transform, TransformAttrs, TransformInputs, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nexport function transform(args: {\n  inputs: TransformInputs,\n  attrs: TransformAttrs,\n  backend: MathBackendCPU\n}): TensorInfo {\n  const {inputs, attrs, backend} = args;\n  const {image, transforms} = inputs;\n  const {interpolation, fillMode, fillValue, outputShape} = attrs;\n\n  const [batch, imageHeight, imageWidth, numChannels] = image.shape;\n  const [outHeight, outWidth] =\n      outputShape != null ? outputShape : [imageHeight, imageWidth];\n  const outShape = [batch, outHeight, outWidth, numChannels];\n\n  const inStrides = util.computeStrides(image.shape);\n  const batchInStride = inStrides[0];\n  const rowInStride = inStrides[1];\n  const colInStride = inStrides[2];\n\n  const outStrides = util.computeStrides(outShape);\n  const batchOutStride = outStrides[0];\n  const rowOutStride = outStrides[1];\n  const colOutStride = outStrides[2];\n\n  const outVals = util.getTypedArrayFromDType(\n      image.dtype as NumericDataType, util.sizeFromShape(outShape));\n\n  outVals.fill(fillValue);\n\n  const imageVals = backend.data.get(image.dataId).values as TypedArray;\n  const transformVals =\n      backend.data.get(transforms.dataId).values as TypedArray;\n\n  // Ref TF implementation:\n  // https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/image/image_ops.h\n  for (let b = 0; b < batch; ++b) {\n    const transform = transforms.shape[0] === 1 ?\n        transformVals :\n        transformVals.subarray(b * 8, b * 8 + 8);\n\n    for (let outY = 0; outY < outHeight; ++outY) {\n      for (let outX = 0; outX < outWidth; ++outX) {\n        for (let channel = 0; channel < numChannels; ++channel) {\n          let val;\n\n          const projection = transform[6] * outX + transform[7] * outY + 1;\n\n          if (projection === 0) {\n            // Return the fill value for infinite coordinates,\n            // which are outside the input image\n            continue;\n          }\n\n          const inX =\n              (transform[0] * outX + transform[1] * outY + transform[2]) /\n              projection;\n          const inY =\n              (transform[3] * outX + transform[4] * outY + transform[5]) /\n              projection;\n\n          const x = mapCoord(inX, imageWidth, fillMode);\n          const y = mapCoord(inY, imageHeight, fillMode);\n\n          switch (interpolation) {\n            case 'nearest':\n              val = nearestInterpolation(\n                  imageVals, imageHeight, imageWidth, batchInStride,\n                  rowInStride, colInStride, b, y, x, channel, fillValue);\n              break;\n            case 'bilinear':\n              val = bilinearInterpolation(\n                  imageVals, imageHeight, imageWidth, batchInStride,\n                  rowInStride, colInStride, b, y, x, channel, fillValue);\n              break;\n            default:\n              throw new Error(\n                  `Error in Transform: Expect 'nearest' or ` +\n                  `'bilinear', but got ${interpolation}`);\n          }\n\n          const ind =\n              b * batchOutStride + outY * rowOutStride +\n              outX * colOutStride + channel;\n\n          outVals[ind] = val;\n        }\n      }\n    }\n\n    return backend.makeTensorInfo(outShape, image.dtype, outVals);\n  }\n\n  const dataId = backend.write(outVals, outShape, image.dtype);\n  return {dataId, shape: image.shape, dtype: image.dtype};\n}\n\nexport const transformConfig: KernelConfig = {\n  kernelName: Transform,\n  backendName: 'cpu',\n  kernelFunc: transform as unknown as KernelFunc\n};\n\nfunction mapCoord(\n    outCoord: number, len: number,\n    mode: 'constant'|'reflect'|'wrap'|'nearest') {\n  switch (mode) {\n    case 'reflect':\n      return mapCoordReflect(outCoord, len);\n    case 'wrap':\n      return mapCoordWrap(outCoord, len);\n    case 'nearest':\n      return mapCoordNearest(outCoord, len);\n    case 'constant':\n    default:\n      return mapCoordConstant(outCoord, len);\n  }\n}\n\nfunction mapCoordReflect(outCoord: number, len: number): number {\n  // Reflect [abcd] to [dcba|abcd|dcba].\n  let inCoord = outCoord;\n  if (inCoord < 0) {\n    if (len <= 1) {\n      inCoord = 0;\n    } else {\n      const sz2 = 2 * len;\n      if (inCoord < sz2) {\n        inCoord = sz2 * Math.trunc(-inCoord / sz2) + inCoord;\n      }\n      inCoord = inCoord < -len ? inCoord + sz2 : -inCoord - 1;\n    }\n  } else if (inCoord > len - 1) {\n    if (len <= 1) {\n      inCoord = 0;\n    } else {\n      const sz2 = 2 * len;\n      inCoord -= sz2 * Math.trunc(inCoord / sz2);\n      if (inCoord >= len) {\n        inCoord = sz2 - inCoord - 1;\n      }\n    }\n  }\n  // clamp is necessary because when outCoord = 3.5 and len = 4,\n  // inCoord = 3.5 and will be rounded to 4 in nearest interpolation.\n  return util.clamp(0, inCoord, len - 1);\n}\n\nfunction mapCoordWrap(outCoord: number, len: number): number {\n  // Wrap [abcd] to [abcd|abcd|abcd].\n  let inCoord = outCoord;\n  if (inCoord < 0) {\n    if (len <= 1) {\n      inCoord = 0;\n    } else {\n      const sz = len - 1;\n      inCoord += len * (Math.trunc(-inCoord / sz) + 1);\n    }\n  } else if (inCoord > len - 1) {\n    if (len <= 1) {\n      inCoord = 0;\n    } else {\n      const sz = len - 1;\n      inCoord -= len * Math.trunc(inCoord / sz);\n    }\n  }\n  // clamp is necessary because when outCoord = -0.5 and len = 4,\n  // inCoord = 3.5 and will be rounded to 4 in nearest interpolation.\n  return util.clamp(0, inCoord, len - 1);\n}\n\nfunction mapCoordConstant(outCoord: number, len: number): number {\n  return outCoord;\n}\n\nfunction mapCoordNearest(outCoord: number, len: number): number {\n  return util.clamp(0, outCoord, len - 1);\n}\n\nfunction readWithFillValue(\n    imageVals: TypedArray, imageHeight: number, imageWidth: number,\n    batchStride: number, rowStride: number, colStride: number, batch: number,\n    y: number, x: number, channel: number, fillValue: number): number {\n  const ind = batch * batchStride + y * rowStride + x * colStride + channel;\n  if (0 <= y && y < imageHeight && 0 <= x && x < imageWidth) {\n    return imageVals[ind];\n  } else {\n    return fillValue;\n  }\n}\n\nfunction nearestInterpolation(\n    imageVals: TypedArray, imageHeight: number, imageWidth: number,\n    batchStride: number, rowStride: number, colStride: number, batch: number,\n    y: number, x: number, channel: number, fillValue: number): number {\n  const $y = Math.round(y);\n  const $x = Math.round(x);\n\n  return readWithFillValue(\n      imageVals, imageHeight, imageWidth, batchStride, rowStride, colStride,\n      batch, $y, $x, channel, fillValue);\n}\n\nfunction bilinearInterpolation(\n    imageVals: TypedArray, imageHeight: number, imageWidth: number,\n    batchStride: number, rowStride: number, colStride: number, batch: number,\n    y: number, x: number, channel: number, fillValue: number) {\n  const yFloor = Math.floor(y);\n  const xFloor = Math.floor(x);\n  const yCeil = yFloor + 1;\n  const xCeil = xFloor + 1;\n  // f(x, yFloor) = (xCeil - x) / (xCeil - xFloor) * f(xFloor, yFloor)\n  //               + (x - xFloor) / (xCeil - xFloor) * f(xCeil, yFloor)\n  const valueYFloor =\n      (xCeil - x) *\n          readWithFillValue(\n              imageVals, imageHeight, imageWidth, batchStride, rowStride,\n              colStride, batch, yFloor, xFloor, channel, fillValue) +\n      (x - xFloor) *\n          readWithFillValue(\n              imageVals, imageHeight, imageWidth, batchStride, rowStride,\n              colStride, batch, yFloor, xCeil, channel, fillValue);\n  // f(x, yCeil) = (xCeil - x) / (xCeil - xFloor) * f(xFloor, yCeil)\n  //             + (x - xFloor) / (xCeil - xFloor) * f(xCeil, yCeil)\n  const valueYCeil =\n      (xCeil - x) *\n          readWithFillValue(\n              imageVals, imageHeight, imageWidth, batchStride, rowStride,\n              colStride, batch, yCeil, xFloor, channel, fillValue) +\n      (x - xFloor) *\n          readWithFillValue(\n              imageVals, imageHeight, imageWidth, batchStride, rowStride,\n              colStride, batch, yCeil, xCeil, channel, fillValue);\n  // f(x, y) = (yCeil - y) / (yCeil - yFloor) * f(x, yFloor)\n  //         + (y - yFloor) / (yCeil - yFloor) * f(x, yCeil)\n  return (yCeil - y) * valueYFloor + (y - yFloor) * valueYCeil;\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, TensorInfo, Unique, UniqueAttrs, UniqueInputs} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nimport {uniqueImpl} from './Unique_impl';\n\nexport function unique(\n    args: {inputs: UniqueInputs, attrs: UniqueAttrs, backend: MathBackendCPU}):\n    TensorInfo[] {\n  const {inputs, attrs, backend} = args;\n  const {axis} = attrs;\n  const {x} = inputs;\n  assertNotComplex(x, 'unique');\n\n  const values = backend.data.get(x.dataId).values;\n  const {outputValues, outputShape, indices} =\n      uniqueImpl(values, axis, x.shape, x.dtype);\n  return [\n    backend.makeTensorInfo(outputShape, x.dtype, outputValues),\n    backend.makeTensorInfo([indices.length], 'int32', indices),\n  ];\n}\n\nexport const uniqueConfig: KernelConfig = {\n  kernelName: Unique,\n  backendName: 'cpu',\n  kernelFunc: unique as unknown as KernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, TensorInfo, Unpack, UnpackAttrs, UnpackInputs} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {reshape} from './Reshape';\nimport {slice} from './Slice';\n\nexport function unpack(\n    args: {inputs: UnpackInputs, backend: MathBackendCPU, attrs: UnpackAttrs}):\n    TensorInfo[] {\n  const {inputs, backend, attrs} = args;\n  const {value} = inputs;\n  let {axis} = attrs;\n\n  if (axis < 0) {\n    axis += value.shape.length;\n  }\n\n  const valueRank = value.shape.length;\n\n  const num = value.shape[axis];\n  const outShape: number[] = new Array(valueRank - 1);\n  let outIndex = 0;\n  for (let i = 0; i < valueRank; i++) {\n    if (i !== axis) {\n      outShape[outIndex++] = value.shape[i];\n    }\n  }\n\n  const begin = new Array(valueRank).fill(0);\n  const size = value.shape.slice();\n  size[axis] = 1;\n  const res = new Array(num);\n  for (let i = 0; i < res.length; i++) {\n    begin[axis] = i;\n    const tempRes = slice({inputs: {x: value}, backend, attrs: {begin, size}});\n    res[i] = reshape({inputs: {x: tempRes}, backend, attrs: {shape: outShape}});\n    backend.disposeIntermediateTensorInfo(tempRes);\n  }\n\n  return res;\n}\n\nexport const unpackConfig: KernelConfig = {\n  kernelName: Unpack,\n  backendName: 'cpu',\n  kernelFunc: unpack as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, TensorInfo, UnsortedSegmentSum, UnsortedSegmentSumAttrs, UnsortedSegmentSumInputs, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\nimport {cast} from './Cast';\nimport {equal} from './Equal';\nimport {expandDims} from './ExpandDims';\nimport {multiply} from './Multiply';\nimport {pack} from './Pack';\nimport {sum} from './Sum';\n\nexport function unsortedSegmentSum(args: {\n  inputs: UnsortedSegmentSumInputs,\n  backend: MathBackendCPU,\n  attrs: UnsortedSegmentSumAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x, segmentIds} = inputs;\n  const {numSegments} = attrs;\n\n  assertNotComplex(x, 'unsortedSegmentSum');\n\n  const xRank = x.shape.length;\n  const segmentIdsRank = segmentIds.shape.length;\n  const res = [];\n  const intermediates: TensorInfo[] = [];\n\n  // Reshape the segment id's so that they can be broadcast with\n  // x. The new shape should be [segmentIds.shape, 1, ..., 1]\n  const numIters = xRank - segmentIdsRank;\n  let $segmentIds = segmentIds;\n\n  for (let i = 0; i < numIters; ++i) {\n    const expanded = expandDims(\n        {inputs: {input: $segmentIds}, backend, attrs: {dim: i + 1}});\n    $segmentIds = expanded;\n    intermediates.push(expanded);\n  }\n\n  for (let i = 0; i < numSegments; ++i) {\n    const scalarValue = util.createScalarValue(\n      i as unknown as 'int32', 'int32');\n    const segmentId = backend.makeTensorInfo([], 'int32', scalarValue);\n    const mask =\n        equal({inputs: {a: segmentId, b: $segmentIds}, backend}) as TensorInfo;\n    const maskCasted =\n        cast({inputs: {x: mask}, backend, attrs: {dtype: 'float32'}});\n    const mul =\n        multiply({inputs: {a: maskCasted, b: x}, backend}) as TensorInfo;\n    const sumTensorInfo =\n        sum({inputs: {x: mul}, backend, attrs: {axis: 0, keepDims: false}});\n    res.push(sumTensorInfo);\n    intermediates.push(segmentId);\n    intermediates.push(mask);\n    intermediates.push(maskCasted);\n    intermediates.push(mul);\n    intermediates.push(sumTensorInfo);\n  }\n\n  const result = pack({inputs: res, backend, attrs: {axis: 0}});\n\n  intermediates.forEach(t => backend.disposeIntermediateTensorInfo(t));\n\n  return result;\n}\n\nexport const unsortedSegmentSumConfig: KernelConfig = {\n  kernelName: UnsortedSegmentSum,\n  backendName: 'cpu',\n  kernelFunc: unsortedSegmentSum as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n// We explicitly import the modular kernels so they get registered in the\n// global registry when we compile the library. A modular build would replace\n// the contents of this file and import only the kernels that are needed.\nimport {KernelConfig, registerKernel} from '@tensorflow/tfjs-core';\n\nimport {_fusedMatMulConfig} from './kernels/_FusedMatMul';\nimport {absConfig} from './kernels/Abs';\nimport {acosConfig} from './kernels/Acos';\nimport {acoshConfig} from './kernels/Acosh';\nimport {addConfig} from './kernels/Add';\nimport {addNConfig} from './kernels/AddN';\nimport {allConfig} from './kernels/All';\nimport {anyConfig} from './kernels/Any';\nimport {argMaxConfig} from './kernels/ArgMax';\nimport {argMinConfig} from './kernels/ArgMin';\nimport {asinConfig} from './kernels/Asin';\nimport {asinhConfig} from './kernels/Asinh';\nimport {atanConfig} from './kernels/Atan';\nimport {atan2Config} from './kernels/Atan2';\nimport {atanhConfig} from './kernels/Atanh';\nimport {avgPoolConfig} from './kernels/AvgPool';\nimport {avgPool3DConfig} from './kernels/AvgPool3D';\nimport {avgPool3DGradConfig} from './kernels/AvgPool3DGrad';\nimport {avgPoolGradConfig} from './kernels/AvgPoolGrad';\nimport {batchMatMulConfig} from './kernels/BatchMatMul';\nimport {batchNormConfig} from './kernels/BatchNorm';\nimport {batchToSpaceNDConfig} from './kernels/BatchToSpaceND';\nimport {bincountConfig} from './kernels/Bincount';\nimport {broadcastArgsConfig} from './kernels/BroadcastArgs';\nimport {castConfig} from './kernels/Cast';\nimport {ceilConfig} from './kernels/Ceil';\nimport {clipByValueConfig} from './kernels/ClipByValue';\nimport {complexConfig} from './kernels/Complex';\nimport {complexAbsConfig} from './kernels/ComplexAbs';\nimport {concatConfig} from './kernels/Concat';\nimport {conv2DConfig} from './kernels/Conv2D';\nimport {conv2DBackpropFilterConfig} from './kernels/Conv2DBackpropFilter';\nimport {conv2DBackpropInputConfig} from './kernels/Conv2DBackpropInput';\nimport {conv3DConfig} from './kernels/Conv3D';\nimport {conv3DBackpropFilterV2Config} from './kernels/Conv3DBackpropFilterV2';\nimport {conv3DBackpropInputV2Config} from './kernels/Conv3DBackpropInputV2';\nimport {cosConfig} from './kernels/Cos';\nimport {coshConfig} from './kernels/Cosh';\nimport {cropAndResizeConfig} from './kernels/CropAndResize';\nimport {cumprodConfig} from './kernels/Cumprod';\nimport {cumsumConfig} from './kernels/Cumsum';\nimport {denseBincountConfig} from './kernels/DenseBincount';\nimport {depthToSpaceConfig} from './kernels/DepthToSpace';\nimport {depthwiseConv2dNativeConfig} from './kernels/DepthwiseConv2dNative';\nimport {depthwiseConv2dNativeBackpropFilterConfig} from './kernels/DepthwiseConv2dNativeBackpropFilter';\nimport {depthwiseConv2dNativeBackpropInputConfig} from './kernels/DepthwiseConv2dNativeBackpropInput';\nimport {diagConfig} from './kernels/Diag';\nimport {dilation2DConfig} from './kernels/Dilation2D';\nimport {dilation2DBackpropFilterConfig} from './kernels/Dilation2DBackpropFilter';\nimport {dilation2DBackpropInputConfig} from './kernels/Dilation2DBackpropInput';\nimport {einsumConfig} from './kernels/Einsum';\nimport {eluConfig} from './kernels/Elu';\nimport {eluGradConfig} from './kernels/EluGrad';\nimport {equalConfig} from './kernels/Equal';\nimport {erfConfig} from './kernels/Erf';\nimport {expConfig} from './kernels/Exp';\nimport {expandDimsConfig} from './kernels/ExpandDims';\nimport {expm1Config} from './kernels/Expm1';\nimport {fftConfig} from './kernels/FFT';\nimport {fillConfig} from './kernels/Fill';\nimport {flipLeftRightConfig} from './kernels/FlipLeftRight';\nimport {floorConfig} from './kernels/Floor';\nimport {floorDivConfig} from './kernels/FloorDiv';\nimport {fusedConv2DConfig} from './kernels/FusedConv2D';\nimport {fusedDepthwiseConv2DConfig} from './kernels/FusedDepthwiseConv2D';\nimport {gatherNdConfig} from './kernels/GatherNd';\nimport {gatherV2Config} from './kernels/GatherV2';\nimport {greaterConfig} from './kernels/Greater';\nimport {greaterEqualConfig} from './kernels/GreaterEqual';\nimport {identityConfig} from './kernels/Identity';\nimport {ifftConfig} from './kernels/IFFT';\nimport {imagConfig} from './kernels/Imag';\nimport {isFiniteConfig} from './kernels/IsFinite';\nimport {isInfConfig} from './kernels/IsInf';\nimport {isNaNConfig} from './kernels/IsNaN';\nimport {leakyReluConfig} from './kernels/LeakyRelu';\nimport {lessConfig} from './kernels/Less';\nimport {lessEqualConfig} from './kernels/LessEqual';\nimport {linSpaceConfig} from './kernels/LinSpace';\nimport {logConfig} from './kernels/Log';\nimport {log1pConfig} from './kernels/Log1p';\nimport {logicalAndConfig} from './kernels/LogicalAnd';\nimport {logicalNotConfig} from './kernels/LogicalNot';\nimport {logicalOrConfig} from './kernels/LogicalOr';\nimport {LRNConfig} from './kernels/LRN';\nimport {LRNGradConfig} from './kernels/LRNGrad';\nimport {maxConfig} from './kernels/Max';\nimport {maximumConfig} from './kernels/Maximum';\nimport {maxPoolConfig} from './kernels/MaxPool';\nimport {maxPool3DConfig} from './kernels/MaxPool3D';\nimport {maxPool3DGradConfig} from './kernels/MaxPool3DGrad';\nimport {maxPoolGradConfig} from './kernels/MaxPoolGrad';\nimport {maxPoolWithArgmaxConfig} from './kernels/MaxPoolWithArgmax';\nimport {meanConfig} from './kernels/Mean';\nimport {minConfig} from './kernels/Min';\nimport {minimumConfig} from './kernels/Minimum';\nimport {mirrorPadConfig} from './kernels/MirrorPad';\nimport {modConfig} from './kernels/Mod';\nimport {multinomialConfig} from './kernels/Multinomial';\nimport {multiplyConfig} from './kernels/Multiply';\nimport {negConfig} from './kernels/Neg';\nimport {nonMaxSuppressionV3Config} from './kernels/NonMaxSuppressionV3';\nimport {nonMaxSuppressionV4Config} from './kernels/NonMaxSuppressionV4';\nimport {nonMaxSuppressionV5Config} from './kernels/NonMaxSuppressionV5';\nimport {notEqualConfig} from './kernels/NotEqual';\nimport {oneHotConfig} from './kernels/OneHot';\nimport {onesLikeConfig} from './kernels/OnesLike';\nimport {packConfig} from './kernels/Pack';\nimport {padV2Config} from './kernels/PadV2';\nimport {powConfig} from './kernels/Pow';\nimport {preluConfig} from './kernels/Prelu';\nimport {prodConfig} from './kernels/Prod';\nimport {raggedGatherConfig} from './kernels/RaggedGather';\nimport {raggedRangeConfig} from './kernels/RaggedRange';\nimport {raggedTensorToTensorConfig} from './kernels/RaggedTensorToTensor';\nimport {rangeConfig} from './kernels/Range';\nimport {realConfig} from './kernels/Real';\nimport {realDivConfig} from './kernels/RealDiv';\nimport {reciprocalConfig} from './kernels/Reciprocal';\nimport {reluConfig} from './kernels/Relu';\nimport {relu6Config} from './kernels/Relu6';\nimport {reshapeConfig} from './kernels/Reshape';\nimport {resizeBilinearConfig} from './kernels/ResizeBilinear';\nimport {resizeBilinearGradConfig} from './kernels/ResizeBilinearGrad';\nimport {resizeNearestNeighborConfig} from './kernels/ResizeNearestNeighbor';\nimport {resizeNearestNeighborGradConfig} from './kernels/ResizeNearestNeighborGrad';\nimport {reverseConfig} from './kernels/Reverse';\nimport {rotateWithOffsetConfig} from './kernels/RotateWithOffset';\nimport {roundConfig} from './kernels/Round';\nimport {rsqrtConfig} from './kernels/Rsqrt';\nimport {scatterNdConfig} from './kernels/ScatterNd';\nimport {searchSortedConfig} from './kernels/SearchSorted';\nimport {selectConfig} from './kernels/Select';\nimport {seluConfig} from './kernels/Selu';\nimport {sigmoidConfig} from './kernels/Sigmoid';\nimport {signConfig} from './kernels/Sign';\nimport {sinConfig} from './kernels/Sin';\nimport {sinhConfig} from './kernels/Sinh';\nimport {sliceConfig} from './kernels/Slice';\nimport {softmaxConfig} from './kernels/Softmax';\nimport {softplusConfig} from './kernels/Softplus';\nimport {spaceToBatchNDConfig} from './kernels/SpaceToBatchND';\nimport {sparseFillEmptyRowsConfig} from './kernels/SparseFillEmptyRows';\nimport {sparseReshapeConfig} from './kernels/SparseReshape';\nimport {sparseSegmentMeanConfig} from './kernels/SparseSegmentMean';\nimport {sparseSegmentSumConfig} from './kernels/SparseSegmentSum';\nimport {sparseToDenseConfig} from './kernels/SparseToDense';\nimport {splitVConfig} from './kernels/SplitV';\nimport {sqrtConfig} from './kernels/Sqrt';\nimport {squareConfig} from './kernels/Square';\nimport {squaredDifferenceConfig} from './kernels/SquaredDifference';\nimport {staticRegexReplaceConfig} from './kernels/StaticRegexReplace';\nimport {stepConfig} from './kernels/Step';\nimport {stridedSliceConfig} from './kernels/StridedSlice';\nimport {stringNGramsConfig} from './kernels/StringNGrams';\nimport {stringSplitConfig} from './kernels/StringSplit';\nimport {stringToHashBucketFastConfig} from './kernels/StringToHashBucketFast';\nimport {subConfig} from './kernels/Sub';\nimport {sumConfig} from './kernels/Sum';\nimport {tanConfig} from './kernels/Tan';\nimport {tanhConfig} from './kernels/Tanh';\nimport {tensorScatterUpdateConfig} from './kernels/TensorScatterUpdate';\nimport {tileConfig} from './kernels/Tile';\nimport {topKConfig} from './kernels/TopK';\nimport {transformConfig} from './kernels/Transform';\nimport {transposeConfig} from './kernels/Transpose';\nimport {uniqueConfig} from './kernels/Unique';\nimport {unpackConfig} from './kernels/Unpack';\nimport {unsortedSegmentSumConfig} from './kernels/UnsortedSegmentSum';\nimport {zerosLikeConfig} from './kernels/ZerosLike';\n\n// List all kernel configs here\nconst kernelConfigs: KernelConfig[] = [\n  _fusedMatMulConfig,\n  absConfig,\n  acosConfig,\n  acoshConfig,\n  addConfig,\n  addNConfig,\n  allConfig,\n  anyConfig,\n  argMaxConfig,\n  argMinConfig,\n  asinConfig,\n  asinhConfig,\n  atanConfig,\n  atan2Config,\n  atanhConfig,\n  avgPoolConfig,\n  avgPool3DConfig,\n  avgPool3DGradConfig,\n  avgPoolGradConfig,\n  batchMatMulConfig,\n  batchNormConfig,\n  batchToSpaceNDConfig,\n  bincountConfig,\n  broadcastArgsConfig,\n  castConfig,\n  ceilConfig,\n  clipByValueConfig,\n  complexConfig,\n  complexAbsConfig,\n  concatConfig,\n  conv2DConfig,\n  conv2DBackpropFilterConfig,\n  conv2DBackpropInputConfig,\n  conv3DConfig,\n  conv3DBackpropFilterV2Config,\n  conv3DBackpropInputV2Config,\n  cosConfig,\n  coshConfig,\n  cropAndResizeConfig,\n  cumprodConfig,\n  cumsumConfig,\n  denseBincountConfig,\n  depthToSpaceConfig,\n  depthwiseConv2dNativeConfig,\n  depthwiseConv2dNativeBackpropFilterConfig,\n  depthwiseConv2dNativeBackpropInputConfig,\n  diagConfig,\n  dilation2DConfig,\n  dilation2DBackpropFilterConfig,\n  dilation2DBackpropInputConfig,\n  einsumConfig,\n  eluConfig,\n  eluGradConfig,\n  equalConfig,\n  erfConfig,\n  expConfig,\n  expandDimsConfig,\n  expm1Config,\n  fftConfig,\n  fillConfig,\n  flipLeftRightConfig,\n  floorConfig,\n  floorDivConfig,\n  fusedConv2DConfig,\n  fusedDepthwiseConv2DConfig,\n  gatherNdConfig,\n  gatherV2Config,\n  greaterConfig,\n  greaterEqualConfig,\n  identityConfig,\n  ifftConfig,\n  imagConfig,\n  isFiniteConfig,\n  isInfConfig,\n  isNaNConfig,\n  leakyReluConfig,\n  lessConfig,\n  lessEqualConfig,\n  linSpaceConfig,\n  logConfig,\n  log1pConfig,\n  logicalAndConfig,\n  logicalNotConfig,\n  logicalOrConfig,\n  LRNConfig,\n  LRNGradConfig,\n  maxConfig,\n  maximumConfig,\n  maxPoolConfig,\n  maxPool3DConfig,\n  maxPool3DGradConfig,\n  maxPoolGradConfig,\n  maxPoolWithArgmaxConfig,\n  meanConfig,\n  minConfig,\n  minimumConfig,\n  mirrorPadConfig,\n  modConfig,\n  multinomialConfig,\n  multiplyConfig,\n  negConfig,\n  nonMaxSuppressionV3Config,\n  nonMaxSuppressionV4Config,\n  nonMaxSuppressionV5Config,\n  notEqualConfig,\n  oneHotConfig,\n  onesLikeConfig,\n  packConfig,\n  padV2Config,\n  powConfig,\n  preluConfig,\n  prodConfig,\n  raggedGatherConfig,\n  raggedRangeConfig,\n  raggedTensorToTensorConfig,\n  rangeConfig,\n  realConfig,\n  realDivConfig,\n  reciprocalConfig,\n  reluConfig,\n  relu6Config,\n  reshapeConfig,\n  resizeBilinearConfig,\n  resizeBilinearGradConfig,\n  resizeNearestNeighborConfig,\n  resizeNearestNeighborGradConfig,\n  reverseConfig,\n  rotateWithOffsetConfig,\n  roundConfig,\n  rsqrtConfig,\n  scatterNdConfig,\n  searchSortedConfig,\n  selectConfig,\n  seluConfig,\n  sigmoidConfig,\n  signConfig,\n  sinConfig,\n  sinhConfig,\n  sliceConfig,\n  softmaxConfig,\n  softplusConfig,\n  spaceToBatchNDConfig,\n  sparseFillEmptyRowsConfig,\n  sparseReshapeConfig,\n  sparseSegmentMeanConfig,\n  sparseSegmentSumConfig,\n  sparseToDenseConfig,\n  splitVConfig,\n  sqrtConfig,\n  squareConfig,\n  squaredDifferenceConfig,\n  staticRegexReplaceConfig,\n  stepConfig,\n  stridedSliceConfig,\n  stringNGramsConfig,\n  stringSplitConfig,\n  stringToHashBucketFastConfig,\n  subConfig,\n  sumConfig,\n  tanConfig,\n  tanhConfig,\n  tensorScatterUpdateConfig,\n  tileConfig,\n  topKConfig,\n  transformConfig,\n  transposeConfig,\n  uniqueConfig,\n  unpackConfig,\n  unsortedSegmentSumConfig,\n  zerosLikeConfig\n];\n\nfor (const kernelConfig of kernelConfigs) {\n  registerKernel(kernelConfig);\n}\n","/** @license See the LICENSE file. */\n\n// This code is auto-generated, do not modify this file!\nconst version = '4.4.0';\nexport {version};\n"],"names":["assertNotComplex","tensor","opName","Array","isArray","forEach","t","util","assert","dtype","whereImpl","kernel_impls","MathBackendCPU","KernelBackend","nextDataId","constructor","super","this","data","DataStorage","engine","write","values","shape","firstUse","env","get","backend_util","warn","dataId","id","set","refCount","makeTensorInfo","outId","length","isString","encodedValues","map","d","encodeString","has","incRef","decRef","move","numDataIds","async","readSync","complexTensorInfos","realValues","real","imagValues","imag","mergeRealAndImagArrays","convertBackendValuesAndArrayBuffer","bufferSync","strings","decodeString","buffer","Error","makeOutput","makeTensorFromTensorInfo","disposeData","force","delete","disposeIntermediateTensorInfo","tensorInfo","f","start","now","kernelMs","memory","unreliable","reasons","where","condition","condVals","dispose","floatPrecision","epsilon","simpleAbsImpl","vals","resultValues","Float32Array","i","Math","abs","absConfig","kernelName","Abs","backendName","kernelFunc","args","x","inputs","cpuBackend","backend","sizeFromShape","createSimpleBinaryKernelImpl","op","aShape","bShape","aVals","bVals","newShape","assertAndGetBroadcastShape","resultRank","resultStrides","computeStrides","resultSize","result","getTypedArrayFromDType","aRank","bRank","aStrides","bStrides","aBroadcastDims","getBroadcastDims","bBroadcastDims","loc","indexToLoc","aLoc","slice","aIndex","locToIndex","bLoc","bIndex","complex","realVals","imagVals","complexInfo","complexConfig","Complex","zeros","makeZerosTypedArray","identity","identityConfig","Identity","input","realVal","realConfig","Real","castImpl","inputType","Int32Array","from","zero","toTypedArray","resultData","resultShape","a","b","cast","attrs","zerosTensorInfo","floatX","realPart","hasEncodingLoss","resultType","castConfig","Cast","binaryKernelFunc","name","simpleImpl","complexImpl","decodedAVals","fromUint8ToStringArray","decodedBVals","$dtype","$aComplex","$aComplexVals","aReal","aImag","aRealVals","aImagVals","$bComplex","$bComplexVals","bReal","bImag","bRealVals","bImagVals","resultRealData","resultImagData","resultReal","resultImag","createComplexBinaryKernelImpl","resultRealVals","resultImagVals","aIdx","bIdx","opResult","addImpl","addComplexImpl","add","Add","addConfig","bincountImpl","xVals","weightsVals","weightsDtype","weightsShape","size","weightsSize","outVals","value","bincountReduceImpl","xBuf","weightsBuf","binaryOutput","numRows","numCols","outBuf","j","createSimpleUnaryImpl","newValues","getArrayFromDType","unaryKernelFunc","unaryKernelFuncFromImpl","unaryImpl","decoded","ceilImpl","xi","ceil","Ceil","ceilConfig","concatImpl","outShape","simplyConcat","offset","colOffset","decodedData","tIdx","row","resIdx","col","equalImpl","equal","Equal","equalConfig","expImpl","exp","Exp","expConfig","expm1Impl","expm1","Expm1","expm1Config","floorImpl","floor","Floor","floorConfig","floorDivImpl","floorDiv","FloorDiv","floorDivConfig","gatherNdImpl","indicesData","paramsBuf","numSlices","sliceRank","sliceSize","strides","paramsShape","paramsSize","index","flattenIndex","dim","push","k","gatherV2Impl","indicesBuf","flattenOutputShape","originalLoc","batchIdx","indicesIdx","indicesIndex","originalIndex","greaterImpl","greater","Greater","greaterConfig","greaterEqualImpl","greaterEqual","GreaterEqual","greaterEqualConfig","lessImpl","less","Less","lessConfig","lessEqualImpl","lessEqual","LessEqual","lessEqualConfig","linSpaceImpl","stop","num","step","logImpl","log","Log","logConfig","maxImpl","reduceSize","max","Number","isNaN","maximumImpl","aValue","bValue","maximum","Maximum","maximumConfig","minimumImpl","min","minimum","Minimum","minimumConfig","multiplyImpl","multiplyComplexImpl","multiply","Multiply","multiplyConfig","negImpl","xShape","xDtype","minusOne","createScalarValue","negConfig","Neg","res","notEqualImpl","notEqual","NotEqual","notEqualConfig","transposeImpl","perm","xRank","xSize","xStrides","newStrides","newLoc","transpose","transposeConfig","Transpose","prodImpl","reductionAxes","reduceShape","computeOutAndReduceShapes","outDtype","upcastType","prod","prodConfig","Prod","axis","keepDims","axes","parseAxisParam","permutation","getAxesPermutation","permutedX","intermediateTensorInfos","getInnerMostAxes","expandShapeToKeepDim","makeSplits","indices","indicesShape","paramsNestedSplits","numParamsDenseValues","valueSlices","numValues","numSplits","outSplits","fill","splits","lastSplit","validateSplits","nrows","rowLength","limit","outDim","outSplitsOutDim","delta","computeFlatOuterDims","orig","numOutDims","outDims","inDim","getValues","paramsDenseValues","paramsDenseValuesShape","paramsDenseValuesDType","valuesShape","valuesOut","numElements","valueSize","denseM","valuesM","outPos","writeValueSlices","raggedGatherImpl","paramsNestedSplitsShapes","outputRaggedRank","numParams","locString","join","validateIndices","outputNestedSplits","splitsOut","getSplits","outputDenseValues","INT32_MAX","raggedRangeImpl","starts","startsShape","startsDType","limits","limitsShape","deltas","deltasShape","broadcastStarts","broadcastLimits","broadcastDeltas","inSizes","nRows","rtNestedSplits","nVals","rtDenseValues","valueIndex","rowSize","RowPartitionType","RaggedTensorToTensorOp","shapeShape","valuesDType","defaultValue","defaultValueShape","rowPartitionValues","rowPartitionValuesShapes","rowPartitionTypeStrings","rowPartitionTypes","getRowPartitionTypesHelper","raggedRank","getRaggedRank","getRowPartitionTypeByDimension","dimension","FIRST_DIM_SIZE","getRowPartitionTensor","getMaxWidth","rowPartitionTensor","VALUE_ROWIDS","getMaxWidthValueRowID","ROW_SPLITS","getMaxWidthRowSplit","static","rowSplit","tensorLength","maxWidth","currentWidth","valueRowIds","indexLength","firstEqualIndex","firstEqualIndexValue","tensorShapeFromTensor","tShape","isPartial","makeShape","calculateOutputSize","firstDim","valueShape","validateDefaultValueShape","combineRaggedTensorToTensorShapes","calculateFirstParentOutputIndex","firstDimension","outputIndexMultiplier","firstDimensionOutput","minDimension","currentOutputIndex","calculateOutputIndexRowSplit","parentOutputIndex","outputSize","rowSplitSize","realLength","parentOutputIndexCurrent","calculateOutputIndexValueRowID","indexSize","currentOutputColumn","currentValueRowId","nextValueRowId","calculateOutputIndex","partitionType","getFirstDimensionSize","firstPartitionTensor","firstPartitionType","compute","multiplier","outputShape","outputTensor","outputIndex","setOutput","valuesBase","outputBase","elementShape","valueElementSize","outputIndexSize","srcShape","tidy","defaultValueTensor","reshape","bCastDefault","broadcastTo","dataSync","srcStart","dstStart","dstEnd","srcI","dstI","src","subarray","copyArray","dst","out","raggedTensorToTensorImpl","shapesShape","rangeImpl","rsqrtImpl","sqrt","rsqrt","Rsqrt","rsqrtConfig","scatterImpl","updates","numUpdates","sumDupeIndices","flattenShape","updatesData","TensorBuffer","rank","sigmoidImpl","sigmoid","Sigmoid","sigmoidConfig","sliceImpl","begin","isContinous","slice_util","isSliceContinous","flatOffset","computeFlatOffset","inBuf","outLoc","inLoc","idx","fromStringArrayToUint8","$begin","$size","parseSliceParams","assertParamsValid","sliceConfig","Slice","sparseFillEmptyRowsImpl","indicesDType","denseShape","indicesCount","denseRows","emptyRowIndicator","reverseIndexMap","getSparseFillEmptyRowsIndicesDenseShapeMismatch","rowsAreOrdered","lastIndicesRow","csrOffset","getSparseFillEmptyRowsNegativeIndexErrorMessage","getSparseFillEmptyRowsOutOfRangeIndexErrorMessage","allRowsFull","rowEmpty","outputIndices","outputValues","fullIndicesCount","filledCount","outputI","startingIndex","sparseReshapeImpl","inputIndices","inputIndicesShape","inputDType","inputShape","targetShape","denseSize","nnz","outputRank","product","unknownIndex","getSparseReshapeMultipleNegativeOneOutputDimErrorMessage","getSparseReshapeNegativeOutputDimErrorMessage","getSparseReshapeEmptyTensorZeroOutputDimErrorMessage","missing","trunc","getSparseReshapeInputOutputMultipleErrorMessage","getSparseReshapeInputOutputMismatchErrorMessage","inputRank","inputStrides","outputStrides","newIndices","sparseSegmentReductionImpl","segmentIds","isMean","numIndices","inputFlat","numCol","outputRows","getSparseSegmentReductionNegativeSegmentIdsErrorMessage","outputLength","reduce","output","end","uninitializedIndex","outIndex","nextIndex","getSparseSegmentReductionNonIncreasingSegmentIdsErrorMessage","getSparseSegmentReductionSegmentIdOutOfRangeErrorMessage","getSparseSegmentReductionIndicesOutOfRangeErrorMessage","sqrtImpl","Sqrt","sqrtConfig","squaredDifferenceImpl","diff","squaredDifference","SquaredDifference","squaredDifferenceConfig","staticRegexReplaceImpl","pattern","replaceGlobal","rewrite","replace","RegExp","staticRegexReplace","StaticRegexReplace","staticRegexReplaceConfig","stridedSliceImpl","StringNGramsOp","separator","nGramWidths","leftPad","rightPad","padWidth","preserveShortSequences","preserveShort","getPadWidth","nGramWidth","getNumNGrams","createNGrams","splitIndex","outputStartIndex","numNGrams","nGramIndex","leftPadding","rightPadding","numTokens","dataStartIndex","nGramSize","n","Uint8Array","nGram","nextNGramIndex","appendToNGram","str","inputDataSize","splitsSize","prevSplit","validSplits","numBatchItems","nGramsSplits","empty","nGrams","outputStartIdx","dataLength","stringNGramsImpl","dataSplits","split","delimiters","skipEmpty","delimiter","indexOf","token","tokenStart","stringSplitImpl","batchSize","tokens","maxNumEntries","prevTokensLength","nEntries","c","stringToHashBucketFastImpl","numBuckets","fingerPrint64","modulo","getLowBitsUnsigned","subImpl","subComplexImpl","sub","Sub","subConfig","tileImpl","reps","comparePair","valueDiff","select","array","left","right","z","s","sd","sign","swap","topKImpl","sorted","lastDim","batch","allTopKVals","allTopKIndices","valAndInd","sort","outOffset","topKVals","topKIndices","uniqueImpl","$axis","uniqueElements","Map","inputBuffer","uniqueIndices","is1DTensor","element","toString","axisValues","m","existingIndex","uniqueIndex","outputTmpShape","outputBuffer","uniqueElementIndex","elu","Elu","eluConfig","leakyRelu","alpha","leakyReluConfig","LeakyRelu","preluImpl","xValue","prelu","preluConfig","Prelu","relu","Relu","reluConfig","relu6","Relu6","relu6Config","applyActivation","activation","preluActivationWeights","leakyreluAlpha","$shape","inferFromImplicitShape","$xSize","xData","reshapeConfig","Reshape","batchMatMul","transposeA","transposeB","innerShapeA","innerShapeB","outerShapeA","outerShapeB","outerDimsA","outerDimsB","batchDimA","batchDimB","broadcast_util","concat","b3dShape","a3d","b3d","sharedDim","leftDim","rightDim","batchDim","a3dValues","b3dValues","a3dStrides","b3dStrides","aBatch","aOuterStep","aInnerStep","bInnerStep","bOuterStep","bBatch","resVals","blockSize","bi","batchIndexA","batchIndexB","i0","iBlock","j0","jBlock","k0","kBlock","sum","batchMatMulConfig","BatchMatMul","_fusedMatMulConfig","_FusedMatMul","bias","current","addRes","activationRes","intermediates","acos","Acos","acosConfig","acosh","Acosh","acoshConfig","addNConfig","AddN","tensors","currVals","allConfig","All","origAxes","permutedAxes","$x","assertAxesAreInnerMostDims","all","reshapedResult","anyConfig","Any","anyVal","argMaxConfig","ArgMax","outSize","maxIndex","argMinConfig","ArgMin","minIndex","asin","Asin","asinConfig","asinh","Asinh","asinhConfig","atan","Atan","atanConfig","atan2Impl","atan2","Atan2","atan2Config","atanh","Atanh","atanhConfig","pool","xValues","convInfo","poolType","strideHeight","strideWidth","dilationHeight","dilationWidth","effectiveFilterHeight","effectiveFilterWidth","padTop","padInfo","top","padLeft","initialValue","NEGATIVE_INFINITY","POSITIVE_INFINITY","outputVals","outputBatchStrides","outputRowStrides","outputColStrides","outputBatchOffset","inputBatchOffset","inChannels","yR","outHeight","xRCorner","xRMin","xRMax","inHeight","outputRowOffset","yC","outWidth","xCCorner","xCMin","xCMax","inWidth","minMaxValue","avgValue","count","xR","xROffset","xC","pixel","maxPoolPositions","flattenPositions","includeBatchInIndex","maxPositions","maxValue","maxPosition","wR","wC","pool3d","strideDepth","dilationDepth","effectiveFilterDepth","padFront","front","outputDepthStrides","channel","yDepth","outDepth","xDepthCorner","xDepthMin","xDepthMax","inDepth","outputDepthOffset","yRow","xRowCorner","xRowMin","xRowMax","yCol","xColCorner","xColMin","xColMax","outputColOffset","xDepth","xDepthOffset","xRow","xRowOffset","xCol","avgPoolConfig","AvgPool","filterSize","pad","dimRoundingMode","eitherStridesOrDilationsAreOne","computePool2DInfo","filterWidth","filterHeight","arraysEqual","inShape","avgPool3DConfig","AvgPool3D","dataFormat","computePool3DInfo","avgPool3DGradConfig","AvgPool3DGrad","dy","filterDepth","dx","avgMultiplier","dyBuf","dxDepth","dxRow","dxCol","dyDepthCorner","dyRowCorner","dyColCorner","dotProd","wDepth","dyDepth","wRow","dyRow","wCol","dyCol","avgPoolGradConfig","AvgPoolGrad","dyData","dxR","dxC","dyRCorner","dyCCorner","dyR","dyC","batchNormConfig","FusedBatchNorm","scale","mean","variance","varianceEpsilon","mVals","varVals","sVals","offVals","offValsLength","sValsLength","varValsLength","mValsLength","offi","mi","si","vi","batchToSpaceNDConfig","BatchToSpaceND","blockShape","crops","reshaped","getReshaped","permuted","getPermuted","reshapedPermuted","getReshapedPermuted","sliceBeginCoords","getSliceBeginCoords","getSliceSize","xReshaped","xTransposed","xTransposedReshaped","bincountConfig","Bincount","weights","broadcastArgsConfig","BroadcastArgs","s0","s1","s0Vals","s1Vals","broadcastShape","clipByValue","ClipByValue","clipAttrs","clipValueMax","clipValueMin","clipByValueConfig","complexAbsConfig","ComplexAbs","complexVals","hypot","imagVal","imagConfig","Imag","shapes","assertParamsConsistent","computeOutShape","$inputs","filter","reals","imags","realConcated","imagConcated","r","inputs2D","innerSize","inputsValShapes","finalOutShape","outInfo","concatConfig","Concat","conv2D","dilations","$dataFormat","convertConv2DDataFormat","computeConv2DInfo","isChannelsLast","y","filterStrides","xBatchStride","xRowStride","xColStride","xChannelStride","yBatchStride","yRowStride","yColStride","yChannelStride","wVals","yVals","xOffset1","yOffset1","yOffset2","wOffset1","xOffset2","yOffset3","xOffset3","wOffset3","d1","xVal","d2","outChannels","conv2DConfig","Conv2D","conv2DBackpropFilterConfig","Conv2DBackpropFilter","filterShape","dW","topPad","dyVals","yRMin","yRMax","yCMin","yCMax","conv2DBackpropInputConfig","Conv2DBackpropInput","dyStrides","dxValues","dyValues","fltValues","fltS0","fltS1","fltS2","dyOffset","fltOffset","conv3DConfig","Conv3D","computeConv3DInfo","yF","xFCorner","wF","xF","wOffset2","yOffset4","xOffset4","wOffset4","conv3DBackpropFilterV2Config","Conv3DBackpropFilterV2","dw","dwValues","dwS0","dwS1","dwS2","dwS3","dyS0","dyS1","dyS2","dyS3","xS0","xS1","xS2","xS3","frontPad","yFMin","yFMax","conv3DBackpropInputV2Config","Conv3DBackpropInputV2","dxS0","dxS1","dxS2","dxS3","fltS3","xFMin","cos","Cos","cosConfig","cosh","Cosh","coshConfig","cropAndResizeConfig","CropAndResize","image","boxes","boxInd","cropSize","method","extrapolationValue","imageHeight","imageWidth","numChannels","numBoxes","cropHeight","cropWidth","boxVals","boxIndVals","imageVals","inStride","outStride","startInd","y1","x1","y2","x2","bInd","heightScale","widthScale","yInd","ind","topInd","bottomInd","yLerp","xInd","leftInd","rightInd","xLerp","topLeft","topRight","bottomLeft","bottom","closestX","round","closestY","inInd","outInd","cumprodConfig","Cumprod","exclusive","reverse","permutedAxis","resultDtype","makeOnesTypedArray","finalDim","indexAdjuster","prevIdx","reverseTransposedResult","getUndoAxesPermutation","cumsumConfig","Cumsum","denseBincountConfig","DenseBincount","depthToSpaceConfig","DepthToSpace","inputHeight","inputWidth","inputDepth","outputHeight","outputWidth","outputDepth","outputIdx","h","inH","offsetH","w","inW","offsetD","inputIdx","depthwiseConv2dNative","$dilations","chMul","q","depthwiseConv2dNativeConfig","DepthwiseConv2dNative","depthwiseConv2dNativeBackpropFilterConfig","DepthwiseConv2dNativeBackpropFilter","dm","depthwiseConv2dNativeBackpropInputConfig","DepthwiseConv2dNativeBackpropInput","diagConfig","Diag","dilation2DConfig","Dilation2D","filterVals","filterRank","computeDilation2DInfo","outRank","hOut","hBeg","wOut","wBeg","curVal","MIN_SAFE_INTEGER","hIn","wIn","xIndex","filterIndex","val","dilation2DBackpropFilterConfig","Dilation2DBackpropFilter","toNestedArray","$filter","$dy","gradients","makeZerosNestedTypedArray","hMax","wMax","dilation2DBackpropInputConfig","Dilation2DBackpropInput","hInMax","wInMax","oldResult","sumConfig","Sum","einsumConfig","Einsum","equation","allDims","summedDims","idDims","decodeEinsumEquation","checkEinsumDimSizes","path","steps","getEinsumComputePath","nSteps","numDimsRemaining","tensorsToDispose","idTerm","permutationIndices","expandDims","dimsToExpand","getEinsumPermutation","isIdentityPermutation","splice","eluGradConfig","EluGrad","v","p","ERF_P","a1","ERF_A1","a2","ERF_A2","a3","ERF_A3","a4","ERF_A4","a5","ERF_A5","erf","Erf","erfConfig","$dim","expandDimsConfig","ExpandDims","realDivImpl","div","RealDiv","realDivConfig","fftBatch","inverse","innerDim","inputVals","real2D","imag2D","fftImpl","getComplexWithIndex","$realInfo","$imagInfo","inputSize","fftRadix2","realInfo","imagInfo","sizeInfo","sizeInfoCopy","divRealInfo","divImagInfo","divRealVals","divImagVals","rawOutput","ret","e","exponent","term","assignToTypedArray","fourierTransformByMatmul","splitRealAndImagArrays","half","evenComplex","complexWithEvenIndex","evenRealVals","evenImagVals","evenShape","evenRealInfo","evenImagInfo","evenTensorInfo","oddComplex","complexWithOddIndex","oddRealVals","oddImagVals","oddShape","oddRealInfo","oddImagInfo","oddTensorInfo","$evenComplex","$evenRealVals","$evenImagVals","$evenShape","$evenRealInfo","$evenImagInfo","$evenTensorInfo","$oddComplex","$oddRealVals","$oddImagVals","$oddShape","$oddRealInfo","$oddImagInfo","$oddTensorInfo","exponents","eShape","eRealInfo","eImagInfo","exponentInfo","addPart","subPart","addPartReal","subPartReal","addPartImag","subPartImag","$real","$imag","$realVals","$imagVals","fftConfig","FFT","innerDimensionSize","input2D","resultReshaped","inferDtype","fillValues","fillConfig","Fill","flipLeftRightConfig","FlipLeftRight","batchOffset","rowOffset","coordX","outIdx","outputValue","fusedConv2DConfig","FusedConv2D","resultOld","reshapedBias","reshapedAlpha","fusedDepthwiseConv2DConfig","FusedDepthwiseConv2D","gatherNdConfig","GatherNd","params","prepareAndValidate","gatherV2Config","GatherV2","batchDims","parsedAxis","indicesVals","axisDim","$batchDims","indicesSize","shapeInfo","segment_util","collectGatherOpShapeInfo","flattenX","outerSize","dimSize","ifftConfig","IFFT","isFinite","IsFinite","isFiniteConfig","isInf","IsInf","Infinity","isInfConfig","IsNan","isNaNConfig","linSpaceConfig","LinSpace","log1p","Log1p","log1pConfig","logicalAndImpl","logicalAnd","LogicalAnd","logicalAndConfig","logicalNot","LogicalNot","logicalNotConfig","logicalOrImpl","logicalOr","LogicalOr","logicalOrConfig","LRNConfig","LRN","depthRadius","beta","channels","maxD","sumAcrossChannels","currentChannel","beginSumOffset","endSumOffset","pow","LRNGradConfig","LRNGrad","dySize","yValues","depthBegin","depthEnd","norm","dyi","reductionIndices","maxOutShape","maxConfig","Max","maxPoolConfig","MaxPool","maxPool3DConfig","MaxPool3D","maxPool3DGradConfig","MaxPool3DGrad","maxPosBuf","maxPool3dPositions","mask","maxPoolGradConfig","MaxPoolGrad","maxPoolWithArgmaxConfig","MaxPoolWithArgmax","pooled","indexes","maxPools","maxPoolWithArgmaxImpl","pooledDataId","indexesDataId","meanConfig","Mean","toDispose","reduceSizeScalar","minConfig","Min","mirrorPadConfig","MirrorPad","paddings","mode","coords","inIndex","modImpl","rem","mod","Mod","modConfig","softmax","logits","logitsRank","maxLogit","expandedShape","maxLogitReshaped","sumExp","sumReshaped","softmaxConfig","Softmax","multinomialConfig","Multinomial","numSamples","seed","normalized","probabilities","numEvents","probVals","resShape","cdf","event","random","seedrandom","alea","sampleId","nonMaxSuppressionV3Impl","nonMaxSuppressionV3Config","NonMaxSuppressionV3","scores","maxOutputSize","iouThreshold","scoreThreshold","boxesVals","scoresVals","selectedIndices","nonMaxSuppressionV4Impl","nonMaxSuppressionV4Config","NonMaxSuppressionV4","padToMaxOutputSize","validOutputs","nonMaxSuppressionV5Impl","nonMaxSuppressionV5Config","NonMaxSuppressionV5","softNmsSigma","maxOutputSizeVal","iouThresholdVal","scoreThresholdVal","softNmsSigmaVal","selectedScores","oneHotConfig","OneHot","depth","onValue","offValue","indicesVal","zerosLike","imagPart","zerosLikeConfig","ZerosLike","onesLikeConfig","OnesLike","onesLike","pack","assertShapesMatch","expandedT","packConfig","Pack","padV2Config","PadV2","constantValue","outCoords","powImpl","Pow","powConfig","raggedGatherConfig","RaggedGather","$paramsNestedSplits","$paramsNestedSplitsShapes","$paramsDenseValues","$indices","outputDenseValuesShape","outputNestedSplitsTensors","outputDenseValuesTensor","raggedRangeConfig","RaggedRange","$starts","$limits","$deltas","rtNestedSplitsData","rtDenseValuesData","raggedTensorToTensorConfig","RaggedTensorToTensor","rowPartitionTensors","$values","$defaultValue","$rowPartitionValues","rangeConfig","Range","reciprocal","Reciprocal","reciprocalConfig","resizeBilinearConfig","ResizeBilinear","images","alignCorners","halfPixelCenters","imagesStrides","newHeight","newWidth","oldHeight","oldWidth","effectiveInputSize","effectiveOutputSize","effectiveRowSizeRatio","effectiveColSizeRatio","sourceFracRow","sourceRowFloor","rowFrac","sourceRowCeil","topRowOffset","botRowOffset","sourceFracCol","sourceColFloor","colFrac","sourceColCeil","topLeftOffest","botLeftOffset","topRightOffset","botRightOffest","newValue","resizeBilinearGradConfig","ResizeBilinearGrad","xHeight","xWidth","yHeight","yWidth","effectiveXSize","effectiveYSize","bOffset","topDxRIndex","bottomDxRIndex","topDxROffset","bottomDxROffset","dxRLerp","inverseDxRLerp","leftDxCIndex","rightDxCIndex","dxCLerp","inverseDxCLerp","topLeftRCOffset","topRightRCOffset","bottomLeftRCOffset","bottomRightRCOffset","inverseDxRLerpTimesInverseDxCLerp","inverseDxRLerpTimesDxCLerp","dxRLerpTimesInverseDxCLerp","dxRLerpTimesDxCLerp","dyVal","resizeNearestNeighborConfig","ResizeNearestNeighbor","outputOffset","sourceNearestRow","sourceNearestCol","newVal","resizeNearestNeighborGradConfig","ResizeNearestNeighborGrad","invHeightScale","invWidthScale","winHeight","winWidth","startRLerp","startDyR","startCLerp","startDyC","accum","dyRIndex","dyROffset","dyCIndex","dyCOffset","reverseConfig","Reverse","dims","$dims","rotateWithOffsetConfig","RotateWithOffset","radians","fillValue","center","centerX","centerY","getImageCenter","sinFactor","sin","cosFactor","coordY","Round","base","roundConfig","scatterNdConfig","ScatterNd","calculateShapes","lowerBound","mid","upperBound","searchSortedConfig","SearchSorted","sortedSequence","side","sortedInputs","numInputs","sortedInputsSlice","searchSortedImpl","selectConfig","Select","conditionRank","tValues","eValues","scaleAlpha","SELU_SCALEALPHA","SELU_SCALE","selu","Selu","seluConfig","Sign","signConfig","Sin","sinConfig","sinh","Sinh","sinhConfig","threshold","softplus","Softplus","tooLarge","tooSmall","expX","softplusConfig","spaceToBatchNDConfig","SpaceToBatchND","completePaddings","paddedX","reshapedPaddedShape","permutedReshapedPaddedPermutation","paddedXReshaped","paddedXT","sparseFillEmptyRowsConfig","SparseFillEmptyRows","$denseShape","outputIndicesShape","sparseReshapeConfig","SparseReshape","$inputShape","$inputIndices","sparseSegmentMeanConfig","SparseSegmentMean","$data","$segmentIds","outputData","outputDataShape","sparseSegmentSumConfig","SparseSegmentSum","sparseToDenseConfig","SparseToDense","sparseIndices","sparseValues","Boolean","splitVConfig","SplitV","numOrSizeSplits","splitSizes","prepareSplitSize","sliceT","squareConfig","Square","Step","stepAttrs","NaN","stepConfig","stridedSliceConfig","StridedSlice","beginMask","endMask","ellipsisMask","newAxisMask","shrinkAxisMask","finalShapeSparse","finalShape","isIdentity","sliceDim0","isSimpleSlice","$end","$strides","sliceInfo","sliced","stringNGramsConfig","StringNGrams","$dataSplits","stringSplitConfig","StringSplit","$input","$delimiter","stringToHashBucketFastConfig","StringToHashBucketFast","tan","Tan","tanConfig","tanh","Tanh","tanhConfig","tensorScatterUpdateConfig","TensorScatterUpdate","updatesBuf","tensorBuf","tileConfig","Tile","topKConfig","TopK","transformConfig","Transform","transforms","interpolation","fillMode","inStrides","batchInStride","rowInStride","colInStride","outStrides","batchOutStride","rowOutStride","colOutStride","transformVals","transform","outY","outX","projection","inX","inY","mapCoord","nearestInterpolation","bilinearInterpolation","outCoord","len","inCoord","sz2","clamp","mapCoordReflect","sz","mapCoordWrap","mapCoordNearest","mapCoordConstant","readWithFillValue","batchStride","rowStride","colStride","yFloor","xFloor","yCeil","xCeil","uniqueConfig","Unique","unpackConfig","Unpack","valueRank","tempRes","unsortedSegmentSumConfig","UnsortedSegmentSum","numSegments","numIters","expanded","scalarValue","segmentId","maskCasted","mul","sumTensorInfo","kernelConfigs","kernelConfig","registerKernel"],"mappings":";;;;;;;;;;;;;;;;soBAmBgBA,EACZC,EAAiCC,GAC9BC,MAAMC,QAAQH,KACjBA,EAAS,CAACA,IAEZA,EAAOI,SAAQC,IACJ,MAALA,GACFC,OAAKC,OACW,cAAZF,EAAEG,OACF,IAAM,GACFP,+DAGd,CCbA,MAAMQ,EAAYC,eAAaD,gBAiBlBE,UAAuBC,gBAM1BC,aACN,OAAOF,EAAeE,aAGxBC,cACEC,QAVKC,eAAY,GAGXA,eAAW,EAQjBA,KAAKC,KAAO,IAAIC,cAAYF,KAAMG,YAG3BC,MACLC,EAAoCC,EACpCd,GACEQ,KAAKO,WACPP,KAAKO,UAAW,EACZC,QAAMC,IAAI,YACZC,eAAaC,KACT,uPAOR,MAAMC,EAAS,CAACC,GAAIb,KAAKH,cAIzB,OAFAG,KAAKC,KAAKa,IAAIF,EAAQ,CAACP,SAAQb,QAAOuB,SAAU,IAEzCH,EASTI,eACIV,EAAiBd,EACjBa,GACF,IAAIY,EACJ,GAAc,WAAVzB,GAAgC,MAAVa,GAAkBA,EAAOa,OAAS,GACxD5B,OAAK6B,SAASd,EAAO,IAAK,CAC5B,MAAMe,EACDf,EAA+BgB,KAAIC,GAAKhC,OAAKiC,aAAaD,KAE/DL,EAAQjB,KAAKI,MAAMgB,EAAed,EAAOd,QAEzCyB,EAAQjB,KAAKI,MAAMC,EAAsBC,EAAOd,GAGlD,MAAO,CAACoB,OAAQK,EAAOX,QAAOd,SAIvBuB,SAASH,GAChB,GAAIZ,KAAKC,KAAKuB,IAAIZ,GAAS,CAEzB,OADmBZ,KAAKC,KAAKQ,IAAIG,GACfG,SAEpB,OAAO,EAIAU,OAAOb,GACKZ,KAAKC,KAAKQ,IAAIG,GACtBG,WAIbW,OAAOd,GACL,GAAIZ,KAAKC,KAAKuB,IAAIZ,GAAS,CACNZ,KAAKC,KAAKQ,IAAIG,GACtBG,YAINY,KACLf,EAAgBP,EAAoCC,EACpDd,EAAiBuB,GACnBf,KAAKC,KAAKa,IAAIF,EAAQ,CAACP,SAAQb,QAAOuB,aAG/Ba,aACP,OAAO5B,KAAKC,KAAK2B,aAGVC,WAAWjB,GAClB,OAAOZ,KAAK8B,SAASlB,GAEdkB,SAASlB,GAChB,MAAMpB,MAACA,EAAKuC,mBAAEA,GAAsB/B,KAAKC,KAAKQ,IAAIG,GAElD,GAAc,cAAVpB,EAAuB,CACzB,MAAMwC,EACFhC,KAAK8B,SAASC,EAAmBE,KAAKrB,QACpCsB,EACFlC,KAAK8B,SAASC,EAAmBI,KAAKvB,QAC1C,OAAOF,eAAa0B,uBAAuBJ,EAAYE,GAEzD,OAAO5C,OAAK+C,mCACRrC,KAAKC,KAAKQ,IAAIG,GAAQP,OAAQb,GAGpC8C,WAA+CjD,GAE7C,MAAMY,EAAOD,KAAK8B,SAASzC,EAAEuB,QAC7B,GAAgB,WAAZvB,EAAEG,MACJ,IAEE,MAAM+C,EAAWtC,EAAsBoB,KAAIC,GAAKhC,OAAKkD,aAAalB,KAClE,OAAOmB,SAAOpD,EAAEiB,MAAsBjB,EAAEG,MAAO+C,GAE/C,SACA,MAAM,IAAIG,MAAM,oDAGpB,OAAOD,SAAOpD,EAAEiB,MAAsBjB,EAAEG,MAAOS,GAIjD0C,WACItC,EAAoCC,EAAiBd,GACvD,OAAOW,WAASyC,yBACL5C,KAAKgB,eAAeV,EAAOd,EAAOa,GAASL,MAU/C6C,YAAYjC,EAAgBkC,GAAQ,GAC3C,GAAI9C,KAAKC,KAAKuB,IAAIZ,GAAS,CAEzB,GADAZ,KAAKC,KAAKQ,IAAIG,GAAQG,YACjB+B,GAAS9C,KAAKC,KAAKQ,IAAIG,GAAQG,SAAW,EAC7C,OAAO,EAGT,MAAMgB,mBAACA,GAAsB/B,KAAKC,KAAKQ,IAAIG,GAEjB,MAAtBmB,IACF/B,KAAK6C,YAAYd,EAAmBE,KAAKrB,QAAQ,GACjDZ,KAAK6C,YAAYd,EAAmBI,KAAKvB,QAAQ,IAGnDZ,KAAKC,KAAK8C,OAAOnC,GAEnB,OAAO,EAGToC,8BAA8BC,GAC5BjD,KAAK6C,YAAYI,EAAWrC,QAGrBiB,WAAWqB,GAClB,MAAMC,EAAQ7D,OAAK8D,MACnBF,IAEA,MAAO,CAACG,SADS/D,OAAK8D,MAAQD,GAIvBG,SACP,MAAO,CAELC,YAAY,EACZC,QACI,CAAC,uHAKTC,MAAMC,GACJ3E,EAAiB,CAAC2E,GAAY,SAE9B,MAAMC,EAAW3D,KAAK8B,SAAS4B,EAAU9C,QACzC,OAAOnB,EAAUiE,EAAUpD,MAAOqD,GAG3BC,WAEAC,iBACP,OAAO,GAIAC,UACP,OAAO/D,MAAM+D,oBChNDC,EAAcC,GAC5B,MAAMC,EAAe,IAAIC,aAAaF,EAAK9C,QAC3C,IAAK,IAAIiD,EAAI,EAAGA,EAAIH,EAAK9C,SAAUiD,EACjCF,EAAaE,GAAKC,KAAKC,IAAIL,EAAKG,IAElC,OAAOF,CACT,CDaiBtE,aAAa,ECXvB,MAaM2E,EAA0B,CACrCC,WAAYC,MACZC,YAAa,MACbC,WAhBkBC,IAClB,MAAMC,EAACA,GAAKD,EAAKE,OACXC,EAAaH,EAAKI,QAExBhG,EAAiB6F,EAAG,OAEpB,IAAIX,EAAe,IAAIC,aAAa5E,OAAK0F,cAAcJ,EAAEtE,QAIzD,OAFA2D,EAAeF,EADAe,EAAW7E,KAAKQ,IAAImE,EAAEhE,QAAQP,QAGtCyE,EAAWnC,WAAWsB,EAAcW,EAAEtE,MAAOsE,EAAEpF,MAAM,YChB9CyF,EAA6BC,GAE3C,MAAO,CAACC,EAAkBC,EAAkBC,EACpCC,EAAmB9F,KACzB,MAAM+F,EAAW7E,eAAa8E,2BAA2BL,EAAQC,GAE3DK,EAAaF,EAASrE,OACtBwE,EAAgBpG,OAAKqG,eAAeJ,GACpCK,EAAatG,OAAK0F,cAAcO,GAEhCM,EACFvG,OAAKwG,uBAAuBtG,EAA0BoG,GAEpDG,EAAQZ,EAAOjE,OACf8E,EAAQZ,EAAOlE,OAEf+E,EAAW3G,OAAKqG,eAAeR,GAC/Be,EAAW5G,OAAKqG,eAAeP,GAE/Be,EAAiBzF,eAAa0F,iBAAiBjB,EAAQI,GACvDc,EAAiB3F,eAAa0F,iBAAiBhB,EAAQG,GAE7D,GAAIY,EAAejF,OAASmF,EAAenF,SAAW,EACpD,IAAK,IAAIiD,EAAI,EAAGA,EAAI0B,EAAO3E,SAAUiD,EACnC0B,EAAO1B,GAAKe,EAAGG,EAAMlB,EAAIkB,EAAMnE,QAASoE,EAAMnB,EAAImB,EAAMpE,cAG1D,IAAK,IAAIiD,EAAI,EAAGA,EAAI0B,EAAO3E,SAAUiD,EAAG,CACtC,MAAMmC,EAAMhH,OAAKiH,WAAWpC,EAAGsB,EAAYC,GAErCc,EAAOF,EAAIG,OAAOV,GACxBI,EAAe/G,SAAQkC,GAAKkF,EAAKlF,GAAK,IACtC,MAAMoF,EAASpH,OAAKqH,WAAWH,EAAMT,EAAOE,GAEtCW,EAAON,EAAIG,OAAOT,GACxBK,EAAejH,SAAQkC,GAAKsF,EAAKtF,GAAK,IACtC,MAAMuF,EAASvH,OAAKqH,WAAWC,EAAMZ,EAAOE,GAE5CL,EAAO1B,GAAKe,EAAGG,EAAMqB,GAASpB,EAAMuB,IAIxC,MAAO,CAAChB,EAAQN,EAAS,CAE7B,UC/CgBuB,EAAQnC,GAEtB,MAAME,OAACA,EAAME,QAAEA,GAAWJ,GACpB1C,KAACA,EAAIE,KAAEA,GAAQ0C,EAEfkC,EAAWhC,EAAQ9E,KAAKQ,IAAIwB,EAAKrB,QAAQP,OACzC2G,EAAWjC,EAAQ9E,KAAKQ,IAAI0B,EAAKvB,QAAQP,OAEzC4G,EAAclC,EAAQ/D,eAAeiB,EAAK3B,MAAO,aAYvD,OAVgByE,EAAQ9E,KAAKQ,IAAIwG,EAAYrG,QAKrCmB,mBAAqB,CAC3BE,KAAM8C,EAAQ/D,eAAeiB,EAAK3B,MAAO,UAAWyG,GACpD5E,KAAM4C,EAAQ/D,eAAemB,EAAK7B,MAAO,UAAW0G,IAG/CC,CACT,CAEO,MAAMC,EAA8B,CACzC3C,WAAY4C,UACZ1C,YAAa,MACbC,WAAYoC,YCpBEM,EACZrC,EAAyBzE,EACzBd,EAAkB,WACpB,GAAc,cAAVA,EAAuB,CAIzB,OAAOsH,EAAQ,CAACjC,OAAQ,CAAC5C,KAHZmF,EAAMrC,EAASzE,EAAO,WAGJ6B,KAFlBiF,EAAMrC,EAASzE,EAAO,YAEGyE,YAGxC,MAAM1E,EAASf,OAAK+H,oBAAoB/H,OAAK0F,cAAc1E,GAAQd,GAEnE,OAAOuF,EAAQ/D,eAAeV,EAAOd,EAAOa,EAC9C,UCnBgBiH,EACZ3C,GACF,MAAME,OAACA,EAAME,QAAEA,GAAWJ,GACpBC,EAACA,GAAKC,EAIZ,OAFAE,EAAQtD,OAAOmD,EAAEhE,QAEV,CAACA,OAAQgE,EAAEhE,OAAQN,MAAOsE,EAAEtE,MAAOd,MAAOoF,EAAEpF,MACrD,CAEO,MAAM+H,EAA+B,CAC1ChD,WAAYiD,WACZ/C,YAAa,MACbC,WAAY4C,YCbErF,EAAK0C,GAEnB,MAAME,OAACA,EAAME,QAAEA,GAAWJ,GACpB8C,MAACA,GAAS5C,EAEV5C,EAAO8C,EAAQ9E,KAAKQ,IAAIgH,EAAM7G,QAAQmB,mBAAmBE,KACzDyF,EAAU3C,EAAQ9E,KAAKQ,IAAIwB,EAAKrB,QAAQP,OAK9C,OAAO0E,EAAQ/D,eAAeiB,EAAK3B,MAAO2B,EAAKzC,MAAOkI,EACxD,CAEO,MAAMC,EAA2B,CACtCpD,WAAYqD,OACZnD,YAAa,MACbC,WAAYzC,YCZE4F,EACZxH,EAAoBC,EAAiBwH,EACrCtI,GACF,GAAc,UAAVA,EAAmB,CAErB,MAAO,CAACc,EAAO,QADMyH,WAAWC,KAAK3H,IAIvC,GAAc,SAAVb,EAAkB,CAIpB,MAAMyI,EAAO3I,OAAK4I,aAAa,CAAC,GAAIJ,IAE7BK,EAAYC,GAAenD,GAC9B,CAACoD,EAAGC,IAAOD,IAAMC,EAAK,EAAI,GADIrD,CACD3E,EAAO,GAAID,EAAQ4H,EAAM,QAE1D,MAAO,CAACG,EAAa,OAAQD,GAE/B,MAAM,IAAIzF,MAAM,iCAAiCoF,QAAgBtI,IACnE,UAEgB+I,EACZ5D,GAEF,MAAME,OAACA,EAAME,QAAEA,EAAOyD,MAAEA,GAAS7D,GAC3BC,EAACA,GAAKC,GACNrF,MAACA,GAASgJ,EAGhB,GAAc,cAAVhJ,EAAuB,CACzB,GAAgB,cAAZoF,EAAEpF,MACJ,OAAO8H,EAAS,CAACzC,OAAQ,CAACD,KAAIG,YAGhC,MAAM0D,EAAkBrB,EAAMrC,EAASH,EAAEtE,MAAOsE,EAAEpF,OAC5CkJ,EAASH,EAAK,CAAC1D,OAAQ,CAACD,KAAIG,UAASyD,MAAO,CAAChJ,MAAO,aAEpDqG,EACFiB,EAAQ,CAACjC,OAAQ,CAAC5C,KAAMyG,EAAQvG,KAAMsG,GAAkB1D,YAK5D,OAHAA,EAAQ/B,8BAA8ByF,GACtC1D,EAAQ/B,8BAA8B0F,GAE/B7C,EAIT,GAAgB,cAAZjB,EAAEpF,MAAuB,CAC3B,MAAMmJ,EAAW1G,EAAK,CAAC4C,OAAQ,CAAC4C,MAAO7C,GAAIG,YACrCc,EAAS0C,EAAK,CAAC1D,OAAQ,CAACD,EAAG+D,GAAW5D,UAASyD,MAAO,CAAChJ,WAI7D,OAFAuF,EAAQ/B,8BAA8B2F,GAE/B9C,EAGT,IAAKvG,OAAKsJ,gBAAgBhE,EAAEpF,MAAOA,GAAQ,CAGzC,MAAMqG,EAASyB,EAAS,CAACzC,OAAQ,CAACD,KAAIG,YACtC,MAAO,CAACnE,OAAQiF,EAAOjF,OAAQN,MAAOuF,EAAOvF,MAAOd,SAGtD,MAAMa,EAAS0E,EAAQ9E,KAAKQ,IAAImE,EAAEhE,QAAQP,QACnC+H,EAAaS,EAAYV,GAC5BN,EAASxH,EAAQuE,EAAEtE,MAAOsE,EAAEpF,MAAOA,GACvC,OAAOuF,EAAQ/D,eAAeoH,EAAaS,EAAYV,EACzD,CAEO,MAAMW,EAA2B,CACtCvE,WAAYwE,OACZtE,YAAa,MACbC,WAAY6D,YC9DES,EACZC,EAAcC,EACdC,EAAuC3J,GACzC,OAAmB,MAAf2J,EACK,EAAEtE,SAAQE,cACf,MAAMsD,EAACA,EAACC,EAAEA,GAAKzD,EACTC,EAAaC,EAEnBhG,EAAiB,CAACsJ,EAAGC,GAAIW,GAEzB,MAAM5D,EAAQP,EAAW7E,KAAKQ,IAAI4H,EAAEzH,QAAQP,OACtCiF,EAAQR,EAAW7E,KAAKQ,IAAI6H,EAAE1H,QAAQP,OAEtC+I,EAA2B,WAAZf,EAAE7I,MAEnBkB,eAAa2I,uBAAuBhE,GACpCA,EACEiE,EAA2B,WAAZjB,EAAE7I,MAEnBkB,eAAa2I,uBAAuB/D,GACpCA,EACEiE,EAAS/J,GAAS6I,EAAE7I,OAEnB2I,EAAYC,GACfc,EAAWb,EAAE/H,MAAOgI,EAAEhI,MAAO8I,EAAcE,EAAcC,GAE7D,OAAOzE,EAAW9D,eAAeoH,EAAamB,EAAQpB,EAAW,EAI9D,EAAEtD,SAAQE,cACf,MAAMsD,EAACA,EAACC,EAAEA,GAAKzD,EACTC,EAAaC,EAEnB,GAAgB,cAAZsD,EAAE7I,OAAqC,cAAZ8I,EAAE9I,MAAuB,CACtD,MAAMgK,EAAYjB,EACd,CAAC1D,OAAQ,CAACD,EAAGyD,GAAItD,QAASD,EAAY0D,MAAO,CAAChJ,MAAO,eAEnDiK,EAAgB3E,EAAW7E,KAAKQ,IAAI+I,EAAU5I,QAE9C8I,EAAQD,EAAc1H,mBAAmBE,KACzC0H,EAAQF,EAAc1H,mBAAmBI,KAEzCyH,EACF9E,EAAW7E,KAAKQ,IAAIiJ,EAAM9I,QAAQP,OAChCwJ,EACF/E,EAAW7E,KAAKQ,IAAIkJ,EAAM/I,QAAQP,OAEhCyJ,EAAYvB,EACd,CAAC1D,OAAQ,CAACD,EAAG0D,GAAIvD,QAASD,EAAY0D,MAAO,CAAChJ,MAAO,eAEnDuK,EAAgBjF,EAAW7E,KAAKQ,IAAIqJ,EAAUlJ,QAE9CoJ,EAAQD,EAAchI,mBAAmBE,KACzCgI,EAAQF,EAAchI,mBAAmBI,KAEzC+H,EACFpF,EAAW7E,KAAKQ,IAAIuJ,EAAMpJ,QAAQP,OAChC8J,EACFrF,EAAW7E,KAAKQ,IAAIwJ,EAAMrJ,QAAQP,QAE/B+J,EAAgBC,EAAgBjC,GAAee,EAClDd,EAAE/H,MAAOgI,EAAEhI,MAAOsJ,EAAWC,EAAWK,EAAWC,GAEjDG,EACFxF,EAAW9D,eAAeoH,EAAa,UAAWgC,GAEhDG,EACFzF,EAAW9D,eAAeoH,EAAa,UAAWiC,GAEhDxE,EAASiB,EACX,CAACjC,OAAQ,CAAC5C,KAAMqI,EAAYnI,KAAMoI,GAAaxF,QAASD,IAO5D,OALAA,EAAW9B,8BAA8BwG,GACzC1E,EAAW9B,8BAA8B8G,GACzChF,EAAW9B,8BAA8BsH,GACzCxF,EAAW9B,8BAA8BuH,GAElC1E,EACF,CACL,MAAMR,EAAQP,EAAW7E,KAAKQ,IAAI4H,EAAEzH,QAAQP,OACtCiF,EAAQR,EAAW7E,KAAKQ,IAAI6H,EAAE1H,QAAQP,OAEtCkJ,EAAS/J,GAAS6I,EAAE7I,OAEnB2I,EAAYC,GACfc,EAAWb,EAAE/H,MAAOgI,EAAEhI,MAAO+E,EAAOC,EAAOiE,GAE/C,OAAOzE,EAAW9D,eAAeoH,EAAamB,EAAQpB,IAG5D,UAMgBqC,EAA8BtF,GAE5C,MAAO,CAACC,EAAkBC,EAAkBwE,EACpCC,EAAyBK,EACzBC,KACN,MAAM/B,EAAc1H,eAAa8E,2BAA2BL,EAAQC,GAC9DQ,EAAatG,OAAK0F,cAAcoD,GAChC3C,EAAa2C,EAAYlH,OACzBwE,EAAgBpG,OAAKqG,eAAeyC,GAEpCqC,EAAiBnL,OAAKwG,uBAAuB,UAAWF,GACxD8E,EAAiBpL,OAAKwG,uBAAuB,UAAWF,GAExDO,EAAiBzF,eAAa0F,iBAAiBjB,EAAQiD,GACvD/B,EAAiB3F,eAAa0F,iBAAiBhB,EAAQgD,GAEvD/C,EAAQ3E,eAAa0B,uBAAuBwH,EAAWC,GACvDvE,EAAQ5E,eAAa0B,uBAAuB8H,EAAWC,GAEvDpE,EAAQZ,EAAOjE,OACf+E,EAAW3G,OAAKqG,eAAeR,GAE/Ba,EAAQZ,EAAOlE,OACfgF,EAAW5G,OAAKqG,eAAeP,GAErC,GAAIe,EAAejF,OAASmF,EAAenF,SAAW,EACpD,IAAK,IAAIiD,EAAI,EAAGA,EAAIsG,EAAevJ,OAAQiD,IAAK,CAC9C,MAAMwG,EAAOxG,EAAIkB,EAAMnE,OACjB0J,EAAOzG,EAAImB,EAAMpE,OAEjB2E,EACFX,EAAGG,EAAa,EAAPsF,GAAWtF,EAAa,EAAPsF,EAAW,GAAIrF,EAAa,EAAPsF,GAC5CtF,EAAa,EAAPsF,EAAW,IAExBH,EAAetG,GAAK0B,EAAO5D,KAC3ByI,EAAevG,GAAK0B,EAAO1D,UAG7B,IAAK,IAAIgC,EAAI,EAAGA,EAAIsG,EAAevJ,OAAQiD,IAAK,CAC9C,MAAMmC,EAAMhH,OAAKiH,WAAWpC,EAAGsB,EAAYC,GAErCc,EAAOF,EAAIG,OAAOV,GACxBI,EAAe/G,SAAQkC,GAAKkF,EAAKlF,GAAK,IACtC,MAAMoF,EAASpH,OAAKqH,WAAWH,EAAMT,EAAOE,GAEtCW,EAAON,EAAIG,OAAOT,GACxBK,EAAejH,SAAQkC,GAAKsF,EAAKtF,GAAK,IACtC,MAAMuF,EAASvH,OAAKqH,WAAWC,EAAMZ,EAAOE,GAEtC2E,EACF3F,EAAGG,EAAe,EAATqB,GAAarB,EAAe,EAATqB,EAAa,GAAIpB,EAAe,EAATuB,GAChDvB,EAAe,EAATuB,EAAa,IAE1B4D,EAAetG,GAAK0G,EAAS5I,KAC7ByI,EAAevG,GAAK0G,EAAS1I,KAGjC,MAAO,CAACsI,EAAgBC,EAAgBtC,EAAY,CAExD,CC3KO,MAAM0C,EACT7F,IAA+BoD,EAAWC,IAAcD,EAAIC,IACnDyC,EACTP,IAAgCd,EAAOC,EAAOK,EAAOC,KAC5C,CAAChI,KAAMyH,EAAQM,EAAO7H,KAAMwH,EAAQM,MAGpCe,EAAMhC,EAAiBiC,MAAKH,EAASC,GAErCG,EAA0B,CACrC3G,WAAY0G,MACZxG,YAAa,MACbC,WAAYsG,YCfEG,EACZC,EAAmBC,EAAyBC,EAC5CC,EAAwBC,GAC1B,MAAMC,EAAcnM,OAAK0F,cAAcuG,GACjCG,EAAUpM,OAAK+H,oBAAoBmE,EAAMF,GAE/C,IAAK,IAAInH,EAAI,EAAGA,EAAIiH,EAAMlK,OAAQiD,IAAK,CACrC,MAAMwH,EAAQP,EAAMjH,GACpB,GAAIwH,EAAQ,EACV,MAAM,IAAIjJ,MAAM,iCAGdiJ,GAASH,IAKXE,EAAQC,IADNF,EAAc,EACEJ,EAAYlH,GAEZ,GAItB,OAAOuH,CACT,UAEgBE,EACZC,EAAuBC,EAA6BN,EACpDO,GAAe,GACjB,MAAMC,EAAUH,EAAKvL,MAAM,GACrB2L,EAAUJ,EAAKvL,MAAM,GAErB4L,EAASzJ,SAAO,CAACuJ,EAASR,GAAOM,EAAWtM,OAElD,IAAK,IAAI2E,EAAI,EAAGA,EAAI6H,EAAS7H,IAC3B,IAAK,IAAIgI,EAAI,EAAGA,EAAIF,EAASE,IAAK,CAChC,MAAMR,EAAQE,EAAKpL,IAAI0D,EAAGgI,GAC1B,GAAIR,EAAQ,EACV,MAAM,IAAIjJ,MAAM,iCAGdiJ,GAASH,IAITO,EACFG,EAAOpL,IAAI,EAAGqD,EAAGwH,GAEbG,EAAWN,KAAO,EACpBU,EAAOpL,IAAIoL,EAAOzL,IAAI0D,EAAGwH,GAASG,EAAWrL,IAAI0D,EAAGgI,GAAIhI,EAAGwH,GAE3DO,EAAOpL,IAAIoL,EAAOzL,IAAI0D,EAAGwH,GAAS,EAAGxH,EAAGwH,IAMhD,OAAOO,CACT,UCrDgBE,EACsBlH,GAEpC,MAAO,CAAC7E,EAAQb,EAAOgJ,KACrB,MAAM6D,EACF/M,OAAKgN,kBAAkB9M,EAAOa,EAAOa,QACzC,IAAK,IAAIiD,EAAI,EAAGA,EAAI9D,EAAOa,SAAUiD,EACnCkI,EAAUlI,GAAKe,EAAG7E,EAAO8D,GAAIqE,GAE/B,OAAO6D,CAAS,CAEpB,UCFgBE,EAEdtD,EAAc/D,EACd1F,GAIA,OAAOgN,EAA8BvD,EAFxBmD,EAA4BlH,GAEQ1F,EACnD,UAWgBgN,EAEdvD,EAAcwD,EACdjN,GAEA,MAAO,EAAEqF,SAAQ2D,QAAOzD,cACtB,MAAMH,EAACA,GAAKC,EACZ9F,EAAiB6F,EAAGqE,GAEpB,MAAMnE,EAAaC,EACb1E,EAASyE,EAAW7E,KAAKQ,IAAImE,EAAEhE,QAAQP,OAC7C,IAAIqM,EACJ,GAAgB,WAAZ9H,EAAEpF,MAAoB,CACxB,IAAKN,MAAMC,QAAQkB,GACjB,MAAM,IAAIqC,MAAM,sDAElBgK,EAAUhM,eAAa2I,uBAAuBhJ,QAG9CqM,EAAUrM,EAGZ,MAAMkJ,EAAS/J,GAASoF,EAAEpF,MACpB6M,EAAYI,EAAUC,EAASnD,EAAQf,GAC7C,OAAO1D,EAAW9D,eAAe4D,EAAEtE,MAAOiJ,EAAQ8C,EAAU,CAEhE,CCxDO,MAAMM,EAAWP,GAAuBQ,GAAOxI,KAAKyI,KAAKD,KACnDC,EAAOL,EAAwBM,OAAMH,GAErCI,EAA2B,CACtCxI,WAAYuI,OACZrI,YAAa,MACbC,WAAYmI,YCTEG,EACZnI,EAAuDoI,EACvDzN,EAAiB0N,GACnB,MAAMxB,EAAUpM,OAAKgN,kBAAkB9M,EAAOF,OAAK0F,cAAciI,IAEjE,GAAIC,GAA0B,WAAV1N,EAAoB,CAEtC,IAAI2N,EAAS,EACbtI,EAAOzF,SAAQqI,IACb,MAAM+D,EAAOlM,OAAK0F,cAAcyC,EAAMnH,OAErCoL,EAAuB5K,IAAI2G,EAAMzD,KAAoBmJ,GACtDA,GAAU3B,CAAI,QAEX,CACL,IAAI4B,EAAY,EAEhBvI,EAAOzF,SAAQqI,IACb,MAAM4F,EAAwB,WAAV7N,EAChBkB,eAAa2I,uBAAuB5B,EAAMzD,MAC1CyD,EAAMzD,KAEV,IAAIsJ,EAAO,EAEX,IAAK,IAAIC,EAAM,EAAGA,EAAM9F,EAAMnH,MAAM,KAAMiN,EAAK,CAC7C,MAAMC,EAASD,EAAMN,EAAS,GAAKG,EACnC,IAAK,IAAIK,EAAM,EAAGA,EAAMhG,EAAMnH,MAAM,KAAMmN,EACxC/B,EAAQ8B,EAASC,GAAOJ,EAAYC,KAIxCF,GAAa3F,EAAMnH,MAAM,EAAE,IAI/B,OAAOoL,CACT,CCjCO,MAAMgC,EACTzI,GAA6B,CAACoD,EAAWC,IAAeD,IAAMC,EAAK,EAAI,IAC9DqF,EACT3E,EAAiB4E,QAAOF,EAAW,KAAwB,QAElDG,EAA4B,CACvCtJ,WAAYqJ,QACZnJ,YAAa,MACbC,WAAYiJ,GCRDG,EAAU1B,GAAuBQ,GAAOxI,KAAK2J,IAAInB,KACjDmB,EAAMvB,EAAwBwB,MAAKF,EAAS,WAE5CG,EAA0B,CACrC1J,WAAYyJ,MACZvJ,YAAa,MACbC,WAAYqJ,GCNDG,EAAY9B,GAAuBQ,GAAOxI,KAAK+J,MAAMvB,KACrDuB,EAAQ3B,EAAwB4B,QAAOF,GAEvCG,EAA4B,CACvC9J,WAAY6J,QACZ3J,YAAa,MACbC,WAAYyJ,GCNDG,EAAYlC,GAAuBQ,GAAOxI,KAAKmK,MAAM3B,KACrD2B,EAAQ/B,EAAwBgC,QAAOF,GAEvCG,EAA4B,CACvClK,WAAYiK,QACZ/J,YAAa,MACbC,WAAY6J,GCNDG,EACTzJ,GAA6B,CAACoD,EAAWC,IAAclE,KAAKmK,MAAMlG,EAAIC,KAC7DqG,EACT3F,EAAiB4F,WAAUF,EAAc,KAAwB,SAExDG,EAA+B,CAC1CtK,WAAYqK,WACZnK,YAAa,MACbC,WAAYiK,YCXEG,EACZC,EAAyBC,EAA4BxP,EACrDyP,EAAmBC,EAAmBC,EAAmBC,EACzDC,EAAuBC,GACzB,MAAMpD,EAASzJ,SAAO,CAACwM,EAAWE,GAAY3P,GAE9C,IAAK,IAAI2E,EAAI,EAAGA,EAAI8K,EAAW9K,IAAK,CAClC,MAAMoL,EAAQ,GACd,IAAIC,EAAe,EACnB,IAAK,IAAIrD,EAAI,EAAGA,EAAI+C,EAAW/C,IAAK,CAClC,MAAMsD,EAAMV,EAAY5K,EAAI+K,EAAY/C,GACxCqD,GAAgBC,EAAML,EAAQjD,GAC9BoD,EAAMG,KAAKD,GAEb,GAAID,EAAe,GAAKA,GAAgBF,EAAaH,EACnD,MAAM,IAAIzM,MACN,oBAAoB6M,yBAA6BF,KAGvD,IAAK,IAAIM,EAAI,EAAGA,EAAIR,EAAWQ,IAC7BzD,EAAO7L,OAAO8D,EAAIgL,EAAYQ,GAC1BX,EAAUvO,OAAOuO,EAAUzI,WAAWiJ,EAAeL,EAAYQ,IAIzE,OAAOzD,CACT,UC1BgB0D,EACZ/D,EAA0BgE,EAC1BC,GACF,MAAM5D,EAASzJ,SAAOqN,EAAoBjE,EAAKrM,OAC/C,IAAK,IAAI2E,EAAI,EAAGA,EAAI+H,EAAOV,OAAQrH,EAAG,CACpC,MAEM4L,EAFS7D,EAAO3F,WAAWpC,GAEIsC,QAC/BuJ,EAAWD,EAAY,GACvBE,EAAaF,EAAY,GACzBG,EAAeL,EAAWlJ,WAAW,CAACqJ,EAAUC,IACtDF,EAAY,GAAKF,EAAWxP,OAAO6P,GAEnC,MAAMC,EAAgBtE,EAAKlF,WAAWoJ,GAElC,GAAKI,GAAiBA,EAAgBtE,EAAKxL,OAAOa,SACpDgL,EAAO7L,OAAO8D,GAAK0H,EAAKxL,OAAO8P,IAInC,OAAOjE,CACT,CClBO,MAAMkE,EACTnL,GAA6B,CAACoD,EAAWC,IAAeD,EAAIC,EAAK,EAAI,IAC5D+H,GACTrH,EAAiBsH,UAASF,EAAa,KAAwB,QAEtDG,GAA8B,CACzChM,WAAY+L,UACZ7L,YAAa,MACbC,WAAY2L,ICRDG,GACTvL,GAA6B,CAACoD,EAAWC,IAAeD,GAAKC,EAAK,EAAI,IAC7DmI,GAAezH,EACxB0H,eAAcF,GAAkB,KAAwB,QAE/CG,GAAmC,CAC9CpM,WAAYmM,eACZjM,YAAa,MACbC,WAAY+L,ICRDG,GACT3L,GAA6B,CAACoD,EAAWC,IAAeD,EAAIC,EAAK,EAAI,IAC5DuI,GACT7H,EAAiB8H,OAAMF,GAAU,KAAwB,QAEhDG,GAA2B,CACtCxM,WAAYuM,OACZrM,YAAa,MACbC,WAAYmM,ICRDG,GACT/L,GAA6B,CAACoD,EAAWC,IAAeD,GAAKC,EAAK,EAAI,IAC7D2I,GACTjI,EAAiBkI,YAAWF,GAAe,KAAwB,QAE1DG,GAAgC,CAC3C5M,WAAY2M,YACZzM,YAAa,MACbC,WAAYuM,aCXEG,GACZjO,EAAekO,EAAcC,GAC/B,MAAMC,GAAQF,EAAOlO,IAAUmO,EAAM,GAE/BjR,EAASf,OAAK+H,oBAAoBiK,EAAK,WAC7CjR,EAAO,GAAK8C,EACZ,IAAK,IAAIgB,EAAI,EAAGA,EAAI9D,EAAOa,OAAQiD,IACjC9D,EAAO8D,GAAK9D,EAAO8D,EAAI,GAAKoN,EAG9B,OAAOlR,CACT,CCRO,MAAMmR,GAAUpF,GAAuBQ,GAAOxI,KAAKqN,IAAI7E,KACjD6E,GAAMjF,EAAwBkF,MAAKF,IAEnCG,GAA0B,CACrCpN,WAAYmN,MACZjN,YAAa,MACbC,WAAY+M,aCTEG,GACZvM,EAAmBwM,EAAoB5E,EACvCzN,GACF,MAAMwE,EAAO1E,OAAKwG,uBACdtG,EAA0BF,OAAK0F,cAAciI,IAEjD,IAAK,IAAI9I,EAAI,EAAGA,EAAIH,EAAK9C,SAAUiD,EAAG,CACpC,MAAMgJ,EAAShJ,EAAI0N,EACnB,IAAIC,EAAMzM,EAAM8H,GAChB,IAAK,IAAIhB,EAAI,EAAGA,EAAI0F,IAAc1F,EAAG,CACnC,MAAMR,EAAQtG,EAAM8H,EAAShB,IACzB4F,OAAOC,MAAMrG,IACbA,EAAQmG,KACVA,EAAMnG,GAGV3H,EAAKG,GAAK2N,EAEZ,OAAO9N,CACT,CChBO,MAAMiO,GAAchN,IACrBiN,EAAQC,IAAW/N,KAAK0N,IAAII,EAAkBC,KACvCC,GAAUpJ,EAAiBqJ,UAASJ,IAEpCK,GAA8B,CACzC/N,WAAY8N,UACZ5N,YAAa,MACbC,WAAY0N,ICPDG,GAActN,IACrBiN,EAAQC,IAAW/N,KAAKoO,IAAIN,EAAkBC,KACvCM,GAAUzJ,EAAiB0J,UAASH,IAEpCI,GAA8B,CACzCpO,WAAYmO,UACZjO,YAAa,MACbC,WAAY+N,ICRDG,GAAe3N,IACtBiN,EAAgBC,IAAmBD,EAASC,IACrCU,GACTrI,IAAgCd,EAAOC,EAAOK,EAAOC,KAC5C,CACLhI,KAAMyH,EAAQM,EAAQL,EAAQM,EAC9B9H,KAAMuH,EAAQO,EAAQN,EAAQK,MAIzB8I,GACT9J,EAAiB+J,WAAUH,GAAcC,IAEhCG,GAA+B,CAC1CzO,WAAYwO,WACZtO,YAAa,MACbC,WAAYoO,aCdEG,GAAQ7H,EAAmB8H,EAAkBC,GAE3D,MAAMC,EACF9T,OAAK+T,mBAAmB,EAA2BF,GACvD,OAAOP,GAAa,GAAIM,EAAQE,EAAUhI,EAAO+H,EACnD,CAeO,MAAMG,GAA0B,CACrC/O,WAAYgP,MACZ9O,YAAa,MACbC,oBAhBkBC,GAElB,MAAME,OAACA,EAAME,QAAEA,GAAWJ,GACpBC,EAACA,GAAKC,EAEZ9F,EAAiB6F,EAAG,OAEpB,MAAMwG,EAAQrG,EAAQ9E,KAAKQ,IAAImE,EAAEhE,QAAQP,QAClCmT,EAAKjO,GAAY0N,GAAQ7H,EAAOxG,EAAEtE,MAAOsE,EAAEpF,OAElD,OAAOuF,EAAQ/D,eAAeuE,EAAUX,EAAEpF,MAAOgU,EACnD,GCnBaC,GACTxO,IAA+BoD,EAAGC,IAAOD,IAAMC,EAAK,EAAI,IAC/CoL,GACT1K,EAAiB2K,WAAUF,GAAc,KAAsB,QAEtDG,GAA+B,CAC1CrP,WAAYoP,WACZlP,YAAa,MACbC,WAAYgP,aCVEG,GACZzI,EAAmB8H,EAAkB1T,EAAiBsU,EACtDvO,GACF,MAAMwO,EAAQb,EAAOhS,OACf8S,EAAQ1U,OAAK0F,cAAckO,GAC3Be,EAAW3U,OAAKqG,eAAeuN,GAC/BgB,EAAa5U,OAAKqG,eAAeJ,GAEjCM,EAASvG,OAAKwG,uBAChBtG,EAA0BF,OAAK0F,cAAcO,IAEjD,IAAK,IAAIpB,EAAI,EAAGA,EAAI6P,IAAS7P,EAAG,CAC9B,MAAMmC,EAAMhH,OAAKiH,WAAWpC,EAAG4P,EAAOE,GAGhCE,EAAmB,IAAIjV,MAAMoH,EAAIpF,QACvC,IAAK,IAAIiD,EAAI,EAAGA,EAAIgQ,EAAOjT,OAAQiD,IACjCgQ,EAAOhQ,GAAKmC,EAAIwN,EAAK3P,IAIvB0B,EADiBvG,OAAKqH,WAAWwN,EAAQJ,EAAOG,IAC7B9I,EAAMjH,GAE3B,OAAO0B,CACT,UCpBgBuO,GAAUzP,GAKxB,MAAME,OAACA,EAAM2D,MAAEA,EAAKzD,QAAEA,GAAWJ,GAC3BC,EAACA,GAAKC,GACNiP,KAACA,GAAQtL,EAEfzJ,EAAiB6F,EAAG,aAEpB,MAAMmP,EAAQnP,EAAEtE,MAAMY,OAEhBqE,EAAqB,IAAIrG,MAAM6U,GACrC,IAAK,IAAI5P,EAAI,EAAGA,EAAIoB,EAASrE,OAAQiD,IACnCoB,EAASpB,GAAKS,EAAEtE,MAAMwT,EAAK3P,IAG7B,MACM0B,EAASgO,GADA9O,EAAQ9E,KAAKQ,IAAImE,EAAEhE,QAAQP,OACLuE,EAAEtE,MAAOsE,EAAEpF,MAAOsU,EAAMvO,GAG7D,MAAO,CAAC3E,OADOmE,EAAQ3E,MAAMyF,EAAQN,EAAUX,EAAEpF,OACjCc,MAAOiF,EAAU/F,MAAOoF,EAAEpF,MAC5C,CAEO,MAAM6U,GAAgC,CAC3C9P,WAAY+P,YACZ7P,YAAa,MACbC,WAAY0P,aC7BEG,GACZrB,EAAkBC,EAAkB/H,EACpCoJ,GAEF,MAAOvH,EAAUwH,GACb/T,eAAagU,0BAA0BxB,EAAQsB,GAC7CG,EAAWC,aAAWzB,EAAQ,SAC9BzH,EAAUpM,OAAK+H,oBACD/H,OAAK0F,cAAciI,GAAW0H,GAC5C9C,EAAavS,OAAK0F,cAAcyP,GAEtC,IAAK,IAAItQ,EAAI,EAAGA,EAAIuH,EAAQxK,SAAUiD,EAAG,CACvC,MAAMgJ,EAAShJ,EAAI0N,EACnB,IAAIgD,EAAO,EACX,IAAK,IAAI1I,EAAI,EAAGA,EAAI0F,IAAc1F,EAChC0I,GAAQzJ,EAAM+B,EAAShB,GAEzBT,EAAQvH,GAAK0Q,EAGf,MAAO,CAACnJ,UAASuB,WAAU0H,WAC7B,CAuCO,MAAMG,GAA2B,CACtCvQ,WAAYwQ,OACZtQ,YAAa,MACbC,oBAvCEC,GAEF,MAAME,OAACA,EAAME,QAAEA,EAAOyD,MAAEA,GAAS7D,GAC3BC,EAACA,GAAKC,GACNmQ,KAACA,EAAIC,SAAEA,GAAYzM,EAEzBzJ,EAAiB6F,EAAG,QAEpB,MAAMmP,EAAQnP,EAAEtE,MAAMY,OAChBgU,EAAO5V,OAAK6V,eAAeH,EAAMpQ,EAAEtE,OAEnC8U,EAAc1U,eAAa2U,mBAAmBH,EAAMnB,GAC1D,IAAIS,EAAgBU,EAChBI,EAAY1Q,EAChB,MAAM2Q,EAA0B,GACb,MAAfH,IACFE,EAAYlB,GAAU,CAACvP,OAAQ,CAACD,KAAIG,UAASyD,MAAO,CAACsL,KAAMsB,KAC3DG,EAAwB7F,KAAK4F,GAC7Bd,EAAgB9T,eAAa8U,iBAAiBhB,EAActT,OAAQ6S,IAGtE,MAAM3I,EAAQrG,EAAQ9E,KAAKQ,IAAI6U,EAAU1U,QAAQP,QAC3CqL,QAACA,EAAOuB,SAAEA,EAAQ0H,SAAEA,GACtBJ,GAASe,EAAUhV,MAAOgV,EAAU9V,MAAO4L,EAAOoJ,GAEtD,IAAIpM,EAAc6E,EAQlB,OAPIgI,IACF7M,EAAc1H,eAAa+U,qBAAqBxI,EAAUiI,IAG5DK,EAAwBnW,SACpBC,GAAK0F,EAAQ/B,8BAA8B3D,KAExC0F,EAAQ/D,eAAeoH,EAAauM,EAAUjJ,EACvD,GCnBA,SAASgK,GACLC,EAAqBC,EACrBC,EAAkCC,GACpC,MAAMC,EAAuC,GAC7C,IAAIC,EAAY,EAEhB,MAAMC,EAAYL,EAAa1U,OAAS,EAAI2U,EAAmB3U,OACzDgV,EAAY,IAAIhX,MAAM+W,GAAWE,KAAK,MAAM9U,KAAI,IAAM,CAAC,MApC/D,SACIwU,EAAkCC,GAEpC,IAAK,IAAIrG,EAAM,EAAGA,EAAMoG,EAAmB3U,SAAUuO,EAAK,CACxD,MAAM2G,EAASP,EAAmBpG,GAC5B4G,EAAa5G,IAAQoG,EAAmB3U,OAAS,EACnD4U,EACAD,EAAmBpG,EAAM,GAAGvO,OAChC,GAAsB,IAAlBkV,EAAOlV,OACT,MAAM,IAAIwB,MAAM,kCAElB,GAAI0T,EAAO,GAAK,EACd,MAAM,IAAI1T,MAAM,sCAElB,GAAI0T,EAAOA,EAAOlV,OAAS,GAAKmV,EAC9B,MAAM,IAAI3T,MAAM,4CAElB,IAAK,IAAIyB,EAAI,EAAGA,EAAIiS,EAAOlV,SAAUiD,EACnC,GAAIiS,EAAOjS,EAAI,GAAKiS,EAAOjS,GACzB,MAAM,IAAIzB,MAAM,mDAIxB,CAeE4T,CAAeT,EAAoBC,GASnC,IAAIS,EAAQ,EACZ,IAAK,IAAI9G,EAAM,EAAGA,EAAMmG,EAAa1U,OAAS,IAAKuO,EAAK,CACtD8G,GAASX,EAAanG,GACtB,MAAM+G,EAAYZ,EAAanG,EAAM,GACrC,IAAK,IAAItL,EAAI,EAAGA,EAAIoS,EAAQ,IAAKpS,EAC/B+R,EAAUzG,GAAKC,KAAKvL,EAAIqS,GAa5B,IAAK,IAAIrS,EAAI,EAAGA,EAAIwR,EAAQzU,SAAUiD,EAAG,CACvC,IAAIhB,EAAQwS,EAAQxR,GAChBsS,EAAQd,EAAQxR,GAAK,EAGzB,IAAK,IAAIsL,EAAM,EAAGA,EAAMoG,EAAmB3U,SAAUuO,EAAK,CACxD,MAAM2G,EAASP,EAAmBpG,GAC5BiH,EAASjH,EAAMmG,EAAa1U,OAAS,EAC3C,GAAIwV,GAAU,EAAG,CACf,MAAMC,EAAkBT,EAAUQ,GAC5BE,EACFD,EAAgBA,EAAgBzV,OAAS,GAAKkV,EAAOjT,GACzD,IAAK,IAAIgJ,EAAIhJ,EAAOgJ,EAAIsK,IAAStK,EAC/B+J,EAAUQ,GAAQhH,KAAK0G,EAAOjK,EAAI,GAAKyK,GAG3CzT,EAAQiT,EAAOjT,GACfsT,EAAQL,EAAOK,GAEbA,IAAUtT,IACZ4S,EAAYrG,KAAK,CAACvM,EAAOsT,IACzBT,GAAaS,EAAQtT,GAIzB,MAAO,CAAC+S,YAAWH,cAAaC,YAClC,CAeA,SAASa,GAAqBC,EAAgBC,GAC5C,MAAMC,EAAUF,EAAKrQ,MAAM,EAAGsQ,GAC9B,KAAOC,EAAQ9V,OAAS6V,GACtBC,EAAQtH,KAAK,GAGf,IAAK,IAAIuH,EAAQF,EAAYE,EAAQH,EAAK5V,OAAQ+V,IAChDD,EAAQD,EAAa,IAAMD,EAAKG,GAGlC,OAAOD,CACT,CAsBA,SAASE,GACLC,EAA+BC,EAC/BC,EAAkCtB,EAClCC,GACF,MAAMsB,EAAcF,EAAuB3Q,QAC3C6Q,EAAY,GAAKtB,EAEjB,MAAMuB,EAAYjY,OAAKgN,kBACD+K,EACA/X,OAAK0F,cAAcsS,IAEnCE,EAAcL,EAAkBjW,OAOtC,OApCF,SACIiW,EAA+BC,EAC/BrB,EAAsC0B,EAAmBpX,EACzDiX,GACF,MAAMI,EAASb,GAAqBO,EAAwB,GAAG,GACzDO,EAAUd,GAAqBS,EAAa,GAAG,GAErD,IAAIM,EAAS,EACb,IAAK,MAAMnR,KAASsP,EAClB,IAAK,IAAI5R,EAAIsC,EAAM,GAAItC,EAAIsC,EAAM,KAAMtC,EAAG,CACxC,IAAK,IAAIgI,EAAI,EAAGA,EAAIsL,IAAatL,EAC/B9L,EAAOuX,EAASD,EAAUxL,GAAKgL,EAAkBhT,EAAIuT,EAASvL,KAE9DyL,EAGR,CAgBEC,CACIV,EAAmBC,EAAwBrB,EAF3B,IAAhByB,EAAoB,EAAKA,EAAcJ,EAAuB,GAG9DG,EAAWD,GAER,CAACC,EAAWD,EACrB,UACgBQ,GACZjC,EAAkCkC,EAClCZ,EAA+BC,EAC/BC,EAAkC1B,EAClCC,EACAoC,GACF,GAAkC,IAA9BnC,EAAmB3U,OACrB,MAAM,IAAIwB,MAAM,wCAGlB,GAA2C,IAAvCqV,EAAyB,GAAG7W,OAC9B,MAAM,IAAIwB,MAAM,qCAKlB,GA7LF,SACIiT,EAAqBC,EAAwBqC,GAC/CtC,EAAQvW,SAAQ,CAACmQ,EAAepL,KAC9B,GAAIoL,EAAQ,GAAKA,GAAS0I,EAAW,CACnC,MAAMC,EACF5Y,OAAKiH,WACGpC,EAAGyR,EAAa1U,OAAQ5B,OAAKqG,eAAeiQ,IAC/CuC,KAAK,KACd,MAAM,IAAIzV,MACN,WAAWwV,QAAgB3I,mBAAuB0I,SAG5D,CA+KEG,CAAgBzC,EAASC,EADPmC,EAAyB,GAAG,GAAK,GAGb,IAAlCX,EAAuBlW,OACzB,MAAM,IAAIwB,MAAM,+BAElB,MAAMoT,EAAuBsB,EAAuB,IAI9ClB,UAACA,EAASH,YAAEA,EAAWC,UAAEA,GAAaN,GACxCC,EAASC,EAAcC,EAAoBC,GAGzCuC,EA7FR,SAAmBnC,GACjB,MAAMoC,EAA0B,GAChC,IAAK,IAAInU,EAAI,EAAGA,EAAI+R,EAAUhV,SAAUiD,EAAG,CACzC,MAAM8R,EAAYC,EAAU/R,GAAGjD,OACzBkV,EAAS9W,OAAKgN,kBAAkB,QAAS2J,GAC/CqC,EAAU5I,KAAK0G,GAEfF,EAAU/R,GAAG/E,SAAQ,CAACuM,EAAOQ,IAAciK,EAAOjK,GAAKR,IAGzD,OAAO2M,CACT,CAkF6BC,CAAUrC,GAC/BsC,EAAoBtB,GACtBC,EAAmBC,EAAwBC,EAC3CtB,EAAaC,GAEjB,MAAO,CAACqC,EAAoBG,EAAkB,GAAIA,EAAkB,GACtE,CC9MA,MAAMC,GAAY,oBAEFC,GACZC,EAAoBC,EAAuBC,EAC3CC,EAAoBC,EAAuBC,EAC3CC,GAEF,GAAIL,EAAY1X,OAAS,EACvB,MAAM,IAAIwB,MAAM,qCAElB,GAAIqW,EAAY7X,OAAS,EACvB,MAAM,IAAIwB,MAAM,qCAElB,GAAIuW,EAAY/X,OAAS,EACvB,MAAM,IAAIwB,MAAM,qCAIlB,MAAMwW,EAAyC,IAAvBN,EAAY1X,OAC9BiY,EAAyC,IAAvBJ,EAAY7X,OAC9BkY,EAAyC,IAAvBH,EAAY/X,OAI9BmY,EAAoB,GACrBH,GACHG,EAAQ3J,KAAKkJ,EAAY,IAEtBO,GACHE,EAAQ3J,KAAKqJ,EAAY,IAEtBK,GACHC,EAAQ3J,KAAKuJ,EAAY,IAG3B,IAAK,IAAI9U,EAAI,EAAGA,EAAIkV,EAAQnY,SAAUiD,EACpC,GAAIkV,EAAQlV,KAAOkV,EAAQlV,EAAI,GAC7B,MAAM,IAAIzB,MAAM,uDAGpB,MAAM4W,EAA2B,IAAnBD,EAAQnY,OAAe,EAAImY,EAAQ,GAG3CE,EACFja,OAAKgN,kBAAkB,QAASgN,EAAQ,GAC5CC,EAAe,GAAK,EACpB,IAAK,IAAIhM,EAAM,EAAGA,EAAM+L,IAAS/L,EAAK,CACpC,MAAMpK,EAAQ+V,EAAkBP,EAAO,GAAKA,EAAOpL,GAC7CkJ,EAAQ0C,EAAkBL,EAAO,GAAKA,EAAOvL,GAC7CqJ,EAAQwC,EAAkBJ,EAAO,GAAKA,EAAOzL,GACnD,GAAc,IAAVqJ,EACF,MAAM,IAAIlU,MAAM,uBAElB,IAAI8I,EACJ,GAAMoL,EAAQ,GAAOH,EAAQtT,GAAayT,EAAQ,GAAOH,EAAQtT,EAC/DqI,EAAO,OAIP,GAFAA,EAAOpH,KAAKyI,KAAKzI,KAAKC,KAAKoS,EAAQtT,GAASyT,IAExCpL,EAAOiN,GACT,MAAM,IAAI/V,MAAM,oDAGpB6W,EAAehM,EAAM,GAAKgM,EAAehM,GAAO/B,EAGlD,MAAMgO,EAAQD,EAAeD,GAGvBG,EACFna,OAAKgN,kBAAkBuM,EAAaW,GAExC,IAAIE,EAAa,EACjB,IAAK,IAAInM,EAAM,EAAGA,EAAM+L,IAAS/L,EAAK,CACpC,MAAMoM,EAAUJ,EAAehM,EAAM,GAAKgM,EAAehM,GACzD,IAAI5B,EAAQuN,EAAkBP,EAAO,GAAKA,EAAOpL,GACjD,MAAMqJ,EAAQwC,EAAkBJ,EAAO,GAAKA,EAAOzL,GACnD,IAAK,IAAIpJ,EAAI,EAAGA,EAAIwV,IAAWxV,EAC7BsV,EAAcC,KAAgB/N,EAC9BA,GAASiL,EAIb,MAAO,CAAC2C,EAAgBE,EAC1B,CCpFA,IAAOG,GAAmBlZ,eAAakZ,iBAGvC,MAAMC,GAGJ/Z,YACYQ,EAA2BwZ,EAC3BzZ,EAA4BiX,EAC5ByC,EAA+BC,EAC/BC,EACSC,EACAC,EACjBC,GANQpa,WAAAM,EAA2BN,gBAAA8Z,EAC3B9Z,YAAAK,EAA4BL,iBAAAsX,EAC5BtX,iBAAA+Z,EAA+B/Z,kBAAAga,EAC/Bha,uBAAAia,EACSja,wBAAAka,EACAla,8BAAAma,EAEnBna,KAAKqa,kBACD3Z,eAAa4Z,2BAA2BF,GAC5Cpa,KAAKua,WAAa7Z,eAAa8Z,cAAcxa,KAAKqa,mBAG5CI,+BAA+BC,GACrC,OAAI1a,KAAKqa,kBAAkB,KAAOT,GAAiBe,eAC1C3a,KAAKqa,kBAAkBK,EAAY,GAEnC1a,KAAKqa,kBAAkBK,GAK1BE,sBAAsBF,GAC5B,OAAI1a,KAAKqa,kBAAkB,KAAOT,GAAiBe,eAC1C3a,KAAKka,mBAAmBQ,EAAY,GAEpC1a,KAAKka,mBAAmBQ,GAI3BG,YAAYH,GAClB,MAAMI,EAAqB9a,KAAK4a,sBAAsBF,EAAY,GAClE,OAAQ1a,KAAKya,+BAA+BC,EAAY,IACtD,KAAKd,GAAiBmB,aACpB,OAAOlB,GAAuBmB,sBAAsBF,GACtD,KAAKlB,GAAiBqB,WACpB,OAAOpB,GAAuBqB,oBAAoBJ,GACpD,QACE,MAAM,IAAIpY,MAAM,gCACZkX,GAAiB5Z,KAAKya,+BAClBC,EAAY,QAI1BS,2BAA2BC,GACzB,MAAMC,EAAeD,EAASla,OAC9B,GAAqB,IAAjBma,GAAuC,IAAjBA,EACxB,OAAO,EAET,IAAIC,EAAW,EACf,IAAK,IAAInX,EAAI,EAAGA,EAAIkX,EAAe,IAAKlX,EAAG,CACzC,MAAMoX,EAAeH,EAASjX,EAAI,GAAKiX,EAASjX,GAC5CoX,EAAeD,IACjBA,EAAWC,GAGf,OAAOD,EAGTH,6BAA6BK,GAC3B,MAAMC,EAAcD,EAAYta,OAChC,GAAoB,IAAhBua,EACF,OAAO,EAET,IAAIC,EAAkB,EAClBC,EAAuBH,EAAY,GACnCF,EAAW,EACf,IAAK,IAAInX,EAAI,EAAGA,EAAIsX,IAAetX,EAAG,CACpC,MAAMwH,EAAQ6P,EAAYrX,GACtBwH,IAAUgQ,IACZA,EAAuBhQ,EACvB2P,EAAWlX,KAAK0N,IAAI3N,EAAIuX,EAAiBJ,GACzCI,EAAkBvX,GAGtB,OAAOC,KAAK0N,IAAI2J,EAAcC,EAAiBJ,GAGzCM,sBACJvc,EAAewc,EAAkBC,GAAY,GAC/C,GAAsB,IAAlBD,EAAO3a,OAAc,CACvB,IAAc,IAAV7B,EAAE,GACJ,MAAO,GAET,MAAM,IAAIqD,MACN,kFAGN,OAAOqZ,GAAU1c,EAAGyc,GAGdE,oBAAoBC,GAC1B,MAAMC,EAAalc,KAAKsX,YAClB2C,EAAoBja,KAAKia,kBAE/BvZ,eAAayb,0BAA0BlC,EAAmBiC,GAE1D,MAAM5b,EAAQN,KAAK4b,sBAAsB5b,KAAKM,MAAON,KAAK8Z,YAIpDjU,EAHcnF,eAAa0b,kCAC7Bpc,KAAKua,WAAYja,EAAO4b,GAIxBrW,EAAO,GAAK,IACdA,EAAO,GAAKoW,GAEd,IAAK,IAAI9X,EAAI,EAAGA,GAAKnE,KAAKua,aAAcpW,EAClC0B,EAAO1B,GAAK,IACd0B,EAAO1B,GAAKnE,KAAK6a,YAAY1W,IAIjC,OAAO0B,EAaDwW,gCACJC,EAAwBC,EACxBC,GACF,MAAMC,EAAerY,KAAKoO,IAAI8J,EAAgBE,GACxC3W,EAAmB,GACzB,IAAI6W,EAAqB,EACzB,IAAK,IAAIvY,EAAI,EAAGA,EAAIsY,IACbtY,EAAGuY,GAAsBH,EAC9B1W,EAAO6J,KAAKgN,GAEd,IAAK,IAAIvY,EAAIsY,EAActY,EAAImY,IAAkBnY,EAC/C0B,EAAO6J,MAAM,GAMf,OAJApQ,OAAKC,OACDsG,EAAO3E,SAAWob,GAClB,IAAM,4DAEHzW,EAGD8W,6BACJvB,EAAsBwB,EACtBL,EAA+BM,GACjC,MAAMC,EAAe1B,EAASla,OACxB2E,EAAmB,GACzB,IAAK,IAAI1B,EAAI,EAAGA,EAAI2Y,EAAe,IAAK3Y,EAAG,CACzC,MAAMqS,EAAY4E,EAASjX,EAAI,GAAKiX,EAASjX,GAC7C,IAAI4Y,EAAa3Y,KAAKoO,IAAIqK,EAAYrG,GAClCwG,EAA2BJ,EAAkBzY,IAEf,IAA9B6Y,IACFD,EAAa,GAEf,IAAK,IAAI5Q,EAAI,EAAGA,EAAI4Q,IAAc5Q,EAChCtG,EAAO6J,KAAKsN,GACZA,GAA4BT,EAE9B,IAAK,IAAIpQ,EAAI,EAAGA,EAAIqK,EAAYuG,IAAc5Q,EAC5CtG,EAAO6J,MAAM,GAGjB,GAAIoN,EAAe,GAAKjX,EAAO3E,SAAWka,EAAS0B,EAAe,GAChE,MAAM,IAAIpa,MAAM,2BAGlB,OAAOmD,EAwBDoX,+BACJzB,EAAyBoB,EACzBL,EAA+BM,GACjC,MAAMK,EAAY1B,EAAYta,OACxB2E,EAAmB,GACzB,GAAkB,IAAdqX,EACF,MAAO,GAGT,IAAIC,EAAsB,EACtBC,EAAoB5B,EAAY,GAEpC,GAAI4B,GAAqBR,EAAkB1b,OACzC,MAAM,IAAIwB,MACN,yBAAyB0a,6BACrBR,EAAkB1b,UAG5B,IAAIwb,EAAqBE,EAAkBQ,GAC3CvX,EAAO6J,KAAKgN,GACZ,IAAK,IAAIvY,EAAI,EAAGA,EAAI+Y,IAAa/Y,EAAG,CAClC,MAAMkZ,EAAiB7B,EAAYrX,GACnC,GAAIkZ,IAAmBD,EACjBV,GAAsB,MACtBS,EACEA,EAAsBN,EACxBH,GAAsBH,EAEtBG,GAAsB,OAGrB,CAIL,GAHAS,EAAsB,EACtBC,EAAoBC,EAEhBA,GAAkBT,EAAkB1b,OACtC,MAAM,IAAIwB,MACN,sBAAsB2a,4BAClBT,EAAkB1b,UAG5Bwb,EAAqBE,EAAkBS,GAEzCxX,EAAO6J,KAAKgN,GAGd,GAAI7W,EAAO3E,SAAWsa,EAAYta,OAChC,MAAM,IAAIwB,MAAM,oBAGlB,OAAOmD,EAGDyX,qBACJ5C,EAAmBkC,EACnBL,EAA+BM,GACjC,MAAM/B,EAAqB9a,KAAK4a,sBAAsBF,GAChD6C,EAAgBvd,KAAKya,+BAA+BC,GAC1D,OAAQ6C,GACN,KAAK3D,GAAiBmB,aACpB,OAAO/a,KAAKid,+BACRnC,EAAoB8B,EAAmBL,EACvCM,GACN,KAAKjD,GAAiBqB,WACpB,GAAIH,EAAmB5Z,OAAS,EAAI0b,EAAkB1b,OACpD,MAAM,IAAIwB,MAAM,mDACZoY,EAAmB5Z,OAAS,OAAO0b,EAAkB1b,UAE3D,OAAOlB,KAAK2c,6BACR7B,EAAoB8B,EAAmBL,EACvCM,GACN,QACE,MAAM,IAAIna,MACN,+BAA+BkX,GAAiB2D,OAIlDC,wBACN,MAAMC,EAAuBzd,KAAKka,mBAAmB,GACrD,GAAsC,IAAlCla,KAAKqa,kBAAkBnZ,OACzB,MAAM,IAAIwB,MAAM,iCAElB,MAAMgb,EAAqB1d,KAAKqa,kBAAkB,GAClD,OAAQqD,GACN,KAAK9D,GAAiBe,eACpB,OAAO8C,EAAqB,GAC9B,KAAK7D,GAAiBmB,aACpB,MAAM,IAAIrY,MAAM,kDAClB,KAAKkX,GAAiBqB,WACpB,OAAOjb,KAAKma,yBAAyB,GAAG,GAAK,EAC/C,QACE,MAAM,IAAIzX,MACN,sBAAsBkX,GAAiB8D,OAIjDC,UAEE,GAD6B3d,KAAKka,mBAAmB,GAC5BhZ,QAAU,EACjC,MAAM,IAAIwB,MACN,wEAGN,MAAM4Z,EAAiBtc,KAAKwd,wBACtBX,EAAa7c,KAAKgc,oBAAoBM,GACtCsB,EAAuB,IAAI1e,MAAMc,KAAKua,WAAa,GAEzDqD,EAAWA,EAAW1c,OAAS,GAAK,EACpC,IAAK,IAAIiD,EAAIyZ,EAAW1c,OAAS,EAAGiD,GAAK,IAAKA,EAC5CyZ,EAAWzZ,GAAKyZ,EAAWzZ,EAAI,GAAK0Y,EAAW1Y,EAAI,GAGrD,MAAM0Z,EAAwB9B,GAAUc,GAAY,GAC9CiB,EACFxe,OAAKgN,kBACDtM,KAAK+Z,YAAaza,OAAK0F,cAAc6Y,IAG7C,GADiBD,EAAW,GAAKf,EAAW,GAC7B,EAAG,CAChB,IAAIkB,EAAc/d,KAAKqc,gCACnBC,EAAgBsB,EAAW,GAAIf,EAAW,IAC9C,IAAK,IAAI1Y,EAAI,EAAGA,GAAKnE,KAAKua,aAAcpW,EAAG,CAGzC4Z,EAFuB/d,KAAKsd,qBACxBnZ,EAAI,EAAG4Z,EAAaH,EAAWzZ,GAAI0Y,EAAW1Y,IAIpDnE,KAAKge,UAAUhe,KAAKua,WAAYwD,EAAaD,EAAcD,GAG7D,MAAO,CAACA,EAAaC,GAEvBE,UACIzD,EAAoBwD,EAAuBD,EAC3CD,GACF,GAA4B,IAAxBC,EAAa5c,OACf,OAGF,MAAM+c,EAAaje,KAAKK,OAClB6d,EAAaJ,EAEnB,IAAIK,EAAeN,EAAYpX,QAC/B0X,EAAeA,EAAa1X,MAAM8T,EAAa,GAC/C,MAAM6D,EAAmB9e,OAAK0F,cAAcmZ,GACtCE,EAAkBN,EAAY7c,OAIpC,IAAI8Y,EAAeha,KAAKga,aACxB,GAAIA,EAAa9Y,SAAWkd,GAA4C,IAAxBpE,EAAa9Y,OAAc,CACzE,MAAMod,EAAWte,KAAKia,kBACtBsE,QAAK,KACH,MAAMC,EAAqBC,UAAQzE,EAAcsE,GAC3CI,EAAeC,cAAYH,EAAoBL,GACrDnE,EAAe0E,EAAaE,UAAU,IAO1C,IAAIC,EAAW,EACXC,EAAW,EACXC,EAAS,EACb,IAAK,IAAIC,EAAO,EAAGA,GAAQX,IAAmBW,EAAM,CAElD,IAAIC,EAAOD,EAAOX,EAAkBN,EAAYiB,IAAS,EAIzD,GAAIC,IAASF,EAAb,CASA,GAAID,EAAWC,EAAQ,CAErB,MAAMG,EAAMjB,EAAWkB,SAASN,EAAWT,GAG3CgB,GAFYlB,EAAWiB,SAASL,EAAWV,GAE5Bc,GADAH,EAASD,GAAYV,GAKtC,GAAIY,GAAQX,EAAiB,CAE3B,MAAMxB,EAAaiB,EAAa5c,OAChC+d,EAAO7a,KAAKmK,MAAMsO,EAAauB,GAEjC,GAAIa,EAAOF,EACT,GAAiC,IAA7B/e,KAAKga,aAAa9Y,OACpBgd,EACKiB,SAASJ,EAASX,EAAkBa,EAAOb,GAC3CjI,KAAKnW,KAAKga,aAAa,IAC5B+E,EAASE,OAET,KAAOA,EAAOF,GAAQ,CAEpBK,GADYlB,EAAWzX,MAAMsY,EAASX,GACvBpE,EAAcoE,KAC3BW,EAMJE,EAAO,GAETJ,EAAWG,EAAO,EAClBF,EAAWC,IAGXF,EAAWG,EACXF,EAAWC,EACXA,EAASD,EAAW,SA9ClBC,IAoDV,SAASK,GAAUC,EAAiBH,EAAiB1T,GACnD,IAAK,IAAIrH,EAAI,EAAGA,EAAIqH,EAAMrH,IACxBkb,EAAIlb,GAAK+a,EAAI/a,EAEjB,CAEA,SAAS4X,GAAUzb,EAA4Bwb,GAC7C,MAAMwD,EAAgB,GACtB,IAAK,IAAI7P,KAAOnP,EAAO,CACrB,GAAImP,EAAM,EAAG,CACX,IAAKqM,EACH,MAAM,IAAIpZ,MAAM,aAAa+M,kBAE/B,GAAIA,GAAO,EACT,MAAM,IAAI/M,MAAM,aAAa+M,mBAE/BA,GAAO,EAET6P,EAAI5P,KAAKD,GAGX,OAAO6P,CACT,UAEgBC,GACZjf,EAAmBkf,EAAuBnf,EAC1CiX,EAAuByC,EAAuBC,EAC9CC,EAA6BC,EAC7BC,EACAE,GACF,OAAO,IAAIR,GACAvZ,EAAOkf,EAAanf,EAAQiX,EAAayC,EAAaC,EACtDC,EAAmBC,EAAoBC,EACvCE,GACNsD,SACP,UC3cgB8B,GACZtc,EAAekO,EAAcE,EAC7B/R,GAKF,GAJsB2D,IAAUkO,GACIlO,EAAQkO,GAAQE,EAAO,GACvBF,EAAOlO,GAASoO,EAAO,EAIzD,OAAOjS,OAAK+H,oBAAoB,EAAG7H,GAGrC,MAAMgY,EAAcpT,KAAKC,IAAID,KAAKyI,MAAMwE,EAAOlO,GAASoO,IAClDlR,EAASf,OAAK+H,oBAAoBmQ,EAAahY,GAEjD6R,EAAOlO,GAAkB,IAAToO,IAGlBA,GAAQ,GAGVlR,EAAO,GAAK8C,EACZ,IAAK,IAAIgB,EAAI,EAAGA,EAAI9D,EAAOa,OAAQiD,IACjC9D,EAAO8D,GAAK9D,EAAO8D,EAAI,GAAKoN,EAE9B,OAAOlR,CACT,CCvBO,MAAMqf,GAAYtT,GAAuBQ,GAAO,EAAIxI,KAAKub,KAAK/S,KACxDgT,GAAQpT,EAAwBqT,QAAOH,IAEvCI,GAA4B,CACvCvb,WAAYsb,QACZpb,YAAa,MACbC,WAAYkb,aCFdG,GACIpK,EAAmCqK,EACnC1f,EAAiBuc,EAAoB1N,EAAmB8Q,EACxD/Q,EAAmBE,EACnB4K,EACAkG,GACF,MAAMC,EAAe,CAACtD,EAAa1N,EAAWA,GAExCJ,EAAc4G,EAAQtV,OACtB+f,EAAcJ,EAAQ3f,OAE5B,GAAmB,IAAfwc,EACF,OAAOpa,SAAOnC,EAAsB0f,EAAQxgB,OAG9C,MAAM0M,EAAU8N,aAAwBqG,eACpCrG,EACAvX,SAAO0d,EAAcH,EAAQxgB,OACL,iBAAjBwa,GAEwB,iBAAjBA,EADf9N,EAAO7L,OAAoB8V,KAAK6D,GAGA,kBAAjBA,GACf9N,EAAO7L,OAAsB8V,MAAM6D,GAGtC,IAAK,IAAI7V,EAAI,EAAGA,EAAI8b,EAAY9b,IAAK,CACnC,MAAMoL,EAAQ,GACd,IAAIC,EAAe,EACnB,IAAK,IAAIrD,EAAI,EAAGA,EAAI+C,EAAW/C,IAAK,CAClC,MAAMsD,EAAMV,EAAY5K,EAAI+K,EAAY/C,GACxCoD,EAAMG,KAAKD,GACXD,GAAgBC,EAAML,EAAQjD,GAGhC,GAAIqD,EAAe,GAAKA,GAAgBqN,EAAa1N,EACnD,MAAM,IAAIzM,MAAM,oBAAoB6M,yBAA6BjP,KAGnE,IAAK,IAAIqP,EAAI,EAAGA,EAAIR,EAAWQ,IACzBuQ,EACDhU,EAAO7L,OAAsBmP,EAAeL,EAAYQ,IACpDyQ,EAA2Bjc,EAAIgL,EAAYQ,GAEhDzD,EAAO7L,OAAOmP,EAAeL,EAAYQ,GAAsB,IAAjBqQ,EAAQM,KAClDF,EAAY,GACZA,EAAYjc,EAAIgL,EAAYQ,GAKtC,OAAOzD,CACT,CCxDO,MAAMqU,GACTnU,GAAuBQ,GAAO,GAAK,EAAIxI,KAAK2J,KAAKnB,MACxC4T,GACTjU,EAAgBkU,WAAU7T,GAAO,GAAK,EAAIxI,KAAK2J,KAAKnB,MAE3C8T,GAA8B,CACzCnc,WAAYkc,UACZhc,YAAa,MACbC,WAAY8b,aCREG,GACZ3c,EAAqB4c,EAAiBpV,EAAgBlL,EACtDd,GACF,MAAMqhB,EAAcC,aAAWC,iBAAiBzgB,EAAOsgB,EAAOpV,GACxDtK,EAAS5B,OAAK0F,cAAcwG,GAC5ByI,EAAW3U,OAAKqG,eAAerF,GAErC,GAAIugB,EAAa,CACf,MAAMG,EAAaF,aAAWG,kBAAkBL,EAAO3M,GAEvD,MAAc,WAAVzU,EACMwE,EAAsByC,MAAMua,EAAYA,EAAa9f,GAGvD8C,EAAoBmb,SAAS6B,EAAYA,EAAa9f,GAGhE,MAAMmM,EAAwB,WAAV7N,EAChBkB,eAAa2I,uBAAuBrF,GACpCA,EAEEkd,EAAQze,SAAOnC,EAAOd,EAAO6N,GAC7BnB,EAASzJ,SAAO+I,EAAMhM,GAC5B,IAAK,IAAI2E,EAAI,EAAGA,EAAI+H,EAAOV,OAAQrH,EAAG,CACpC,MAAMgd,EAASjV,EAAO3F,WAAWpC,GAC3Bid,EAAQD,EAAO9f,KAAI,CAACggB,EAAalV,IAAMkV,EAAMT,EAAMzU,KACzDD,EAAOpL,IAAIogB,EAAMzgB,OAAO2gB,MAAWD,GAGrC,MAAc,WAAV3hB,EACKkB,eAAa4gB,uBAAuBpV,EAAO7L,QAE7C6L,EAAO7L,MAChB,UAEgBoG,GACZ9B,GAEF,MAAME,OAACA,EAAME,QAAEA,EAAOyD,MAAEA,GAAS7D,GAC3BC,EAACA,GAAKC,GACN+b,MAACA,EAAKpV,KAAEA,GAAQhD,EAEtBzJ,EAAiB6F,EAAG,SAEpB,MAAO2c,EAAQC,GAASV,aAAWW,iBAAiB7c,EAAGgc,EAAOpV,GAC9DsV,aAAWY,kBAAkB9c,EAAG2c,EAAQC,GAExC,MACM9V,EAAUiV,GADH5b,EAAQ9E,KAAKQ,IAAImE,EAAEhE,QAAQP,OACRkhB,EAAQC,EAAO5c,EAAEtE,MAAOsE,EAAEpF,OAC1D,OAAOuF,EAAQ/D,eAAewgB,EAAO5c,EAAEpF,MAAOkM,EAChD,CAEO,MAAMiW,GAA4B,CACvCpd,WAAYqd,QACZnd,YAAa,MACbC,WAAY+B,aC1DEob,GACZlM,EAAqBC,EAAwBkM,EAC7CzhB,EAAoB0Z,EAAuBgI,EAC3C/H,GAEF,MAAMgI,EAAepM,EAAa,GAC5BqM,EAAYF,EAAW,GAEvBG,EAA+B,IAAIhjB,MAAM+iB,GACzCE,EAA4B,IAAIjjB,MAAM8iB,GAEtC1B,EAAO1K,EAAa,GAE1B,GAAkB,IAAdqM,EAAiB,CACnB,GAAqB,IAAjBD,EACF,MAAM,IAAItf,MACNhC,eAAa0hB,gDACTJ,IAIV,MAAO,CAFe1iB,OAAKgN,kBAAkBwV,EAAc,GAG1C,CAAC,EAAGxB,GAFAhhB,OAAKgN,kBAAkByN,EAAa,GAEfmI,EAAmBC,GAI/D,IAAIE,GAAiB,EACjBC,EAAiB,EACrB,MAAMC,EAAsB,IAAIrjB,MAAM+iB,GAAW9L,KAAK,GAEtD,IAAK,IAAIhS,EAAI,EAAGA,EAAI6d,IAAgB7d,EAAG,CAErC,MAAMoJ,EAAMoI,EAAQxR,EAAImc,GACxB,GAAI/S,EAAM,EACR,MAAM,IAAI7K,MACNhC,eAAa8hB,gDAAgDre,EAAGoJ,IAEtE,GAAIA,GAAO0U,EACT,MAAM,IAAIvf,MACNhC,eAAa+hB,kDACTte,EAAGoJ,EAAK0U,MAEhBM,EAAUhV,GACZ8U,EAAiBA,GAAmB9U,GAAO+U,EAC3CA,EAAiB/U,EAGnB,IAAImV,GAAc,EAClB,IAAK,IAAInV,EAAM,EAAGA,EAAM0U,IAAa1U,EAAK,CAExC,MAAMoV,EAA+B,IAAnBJ,EAAUhV,GAC5B2U,EAAkB3U,GAAOoV,EACzBD,EAAcA,IAAgBC,EAE9BJ,EAAUhV,GAAOnJ,KAAK0N,IAAIyQ,EAAUhV,GAAM,GAOtCA,EAAM,IACRgV,EAAUhV,IAAQgV,EAAUhV,EAAM,IAItC,GAAImV,GAAeL,EAAgB,CACjC,MAAMO,EAA4BjN,EAC5BkN,EAA2BxiB,EACjC,IAAK,IAAI8D,EAAI,EAAGA,EAAI6d,IAAgB7d,EAClCge,EAAgBhe,GAAKA,EAEvB,MAAO,CACLye,EAAe,CAACZ,EAAc1B,GAAOuC,EAAcX,EACnDC,GAEG,CACL,MAAMW,EAAmBP,EAAUN,EAAY,GACzCW,EACFtjB,OAAKgN,kBAAkBwV,EAAcgB,EAAmBxC,GAEtDuC,EACFvjB,OAAKgN,kBAAkByN,EAAa+I,GAClCC,EAAwB,IAAI7jB,MAAM+iB,GAAW9L,KAAK,GAGxD,IAAK,IAAIhS,EAAI,EAAGA,EAAI6d,IAAgB7d,EAAG,CAErC,MAAMoJ,EAAMoI,EAAQxR,EAAImc,GAClBnT,EAAS4V,EAAYxV,GACrByV,GAAoB,IAARzV,EAAa,EAAIgV,EAAUhV,EAAM,IAAMJ,EACzD4V,EAAYxV,KACZ,IAAK,IAAIpB,EAAI,EAAGA,EAAImU,IAAQnU,EAE1ByW,EAAcI,EAAU1C,EAAOnU,GAAKwJ,EAAQxR,EAAImc,EAAOnU,GAEzD0W,EAAaG,GAAW3iB,EAAO8D,GAE/Bge,EAAgBhe,GAAK6e,EAIvB,IAAK,IAAIzV,EAAM,EAAGA,EAAM0U,IAAa1U,EAAK,CAExC,GAAiB,IADAwV,EAAYxV,GACT,CAClB,MAAM0V,EAAyB,IAAR1V,EAAa,EAAIgV,EAAUhV,EAAM,GAIxDqV,EAAcK,EAAgB3C,EAAO,GAAK/S,EAC1C,IAAK,IAAIE,EAAM,EAAGA,EAAM6S,IAAQ7S,EAC9BmV,EAAcK,EAAgB3C,EAAO7S,GAAO,EAE9CoV,EAAaI,GAAiBjJ,GAGlC,MAAO,CACL4I,EAAe,CAACE,EAAkBxC,GAAOuC,EAAcX,EACvDC,GAGN,UCzHgBe,GACZC,EAA0BC,EAA6BC,EACvDC,EACAC,GACF,MAAMC,EAAYlkB,OAAK0F,cAAcse,GAC/BG,EAAML,EAAkB,GACxBM,EAAaH,EAAYriB,OAIzB2c,EAAwB,GAC9B,IAAI8F,EAAU,EACVC,GAAgB,EACpB,IAAK,IAAItiB,EAAI,EAAGA,EAAIoiB,IAAcpiB,EAAG,CACnC,MAAMkK,EAAO+X,EAAYjiB,GACzB,IAAc,IAAVkK,EAAa,CACf,IAAsB,IAAlBoY,EACF,MAAM,IAAIlhB,MACNhC,eACKmjB,yDACGD,EAActiB,IAE5BsiB,EAAetiB,EACfuc,EAAYnO,KAAK,OACZ,CACL,GAAIlE,EAAO,EACT,MAAM,IAAI9I,MACNhC,eAAaojB,8CACTxiB,EAAGkK,IAEbmY,GAAWnY,EACXqS,EAAYnO,KAAKlE,IAGrB,IAAsB,IAAlBoY,EAAqB,CACvB,GAAID,GAAW,EACb,MAAM,IAAIjhB,MACNhC,eAAaqjB,wDAEnB,MAAMC,EAAU5f,KAAK6f,MAAMT,EAAYG,GACvC,GAAIA,EAAUK,IAAYR,EACxB,MAAM,IAAI9gB,MACNhC,eAAawjB,gDACTZ,EAAYzF,IAGtBA,EAAY+F,GAAgBI,EAG9B,GADmB1kB,OAAK0F,cAAc6Y,KACnB2F,EACjB,MAAM,IAAI9gB,MACNhC,eAAayjB,gDACTb,EAAYzF,IAGtB,MAAMuG,EAAYd,EAAWpiB,OACvBmjB,EAAyB,GAC/B,GAAID,EAAY,EAAG,CACjBC,EAAaD,EAAY,GAAK,EAC9B,IAAK,IAAI9iB,EAAI8iB,EAAY,EAAG9iB,GAAK,IAAKA,EACpC+iB,EAAa/iB,GAAK+iB,EAAa/iB,EAAI,GAAKgiB,EAAWhiB,EAAI,GAI3D,MAAMgjB,EAA0B,GAChC,GAAIZ,EAAa,EAAG,CAClBY,EAAcZ,EAAa,GAAK,EAChC,IAAK,IAAIpiB,EAAIoiB,EAAa,EAAGpiB,GAAK,IAAKA,EACrCgjB,EAAchjB,GAAKgjB,EAAchjB,EAAI,GAAKuc,EAAYvc,EAAI,GAI9D,MAAMijB,EACFjlB,OAAKgN,kBAAkB+W,EAAYI,EAAMC,GAC7C,IAAK,IAAIvf,EAAI,EAAGA,EAAIsf,IAAOtf,EAAG,CAC5B,IAAItD,EAAK,EACT,IAAK,IAAIsL,EAAI,EAAGA,EAAIiY,IAAajY,EAE/BtL,GAAMsiB,EAAahf,EAAIigB,EAAYjY,GAAKkY,EAAalY,GAEvD,IAAK,IAAIA,EAAI,EAAGA,EAAIuX,IAAcvX,EAEhCoY,EAAWpgB,EAAIuf,EAAavX,GAAK/H,KAAK6f,MAAMpjB,EAAKyjB,EAAcnY,IAC/DtL,GAAMyjB,EAAcnY,GAGxB,MAAO,CAACoY,EAAY,CAACd,EAAKC,GAAa7F,EACzC,UCvFgB2G,GACZ/c,EAAmB6b,EAAsBD,EACzC1N,EAAqB8O,EAAwBC,GAAS,EACtD1K,EAAe,GACjB,MAAM2K,EAAahP,EAAQzU,OAGrB0jB,EAAsB,CAACtB,EAAW,GAAI7b,EAAMvG,OAASoiB,EAAW,IAChEuB,EAASD,EAAU,GAKnBE,EADFH,EAAa,EAAIF,EAAWE,EAAa,GAAK,EAAI,EAGtD,GAAIG,EAAa,EACf,MAAM,IAAIpiB,MACNhC,eAAaqkB,2DAGnB,MAAMlH,EAAcyF,EAAW7c,QAC/BoX,EAAY,GAAKiH,EAEjB,MAAME,EACFnH,EAAYoH,QAAO,CAACtB,EAAShY,IAAUgY,EAAUhY,GAAO,GAEtDuZ,EAAS5lB,OAAKgN,kBAAkB+W,EAAY2B,GAIlD,GAAmB,IAAfL,EAIF,OAHIG,EAAa,GACfI,EAAO/O,KAAK6D,GAEP,CAACkL,EAAQrH,GAGlB,GAAIiH,GAAc,EAChB,MAAM,IAAIpiB,MACNhC,eAAaqkB,2DAGnB,IAAI5hB,EAAQ,EAAGgiB,EAAM,EAEjBC,EAAqB,EACrBC,EAAWZ,EAAWthB,GAE1B,OAAa,CAEX,IAAImiB,EAAY,EAChB,GAAIH,EAAMR,EAAY,CAEpB,GADAW,EAAYb,EAAWU,GACnBE,IAAaC,EAAW,GACxBH,EACF,SAGF,GAAIE,GAAYC,EACd,MAAM,IAAI5iB,MAAMhC,eACX6kB,gEAIT,GAAIF,EAAW,GAAKA,GAAYP,EAC9B,MAAM,IAAIpiB,MACNhC,eAAa8kB,yDACTH,EAAUP,IAKhBO,EAAWD,GACbF,EAAO/O,KAAK6D,EAAcoL,EAAqBP,EAAQQ,EAAWR,GAGpE,IAAK,IAAI1gB,EAAIhB,EAAOgB,EAAIghB,IAAOhhB,EAAG,CAChC,MAAMoL,EAAQoG,EAAQxR,GACtB,GAAIoL,EAAQ,GAAKA,GAASqV,EAAU,GAClC,MAAM,IAAIliB,MACNhC,eAAa+kB,uDACTthB,EAAGwR,EAAQxR,GAAIygB,EAAU,KAEnC,IAAK,IAAIzY,EAAI,EAAGA,EAAI0Y,EAAQ1Y,IAC1B+Y,EAAOG,EAAWR,EAAS1Y,IAAM1E,EAAM8H,EAAQsV,EAAS1Y,GAI5D,GAAIuY,EACF,IAAK,IAAIvY,EAAI,EAAGA,EAAI0Y,EAAQ1Y,IAC1B+Y,EAAOG,EAAWR,EAAS1Y,IAAMgZ,EAAMhiB,EAQ3C,GAJAA,EAAQgiB,IACNA,EACFC,EAAqBC,EAAW,EAChCA,EAAWC,EACPH,EAAMR,EACR,MASJ,OAJIS,EAAqBN,GACvBI,EAAO/O,KAAK6D,EAAcoL,EAAqBP,EAAQC,EAAaD,GAG/D,CAACK,EAAQrH,EAClB,CCzGO,MAAM6H,GAAWtZ,GAAuBQ,GAAOxI,KAAKub,KAAK/S,KACnD+S,GAAOpT,EAAgBoZ,QAAO/Y,GAAOxI,KAAKub,KAAK/S,KAE/CgZ,GAA2B,CACtCrhB,WAAYohB,OACZlhB,YAAa,MACbC,WAAYib,ICNDkG,GACT5gB,IAA+BoD,EAAWC,KACxC,MAAMwd,EAAOzd,EAAIC,EACjB,OAAOwd,EAAOA,CACf,IACQC,GACT/c,EAAiBgd,oBAAmBH,IAE3BI,GAAwC,CACnD1hB,WAAYyhB,oBACZvhB,YAAa,MACbC,WAAYqhB,ICZDG,GAAyB9Z,GAC5B,CAACxH,EAAW4D,KAClB,MAAM2d,QAACA,EAAOC,cAAEA,EAAaC,QAAEA,GAC7B7d,EAEF,OAAO5D,EAAE0hB,QAAQ,IAAIC,OAAOJ,EAASC,EAAgB,IAAM,IAAKC,EAAQ,IAGtEG,GACJha,EAAwBia,qBAAoBP,IAEjCQ,GAAyC,CACpDniB,WAAYkiB,qBACZhiB,YAAa,MACbC,WAAY8hB,aChBEG,GACZ1Z,EAAoBpB,EAAuBuD,EAC3CwR,GACF,MAAM1U,EAASzJ,SAAOwK,EAAUpB,EAAKrM,OAErC,IAAK,IAAI2E,EAAI,EAAGA,EAAI+H,EAAOV,KAAMrH,IAAK,CACpC,MAAMmC,EAAM4F,EAAO3F,WAAWpC,GAExBgQ,EAAmB,IAAIjV,MAAMoH,EAAIpF,QACvC,IAAK,IAAIiL,EAAI,EAAGA,EAAIgI,EAAOjT,OAAQiL,IACjCgI,EAAOhI,GAAK7F,EAAI6F,GAAKiD,EAAQjD,GAAKyU,EAAMzU,GAE1CD,EAAOpL,IAAI+K,EAAKpL,OAAO0T,MAAY7N,GAGrC,OAAO4F,CACT,CCVA,MAAM0a,GAQJ9mB,YACI+mB,EAAmBC,EAAuBC,EAC1CC,EAAkBC,EAAkBC,GACtClnB,KAAK6mB,UAAYvnB,OAAKiC,aAAaslB,GACnC7mB,KAAK8mB,YAAcA,EACnB9mB,KAAK+mB,QAAUznB,OAAKiC,aAAawlB,GACjC/mB,KAAKgnB,SAAW1nB,OAAKiC,aAAaylB,GAClChnB,KAAKinB,SAAWA,EAChBjnB,KAAKmnB,cAAgBD,EAGfE,YAAYC,GAIlB,OAAOjjB,KAAKoO,IACRxS,KAAKinB,SAAW,EAAII,EAAa,EAAIrnB,KAAKinB,SAAUI,EAAa,GAG/DC,aAAapmB,EAAgBmmB,GACnC,MAAMJ,EAAWjnB,KAAKonB,YAAYC,GAClC,OAAOjjB,KAAK0N,IAAI,EAAK5Q,EAAS,EAAI+lB,EAAYI,EAAc,GAGtDE,aACJtnB,EAAoBunB,EAAoBtC,EACxCuC,EAA0BC,EAAmBL,GAC/C,IAAK,IAAIM,EAAa,EAAGA,EAAaD,IAAaC,EAAY,CAC7D,MAAMV,EAAWjnB,KAAKonB,YAAYC,GAC5BO,EAAcxjB,KAAK0N,IAAI,EAAGmV,EAAWU,GACrCE,EACFzjB,KAAK0N,IAAI,EAAGmV,GAAYS,GAAaC,EAAa,KAChDG,EAAYT,GAAcO,EAAcC,GACxCE,EACFP,GAAcI,EAAc,EAAI,EAAID,EAAaV,GAIrD,IAAIe,EAAY,EAEhBA,GAAaJ,EAAc5nB,KAAK+mB,QAAQ7lB,OAExC,IAAK,IAAI+mB,EAAI,EAAGA,EAAIH,IAAaG,EAC/BD,GAAa/nB,EAAK8nB,EAAiBE,GAAG/mB,OAGxC8mB,GAAaH,EAAe7nB,KAAKgnB,SAAS9lB,OAG1C8mB,IADsBJ,EAAcC,EAAeC,EAAY,GAClC9nB,KAAK6mB,UAAU3lB,OAG5CgkB,EAAOuC,EAAmBE,GAAc,IAAIO,WAAWF,GACvD,MAAMG,EAAQjD,EAAOuC,EAAmBE,GAExC,IAAIS,EAAiB,EACrB,MAAMC,EAAiBC,GACnBA,EAAIlpB,SAASuM,GAAUwc,EAAMC,KAAoBzc,IAErD,IAAK,IAAIsc,EAAI,EAAGA,EAAIL,IAAeK,EACjCI,EAAcroB,KAAK+mB,SACnBsB,EAAcroB,KAAK6mB,WAGrB,IAAK,IAAIoB,EAAI,EAAGA,EAAIH,EAAY,IAAKG,EACnCI,EAAcpoB,EAAK8nB,EAAiBE,IACpCI,EAAcroB,KAAK6mB,WAIrB,GAAIiB,EAAY,EAAG,CAIjBO,EAAcpoB,EAAK8nB,EAAiBD,EAAY,IAChD,IAAK,IAAIG,EAAI,EAAGA,EAAIJ,IAAgBI,EAClCI,EAAcroB,KAAK6mB,WACnBwB,EAAcroB,KAAKgnB,cAEhB,CAKL,IAAK,IAAIiB,EAAI,EAAGA,EAAIJ,EAAe,IAAKI,EACtCI,EAAcroB,KAAKgnB,UACnBqB,EAAcroB,KAAK6mB,WAErBwB,EAAcroB,KAAKgnB,YAQlBrJ,QAAQ1d,EAAoBmW,GAIjC,MAAMmS,EAAgBtoB,EAAKiB,OACrBsnB,EAAapS,EAAOlV,OAC1B,GAAIsnB,EAAa,EAAG,CAClB,IAAIC,EAAYrS,EAAO,GACvB,GAAkB,IAAdqS,EACF,MAAM,IAAI/lB,MAAM,oCAAoC+lB,KAEtD,IAAK,IAAItkB,EAAI,EAAGA,EAAIqkB,IAAcrkB,EAAG,CACnC,IAAIukB,EAActS,EAAOjS,IAAMskB,EAE/B,GADAC,EAAcA,GAAgBtS,EAAOjS,IAAMokB,GACtCG,EACH,MAAM,IAAIhmB,MAAM,uBAAuB0T,EAAOjS,mBAC1CskB,MAAcF,MAEpBE,EAAYrS,EAAOjS,GAErB,GAAIskB,IAAcF,EAChB,MAAM,IAAI7lB,MAAM,gDACZ6lB,UAAsBE,KAI9B,MAAME,EAAgBH,EAAa,EAC7BI,EAAetpB,OAAKgN,kBAAkB,QAASkc,GAErD,GAAsB,IAAlBD,GAAsC,IAAfC,EAAkB,CAC3C,MAAMK,EAAsB,IAAI3pB,MAAMqpB,GACtC,IAAK,IAAIpkB,EAAI,EAAGA,GAAKwkB,IAAiBxkB,EACpCykB,EAAazkB,GAAK,EAEpB,MAAO,CAAC0kB,EAAOD,GAGjBA,EAAa,GAAK,EAClB,IAAK,IAAIzkB,EAAI,EAAGA,GAAKwkB,IAAiBxkB,EAAG,CACvC,MAAMjD,EAASkV,EAAOjS,GAAKiS,EAAOjS,EAAI,GACtC,IAAIujB,EAAY,EAChB1nB,KAAK8mB,YAAY1nB,SAASioB,IACxBK,GAAa1nB,KAAKsnB,aAAapmB,EAAQmmB,EAAW,IAEhDrnB,KAAKmnB,eAAiBjmB,EAAS,GAAmB,IAAdwmB,IACtCA,EAAY,GAEdkB,EAAazkB,GAAKykB,EAAazkB,EAAI,GAAKujB,EAG1C,MAAMoB,EAAuB,IAAI5pB,MAAM0pB,EAAaD,IAEpD,IAAK,IAAIxkB,EAAI,EAAGA,EAAIwkB,IAAiBxkB,EAAG,CACtC,MAAMqjB,EAAapR,EAAOjS,GAC1B,IAAI4kB,EAAiBH,EAAazkB,GAalC,GAZAnE,KAAK8mB,YAAY1nB,SAASioB,IACxB,MAAMnmB,EAASkV,EAAOjS,EAAI,GAAKiS,EAAOjS,GAChCujB,EAAY1nB,KAAKsnB,aAAapmB,EAAQmmB,GAC5CrnB,KAAKunB,aACDtnB,EAAMunB,EAAYsB,EAAQC,EAAgBrB,EAAWL,GACzD0B,GAAkBrB,CAAS,IAOzB1nB,KAAKmnB,eAAiB4B,IAAmBH,EAAazkB,GAAI,CAC5D,MAAM6kB,EAAa5S,EAAOjS,EAAI,GAAKiS,EAAOjS,GAG1C,GAAmB,IAAf6kB,EACF,SAKF,MAAM3B,EAAa2B,EAAa,EAAIhpB,KAAKinB,SACnCS,EAAY,EAClB1nB,KAAKunB,aACDtnB,EAAMunB,EAAYsB,EAAQC,EAAgBrB,EAAWL,IAG7D,MAAO,CAACyB,EAAQF,aAIJK,GACZhpB,EAAoBipB,EAAwBrC,EAC5CC,EAAuBC,EAAiBC,EAAkBC,EAC1DC,GACF,OAAO,IAAIN,GACAC,EAAWC,EAAaC,EAASC,EAAUC,EAC3CC,GACNvJ,QAAQ1d,EAAMipB,EACrB,CC7MA,SAASC,GACLb,EAAiBc,EAAwBC,EACzCxjB,GACF,IAAKyiB,EAAIpnB,OACP,OAGF,GAA0B,IAAtBkoB,EAAWloB,OAAc,CAC3B,IAAK,IAAIiD,EAAI,EAAGA,EAAImkB,EAAIpnB,SAAUiD,EAChC0B,EAAO6J,KAAK4Y,EAAInJ,SAAShb,EAAGA,EAAI,IAElC,OAGF,GAA0B,IAAtBilB,EAAWloB,OAAc,CAC3B,MAAMooB,EAAYF,EAAW,GAC7B,IAAIlmB,EAAIolB,EAAIiB,QAAQD,GACpB,MAAc,IAAPpmB,GAAU,CACf,MAAMsmB,EAAQlB,EAAInJ,SAAS,EAAGjc,GACzBmmB,GAA8B,IAAjBG,EAAMtoB,QACtB2E,EAAO6J,KAAK8Z,GAGdtmB,GADAolB,EAAMA,EAAInJ,SAASjc,EAAI,IACfqmB,QAAQD,GAKlB,YAHKD,GAA4B,IAAff,EAAIpnB,QACpB2E,EAAO6J,KAAK4Y,IAMhB,IAAImB,EAAa,EACjB,IAAK,IAAItlB,EAAI,EAAGA,EAAImkB,EAAIpnB,OAAS,EAAGiD,IAClC,GAAKA,IAAMmkB,EAAIpnB,SAA4C,IAAhCkoB,EAAWG,QAAQjB,EAAInkB,IAAa,CAC7D,MAAMqlB,EAAQlB,EAAInJ,SAASsK,EAAYtlB,GAClCklB,GAA8B,IAAjBG,EAAMtoB,QACtB2E,EAAO6J,KAAK8Z,GAEdC,EAAatlB,EAAI,EAGvB,UAEgBulB,GACZjiB,EAAqB6hB,EACrBD,GACF,MAAMM,EAAYliB,EAAMvG,OAGlB0oB,EAAuB,GAE7B,IAAI/M,EAAa,EACbgN,EAAgB,EACpB,MAAMlF,EAAuB,IAAIzlB,MAAMyqB,GACvC,IAAK,IAAIxlB,EAAI,EAAGA,EAAIwlB,IAAaxlB,EAAG,CAClC,MAAM2lB,EAAmBF,EAAO1oB,OAChCioB,GAAM1hB,EAAMtD,GAAImlB,EAAWD,EAAWO,GACtC,MAAMG,EAAWH,EAAO1oB,OAAS4oB,EACjCnF,EAAWxgB,GAAK4lB,EAChBlN,GAAckN,EACdF,EAAgBzlB,KAAK0N,IAAI+X,EAAeE,GAG1C,MAAMpU,EAAUrW,OAAKgN,kBAAkB,QAAsB,EAAbuQ,GAC1Cxc,EAAuB,IAAInB,MAAM2d,GACjCvc,EAA0B,CAACqpB,EAAWE,GAE5C,IAAIG,EAAI,EACR,IAAK,IAAI7lB,EAAI,EAAGA,EAAIwlB,IAAaxlB,EAC/B,IAAK,IAAIgI,EAAI,EAAGA,EAAIwY,EAAWxgB,KAAMgI,EAEnCwJ,EAAY,EAAJqU,GAAS7lB,EACjBwR,EAAY,EAAJqU,EAAQ,GAAK7d,EACrB9L,EAAO2pB,GAAKJ,EAAOI,KACjBA,EAIN,MAAO,CAACrU,EAAStV,EAAQC,EAC3B,UChFgB2pB,GACZxiB,EAAqByiB,GACvB,MAAMhF,EAAS5lB,OAAKgN,kBAAkB,QAAS7E,EAAMvG,QAErD,IAAK,IAAIiD,EAAI,EAAGA,EAAIsD,EAAMvG,SAAUiD,EAClC+gB,EAAO/gB,GACH7E,OAAK6qB,cAAc1iB,EAAMtD,IAAIimB,OAAOF,GAAYG,qBAGtD,OAAOnF,CACT,CCPO,MAAMoF,GAAUrlB,IACjBiN,EAAgBC,IAAmBD,EAASC,IACrCoY,GACT/f,IAAgCd,EAAOC,EAAOK,EAAOC,KAC5C,CAAChI,KAAMyH,EAAQM,EAAO7H,KAAMwH,EAAQM,MAEpCugB,GAAMxhB,EAAiByhB,MAAKH,GAASC,IAErCG,GAA0B,CACrCnmB,WAAYkmB,MACZhmB,YAAa,MACbC,WAAY8lB,aCTEG,GACZ9e,EACA+e,GACF,MAAMrlB,EAAqB,IAAIrG,MAAM2M,EAAKyU,MAC1C,IAAK,IAAInc,EAAI,EAAGA,EAAIoB,EAASrE,OAAQiD,IACnCoB,EAASpB,GAAK0H,EAAKvL,MAAM6D,GAAKymB,EAAKzmB,GAErC,MAAM0B,EAASpD,SAAO8C,EAAUsG,EAAKrM,OACrC,IAAK,IAAI2E,EAAI,EAAGA,EAAI0B,EAAOxF,OAAOa,SAAUiD,EAAG,CAC7C,MAAMgQ,EAAStO,EAAOU,WAAWpC,GAE3B4L,EAAwB,IAAI7Q,MAAM2M,EAAKyU,MAC7C,IAAK,IAAInU,EAAI,EAAGA,EAAI4D,EAAY7O,OAAQiL,IACtC4D,EAAY5D,GAAKgI,EAAOhI,GAAKN,EAAKvL,MAAM6L,GAG1C,MAAMgE,EAAgBtE,EAAKlF,WAAWoJ,GAEtClK,EAAOxF,OAAO8D,GAAK0H,EAAKxL,OAAO8P,GAEjC,OAAOtK,CACT,CCnBA,MAAMglB,GAAc,CAACxiB,EAASC,KAC5B,MAAMwiB,EAAYxiB,EAAEqD,MAAQtD,EAAEsD,MAC9B,OAAqB,IAAdmf,EAAkBziB,EAAEkH,MAAQjH,EAAEiH,MAAQub,CAAS,EAcxD,SAASC,GAAOC,EAAerb,EAAWsb,EAAO,EAAGC,EAAQF,EAAM9pB,OAAS,GACzE,KAAOgqB,EAAQD,GAAM,CAInB,GAAIC,EAAQD,EAAO,IAAK,CACtB,MAAMhD,EAAIiD,EAAQD,EAAO,EACnB9mB,EAAIwL,EAAIsb,EAAO,EACfE,EAAI/mB,KAAKqN,IAAIwW,GACbmD,EAAI,GAAMhnB,KAAK2J,IAAI,EAAIod,EAAI,GAC3BE,EAAK,GAAMjnB,KAAKub,KAAKwL,EAAIC,GAAKnD,EAAImD,GAAKnD,GAAK7jB,KAAKknB,KAAKnnB,EAAI8jB,EAAI,GAGpE8C,GAAOC,EAAOrb,EAFEvL,KAAK0N,IAAImZ,EAAM7mB,KAAKmK,MAAMoB,EAAIxL,EAAIinB,EAAInD,EAAIoD,IACzCjnB,KAAKoO,IAAI0Y,EAAO9mB,KAAKmK,MAAMoB,GAAKsY,EAAI9jB,GAAKinB,EAAInD,EAAIoD,KAIpE,MAAMhsB,EAAI2rB,EAAMrb,GAChB,IAAIxL,EAAI8mB,EACJ9e,EAAI+e,EAOR,IALA5rB,OAAKisB,KAAKP,EAAOC,EAAMtb,GAEnBkb,GAAYG,EAAME,GAAQ7rB,GAAK,GACjCC,OAAKisB,KAAKP,EAAOC,EAAMC,GAElB/mB,EAAIgI,GAAG,CAIZ,IAHA7M,OAAKisB,KAAKP,EAAO7mB,EAAGgI,GACpBhI,IACAgI,IACO0e,GAAYG,EAAM7mB,GAAI9E,GAAK,GAChC8E,GAAQ,EAEV,KAAO0mB,GAAYG,EAAM7e,GAAI9M,GAAK,GAChC8M,GAAQ,EAGwB,IAAhC0e,GAAYG,EAAMC,GAAO5rB,GAC3BC,OAAKisB,KAAKP,EAAOC,EAAM9e,IAEvBA,GAAQ,EACR7M,OAAKisB,KAAKP,EAAO7e,EAAG+e,IAIlB/e,GAAKwD,IACPsb,EAAO9e,EAAI,GAETwD,GAAKxD,IACP+e,EAAQ/e,EAAI,GAGlB,UAEgBqf,GACZ5mB,EAAesO,EAAkBC,EAAyBxD,EAC1D8b,GAGF,MAAMC,EAAUxY,EAAOA,EAAOhS,OAAS,IAChCyqB,EAAOngB,GAAQ,CAAC5G,EAAE1D,OAASwqB,EAASA,GACrCE,EAActsB,OAAKwG,uBAAuBqN,EAAQwY,EAAQhc,GAC1Dkc,EAAiBvsB,OAAKwG,uBAAuB,QAAS6lB,EAAQhc,GAEpE,IAAK,IAAIrH,EAAI,EAAGA,EAAIqjB,EAAOrjB,IAAK,CAC9B,MAAM6E,EAAS7E,EAAIkD,EACbxH,EAAOY,EAAEua,SAAShS,EAAQA,EAAS3B,GAEzC,IAAIsgB,EAAoB,IAAI5sB,MAAM8E,EAAK9C,QACvC8C,EAAK5E,SACD,CAACuM,EAAe4D,IAAkBuc,EAAUvc,GAAS,CAAC5D,QAAO4D,WAE7DI,EAAImc,EAAU5qB,SAChB6pB,GAAOe,EAAWnc,GAClBmc,EAAYA,EAAUrlB,MAAM,EAAGkJ,IAG7B8b,GACFK,EAAUC,KAAKlB,IAGjB,MAAMmB,EAAY1jB,EAAIqH,EAChBsc,EAAWL,EAAYzM,SAAS6M,EAAWA,EAAYrc,GACvDuc,EAAcL,EAAe1M,SAAS6M,EAAWA,EAAYrc,GACnE,IAAK,IAAIxL,EAAI,EAAGA,EAAIwL,EAAGxL,IACrB8nB,EAAS9nB,GAAK2nB,EAAU3nB,GAAGwH,MAC3BugB,EAAY/nB,GAAK2nB,EAAU3nB,GAAGoL,MAKlC,MAAMsO,EAAc3K,EAAOzM,QAG3B,OAFAoX,EAAYA,EAAY3c,OAAS,GAAKyO,EAE/B,CACLlN,SAAOob,EAA4B1K,EAAQyY,GAC3CnpB,SAAOob,EAA4B,QAASgO,GAEhD,UCxHgBM,GACZ9rB,EAAuB2U,EAAc1U,EAAiBd,GAMxD,MAAM4sB,EAAQ9sB,OAAK6V,eAAeH,EAAM1U,GAAO,GAyDzCiF,EAAW,CAAC,EAAGjF,EAAM,GAAI,GAC/B,IAAK,IAAI6D,EAAI,EAAGA,EAAIioB,EAAOjoB,IACzBoB,EAAS,IAAMjF,EAAM6D,GAEvBoB,EAAS,GAAKjF,EAAM8rB,GACpB,IAAK,IAAIjoB,EAAIioB,EAAQ,EAAGjoB,EAAI7D,EAAMY,OAAQiD,IACxCoB,EAAS,IAAMjF,EAAM6D,GAKvB,MAAMkoB,EAAiB,IAAIC,IAGrB3W,EAAU,IAAI5N,WAAWzH,EAAM8rB,IAE/BG,EAAc,IAAIlM,eAAa9a,EAAU/F,EAAOa,GAGhDmsB,EAA0B,GAC1BC,EAA6B,IAAhBlnB,EAAS,IAA4B,IAAhBA,EAAS,GACjD,IAAK,IAAIpB,EAAI,EAAGA,EAAI7D,EAAM8rB,GAAQjoB,IAAK,CAErC,IAAIuoB,EACJ,GAAID,EAEFC,EAAUrsB,EAAO8D,GAAGwoB,eACf,CACL,MAAMC,EAAa,GACnB,IAAK,IAAIC,EAAI,EAAGA,EAAItnB,EAAS,GAAIsnB,IAC/B,IAAK,IAAI5E,EAAI,EAAGA,EAAI1iB,EAAS,GAAI0iB,IAC/B2E,EAAWld,KAAK6c,EAAY9rB,IAAIosB,EAAG1oB,EAAG8jB,IAG1CyE,EAAUE,EAAWzU,KAAK,KAI5B,MAAM2U,EAAgBT,EAAe5rB,IAAIisB,GACzC,GAAqB,MAAjBI,EACFnX,EAAQxR,GAAK2oB,MACR,CACL,MAAMC,EAAcV,EAAe7gB,KACnC6gB,EAAevrB,IAAI4rB,EAASK,GAC5BpX,EAAQxR,GAAK4oB,EACbP,EAAc9c,KAAKvL,IAOvB,MAAM6oB,EAAiBznB,EAASkB,QAChCumB,EAAe,GAAKX,EAAe7gB,KACnC,MAAMyhB,EAAe,IAAI5M,eAAa2M,EAAgBxtB,GACtDgtB,EAAcptB,SAAQ,CAAC8tB,EAAoB/oB,KACzC,IAAK,IAAI0oB,EAAI,EAAGA,EAAItnB,EAAS,GAAIsnB,IAC/B,IAAK,IAAI5E,EAAI,EAAGA,EAAI1iB,EAAS,GAAI0iB,IAC/BgF,EAAansB,IAAIyrB,EAAY9rB,IAAIosB,EAAGK,EAAoBjF,GAAI4E,EAAG1oB,EAAG8jB,MAOxE,MAAMpK,EAAcvd,EAAMmG,QAG1B,OAFAoX,EAAYuO,GAASY,EAAe,GAE7B,CACLnK,aAAcoK,EAAa5sB,OAC3Bwd,cACAlI,UAEJ,i1BC9HgB,OAAO,IAAM,IAAIhW,GAAkB,GCT5C,MAAMwtB,GACT5gB,EAAgB6gB,OAAMxgB,GAAOA,GAAM,EAAIA,EAAMxI,KAAK2J,IAAInB,GAAM,IAEnDygB,GAA0B,CACrC9oB,WAAY6oB,MACZ3oB,YAAa,MACbC,WAAYyoB,aCLEG,GAAU3oB,GAKxB,MAAME,OAACA,EAAME,QAAEA,EAAOyD,MAAEA,GAAS7D,GAC3BC,EAACA,GAAKC,GACN0oB,MAACA,GAAS/kB,EAEhBzJ,EAAiB,CAAC6F,GAAI,aAEtB,MAAMoP,EAAQ1U,OAAK0F,cAAcJ,EAAEtE,OAC7B8K,EAAQrG,EAAQ9E,KAAKQ,IAAImE,EAAEhE,QAAQP,OACnCqL,EAAUpM,OAAKwG,uBAAuB,UAAWkO,GAEvD,IAAK,IAAI7P,EAAI,EAAGA,EAAIiH,EAAMlK,OAAQiD,IAChCuH,EAAQvH,GAAKiH,EAAMjH,GAAK,EAAIopB,EAAQniB,EAAMjH,GAAKiH,EAAMjH,GAGvD,OAAOY,EAAQ/D,eAAe4D,EAAEtE,MAAO,UAAWoL,EACpD,CAEO,MAAM8hB,GAAgC,CAC3CjpB,WAAYkpB,YACZhpB,YAAa,MACbC,WAAY4oB,ICxBRI,GAAYzoB,GACd,CAAC0oB,EAAgBzb,IAAmByb,EAAS,EAAIzb,EAASyb,EAASA,aAEvDC,GAAMjpB,GAEpB,MAAME,OAACA,EAAME,QAAEA,GAAWJ,GACpBC,EAACA,EAAC2oB,MAAEA,GAAS1oB,EAEnB9F,EAAiB,CAAC6F,EAAG2oB,GAAQ,SAE7B,MAAMloB,EAAQN,EAAQ9E,KAAKQ,IAAImE,EAAEhE,QAAQP,OACnCiF,EAAQP,EAAQ9E,KAAKQ,IAAI8sB,EAAM3sB,QAAQP,QAEtC8H,EAAYC,GACfslB,GAAU9oB,EAAEtE,MAAOitB,EAAMjtB,MAAO+E,EAAOC,EAAO,WAElD,OAAOP,EAAQ/D,eAAeoH,EAAa,UAAWD,EACxD,CAEO,MAAM0lB,GAA4B,CACvCtpB,WAAYupB,QACZrpB,YAAa,MACbC,WAAYkpB,ICxBDG,GAAOxhB,EAAgByhB,QAAOphB,GAAOxI,KAAK0N,IAAI,EAAGlF,KAEjDqhB,GAA2B,CACtC1pB,WAAYypB,OACZvpB,YAAa,MACbC,WAAYqpB,ICLDG,GACT3hB,EAAgB4hB,SAAQvhB,GAAOxI,KAAKoO,IAAIpO,KAAK0N,IAAI,EAAGlF,GAAK,KAEhDwhB,GAA4B,CACvC7pB,WAAY4pB,QACZ1pB,YAAa,MACbC,WAAYwpB,aCCEG,GACZtpB,EAAyBH,EAAe0pB,EACxCC,EAAqCC,GACvC,GAAmB,WAAfF,EACF,OAAOhnB,EAAS,CAACzC,OAAQ,CAACD,KAAIG,YACzB,GAAmB,SAAfupB,EACT,OAAOP,GAAK,CAAClpB,OAAQ,CAACD,KAAIG,YACrB,GAAmB,QAAfupB,EACT,OAAOnB,GAAI,CAACtoB,OAAQ,CAACD,KAAIG,YACpB,GAAmB,UAAfupB,EACT,OAAOJ,GAAM,CAACrpB,OAAQ,CAACD,KAAIG,YACtB,GAAmB,UAAfupB,EACT,OAAOV,GAAM,CAAC/oB,OAAQ,CAACD,IAAG2oB,MAAOgB,GAAyBxpB,YACrD,GAAmB,cAAfupB,EACT,OAAOhB,GAAU,CAACzoB,OAAQ,CAACD,KAAIG,UAASyD,MAAO,CAAC+kB,MAAOiB,KAClD,GAAmB,YAAfF,EACT,OAAO9N,GAAQ,CAAC3b,OAAQ,CAACD,KAAIG,YAE/B,MAAM,IAAIrC,MACN,cAAc4rB,kDACpB,UC3BgB7P,GACZ9Z,GAGF,MAAME,OAACA,EAAME,QAAEA,EAAOyD,MAAEA,GAAS7D,GAC3BC,EAACA,GAAKC,GACNvE,MAACA,GAASkI,EAEVwL,EAAQ1U,OAAK0F,cAAcJ,EAAEtE,OAC7BmuB,EAASnvB,OAAKovB,uBAAuBpuB,EAAO0T,GAC5C2a,EAASrvB,OAAK0F,cAAcypB,GAElCnvB,OAAKC,OACDyU,IAAU2a,GACV,IAAM,kBAAkBF,UAAeE,iCACzB/pB,EAAEtE,cAAc0T,mFAGlCjP,EAAQtD,OAAOmD,EAAEhE,QAEjB,MAAMguB,EAAQ7pB,EAAQ9E,KAAKQ,IAAImE,EAAEhE,QAEjC,GAAgC,MAA5BguB,EAAM7sB,mBAA4B,CACpC,MAAME,EAAO2sB,EAAM7sB,mBAAmBE,KAChCE,EAAOysB,EAAM7sB,mBAAmBI,KAEtCF,EAAK3B,MAAQmuB,EACbtsB,EAAK7B,MAAQmuB,EAGf,MAAO,CAAC7tB,OAAQgE,EAAEhE,OAAQN,MAAOmuB,EAAQjvB,MAAOoF,EAAEpF,MACpD,CAEO,MAAMqvB,GAA8B,CACzCtqB,WAAYuqB,UACZrqB,YAAa,MACbC,WAAY+Z,aCjCEsQ,GAAYpqB,GAK1B,MAAME,OAACA,EAAME,QAAEA,EAAOyD,MAAEA,GAAS7D,GAC3B0D,EAACA,EAACC,EAAEA,GAAKzD,GACTmqB,WAACA,EAAUC,WAAEA,GAAczmB,EAEjCzJ,EAAiB,CAACsJ,EAAGC,GAAI,UAEzB,MAAMvC,EAAQsC,EAAE/H,MAAMY,OAChB8E,EAAQsC,EAAEhI,MAAMY,OAEhBguB,EAAcF,EAAa3mB,EAAE/H,MAAMyF,EAAQ,GAAKsC,EAAE/H,MAAMyF,EAAQ,GAChEopB,EAAcF,EAAa3mB,EAAEhI,MAAM0F,EAAQ,GAAKsC,EAAEhI,MAAM0F,EAAQ,GAEhEopB,EAAcJ,EAAa3mB,EAAE/H,MAAMyF,EAAQ,GAAKsC,EAAE/H,MAAMyF,EAAQ,GAChEspB,EAAcJ,EAAa3mB,EAAEhI,MAAM0F,EAAQ,GAAKsC,EAAEhI,MAAM0F,EAAQ,GAEhEspB,EAAajnB,EAAE/H,MAAMmG,MAAM,GAAI,GAC/B8oB,EAAajnB,EAAEhI,MAAMmG,MAAM,GAAI,GAE/B+oB,EAAYlwB,OAAK0F,cAAcsqB,GAC/BG,EAAYnwB,OAAK0F,cAAcuqB,GAI/BtiB,EAFoByiB,iBAAelqB,2BACrC6C,EAAE/H,MAAMmG,MAAM,GAAI,GAAI6B,EAAEhI,MAAMmG,MAAM,GAAI,IACTkpB,OAAO,CAACP,EAAaC,IAExD/vB,OAAKC,OACD2vB,IAAgBC,GAChB,IAAM,kCAAkCD,WACjCC,6BAAuC9mB,EAAE/H,aACzCgI,EAAEhI,wBAAwB0uB,oBACVC,kBAE3B,MAEMW,EAAWX,EAAa,CAACQ,EAAWJ,EAAaF,GACzB,CAACM,EAAWN,EAAaE,GAGjDQ,EAAMpR,GAAQ,CAAC5Z,OAAQ,CAACD,EAAGyD,GAAItD,UAASyD,MAAO,CAAClI,MANrC0uB,EAAa,CAACQ,EAAWN,EAAaE,GACzB,CAACI,EAAWJ,EAAaF,MAMjDY,EAAMrR,GAAQ,CAAC5Z,OAAQ,CAACD,EAAG0D,GAAIvD,UAASyD,MAAO,CAAClI,MAAOsvB,KAEvDG,EAAYf,EAAaa,EAAIvvB,MAAM,GAAKuvB,EAAIvvB,MAAM,GAClD0vB,EAAUhB,EAAaa,EAAIvvB,MAAM,GAAKuvB,EAAIvvB,MAAM,GAChD2vB,EAAWhB,EAAaa,EAAIxvB,MAAM,GAAKwvB,EAAIxvB,MAAM,GACjD4vB,EAAW9rB,KAAK0N,IAAI0d,EAAWC,GAE/BU,EAAYprB,EAAQ9E,KAAKQ,IAAIovB,EAAIjvB,QAAQP,OACzC+vB,EAAYrrB,EAAQ9E,KAAKQ,IAAIqvB,EAAIlvB,QAAQP,OAEzCgwB,EAAa/wB,OAAKqG,eAAekqB,EAAIvvB,OACrCgwB,EAAahxB,OAAKqG,eAAemqB,EAAIxvB,QAEpCiwB,EAAQC,EAAYC,GAAczB,EACrC,CAACqB,EAAW,GAAI,EAAGA,EAAW,IAC9B,CAACA,EAAW,GAAIA,EAAW,GAAI,IAC5BK,EAAYC,EAAYC,GAAU3B,EACrC,CAAC,EAAGqB,EAAW,GAAIA,EAAW,IAC9B,CAACA,EAAW,GAAI,EAAGA,EAAW,IAE5B9kB,EAAOwkB,EAAUC,EACjBpqB,EAASpD,SAAO,CAACytB,EAAUF,EAASC,GAAWJ,EAAIrwB,OAEnDqxB,EAAUhrB,EAAOxF,OACjBywB,EAAY/rB,EAAQ+rB,UAE1B,IAAK,IAAIC,EAAK,EAAGA,EAAKb,EAAUa,IAAM,CACpC,MAAMC,EAAcD,EAAKvB,EACnByB,EAAcF,EAAKtB,EACzB,IAAK,IAAIyB,EAAK,EAAGA,EAAKlB,EAASkB,GAAMJ,EAAW,CAE9C,MAAMK,EAAS/sB,KAAKoO,IAAI0e,EAAKJ,EAAWd,GACxC,IAAK,IAAIoB,EAAK,EAAGA,EAAKnB,EAAUmB,GAAMN,EAAW,CAC/C,MAAMO,EAASjtB,KAAKoO,IAAI4e,EAAKN,EAAWb,GACxC,IAAK,IAAIqB,EAAK,EAAGA,EAAKvB,EAAWuB,GAAMR,EAAW,CAChD,MAAMS,EAASntB,KAAKoO,IAAI8e,EAAKR,EAAWf,GAExC,IAAK,IAAI5rB,EAAI+sB,EAAI/sB,EAAIgtB,EAAQhtB,IAC3B,IAAK,IAAIgI,EAAIilB,EAAIjlB,EAAIklB,EAAQllB,IAAK,CAChC,IAAIqlB,EAAM,EAEV,IAAK,IAAI7hB,EAAI2hB,EAAI3hB,EAAI4hB,EAAQ5hB,IAAK,CAOhC6hB,GAJIrB,EAAUa,EAAcT,EAASpsB,EAAIqsB,EAAa7gB,EAAI8gB,GAGtDL,EAAUzgB,EAAI+gB,EAAavkB,EAAIwkB,EAAaM,EAAcL,GAGhEC,EAAQE,EAAKvlB,GAAQrH,EAAI8rB,EAAW9jB,KAAOqlB,MAYvD,OAJAzsB,EAAQ/B,8BAA8B6sB,GACtC9qB,EAAQ/B,8BAA8B8sB,GAG/B/qB,EAAQ/D,eACXiM,EAAUpH,EAAOrG,MAAOqG,EAAOxF,OACrC,CAEO,MAAMoxB,GAAkC,CAC7CltB,WAAYmtB,cACZjtB,YAAa,MACbC,WAAYqqB,IC1EP,MAAM4C,GAAmC,CAC9CptB,WAAYqtB,eACZntB,YAAa,MACbC,oBAzC2BC,GAK3B,MAAME,OAACA,EAAME,QAAEA,EAAOyD,MAAEA,GAAS7D,GAC3B0D,EAACA,EAACC,EAAEA,EAACupB,KAAEA,EAAItD,uBAAEA,GAA0B1pB,GACvCmqB,WAACA,EAAUC,WAAEA,EAAUX,WAAEA,EAAUE,eAAEA,GAAkBhmB,EAE7D,IAAIspB,EACAC,EACAC,EAEJ,MAAMC,EAA8B,GAIpCH,EADI/C,GAAY,CAAClqB,OAAQ,CAACwD,IAAGC,KAAIE,MAAO,CAACwmB,aAAYC,cAAalqB,YAG9D8sB,IACFE,EAAS/mB,EAAI,CAACnG,OAAQ,CAACwD,EAAGypB,EAASxpB,EAAGupB,GAAO9sB,YAC7CktB,EAAcviB,KAAKoiB,GACnBA,EAAUC,GAERzD,IACF0D,EAAgB3D,GACZtpB,EAAS+sB,EAASxD,EAAYC,EAAwBC,GAC1DyD,EAAcviB,KAAKoiB,GACnBA,EAAUE,GAGZ,IAAK,MAAM7tB,KAAK8tB,EACdltB,EAAQ/B,8BAA8BmB,GAGxC,OAAO2tB,CACT,GCxCaI,GAAO3lB,EAAgB4lB,QAAOvlB,GAAOxI,KAAK8tB,KAAKtlB,KAE/CwlB,GAA2B,CACtC7tB,WAAY4tB,OACZ1tB,YAAa,MACbC,WAAYwtB,ICLDG,GAAQ9lB,EAAgB+lB,SAAQ1lB,GAAOxI,KAAKiuB,MAAMzlB,KAElD2lB,GAA4B,CACvChuB,WAAY+tB,QACZ7tB,YAAa,MACbC,WAAY2tB,ICiBP,MAAMG,GAA2B,CACtCjuB,WAAYkuB,OACZhuB,YAAa,MACbC,oBAxBmBC,GAEnB,MAAME,OAACA,EAAME,QAAEA,GAAWJ,EACpB+tB,EAAU7tB,EAEhB9F,EAAiB8F,EAAQ,QAEzB,MAAMb,EACF0uB,EAAQrxB,KAAIhC,GAAK0F,EAAQ9E,KAAKQ,IAAIpB,EAAEuB,QAAQP,SAC1C6L,EAASzJ,SAAOiwB,EAAQ,GAAGpyB,MAAOoyB,EAAQ,GAAGlzB,OAC7CkM,EAAUQ,EAAO7L,OACvB,IAAK,IAAI8D,EAAI,EAAGA,EAAIuuB,EAAQxxB,OAAQiD,IAAK,CACvC,MAAMwuB,EAAW3uB,EAAKG,GACtB,IAAK,IAAIgI,EAAI,EAAGA,EAAIT,EAAQxK,OAAQiL,IAClCT,EAAQS,IAAMwmB,EAASxmB,GAI3B,OAAOpH,EAAQ/D,eAAekL,EAAO5L,MAAO4L,EAAO1M,MAAO0M,EAAO7L,OACnE,GCqCO,MAAMuyB,GAA0B,CACrCruB,WAAYsuB,MACZpuB,YAAa,MACbC,oBAxDEC,GAEF,MAAME,OAACA,EAAME,QAAEA,EAAOyD,MAAEA,GAAS7D,GAC3BC,EAACA,GAAKC,GACNmQ,KAACA,EAAIC,SAAEA,GAAYzM,EAEzBzJ,EAAiB6F,EAAG,OAEpB,MAAMkuB,EAAWxzB,OAAK6V,eAAeH,EAAMpQ,EAAEtE,OAC7C,IAAI4U,EAAO4d,EACX,MAAMC,EAAeryB,eAAa2U,mBAAmBH,EAAMtQ,EAAEtE,MAAMY,QACnE,IAAI8xB,EAAKpuB,EACW,MAAhBmuB,IACFC,EAAK5e,GAAU,CAACvP,OAAQ,CAACD,KAAIG,UAASyD,MAAO,CAACsL,KAAMif,KACpD7d,EAAOxU,eAAa8U,iBAAiBN,EAAKhU,OAAQ0D,EAAEtE,MAAMY,SAG5DR,eAAauyB,2BAA2B,MAAO/d,EAAM8d,EAAG1yB,MAAMY,QAC9D,MAAO+L,EAAUwH,GACb/T,eAAagU,0BAA0Bse,EAAG1yB,MAAO4U,GAC/CrD,EAAavS,OAAK0F,cAAcyP,GAChCzQ,EAAO1E,OAAK+H,oBAAoB/H,OAAK0F,cAAciI,GAAW+lB,EAAGxzB,OAEjE6F,EAAQN,EAAQ9E,KAAKQ,IAAIuyB,EAAGpyB,QAAQP,OAC1C,IAAK,IAAI8D,EAAI,EAAGA,EAAIH,EAAK9C,SAAUiD,EAAG,CACpC,MAAMgJ,EAAShJ,EAAI0N,EACnB,IAAIqhB,EAAM7tB,EAAM8H,GAChB,IAAK,IAAIhB,EAAI,EAAGA,EAAI0F,IAAc1F,EAAG,CACnC,MAAMR,EAAQtG,EAAM8H,EAAShB,GAC7B+mB,EAAMA,GAAOvnB,EAEf3H,EAAKG,GAAK+uB,EAGQ,MAAhBH,GACFhuB,EAAQ/B,8BAA8BgwB,GAGxC,MAAMntB,EAASd,EAAQ/D,eAAeiM,EAAU+lB,EAAGxzB,MAAOwE,GAE1D,GAAIiR,EAAU,CACZ,MACMke,EACF1U,GAAQ,CAAC5Z,OAAQ,CAACD,EAAGiB,GAASd,UAASyD,MAAO,CAAClI,MAF7BI,eAAa+U,qBAAqBxI,EAAU6lB,MAMlE,OAFA/tB,EAAQ/B,8BAA8B6C,GAE/BstB,EAGT,OAAOttB,CACT,GCEO,MAAMutB,GAA0B,CACrC7uB,WAAY8uB,MACZ5uB,YAAa,MACbC,oBAxDEC,GAEF,MAAME,OAACA,EAAME,QAAEA,EAAOyD,MAAEA,GAAS7D,GAC3BC,EAACA,GAAKC,GACNmQ,KAACA,EAAIC,SAAEA,GAAYzM,EAEzBzJ,EAAiB6F,EAAG,OAEpB,MAAMkuB,EAAWxzB,OAAK6V,eAAeH,EAAMpQ,EAAEtE,OAC7C,IAAI4U,EAAO4d,EACX,MAAMC,EAAeryB,eAAa2U,mBAAmBH,EAAMtQ,EAAEtE,MAAMY,QACnE,IAAI8xB,EAAKpuB,EACW,MAAhBmuB,IACFC,EAAK5e,GAAU,CAACvP,OAAQ,CAACD,KAAIG,UAASyD,MAAO,CAACsL,KAAMif,KACpD7d,EAAOxU,eAAa8U,iBAAiBN,EAAKhU,OAAQ0D,EAAEtE,MAAMY,SAG5DR,eAAauyB,2BAA2B,MAAO/d,EAAM8d,EAAG1yB,MAAMY,QAC9D,MAAO+L,EAAUwH,GACb/T,eAAagU,0BAA0Bse,EAAG1yB,MAAO4U,GAC/CrD,EAAavS,OAAK0F,cAAcyP,GAChCzQ,EAAO1E,OAAK+H,oBAAoB/H,OAAK0F,cAAciI,GAAW+lB,EAAGxzB,OAEjE6F,EAAQN,EAAQ9E,KAAKQ,IAAIuyB,EAAGpyB,QAAQP,OAC1C,IAAK,IAAI8D,EAAI,EAAGA,EAAIH,EAAK9C,SAAUiD,EAAG,CACpC,MAAMgJ,EAAShJ,EAAI0N,EACnB,IAAIyhB,EAASjuB,EAAM8H,GACnB,IAAK,IAAIhB,EAAI,EAAGA,EAAI0F,IAAc1F,EAAG,CACnC,MAAMR,EAAQtG,EAAM8H,EAAShB,GAC7BmnB,EAASA,GAAU3nB,EAErB3H,EAAKG,GAAKmvB,EAGQ,MAAhBP,GACFhuB,EAAQ/B,8BAA8BgwB,GAGxC,MAAMntB,EAASd,EAAQ/D,eAAeiM,EAAU+lB,EAAGxzB,MAAOwE,GAE1D,GAAIiR,EAAU,CACZ,MACMke,EACF1U,GAAQ,CAAC5Z,OAAQ,CAACD,EAAGiB,GAASd,UAASyD,MAAO,CAAClI,MAF7BI,eAAa+U,qBAAqBxI,EAAU6lB,MAMlE,OAFA/tB,EAAQ/B,8BAA8B6C,GAE/BstB,EAGT,OAAOttB,CACT,GCJO,MAAM0tB,GAA6B,CACxChvB,WAAYivB,SACZ/uB,YAAa,MACbC,oBAnDEC,GAEF,MAAME,OAACA,EAAME,QAAEA,EAAOyD,MAAEA,GAAS7D,GAC3BC,EAACA,GAAKC,GACNmQ,KAACA,GAAQxM,EAEfzJ,EAAiB6F,EAAG,UAEpB,IAAIsQ,EAAO5V,OAAK6V,eAAeH,EAAMpQ,EAAEtE,OACvC,MAAMyyB,EAAeryB,eAAa2U,mBAAmBH,EAAMtQ,EAAEtE,MAAMY,QACnE,IAAI8xB,EAAKpuB,EACT,MAAM2Q,EAA0B,GACZ,MAAhBwd,IACFC,EAAK5e,GAAU,CAACvP,OAAQ,CAACD,KAAIG,UAASyD,MAAO,CAACsL,KAAMif,KACpDxd,EAAwB7F,KAAKsjB,GAC7B9d,EAAOxU,eAAa8U,iBAAiBN,EAAKhU,OAAQ8xB,EAAG1yB,MAAMY,SAG7DgU,EAAO,CAACA,EAAK,IACbxU,eAAauyB,2BAA2B,SAAU/d,EAAM8d,EAAG1yB,MAAMY,QACjE,MAAO+L,EAAUwH,GACb/T,eAAagU,0BAA0Bse,EAAG1yB,MAAO4U,GAE/Cue,EAAUn0B,OAAK0F,cAAciI,GAC7BjJ,EAAO1E,OAAK+H,oBAAoBosB,EAAS,SACzC5hB,EAAavS,OAAK0F,cAAcyP,GAEhCpP,EAAQN,EAAQ9E,KAAKQ,IAAIuyB,EAAGpyB,QAAQP,OAC1C,IAAK,IAAI8D,EAAI,EAAGA,EAAIH,EAAK9C,SAAUiD,EAAG,CACpC,MAAMgJ,EAAShJ,EAAI0N,EACnB,IAAIC,EAAMzM,EAAM8H,GACZumB,EAAW,EACf,IAAK,IAAIvnB,EAAI,EAAGA,EAAI0F,IAAc1F,EAAG,CACnC,MAAMR,EAAQtG,EAAM8H,EAAShB,GACzBR,EAAQmG,IACVA,EAAMnG,EACN+nB,EAAWvnB,GAGfnI,EAAKG,GAAKuvB,EAMZ,OAHAne,EAAwBnW,SACpBC,GAAK0F,EAAQ/B,8BAA8B3D,KAExC0F,EAAQ/D,eAAeiM,EAAU,QAASjJ,EACnD,GCEO,MAAM2vB,GAA6B,CACxCpvB,WAAYqvB,SACZnvB,YAAa,MACbC,oBAnDEC,GAEF,MAAME,OAACA,EAAME,QAAEA,EAAOyD,MAAEA,GAAS7D,GAC3BC,EAACA,GAAKC,GACNmQ,KAACA,GAAQxM,EAEfzJ,EAAiB6F,EAAG,UAEpB,IAAIsQ,EAAO5V,OAAK6V,eAAeH,EAAMpQ,EAAEtE,OACvC,MAAMyyB,EAAeryB,eAAa2U,mBAAmBH,EAAMtQ,EAAEtE,MAAMY,QACnE,IAAI8xB,EAAKpuB,EACT,MAAM2Q,EAA0B,GACZ,MAAhBwd,IACFC,EAAK5e,GAAU,CAACvP,OAAQ,CAACD,KAAIG,UAASyD,MAAO,CAACsL,KAAMif,KACpDxd,EAAwB7F,KAAKsjB,GAC7B9d,EAAOxU,eAAa8U,iBAAiBN,EAAKhU,OAAQ8xB,EAAG1yB,MAAMY,SAG7DgU,EAAO,CAACA,EAAK,IACbxU,eAAauyB,2BAA2B,SAAU/d,EAAM8d,EAAG1yB,MAAMY,QACjE,MAAO+L,EAAUwH,GACb/T,eAAagU,0BAA0Bse,EAAG1yB,MAAO4U,GAE/Cue,EAAUn0B,OAAK0F,cAAciI,GAC7BjJ,EAAO1E,OAAK+H,oBAAoBosB,EAAS,SACzC5hB,EAAavS,OAAK0F,cAAcyP,GAEhCpP,EAAQN,EAAQ9E,KAAKQ,IAAIuyB,EAAGpyB,QAAQP,OAC1C,IAAK,IAAI8D,EAAI,EAAGA,EAAIH,EAAK9C,SAAUiD,EAAG,CACpC,MAAMgJ,EAAShJ,EAAI0N,EACnB,IAAIW,EAAMnN,EAAM8H,GACZ0mB,EAAW,EACf,IAAK,IAAI1nB,EAAI,EAAGA,EAAI0F,IAAc1F,EAAG,CACnC,MAAMR,EAAQtG,EAAM8H,EAAShB,GACzBR,EAAQ6G,IACVA,EAAM7G,EACNkoB,EAAW1nB,GAGfnI,EAAKG,GAAK0vB,EAMZ,OAHAte,EAAwBnW,SACpBC,GAAK0F,EAAQ/B,8BAA8B3D,KAExC0F,EAAQ/D,eAAeiM,EAAU,QAASjJ,EACnD,GCjDa8vB,GAAOvnB,EAAgBwnB,QAAOnnB,GAAOxI,KAAK0vB,KAAKlnB,KAE/ConB,GAA2B,CACtCzvB,WAAYwvB,OACZtvB,YAAa,MACbC,WAAYovB,ICLDG,GAAQ1nB,EAAgB2nB,SAAQtnB,GAAOxI,KAAK6vB,MAAMrnB,KAElDunB,GAA4B,CACvC5vB,WAAY2vB,QACZzvB,YAAa,MACbC,WAAYuvB,ICLDG,GAAO7nB,EAAgB8nB,QAAOznB,GAAOxI,KAAKgwB,KAAKxnB,KAE/C0nB,GAA2B,CACtC/vB,WAAY8vB,OACZ5vB,YAAa,MACbC,WAAY0vB,ICLDG,GAAYtvB,GACrB,CAACiN,EAAQC,IAAW/N,KAAKowB,MAAMtiB,EAAkBC,KAExCqiB,GAAQxrB,EAAiByrB,QAAOF,IAEhCG,GAA4B,CACvCnwB,WAAYkwB,QACZhwB,YAAa,MACbC,WAAY8vB,ICRDG,GAAQpoB,EAAgBqoB,SAAQhoB,GAAOxI,KAAKuwB,MAAM/nB,KAElDioB,GAA4B,CACvCtwB,WAAYqwB,QACZnwB,YAAa,MACbC,WAAYiwB,aCPEG,GACZC,EAAqB7hB,EAAkB1T,EAAiB4P,EACxD4lB,EACAC,GACF,MAAMC,EAAeF,EAASE,aACxBC,EAAcH,EAASG,YACvBC,EAAiBJ,EAASI,eAC1BC,EAAgBL,EAASK,cACzBC,EAAwBN,EAASM,sBACjCC,EAAuBP,EAASO,qBAChCC,EAASR,EAASS,QAAQC,IAC1BC,EAAUX,EAASS,QAAQxK,KAE3B2K,EACY,QAAbX,EAAqBljB,OAAO8jB,kBACP9jB,OAAO+jB,kBAE3B5Q,EAASziB,SAAOuyB,EAAS/nB,SAAUzN,GACnCu2B,EAAa7Q,EAAO7kB,OAEpB21B,EACFhB,EAAS/nB,SAAS,GAAK+nB,EAAS/nB,SAAS,GAAK+nB,EAAS/nB,SAAS,GAC9DgpB,EAAmBjB,EAAS/nB,SAAS,GAAK+nB,EAAS/nB,SAAS,GAC5DipB,EAAmBlB,EAAS/nB,SAAS,GAE3C,IAAK,IAAI3E,EAAI,EAAGA,EAAI0sB,EAASrL,YAAarhB,EAAG,CAC3C,MAAM6tB,EAAoB7tB,EAAI0tB,EACxBI,EAAmB9tB,EAAI8G,EAAQ,GACrC,IAAK,IAAI9N,EAAI,EAAGA,EAAI0zB,EAASqB,aAAc/0B,EACzC,IAAK,IAAIg1B,EAAK,EAAGA,EAAKtB,EAASuB,YAAaD,EAAI,CAC9C,MAAME,EAAWF,EAAKpB,EAAeM,EAC/BiB,EAAQryB,KAAK0N,IAAI,EAAG0kB,GACpBE,EACFtyB,KAAKoO,IAAIwiB,EAAS2B,SAAUrB,EAAwBkB,GAClDI,EAAkBT,EAAoBG,EAAKL,EACjD,IAAK,IAAIY,EAAK,EAAGA,EAAK7B,EAAS8B,WAAYD,EAAI,CAC7C,MAAME,EAAWF,EAAK1B,EAAcQ,EAC9BqB,EAAQ5yB,KAAK0N,IAAI,EAAGilB,GACpBE,EACF7yB,KAAKoO,IAAIwiB,EAASkC,QAAS3B,EAAuBwB,GACtD,IAAII,EAAcvB,EACdwB,EAAW,EACXC,EAAQ,EACZ,IAAK,IAAIC,EAAKb,EAAOa,EAAKZ,EAAOY,GAAMlC,EAAgB,CACrD,MAAMmC,EAAWnB,EAAmBkB,EAAKloB,EAAQ,GACjD,IAAK,IAAIooB,EAAKR,EAAOQ,EAAKP,EAAOO,GAAMnC,EAAe,CACpD,MACMoC,EAAQ1C,EADGwC,EAAWC,EAAKpoB,EAAQ,GACR9N,GACf,QAAb2zB,GAAsBwC,EAAQN,EACjCA,EAAcM,EACQ,QAAbxC,IACTmC,GAAYK,EACZJ,KAGJ,GAAIrlB,MAAMmlB,GACR,MAIJpB,EADqBa,EAAkBC,EAAKX,EAAmB50B,GAE9C,QAAb2zB,EAAqBmC,EAAWC,EAAQF,IAKpD,OAAOjS,CACT,UAEgBwS,GACZ3C,EAAqB7hB,EAAkB1T,EACvCw1B,EAAmC2C,GAAmB,EACtDC,GAAsB,GACxB,MAAMC,EAAep1B,SAAOuyB,EAAS/nB,SAAU,SACzCioB,EAAeF,EAASE,aACxBC,EAAcH,EAASG,YACvBC,EAAiBJ,EAASI,eAC1BC,EAAgBL,EAASK,cACzBC,EAAwBN,EAASM,sBACjCC,EAAuBP,EAASO,qBAChCC,EAASR,EAASS,QAAQC,IAC1BC,EAAUX,EAASS,QAAQxK,KAE3Bpf,EAAOpJ,SAAOyQ,EAAQ1T,EAAOu1B,GACnC,IAAK,IAAIzsB,EAAI,EAAGA,EAAI0sB,EAASrL,YAAarhB,EACxC,IAAK,IAAIhH,EAAI,EAAGA,EAAI0zB,EAASqB,aAAc/0B,EACzC,IAAK,IAAIg1B,EAAK,EAAGA,EAAKtB,EAASuB,YAAaD,EAAI,CAC9C,MAAME,EAAWF,EAAKpB,EAAeM,EACrC,IAAIiB,EAAQD,EACZ,KAAOC,EAAQ,GACbA,GAASrB,EAGX,MAAMsB,EACFtyB,KAAKoO,IAAIwiB,EAAS2B,SAAUrB,EAAwBkB,GACxD,IAAK,IAAIK,EAAK,EAAGA,EAAK7B,EAAS8B,WAAYD,EAAI,CAC7C,MAAME,EAAWF,EAAK1B,EAAcQ,EACpC,IAAIqB,EAAQD,EACZ,KAAOC,EAAQ,GACbA,GAAS3B,EAEX,MAAM4B,EACF7yB,KAAKoO,IAAIwiB,EAASkC,QAAS3B,EAAuBwB,GACtD,IAAIe,EAAW/lB,OAAO8jB,kBAClBkC,GAAe,EAEnB,IAAK,IAAIT,EAAKb,EAAOa,EAAKZ,EAAOY,GAAMlC,EAAgB,CACrD,MAAM4C,EAAKV,EAAKd,EAChB,IAAK,IAAIgB,EAAKR,EAAOQ,EAAKP,EAAOO,GAAMnC,EAAe,CACpD,MAAM4C,EAAKT,EAAKT,EAIVU,EAAQ5rB,EAAKpL,IAAI6H,EAAGgvB,EAAIE,EAAIl2B,GAC9Bm2B,EAAQK,IACVA,EAAWL,EAETM,EADEJ,EACYC,IACRtvB,EAAI0sB,EAAS2B,SAAWW,GAAMtC,EAASkC,QAAUM,GAC3CxC,EAASqB,WACb/0B,GACHg2B,EAAKtC,EAASkC,QAAUM,GAAMxC,EAASqB,WAAa/0B,EAE3C02B,EAAKzC,EAAuB0C,IAKlDJ,EAAa/2B,IAAIi3B,EAAazvB,EAAGguB,EAAIO,EAAIv1B,IAKjD,OAAOu2B,CACT,UAEgBK,GACZnD,EAAqB7hB,EAAkB1T,EAAiB4P,EACxD4lB,EACAC,GACF,MAAMkD,EAAcnD,EAASmD,YACvBjD,EAAeF,EAASE,aACxBC,EAAcH,EAASG,YACvBiD,EAAgBpD,EAASoD,cACzBhD,EAAiBJ,EAASI,eAC1BC,EAAgBL,EAASK,cACzBgD,EAAuBrD,EAASqD,qBAChC/C,EAAwBN,EAASM,sBACjCC,EAAuBP,EAASO,qBAChC+C,EAAWtD,EAASS,QAAQ8C,MAC5B/C,EAASR,EAASS,QAAQC,IAC1BC,EAAUX,EAASS,QAAQxK,KAE3B2K,EACY,QAAbX,EAAqBljB,OAAO8jB,kBACP9jB,OAAO+jB,kBAE3B5Q,EAASziB,SAAOuyB,EAAS/nB,SAAUzN,GACnCu2B,EAAa7Q,EAAO7kB,OAEpB21B,EAAqBhB,EAAS/nB,SAAS,GAAK+nB,EAAS/nB,SAAS,GAChE+nB,EAAS/nB,SAAS,GAAK+nB,EAAS/nB,SAAS,GACvCurB,EACFxD,EAAS/nB,SAAS,GAAK+nB,EAAS/nB,SAAS,GAAK+nB,EAAS/nB,SAAS,GAC9DgpB,EAAmBjB,EAAS/nB,SAAS,GAAK+nB,EAAS/nB,SAAS,GAC5DipB,EAAmBlB,EAAS/nB,SAAS,GAE3C,IAAK,IAAI0e,EAAQ,EAAGA,EAAQqJ,EAASrL,YAAagC,EAAO,CACvD,MAAMwK,EAAoBxK,EAAQqK,EAC5BI,EAAmBzK,EAAQvc,EAAQ,GACzC,IAAK,IAAIqpB,EAAU,EAAGA,EAAUzD,EAASqB,aAAcoC,EACrD,IAAK,IAAIC,EAAS,EAAGA,EAAS1D,EAAS2D,WAAYD,EAAQ,CACzD,MAAME,EAAeF,EAASP,EAAcG,EAC5C,IAAIO,EAAYD,EAChB,KAAOC,EAAY,GACjBA,GAAaT,EAEf,MAAMU,EACF10B,KAAKoO,IAAIwiB,EAAS+D,QAASV,EAAuBO,GAChDI,EACF7C,EAAoBuC,EAASF,EACjC,IAAK,IAAIS,EAAO,EAAGA,EAAOjE,EAASuB,YAAa0C,EAAM,CACpD,MAAMC,EAAaD,EAAO/D,EAAeM,EACzC,IAAI2D,EAAUD,EACd,KAAOC,EAAU,GACfA,GAAW/D,EAEb,MAAMgE,EACFh1B,KAAKoO,IAAIwiB,EAAS2B,SAAUrB,EAAwB4D,GAClDtC,EAAkBoC,EAAoBC,EAAOhD,EACnD,IAAK,IAAIoD,EAAO,EAAGA,EAAOrE,EAAS8B,WAAYuC,EAAM,CACnD,MAAMC,EAAaD,EAAOlE,EAAcQ,EACxC,IAAI4D,EAAUD,EACd,KAAOC,EAAU,GACfA,GAAWlE,EAEb,MAAMmE,EACFp1B,KAAKoO,IAAIwiB,EAASkC,QAAS3B,EAAuB+D,GAEhDG,EAAkB7C,EAAkByC,EAAOnD,EACjD,IAAIiB,EAAcvB,EACdwB,EAAW,EACXC,EAAQ,EACZ,IAAK,IAAIqC,EAASb,EAAWa,EAASZ,EACjCY,GAAUtB,EAAe,CAC5B,MAAMuB,EAAevD,EAAmBsD,EAAStqB,EAAQ,GACzD,IAAK,IAAIwqB,EAAOT,EAASS,EAAOR,EAASQ,GAAQxE,EAAgB,CAC/D,MAAMyE,EAAaF,EAAeC,EAAOxqB,EAAQ,GACjD,IAAK,IAAI0qB,EAAOP,EAASO,EAAON,EAC3BM,GAAQzE,EAAe,CAC1B,MACMoC,EAAQ1C,EADK8E,EAAaC,EAAO1qB,EAAQ,GACZqpB,GAOnC,GANkB,QAAbxD,GAAsBwC,EAAQN,EACjCA,EAAcM,EACQ,QAAbxC,IACTmC,GAAYK,EACZJ,KAEErlB,MAAMmlB,GACR,MAGJ,GAAInlB,MAAMmlB,GACR,MAGJ,GAAInlB,MAAMmlB,GACR,MAIJpB,EADqB0D,EAAkBhB,GACC,QAAbxD,EACvBmC,EAAWhzB,KAAK0N,IAAIulB,EAAO,GAC3BF,KAOd,OAAOjS,CACT,CC5MO,MAAM6U,GAA8B,CACzCx1B,WAAYy1B,UACZv1B,YAAa,MACbC,oBAnCEC,GAGF,MAAME,OAACA,EAAME,QAAEA,EAAOyD,MAAEA,GAAS7D,GAC3BC,EAACA,GAAKC,EACZ9F,EAAiB6F,EAAG,WACpB,MAAMq1B,WAACA,EAAU7qB,QAAEA,EAAO8qB,IAAEA,EAAGC,gBAAEA,GAAmB3xB,EAGpDlJ,OAAKC,OACDmB,eAAa05B,+BAA+BhrB,EAH9B,IAId,IACI,wEAAeA,wBAEvB,MAAM4lB,EAAWt0B,eAAa25B,kBAC1Bz1B,EAAEtE,MAA2C25B,EAAY7qB,EAR3C,EASH8qB,EAAKC,GACpB,IAAI3mB,EAEJ,GAA6B,IAAzBwhB,EAASsF,aAA+C,IAA1BtF,EAASuF,cACvCj7B,OAAKk7B,YAAYxF,EAASyF,QAASzF,EAAS/nB,UAC9CuG,EAAMlM,EAAS,CAACzC,OAAQ,CAACD,KAAIG,gBACxB,CACL,MAAMgwB,EAAUhwB,EAAQ9E,KAAKQ,IAAImE,EAAEhE,QAAQP,OACrC+O,EAAU9P,OAAKqG,eAAef,EAAEtE,OAChCmC,EAASqyB,GAAKC,EAASnwB,EAAEtE,MAAOsE,EAAEpF,MAAO4P,EAAS4lB,EAAU,OAClExhB,EAAMzO,EAAQ/D,eACVg0B,EAAS/nB,SAAUrI,EAAEpF,MAAOiD,EAAOpC,QAEzC,OAAOmT,CACT,GCTO,MAAMknB,GAAgC,CAC3Cn2B,WAAYo2B,YACZl2B,YAAa,MACbC,oBAzBwBC,GAKxB,MAAME,OAACA,EAAME,QAAEA,EAAOyD,MAAEA,GAAS7D,GAC3BC,EAACA,GAAKC,GACNo1B,WAACA,EAAU7qB,QAAEA,EAAO8qB,IAAEA,EAAGC,gBAAEA,EAAeS,WAAEA,GAAcpyB,EAEhEzJ,EAAiB6F,EAAG,aAEpB,MAAMowB,EAAWt0B,eAAam6B,kBAC1Bj2B,EAAEtE,MAAmD25B,EAAY7qB,EACjE,EAAmB8qB,EAAKC,EAAiBS,GAGvC1uB,EAASgsB,GADCnzB,EAAQ9E,KAAKQ,IAAImE,EAAEhE,QAAQP,OAE9BuE,EAAEtE,MAAOsE,EAAEpF,MAAOF,OAAKqG,eAAef,EAAEtE,OAAQ00B,EAAU,OAEvE,OAAOjwB,EAAQ/D,eAAekL,EAAO5L,MAAO,UAAW4L,EAAO7L,OAChE,GCgEO,MAAMy6B,GAAoC,CAC/Cv2B,WAAYw2B,gBACZt2B,YAAa,MACbC,oBAxF4BC,GAK5B,MAAME,OAACA,EAAME,QAAEA,EAAOyD,MAAEA,GAAS7D,GAC3Bq2B,GAACA,EAAEvzB,MAAEA,GAAS5C,GACdo1B,WAACA,EAAU7qB,QAAEA,EAAO8qB,IAAEA,EAAGC,gBAAEA,GAAmB3xB,EAEpDzJ,EAAiB,CAACi8B,EAAIvzB,GAAQ,iBAE9B,MAAMutB,EAAWt0B,eAAam6B,kBAC1BpzB,EAAMnH,MAAmD25B,EACzD7qB,EAAS,EAAmB8qB,EAAKC,GAE/BhC,EAAcnD,EAASmD,YACvBjD,EAAeF,EAASE,aACxBC,EAAcH,EAASG,YACvB8F,EAAcjG,EAASiG,YACvBV,EAAevF,EAASuF,aACxBD,EAActF,EAASsF,YACvBlC,EAAgBpD,EAASoD,cACzBhD,EAAiBJ,EAASI,eAC1BC,EAAgBL,EAASK,cACzBgD,EAAuBrD,EAASqD,qBAChC/C,EAAwBN,EAASM,sBACjCC,EAAuBP,EAASO,qBAChC+C,EAAWD,EAAuB,EAAIrD,EAASS,QAAQ8C,MACvD5C,EAAUJ,EAAuB,EAAIP,EAASS,QAAQxK,KACtDuK,EAASF,EAAwB,EAAIN,EAASS,QAAQC,IACtDwF,EAAKz4B,SAAOgF,EAAMnH,MAAO,WAEzB66B,EAAgB,GAAKF,EAAcV,EAAeD,GAElDc,EAAQr2B,EAAQzC,WAA4B04B,GAElD,IAAK,IAAIrP,EAAQ,EAAGA,EAAQqJ,EAASrL,YAAagC,EAChD,IAAK,IAAI8M,EAAU,EAAGA,EAAUzD,EAASqB,aAAcoC,EACrD,IAAK,IAAI4C,EAAU,EAAGA,EAAUrG,EAAS+D,UAAWsC,EAClD,IAAK,IAAIC,EAAQ,EAAGA,EAAQtG,EAAS2B,WAAY2E,EAC/C,IAAK,IAAIC,EAAQ,EAAGA,EAAQvG,EAASkC,UAAWqE,EAAO,CAErD,MAAMC,EAAgBH,EAAU/C,EAC1BmD,EAAcH,EAAQ9F,EACtBkG,EAAcH,EAAQ5F,EAC5B,IAAIgG,EAAU,EACd,IAAK,IAAIC,EAAS,EAAGA,EAASvD,EACzBuD,GAAUxD,EAAe,CAC5B,MAAMyD,GAAWL,EAAgBI,GAAUzD,EAC3C,KAAI0D,EAAU,GAAKA,GAAW7G,EAAS2D,UACnCv0B,KAAKmK,MAAMstB,KAAaA,GAG5B,IAAK,IAAIC,EAAO,EAAGA,EAAOxG,EACrBwG,GAAQ1G,EAAgB,CAC3B,MAAM2G,GAASN,EAAcK,GAAQ5G,EACrC,KAAI6G,EAAQ,GAAKA,GAAS/G,EAASuB,WAC/BnyB,KAAKmK,MAAMwtB,KAAWA,GAG1B,IAAK,IAAIC,EAAO,EAAGA,EAAOzG,EACrByG,GAAQ3G,EAAe,CAC1B,MAAM4G,GAASP,EAAcM,GAAQ7G,EACrC,GAAI8G,EAAQ,GAAKA,GAASjH,EAAS8B,UAC/B1yB,KAAKmK,MAAM0tB,KAAWA,EACxB,SAKFN,GADIP,EAAM36B,IAAIkrB,EAAOkQ,EAASE,EAAOE,EAAOxD,KAKlDyC,EAAGp6B,IACC66B,EAAUR,EAAexP,EAAO0P,EAASC,EAAOC,EAAO9C,GAOrE,OAAO1zB,EAAQ/D,eAAek6B,EAAG56B,MAAO46B,EAAG17B,MAAO07B,EAAG76B,OACvD,GClBO,MAAM67B,GAAkC,CAC7C33B,WAAY43B,cACZ13B,YAAa,MACbC,oBArE0BC,GAK1B,MAAME,OAACA,EAAME,QAAEA,EAAOyD,MAAEA,GAAS7D,GAC3Bq2B,GAACA,EAAEvzB,MAAEA,GAAS5C,EACdD,EAAI6C,EACV1I,EAAiB,CAACi8B,EAAIvzB,GAAQ,eAC9B,MAAMwyB,WAACA,EAAU7qB,QAAEA,EAAO8qB,IAAEA,GAAO1xB,EAE7BwsB,EAAWt0B,eAAa25B,kBAC1Bz1B,EAAEtE,MAA2C25B,EAAY7qB,EACzD,EAAmB8qB,GACjBhF,EAAeF,EAASE,aACxBC,EAAcH,EAASG,YACvBoF,EAAevF,EAASuF,aACxBD,EAActF,EAASsF,YACvBlF,EAAiBJ,EAASI,eAC1BC,EAAgBL,EAASK,cACzBC,EAAwBN,EAASM,sBACjCC,EAAuBP,EAASO,qBAChCI,EAAUJ,EAAuB,EAAIP,EAASS,QAAQxK,KACtDuK,EAASF,EAAwB,EAAIN,EAASS,QAAQC,IACtDwF,EACFz4B,SAAgBmC,EAAEtE,MAA2C,WAE3D66B,EAAgB,GAAKZ,EAAeD,GAEpC8B,EAASr3B,EAAQ9E,KAAKQ,IAAIu6B,EAAGp6B,QAAQP,OACrC+6B,EAAQ34B,SACVu4B,EAAG16B,MAA2C,UAAW87B,GAE7D,IAAK,IAAI9zB,EAAI,EAAGA,EAAI0sB,EAASrL,YAAarhB,EACxC,IAAK,IAAIhH,EAAI,EAAGA,EAAI0zB,EAASqB,aAAc/0B,EACzC,IAAK,IAAI+6B,EAAM,EAAGA,EAAMrH,EAAS2B,WAAY0F,EAC3C,IAAK,IAAIC,EAAM,EAAGA,EAAMtH,EAASkC,UAAWoF,EAAK,CAE/C,MAAMC,EAAYF,EAAM7G,EAClBgH,EAAYF,EAAM3G,EACxB,IAAIgG,EAAU,EACd,IAAK,IAAI3D,EAAK,EAAGA,EAAK1C,EAAuB0C,GAAM5C,EAAgB,CACjE,MAAMqH,GAAOF,EAAYvE,GAAM9C,EAC/B,KAAIuH,EAAM,GAAKA,GAAOzH,EAASuB,WAC3BnyB,KAAKmK,MAAMkuB,KAASA,GAGxB,IAAK,IAAIxE,EAAK,EAAGA,EAAK1C,EAAsB0C,GAAM5C,EAAe,CAC/D,MAAMqH,GAAOF,EAAYvE,GAAM9C,EAC/B,GAAIuH,EAAM,GAAKA,GAAO1H,EAAS8B,UAC3B1yB,KAAKmK,MAAMmuB,KAASA,EACtB,SAIFf,GADcP,EAAM36B,IAAI6H,EAAGm0B,EAAKC,EAAKp7B,IAIzC45B,EAAGp6B,IAAI66B,EAAUR,EAAe7yB,EAAG+zB,EAAKC,EAAKh7B,GAKrD,OAAOyD,EAAQ/D,eAAek6B,EAAG56B,MAAO46B,EAAG17B,MAAO07B,EAAG76B,OACvD,GCIO,MAAMs8B,GAAgC,CAC3Cp4B,WAAYq4B,iBACZn4B,YAAa,MACbC,oBAtEwBC,GAKxB,MAAME,OAACA,EAAME,QAAEA,EAAOyD,MAAEA,GAAS7D,GAC3BC,EAACA,EAACi4B,MAAEA,EAAK1vB,OAAEA,EAAM2vB,KAAEA,EAAIC,SAAEA,GAAYl4B,EAE3CvF,OAAKC,OACDu9B,EAAKx8B,MAAMY,SAAW67B,EAASz8B,MAAMY,QACrC,IAAM,iFAEV5B,OAAKC,OACS,MAAV4N,GAAkB2vB,EAAKx8B,MAAMY,SAAWiM,EAAO7M,MAAMY,QACrD,IAAM,+EAEV5B,OAAKC,OACQ,MAATs9B,GAAiBC,EAAKx8B,MAAMY,SAAW27B,EAAMv8B,MAAMY,QACnD,IAAM,8EAGVnC,EAAiB,CAAC6F,EAAGk4B,EAAMC,EAAUF,EAAO1vB,GAAS,aAErD,IAAI6vB,gBAACA,GAAmBx0B,EACD,MAAnBw0B,IACFA,EAAkB,MAGpB,MAAM5xB,EAAQrG,EAAQ9E,KAAKQ,IAAImE,EAAEhE,QAAQP,OACnC48B,EAAQl4B,EAAQ9E,KAAKQ,IAAIq8B,EAAKl8B,QAAQP,OACtC68B,EAAUn4B,EAAQ9E,KAAKQ,IAAIs8B,EAASn8B,QAAQP,OAC5C88B,EAAQN,EAAQ93B,EAAQ9E,KAAKQ,IAAIo8B,EAAMj8B,QAAQP,OAC/B,IAAI6D,aAAa,CAAC,IAClCk5B,EAAUjwB,EACZpI,EAAQ9E,KAAKQ,IAAI0M,EAAOvM,QAAQP,OAChC,IAAI6D,aAAa,CAAC,IAChBwH,EAAU,IAAIxH,aAAakH,EAAMlK,QAEjCm8B,EAAgBD,EAAQl8B,OACxBo8B,EAAcH,EAAMj8B,OACpBq8B,EAAgBL,EAAQh8B,OACxBs8B,EAAcP,EAAM/7B,OAE1B,IAAIu8B,EAAO,EACPC,EAAK,EACLC,EAAK,EACLC,EAAK,EACT,IAAK,IAAIz5B,EAAI,EAAGA,EAAIiH,EAAMlK,SAAUiD,EAClCuH,EAAQvH,GAAKi5B,EAAQK,MAChBryB,EAAMjH,GAAK84B,EAAMS,MAASP,EAAMQ,KAC7Bv5B,KAAKub,KAAKud,EAAQU,KAAQZ,GAC9BS,GAAQJ,IACVI,EAAO,GAELC,GAAMF,IACRE,EAAK,GAEHC,GAAML,IACRK,EAAK,GAEHC,GAAML,IACRK,EAAK,GAGT,OAAO74B,EAAQ/D,eAAe4D,EAAEtE,MAAOsE,EAAEpF,MAAOkM,EAClD,GCtBO,MAAMmyB,GAAqC,CAChDt5B,WAAYu5B,iBACZr5B,YAAa,MACbC,oBA3C6BC,GAK7B,MAAME,OAACA,EAAME,QAAEA,EAAOyD,MAAEA,GAAS7D,GAC3BC,EAACA,GAAKC,GACNk5B,WAACA,EAAUC,MAAEA,GAASx1B,EAE5BzJ,EAAiB,CAAC6F,GAAI,kBAEtB,MAAMiQ,EAAOkpB,EAAW9Y,QAAO,CAAC5c,EAAGC,IAAMD,EAAIC,IAEvC21B,EAAWv9B,eAAaw9B,YAAYt5B,EAAEtE,MAAOy9B,EAAYlpB,GACzDspB,EAAWz9B,eAAa09B,YAAYH,EAAS/8B,OAAQ68B,EAAW78B,QAChEm9B,EACF39B,eAAa49B,oBAAoB15B,EAAEtE,MAAOy9B,EAAYlpB,GACpD0pB,EACF79B,eAAa89B,oBAAoBR,EAAOD,EAAW78B,QACjDiO,EACFzO,eAAa+9B,aAAaJ,EAAkBL,EAAOD,EAAW78B,QAE5Dw9B,EAAYjgB,GAAQ,CAAC5Z,OAAQ,CAACD,KAAIG,UAASyD,MAAO,CAAClI,MAAO29B,KAC1DU,EACFvqB,GAAU,CAACvP,OAAQ,CAACD,EAAG85B,GAAY35B,UAASyD,MAAO,CAACsL,KAAMqqB,KACxDS,EAAsBngB,GACxB,CAAC5Z,OAAQ,CAACD,EAAG+5B,GAAc55B,UAASyD,MAAO,CAAClI,MAAO+9B,KACjDx4B,EAASY,GAAM,CACnB5B,OAAQ,CAACD,EAAGg6B,GACZ75B,UACAyD,MAAO,CAACoY,MAAO2d,EAAkB/yB,KAAM2D,KAOzC,OAJApK,EAAQ/B,8BAA8B07B,GACtC35B,EAAQ/B,8BAA8B27B,GACtC55B,EAAQ/B,8BAA8B47B,GAE/B/4B,CACT,GCvBO,MAAMg5B,GAA+B,CAC1Ct6B,WAAYu6B,WACZr6B,YAAa,MACbC,oBArBuBC,GAKvB,MAAME,OAACA,EAAME,QAAEA,EAAOyD,MAAEA,GAAS7D,GAC3BC,EAACA,EAACm6B,QAAEA,GAAWl6B,GACf2G,KAACA,GAAQhD,EAKTkD,EACFP,EAJUpG,EAAQ9E,KAAKQ,IAAImE,EAAEhE,QAAQP,OACrB0E,EAAQ9E,KAAKQ,IAAIs+B,EAAQn+B,QAAQP,OAGhB0+B,EAAQv/B,MAAOu/B,EAAQz+B,MAAOkL,GAEnE,OAAOzG,EAAQ/D,eAAe,CAACwK,GAAOuzB,EAAQv/B,MAAOkM,EACvD,GCAO,MAAMszB,GAAoC,CAC/Cz6B,WAAY06B,gBACZx6B,YAAa,MACbC,oBApB4BC,GAI5B,MAAME,OAACA,EAAME,QAAEA,GAAWJ,GACpBu6B,GAACA,EAAEC,GAAEA,GAAMt6B,EAEXu6B,EAASr6B,EAAQ9E,KAAKQ,IAAIy+B,EAAGt+B,QAAQP,OACrCg/B,EAASt6B,EAAQ9E,KAAKQ,IAAI0+B,EAAGv+B,QAAQP,OAErCi/B,EAAiB5+B,eAAa8E,2BAChCtG,MAAM8I,KAAKo3B,GAASlgC,MAAM8I,KAAKq3B,IAEnC,OAAOt6B,EAAQ/D,eACX,CAACs+B,EAAep+B,QAAS,QAAS6G,WAAWC,KAAKs3B,GACxD,GCfaC,GAAchzB,EAAgBizB,eAAa,CAAC5yB,EAAIpE,KAC3D,MAAMi3B,EAAYj3B,EAClB,OAAIoE,EAAK6yB,EAAUC,aACVD,EAAUC,aAEZ9yB,EAAK6yB,EAAUE,aAAeF,EAAUE,aAAe/yB,CAAE,IAGrDgzB,GAAkC,CAC7Cr7B,WAAYi7B,cACZ/6B,YAAa,MACbC,WAAY66B,ICQDM,GAAiC,CAC5Ct7B,WAAYu7B,aACZr7B,YAAa,MACbC,WArBGC,IACC,MAAMC,EAACA,GAAKD,EAAKE,OACXC,EAAaH,EAAKI,QAClBd,EAAe,IAAIC,aAAa5E,OAAK0F,cAAcJ,EAAEtE,QACrDy/B,EAAcj7B,EAAW7E,KAAKQ,IAAImE,EAAEhE,QACpCqB,EAAO89B,EAAYh+B,mBAAmBE,KACtCE,EAAO49B,EAAYh+B,mBAAmBI,KACtC4E,EAAWjC,EAAW7E,KAAKQ,IAAIwB,EAAKrB,QAAQP,OAC5C2G,EAAWlC,EAAW7E,KAAKQ,IAAI0B,EAAKvB,QAAQP,OAClD,IAAK,IAAI8D,EAAI,EAAGA,EAAI4C,EAAS7F,OAAQiD,IAAK,CACxC,MAAMlC,EAAO8E,EAAS5C,GAChBhC,EAAO6E,EAAS7C,GACtBF,EAAaE,GAAKC,KAAK47B,MAAM/9B,EAAME,GAGrC,OAAO2C,EAAWnC,WAAWsB,EAAcW,EAAEtE,MAAO,UAAU,YChBpD6B,GAAKwC,GAEnB,MAAME,OAACA,EAAME,QAAEA,GAAWJ,GACpB8C,MAACA,GAAS5C,EAEV1C,EAAO4C,EAAQ9E,KAAKQ,IAAIgH,EAAM7G,QAAQmB,mBAAmBI,KACzD89B,EAAUl7B,EAAQ9E,KAAKQ,IAAI0B,EAAKvB,QAAQP,OAK9C,OAAO0E,EAAQ/D,eAAemB,EAAK7B,MAAO6B,EAAK3C,MAAOygC,EACxD,CAEO,MAAMC,GAA2B,CACtC37B,WAAY47B,OACZ17B,YAAa,MACbC,WAAYvC,aCVEwtB,GACZhrB,GAEF,MAAME,OAACA,EAAME,QAAEA,EAAOyD,MAAEA,GAAS7D,GAC3BqQ,KAACA,GAAQxM,EAET4jB,EAAQ9sB,OAAK6V,eAAeH,EAAMnQ,EAAO,GAAGvE,OAAO,GAEnD8/B,EAASv7B,EAAOxD,KAAIhC,GAAKA,EAAEiB,QACjCI,eAAa2/B,uBAAuBD,EAAQhU,GAE5C,IAAInf,EAAWvM,eAAa4/B,gBAAgBz7B,EAAOxD,KAAIhC,GAAKA,EAAEiB,QAAQ8rB,GAEtE,GAAqC,IAAjC9sB,OAAK0F,cAAciI,GACrB,OAAOlI,EAAQ/D,eAAeiM,EAAUpI,EAAO,GAAGrF,MAAO,IAI3D,MAAM+gC,EAAU17B,EAAO27B,QAAOnhC,GAAKC,OAAK0F,cAAc3F,EAAEiB,OAAS,IACjE,GAAuB,IAAnBigC,EAAQr/B,OACV,OAAOoG,EAAS,CAACzC,OAAQ,CAACD,EAAG27B,EAAQ,IAAKx7B,YAG5C,GAAyB,cAArBw7B,EAAQ,GAAG/gC,MAAuB,CACpC,MAAMihC,EAAQF,EAAQl/B,KAAKhC,GAAM4C,EAAK,CAAC4C,OAAQ,CAAC4C,MAAOpI,GAAI0F,cACrD27B,EAAQH,EAAQl/B,KAAKhC,GAAM8C,GAAK,CAAC0C,OAAQ,CAAC4C,MAAOpI,GAAI0F,cAErD47B,EAAehR,GAAO,CAAC9qB,OAAQ47B,EAAO17B,UAASyD,MAAO,CAACwM,KAAMoX,KAC7DwU,EAAejR,GAAO,CAAC9qB,OAAQ67B,EAAO37B,UAASyD,MAAO,CAACwM,KAAMoX,KAE7DvmB,EACFiB,EAAQ,CAACjC,OAAQ,CAAC5C,KAAM0+B,EAAcx+B,KAAMy+B,GAAe77B,YAO/D,OALA07B,EAAMrhC,SAAQyhC,GAAK97B,EAAQ/B,8BAA8B69B,KACzDH,EAAMthC,SAAQ+E,GAAKY,EAAQ/B,8BAA8BmB,KACzDY,EAAQ/B,8BAA8B29B,GACtC57B,EAAQ/B,8BAA8B49B,GAE/B/6B,EAUT,MAAMi7B,EAAWP,EAAQl/B,KAAIhC,IAC3B,MAAM0hC,EAAYzhC,OAAK0F,cAAc3F,EAAEiB,MAAMmG,MAAM2lB,IAEnD,OAAO3N,GAAQ,CAAC5Z,OAAQ,CAACD,EAAGvF,GAAI0F,UAASyD,MAAO,CAAClI,MADnC,EAAE,EAAGygC,KACsC,IAGrDC,EAAkBF,EAASz/B,KAAIhC,IAC5B,CAAC2E,KAAMe,EAAQ9E,KAAKQ,IAAIpB,EAAEuB,QAAQP,OAAQC,MAAOjB,EAAEiB,UAI5D2M,EACIvM,eAAa4/B,gBAAgBQ,EAASz/B,KAAIhC,GAAKA,EAAEiB,QAAQ,GAC7D,MAAM4M,EAAwC,IAAzB4zB,EAAS,GAAGxgC,MAAM,GACjCoL,EACFsB,EAAWg0B,EAAiB/zB,EAAUpI,EAAO,GAAGrF,MAAO0N,GAErD+zB,EACFvgC,eAAa4/B,gBAAgBC,EAAQl/B,KAAIhC,GAAKA,EAAEiB,QAAQ8rB,GAEtD8U,EACFn8B,EAAQ/D,eAAeigC,EAAep8B,EAAO,GAAGrF,MAAOkM,GAI3D,OAFAo1B,EAAS1hC,SAAQC,GAAK0F,EAAQ/B,8BAA8B3D,KAErD6hC,CACT,CAEO,MAAMC,GAA6B,CACxC58B,WAAY68B,SACZ38B,YAAa,MACbC,WAAYirB,aCrFE0R,GACZ18B,GAEF,MAAME,OAACA,EAAME,QAAEA,EAAOyD,MAAEA,GAAS7D,GAC3BC,EAACA,EAAC47B,OAAEA,GAAU37B,GACduK,QAACA,EAAO8qB,IAAEA,EAAGU,WAAEA,EAAU0G,UAAEA,EAASnH,gBAAEA,GAAmB3xB,EAE/DzJ,EAAiB,CAAC6F,EAAG47B,GAAS,UAE9B,MAAMe,EAAc7gC,eAAa8gC,wBAAwB5G,GACnD5F,EAAWt0B,eAAa+gC,kBAC1B78B,EAAEtE,MACFkgC,EAAOlgC,MAA2C8O,EAASkyB,EAAWpH,EACtEC,GAAiB,EAAuBoH,GAEtChH,EAAevF,EAASuF,aACxBD,EAActF,EAASsF,YACvBlF,EAAiBJ,EAASI,eAC1BC,EAAgBL,EAASK,cACzBM,EAAUX,EAASS,QAAQxK,KAC3BuK,EAASR,EAASS,QAAQC,IAC1BgM,EAAyC,iBAAxB1M,EAAS4F,WAE1B+G,EAAI,IAAIthB,eAAa2U,EAAS/nB,SAAUrI,EAAEpF,OAE1CyU,EAAW3U,OAAKqG,eAAef,EAAEtE,OACjCshC,EAAgBtiC,OAAKqG,eAAe66B,EAAOlgC,OAE3CuhC,EAAe5tB,EAAS,GACxB6tB,EAAaJ,EAAiBztB,EAAS,GAAKA,EAAS,GACrD8tB,EAAaL,EAAiBztB,EAAS,GAAK,EAC5C+tB,EAAiBN,EAAiB,EAAIztB,EAAS,GAC/CguB,EAAeN,EAAEvyB,QAAQ,GACzB8yB,EAAaR,EAAiBC,EAAEvyB,QAAQ,GAAKuyB,EAAEvyB,QAAQ,GACvD+yB,EAAaT,EAAiBC,EAAEvyB,QAAQ,GAAK,EAC7CgzB,EAAiBV,EAAiB,EAAIC,EAAEvyB,QAAQ,GAEhDhE,EAAQrG,EAAQ9E,KAAKQ,IAAImE,EAAEhE,QAAQP,OACnCgiC,EAAQt9B,EAAQ9E,KAAKQ,IAAI+/B,EAAO5/B,QAAQP,OACxCiiC,EAAQX,EAAEthC,OAEhB,IAAK,IAAIiI,EAAI,EAAGA,EAAI0sB,EAASrL,YAAarhB,EAAG,CAC3C,MAAMi6B,EAAWj6B,EAAIu5B,EACfW,EAAWl6B,EAAI25B,EACrB,IAAK,IAAI3L,EAAK,EAAGA,EAAKtB,EAASuB,YAAaD,EAAI,CAC9C,MAAMmM,EAAWD,EAAWlM,EAAK4L,EAC3B1L,EAAWF,EAAKtB,EAASE,aAAeM,EAC9C,IAAK,IAAIwC,EAAK,EAAGA,EAAKuC,IAAgBvC,EAAI,CACxC,MAAMV,EAAKd,EAAWwB,EAAK5C,EAC3B,GAAIkC,EAAK,GAAKA,GAAMtC,EAAS2B,SAC3B,SAEF,MAAM+L,EAAW1K,EAAK4J,EAAc,GAC9Be,EAAWJ,EAAWjL,EAAKwK,EACjC,IAAK,IAAIjL,EAAK,EAAGA,EAAK7B,EAAS8B,WAAYD,EAAI,CAC7C,MAAM+L,EAAWH,EAAW5L,EAAKsL,EAC3BpL,EAAWF,EAAK7B,EAASG,YAAcQ,EAC7C,IAAK,IAAIsC,EAAK,EAAGA,EAAKqC,IAAerC,EAAI,CACvC,MAAMT,EAAKT,EAAWkB,EAAK5C,EAC3B,GAAImC,EAAK,GAAKA,GAAMxC,EAASkC,QAC3B,SAEF,MACM2L,EAAWF,EAAWnL,EAAKuK,EACjC,IAAIe,EAFaJ,EAAWzK,EAAK2J,EAAc,GAG/C,IAAK,IAAImB,EAAK,EAAGA,EAAK/N,EAASqB,aAAc0M,EAAI,CAC/C,MAAMC,EAAO53B,EAAMy3B,EAAWE,EAAKf,GACnC,IAAK,IAAIiB,EAAK,EAAGA,EAAKjO,EAASkO,cAAeD,EAC5CX,EAAMM,EAAWK,EAAKb,IAClBY,EAAOX,EAAMS,EAAWG,GAE9BH,GAAY9N,EAASkO,iBAQjC,OAAOn+B,EAAQ/D,eAAe2gC,EAAErhC,MAAOqhC,EAAEniC,MAAO8iC,EAClD,CAEO,MAAMa,GAA6B,CACxC5+B,WAAY6+B,SACZ3+B,YAAa,MACbC,WAAY28B,ICnBP,MAAMgC,GAA2C,CACtD9+B,WAAY++B,uBACZ7+B,YAAa,MACbC,oBArEmCC,GAKnC,MAAME,OAACA,EAAME,QAAEA,EAAOyD,MAAEA,GAAS7D,GAC3BC,EAACA,EAACo2B,GAAEA,GAAMn2B,GACVuK,QAACA,EAAO8qB,IAAEA,EAAGU,WAAEA,EAAUT,gBAAEA,EAAeoJ,YAAEA,GAAe/6B,EAEjEzJ,EAAiB,CAAC6F,EAAGo2B,GAAK,wBAE1B,MAAMuG,EAAc7gC,eAAa8gC,wBAAwB5G,GACnD5F,EAAWt0B,eAAa+gC,kBAC1B78B,EAAEtE,MAA2CijC,EAAan0B,EAC1D,EAAmB8qB,EAAKC,GAAiB,EACzCoH,IAEErM,aAACA,EAAYC,YAAEA,EAAWoF,aAAEA,EAAYD,YAAEA,GAAetF,EACzD0M,EAAyC,iBAAxB1M,EAAS4F,WAC1B4I,EAAK,IAAInjB,eAAa2U,EAASuO,YAAa,WAE5Cxc,EAAUiO,EAASS,QAAQxK,KAC3BwY,EAASzO,EAASS,QAAQC,IAC1BtqB,EAAQrG,EAAQ9E,KAAKQ,IAAImE,EAAEhE,QAAQP,OACnCqjC,EAAS3+B,EAAQ9E,KAAKQ,IAAIu6B,EAAGp6B,QAAQP,OAErCwL,EAAO,IAAIwU,eAAazb,EAAEtE,MAAOsE,EAAEpF,MAAO4L,GAC1CgwB,EAAQ,IAAI/a,eAAa2a,EAAG16B,MAAO06B,EAAGx7B,MAAOkkC,GAEnD,IAAK,IAAI1L,EAAK,EAAGA,EAAKuC,IAAgBvC,EAAI,CACxC,MAAM2L,EAAQv/B,KAAK0N,IAAI,EAAG1N,KAAKyI,MAAM42B,EAASzL,GAAM9C,IAC9C0O,EAAQx/B,KAAKoO,IACfwiB,EAASuB,WAAYvB,EAAS2B,SAAW8M,EAASzL,GAAM9C,GAE5D,IAAK,IAAI+C,EAAK,EAAGA,EAAKqC,IAAerC,EAAI,CACvC,MAAM4L,EAAQz/B,KAAK0N,IAAI,EAAG1N,KAAKyI,MAAMka,EAAUkR,GAAM9C,IAC/C2O,EAAQ1/B,KAAKoO,IACfwiB,EAAS8B,UAAW9B,EAASkC,QAAUnQ,EAAUkR,GAAM9C,GAE3D,IAAK,IAAI4N,EAAK,EAAGA,EAAK/N,EAASqB,aAAc0M,EAC3C,IAAK,IAAIE,EAAK,EAAGA,EAAKjO,EAASkO,cAAeD,EAAI,CAChD,IAAItH,EAAU,EACd,IAAK,IAAIrzB,EAAI,EAAGA,EAAI0sB,EAASrL,YAAarhB,EACxC,IAAK,IAAIguB,EAAKqN,EAAOrN,EAAKsN,IAAStN,EAAI,CACrC,MAAMgB,EAAKU,EAAK1B,EAAKpB,EAAeuO,EACpC,IAAK,IAAI5M,EAAKgN,EAAOhN,EAAKiN,IAASjN,EAAI,CACrC,MAAMW,EAAKS,EAAKpB,EAAK1B,EAAcpO,EAEjC4U,GADE+F,EACU71B,EAAKpL,IAAI6H,EAAGgvB,EAAIE,EAAIuL,GAC3B3H,EAAM36B,IAAI6H,EAAGguB,EAAIO,EAAIoM,GAEdp3B,EAAKpL,IAAI6H,EAAGy6B,EAAIzL,EAAIE,GAC3B4D,EAAM36B,IAAI6H,EAAG26B,EAAI3M,EAAIO,IAKlC2M,EAAG1iC,IAAI66B,EAAS3D,EAAIC,EAAI8K,EAAIE,KAMpC,OAAOl+B,EAAQ/D,eAAewiC,EAAGljC,MAAOkjC,EAAGhkC,MAAOgkC,EAAGnjC,OACvD,GC8BO,MAAM0jC,GAA0C,CACrDx/B,WAAYy/B,sBACZv/B,YAAa,MACbC,oBAjGkCC,GAKlC,MAAME,OAACA,EAAME,QAAEA,EAAOyD,MAAEA,GAAS7D,GAC3Bq2B,GAACA,EAAEwF,OAAEA,GAAU37B,GACfye,WAACA,EAAUlU,QAAEA,EAAO8qB,IAAEA,EAAGU,WAAEA,EAAUT,gBAAEA,GAAmB3xB,EAEhEzJ,EAAiB,CAACi8B,EAAIwF,GAAS,uBAE/B,MAAMoB,EAAgBtiC,OAAKqG,eAAe66B,EAAOlgC,OAC3C2jC,EAAY3kC,OAAKqG,eAAeq1B,EAAG16B,OAEzC,IAAIihC,EAAc7gC,eAAa8gC,wBAAwB5G,GACvD,MAAM5F,EAAWt0B,eAAa+gC,kBAC1Bne,EAAYkd,EAAOlgC,MAA2C8O,EAC9D,EAAmB8qB,EAAKC,GAAiB,EAAOoH,GAE9CrG,EAAK,IAAI7a,eAAa2U,EAASyF,QAAS,WACxCyJ,EAAWhJ,EAAG76B,OACd8jC,EAAWp/B,EAAQ9E,KAAKQ,IAAIu6B,EAAGp6B,QAAQP,OACvC+jC,EAAYr/B,EAAQ9E,KAAKQ,IAAI+/B,EAAO5/B,QAAQP,QAC3CgkC,EAAOC,EAAOC,GAAS3C,GACxBjY,UACJA,EAAS4Q,aACTA,EAAYD,YACZA,EAAWjE,WACXA,EAAUM,SACVA,EAAQO,QACRA,EAAOgM,YACPA,EAAW3M,UACXA,EAASO,SACTA,EAAQ5B,aACRA,EAAYC,YACZA,GACEH,EACJuM,EAAcvM,EAAS4F,WACvB,MAAM6I,EAASlJ,EAAe,EAAIvF,EAASS,QAAQC,IAC7C3O,EAAUuT,EAAc,EAAItF,EAASS,QAAQxK,KAE7CyW,EAAiC,iBAAhBH,EACjBM,EAAe3G,EAAG9rB,QAAQ,GAC1B0yB,EAAaJ,EAAiBxG,EAAG9rB,QAAQ,GAAK8rB,EAAG9rB,QAAQ,GACzD2yB,EAAaL,EAAiBxG,EAAG9rB,QAAQ,GAAK,EAC9C4yB,EAAiBN,EAAiB,EAAIxG,EAAG9rB,QAAQ,GACjD6yB,EAAegC,EAAU,GACzB/B,EAAaR,EAAiBuC,EAAU,GAAKA,EAAU,GACvD9B,EAAaT,EAAiBuC,EAAU,GAAK,EAC7C7B,EAAiBV,EAAiB,EAAIuC,EAAU,GAEtD,IAAK,IAAI37B,EAAI,EAAGA,EAAIqhB,IAAarhB,EAC/B,IAAK,IAAIy6B,EAAK,EAAGA,EAAK1M,IAAc0M,EAClC,IAAK,IAAIzL,EAAK,EAAGA,EAAKX,IAAYW,EAAI,CACpC,MAAMd,EAAWc,EAAKmM,EAChBhN,EAAQryB,KAAK0N,IAAI,EAAG1N,KAAKyI,KAAK2pB,EAAWtB,IACzC0O,EACFx/B,KAAKoO,IAAI+jB,GAAYgE,EAAe/D,GAAYtB,GAEpD,IAAK,IAAIsC,EAAK,EAAGA,EAAKN,IAAWM,EAAI,CACnC,MAAMT,EAAWS,EAAKzQ,EAChBiQ,EAAQ5yB,KAAK0N,IAAI,EAAG1N,KAAKyI,KAAKkqB,EAAW5B,IACzC2O,EACF1/B,KAAKoO,IAAIskB,GAAWwD,EAAcvD,GAAY5B,GAElD,IAAIwG,EAAU,EACd,IAAK,IAAIrF,EAAKG,EAAOH,EAAKsN,IAAStN,EAAI,CACrC,MAAM0B,EAAK1B,EAAKpB,EAAesB,EAE/B,IAAK,IAAIK,EAAKG,EAAOH,EAAKiN,IAASjN,EAAI,CACrC,MACM2N,EACFvC,EAAe35B,EAAI45B,EAAa5L,EAAK6L,EAAatL,EAChD4N,EAAYJ,GAAS9J,EAAe,EAAIvC,GAC1CsM,GAAShK,EAAc,GAJhBzD,EAAK1B,EAAc4B,IAIOwN,EAAQxB,EAE7C,IAAK,IAAIE,EAAK,EAAGA,EAAKC,IAAeD,EAAI,CAGvCtH,GAFcwI,EAASK,EAAWpC,EAAiBa,GACpCmB,EAAUK,EAAYxB,KAO3CiB,EAFiBrC,EAAev5B,EAAIw5B,EAAaxK,EAC7CyK,EAAavK,EAAKwK,EAAiBe,GAClBpH,GAM7B,OAAO52B,EAAQ/D,eAAek6B,EAAG56B,MAAO46B,EAAG17B,MAAO07B,EAAG76B,OACvD,GCJO,MAAMqkC,GAA6B,CACxCngC,WAAYogC,SACZlgC,YAAa,MACbC,oBA1FEC,GAEF,MAAME,OAACA,EAAME,QAAEA,EAAOyD,MAAEA,GAAS7D,GAC3BC,EAACA,EAAC47B,OAAEA,GAAU37B,GACduK,QAACA,EAAO8qB,IAAEA,EAAGoH,UAAEA,GAAa94B,EAElCzJ,EAAiB,CAAC6F,EAAG47B,GAAS,UAE9B,MAAMxL,EAAWt0B,eAAakkC,kBAC1BhgC,EAAEtE,MACFkgC,EAAOlgC,MAAmD8O,EAC1DkyB,EAAWpH,IAETe,YACJA,EAAWV,aACXA,EAAYD,YACZA,EAAWlC,cACXA,EAAahD,eACbA,EAAcC,cACdA,EAAaI,QACbA,GACET,EACEsD,EAAW7C,EAAQ8C,MACnB5C,EAAUF,EAAQxK,KAClBuK,EAASC,EAAQC,IACjBiM,EAAI,IAAIthB,eAAa2U,EAAS/nB,SAAUrI,EAAEpF,OAE1C4L,EAAQrG,EAAQ9E,KAAKQ,IAAImE,EAAEhE,QAAQP,OACnCgiC,EAAQt9B,EAAQ9E,KAAKQ,IAAI+/B,EAAO5/B,QAAQP,OACxCiiC,EAAQX,EAAEthC,OAEV4T,EAAW3U,OAAKqG,eAAef,EAAEtE,OACjCshC,EAAgBtiC,OAAKqG,eAAe66B,EAAOlgC,OAEjD,IAAK,IAAIgI,EAAI,EAAGA,EAAI0sB,EAASrL,YAAarhB,EAAG,CAC3C,MAAMi6B,EAAWj6B,EAAI2L,EAAS,GACxBuuB,EAAWl6B,EAAIq5B,EAAEvyB,QAAQ,GAC/B,IAAK,IAAIy1B,EAAK,EAAGA,EAAK7P,EAAS2D,WAAYkM,EAAI,CAC7C,MAAMpC,EAAWD,EAAWqC,EAAKlD,EAAEvyB,QAAQ,GACrC01B,EAAWD,EAAK7P,EAASmD,YAAcG,EAC7C,IAAK,IAAIyM,EAAK,EAAGA,EAAK9J,IAAe8J,EAAI,CACvC,MAAMC,EAAKF,EAAWC,EAAK3M,EAC3B,GAAI4M,EAAK,GAAKA,GAAMhQ,EAAS+D,QAC3B,SAEF,MAAM2J,EAAWqC,EAAKnD,EAAc,GAC9Be,EAAWJ,EAAWyC,EAAK/wB,EAAS,GAE1C,IAAK,IAAIqiB,EAAK,EAAGA,EAAKtB,EAASuB,YAAaD,EAAI,CAC9C,MAAMsM,EAAWH,EAAWnM,EAAKqL,EAAEvyB,QAAQ,GACrConB,EAAWF,EAAKtB,EAASE,aAAeM,EAC9C,IAAK,IAAIwC,EAAK,EAAGA,EAAKuC,IAAgBvC,EAAI,CACxC,MAAMV,EAAKd,EAAWwB,EAAK5C,EAC3B,GAAIkC,EAAK,GAAKA,GAAMtC,EAAS2B,SAC3B,SAEF,MAAMsO,EAAWvC,EAAW1K,EAAK4J,EAAc,GACzCiB,EAAWF,EAAWrL,EAAKrjB,EAAS,GAC1C,IAAK,IAAI4iB,EAAK,EAAGA,EAAK7B,EAAS8B,WAAYD,EAAI,CAC7C,MAAMqO,EAAWtC,EAAW/L,EAAK7B,EAASkO,YACpCnM,EAAWF,EAAK7B,EAASG,YAAcQ,EAC7C,IAAK,IAAIsC,EAAK,EAAGA,EAAKqC,IAAerC,EAAI,CACvC,MAAMT,EAAKT,EAAWkB,EAAK5C,EAC3B,GAAImC,EAAK,GAAKA,GAAMxC,EAASkC,QAC3B,SAEF,MAAM4L,EAAWmC,EAAWhN,EAAK2J,EAAc,GACzCuD,EAAWtC,EAAWrL,EAAKxC,EAASqB,WAC1C,IAAI+O,EAAWtC,EACf,IAAK,IAAIC,EAAK,EAAGA,EAAK/N,EAASqB,aAAc0M,EAAI,CAC/C,MAAMC,EAAO53B,EAAM+5B,EAAWpC,GAC9B,IAAK,IAAIE,EAAK,EAAGA,EAAKjO,EAASkO,cAAeD,EAC5CX,EAAM4C,EAAWjC,IAAOD,EAAOX,EAAM+C,EAAWnC,GAElDmC,GAAYpQ,EAASkO,mBAUrC,OAAOn+B,EAAQ/D,eAAe2gC,EAAErhC,MAAOqhC,EAAEniC,MAAOmiC,EAAEthC,OACpD,GCQO,MAAMglC,GAA6C,CACxD9gC,WAAY+gC,yBACZ7gC,YAAa,MACbC,oBAjGqCC,GAKrC,MAAME,OAACA,EAAME,QAAEA,EAAOyD,MAAEA,GAAS7D,GAC3BC,EAACA,EAACo2B,GAAEA,GAAMn2B,GACVuK,QAACA,EAAO8qB,IAAEA,EAAGqJ,YAAEA,GAAe/6B,EAEpCzJ,EAAiB,CAAC6F,EAAGo2B,GAAK,0BAE1B,MAAM/mB,EAAW3U,OAAKqG,eAAef,EAAEtE,OACjC2jC,EAAY3kC,OAAKqG,eAAeq1B,EAAG16B,OAEnC00B,EAAWt0B,eAAakkC,kBAC1BhgC,EAAEtE,MAAmDijC,EAAan0B,EAClE,EAAmB8qB,GAEjB/B,EAAcnD,EAASmD,YACvBjD,EAAeF,EAASE,aACxBC,EAAcH,EAASG,YACvB8F,EAAcjG,EAASiG,YACvBV,EAAevF,EAASuF,aACxBD,EAActF,EAASsF,YAEvBiL,EAAK,IAAIllB,eAAa2U,EAASuO,YAAa,WAC5CiC,EAAWD,EAAGllC,QACbolC,EAAMC,EAAMC,EAAMC,GAAQL,EAAGn2B,QAC9B+0B,EAAWp/B,EAAQ9E,KAAKQ,IAAIu6B,EAAGp6B,QAAQP,QACtCwlC,EAAMC,EAAMC,EAAMC,GAAQ/B,EAC3BlP,EAAUhwB,EAAQ9E,KAAKQ,IAAImE,EAAEhE,QAAQP,QACpC4lC,EAAKC,EAAKC,EAAKC,GAAOnyB,EAEvBoyB,EAAWrR,EAASS,QAAQ8C,MAC5BxR,EAAUiO,EAASS,QAAQxK,KAC3BwY,EAASzO,EAASS,QAAQC,IAEhC,IAAK,IAAIqP,EAAK,EAAGA,EAAK9J,IAAe8J,EAAI,CACvC,MAAMuB,EAAQliC,KAAK0N,IAAI,EAAG1N,KAAKyI,MAAMw5B,EAAWtB,GAAM5M,IAChDoO,EAAQniC,KAAKoO,IACfwiB,EAAS2D,UAAW3D,EAAS+D,QAAUsN,EAAWtB,GAAM5M,GACtDuK,EAAWqC,EAAKU,EAEtB,IAAK,IAAIzN,EAAK,EAAGA,EAAKuC,IAAgBvC,EAAI,CACxC,MAAM2L,EAAQv/B,KAAK0N,IAAI,EAAG1N,KAAKyI,MAAM42B,EAASzL,GAAM9C,IAC9C0O,EAAQx/B,KAAKoO,IACfwiB,EAASuB,WAAYvB,EAAS2B,SAAW8M,EAASzL,GAAM9C,GACtD+P,EAAWjN,EAAK0N,EAAOhD,EAE7B,IAAK,IAAIzK,EAAK,EAAGA,EAAKqC,IAAerC,EAAI,CACvC,MAAM4L,EAAQz/B,KAAK0N,IAAI,EAAG1N,KAAKyI,MAAMka,EAAUkR,GAAM9C,IAC/C2O,EAAQ1/B,KAAKoO,IACfwiB,EAAS8B,UAAW9B,EAASkC,QAAUnQ,EAAUkR,GAAM9C,GACrD2N,EAAW7K,EAAK0N,EAAOV,EAE7B,IAAK,IAAIlC,EAAK,EAAGA,EAAK/N,EAASqB,aAAc0M,EAAI,CAC/C,MAAMqC,EAAWrC,EAAK6C,EAAO9C,EAE7B,IAAK,IAAIG,EAAK,EAAGA,EAAKjO,EAASkO,cAAeD,EAAI,CAChD,IAAItH,EAAU,EACd,IAAK,IAAIrzB,EAAI,EAAGA,EAAI0sB,EAASrL,YAAarhB,EAAG,CAC3C,MAAMi6B,EAAWj6B,EAAI29B,EACfzD,EAAWl6B,EAAIu9B,EAErB,IAAK,IAAIhB,EAAKyB,EAAOzB,EAAK0B,IAAS1B,EAAI,CACrC,MACMlC,GADKoC,EAAKF,EAAK1M,EAAckO,GACbH,EAAM3D,EACtBE,EAAWoC,EAAKiB,EAAOtD,EAE7B,IAAK,IAAIlM,EAAKqN,EAAOrN,EAAKsN,IAAStN,EAAI,CACrC,MACMuM,GADK7K,EAAK1B,EAAKpB,EAAeuO,GACd0C,EAAMxD,EACtBC,EAAWtM,EAAKyP,EAAOtD,EAE7B,IAAK,IAAI5L,EAAKgN,EAAOhN,EAAKiN,IAASjN,EAAI,CACrC,MAEMqO,EAAWrO,EAAKmP,EAAOpD,EAE7BjH,GAAW5G,GAJAkD,EAAKpB,EAAK1B,EAAcpO,GACbqf,EAAMvD,EAGEE,GAAMoB,EAASe,EAAWjC,MAKhEuC,EAASJ,EAAWnC,GAAMtH,MAOpC,OAAO52B,EAAQ/D,eAAeukC,EAAGjlC,MAAOilC,EAAG/lC,MAAO+lC,EAAGllC,OACvD,GCSO,MAAMmmC,GAA4C,CACvDjiC,WAAYkiC,wBACZhiC,YAAa,MACbC,oBAxGoCC,GAKpC,MAAME,OAACA,EAAME,QAAEA,EAAOyD,MAAEA,GAAS7D,GAC3Bq2B,GAACA,EAAEwF,OAAEA,GAAU37B,GACfq1B,IAACA,EAAG9qB,QAAEA,EAAOkU,WAAEA,GAAc9a,EAEnCzJ,EAAiB,CAACi8B,GAAK,yBAEvB,MAAMiJ,EAAY3kC,OAAKqG,eAAeq1B,EAAG16B,OACnCshC,EAAgBtiC,OAAKqG,eAAe66B,EAAOlgC,OAE3C00B,EAAWt0B,eAAakkC,kBAC1BthB,EAAYkd,EAAOlgC,MACnB8O,EAAS,EAAmB8qB,GAE1BgB,EAAK,IAAI7a,eAAa2U,EAASyF,QAAS,WACxCyJ,EAAWhJ,EAAG76B,QACbqmC,EAAMC,EAAMC,EAAMC,GAAQ3L,EAAG9rB,QAC9B+0B,EAAWp/B,EAAQ9E,KAAKQ,IAAIu6B,EAAGp6B,QAAQP,QACtCwlC,EAAMC,EAAMC,EAAMC,GAAQ/B,EAC3BG,EAAYr/B,EAAQ9E,KAAKQ,IAAI+/B,EAAO5/B,QAAQP,QAC3CgkC,EAAOC,EAAOC,EAAOuC,GAASlF,GAC/BjY,UACJA,EAASsR,YACTA,EAAWV,aACXA,EAAYD,YACZA,EAAWjE,WACXA,EAAU0C,QACVA,EAAOpC,SACPA,EAAQO,QACRA,EAAOgM,YACPA,EAAWvK,SACXA,EAAQpC,UACRA,EAASO,SACTA,EAAQqB,YACRA,EAAWjD,aACXA,EAAYC,YACZA,GACEH,EACEqR,EAAWpL,EAAc,EAAIjG,EAASS,QAAQ8C,MAC9CkL,EAASlJ,EAAe,EAAIvF,EAASS,QAAQC,IAC7C3O,EAAUuT,EAAc,EAAItF,EAASS,QAAQxK,KAEnD,IAAK,IAAI3iB,EAAI,EAAGA,EAAIqhB,IAAarhB,EAC/B,IAAK,IAAIy6B,EAAK,EAAGA,EAAK1M,IAAc0M,EAElC,IAAK,IAAIiC,EAAK,EAAGA,EAAKjM,IAAWiM,EAAI,CACnC,MAAMF,EAAWE,EAAKqB,EAChBU,EAAQ3iC,KAAK0N,IAAI,EAAG1N,KAAKyI,KAAKi4B,EAAW3M,IACzCoO,EACFniC,KAAKoO,IAAImmB,GAAWsC,EAAc6J,GAAY3M,GAGlD,IAAK,IAAIb,EAAK,EAAGA,EAAKX,IAAYW,EAAI,CACpC,MAAMd,EAAWc,EAAKmM,EAChBhN,EAAQryB,KAAK0N,IAAI,EAAG1N,KAAKyI,KAAK2pB,EAAWtB,IACzC0O,EACFx/B,KAAKoO,IAAI+jB,GAAYgE,EAAe/D,GAAYtB,GAEpD,IAAK,IAAIsC,EAAK,EAAGA,EAAKN,IAAWM,EAAI,CACnC,MAAMT,EAAWS,EAAKzQ,EAChBiQ,EAAQ5yB,KAAK0N,IAAI,EAAG1N,KAAKyI,KAAKkqB,EAAW5B,IACzC2O,EACF1/B,KAAKoO,IAAIskB,GAAWwD,EAAcvD,GAAY5B,GAElD,IAAIwG,EAAU,EACd,IAAK,IAAIkJ,EAAKkC,EAAOlC,EAAK0B,IAAS1B,EAAI,CACrC,MAAME,EAAKF,EAAK1M,EAAc2M,EAE9B,IAAK,IAAIxO,EAAKG,EAAOH,EAAKsN,IAAStN,EAAI,CACrC,MAAM0B,EAAK1B,EAAKpB,EAAesB,EAE/B,IAAK,IAAIK,EAAKG,EAAOH,EAAKiN,IAASjN,EAAI,CACrC,MACM2N,EAAWqB,EAAOv9B,EAAIw9B,EAAOjB,EAAKkB,EAAOzP,EAAK0P,EAAOnP,EACrD4N,EAAYJ,GAASpJ,EAAc,EAAI8J,GACzCT,GAAS/J,EAAe,EAAIvC,GAC5BuM,GAASjK,EAAc,GAJhBzD,EAAK1B,EAAc4B,IAIO+P,EAAQ/D,EAE7C,IAAK,IAAIE,EAAK,EAAGA,EAAKC,IAAeD,EAAI,CAGvCtH,GAFcwI,EAASK,EAAWvB,GACnBmB,EAAUK,EAAYxB,MAM7CiB,EAASwC,EAAOp+B,EAAIq+B,EAAO3B,EAAK4B,EAAOtP,EAAKuP,EAAOrP,EAAKuL,GACpDpH,IAOd,OAAO52B,EAAQ/D,eAAek6B,EAAG56B,MAAO46B,EAAG17B,MAAO07B,EAAG76B,OACvD,GCpGa2mC,GAAMz6B,EAAgB06B,OAAMr6B,GAAOxI,KAAK4iC,IAAIp6B,KAE5Cs6B,GAA0B,CACrC3iC,WAAY0iC,MACZxiC,YAAa,MACbC,WAAYsiC,ICLDG,GAAO56B,EAAgB66B,QAAOx6B,GAAOxI,KAAK+iC,KAAKv6B,KAE/Cy6B,GAA2B,CACtC9iC,WAAY6iC,OACZ3iC,YAAa,MACbC,WAAYyiC,ICuIP,MAAMG,GAAoC,CAC/C/iC,WAAYgjC,gBACZ9iC,YAAa,MACbC,oBA/I4BC,GAK5B,MAAME,OAACA,EAAME,QAAEA,EAAOyD,MAAEA,GAAS7D,GAC3B6iC,MAACA,EAAKC,MAAEA,EAAKC,OAAEA,GAAU7iC,GACzB8iC,SAACA,EAAQC,OAAEA,EAAMC,mBAAEA,GAAsBr/B,GAExCmjB,EAAOmc,EAAaC,EAAYC,GAAeR,EAAMlnC,MACtD2nC,EAAWR,EAAMnnC,MAAM,IAEtB4nC,EAAYC,GAAaR,EAC1BziB,EACFziB,SAAO,CAACwlC,EAAUC,EAAYC,EAAWH,GAAc,WAErDI,EAAUrjC,EAAQ9E,KAAKQ,IAAIgnC,EAAM7mC,QAAQP,OACzCgoC,EAAatjC,EAAQ9E,KAAKQ,IAAIinC,EAAO9mC,QAAQP,OAC7CioC,EAAYvjC,EAAQ9E,KAAKQ,IAAI+mC,EAAM5mC,QAAQP,OAE3CkoC,EACFjpC,OAAKqG,eAAe6hC,EAAMlnC,OACxBkoC,EAAYlpC,OAAKqG,eACnBuf,EAAO5kB,OAKX,IAAK,IAAIgI,EAAI,EAAGA,EAAI2/B,EAAU3/B,IAAK,CACjC,MAAMmgC,EAAe,EAAJngC,EACXogC,EAAKN,EAAQK,GACbE,EAAKP,EAAQK,EAAW,GACxBG,EAAKR,EAAQK,EAAW,GACxBI,EAAKT,EAAQK,EAAW,GAExBK,EAAeT,EAAW//B,GAChC,GAAIwgC,GAAQnd,EACV,SAGF,MAAMod,EACDb,EAAa,GAAMU,EAAKF,IAAOZ,EAAc,IAAMI,EAAa,GAAK,EACpEc,EACDb,EAAY,GAAMU,EAAKF,IAAOZ,EAAa,IAAMI,EAAY,GAAK,EAEvE,IAAK,IAAIxG,EAAI,EAAGA,EAAIuG,EAAYvG,IAAK,CACnC,MAAMsH,EAAgBf,EAAa,EAC/BQ,GAAMZ,EAAc,GAAKnG,IACzB,IAAO+G,EAAKE,IAAOd,EAAc,GAErC,GAAImB,EAAO,GAAKA,EAAOnB,EAAc,EACnC,IAAK,IAAIljC,EAAI,EAAGA,EAAIujC,EAAWvjC,IAC7B,IAAK,IAAIolB,EAAI,EAAGA,EAAIge,EAAahe,IAAK,CACpC,MAAMkf,EACFlf,EAAIplB,EAAI4jC,EAAU,GAAK7G,EAAI6G,EAAU,GAAKlgC,EAAIkgC,EAAU,GAC5DtjB,EAAO7kB,OAAO6oC,GAAOrB,OAM3B,GAAe,aAAXD,EAAuB,CACzB,MAAMuB,EAAS/kC,KAAKmK,MAAM06B,GACpBG,EAAYhlC,KAAKyI,KAAKo8B,GACtBI,EAAQJ,EAAOE,EAErB,IAAK,IAAIvkC,EAAI,EAAGA,EAAIujC,EAAWvjC,IAAK,CAClC,MAAM0kC,EAAQnB,EAAY,EACtBQ,GAAMZ,EAAa,GAAKnjC,EAAIokC,EAC5B,IAAOL,EAAKE,IAAOd,EAAa,GAEpC,GAAIuB,EAAO,GAAKA,EAAOvB,EAAa,EAAG,CACrC,IAAK,IAAI/d,EAAI,EAAGA,EAAIge,EAAahe,IAAK,CACpC,MAAMkf,EACFlf,EAAIplB,EAAI4jC,EAAU,GAAK7G,EAAI6G,EAAU,GAAKlgC,EAAIkgC,EAAU,GAC5DtjB,EAAO7kB,OAAO6oC,GAAOrB,EAEvB,SAGF,MAAM0B,EAAUnlC,KAAKmK,MAAM+6B,GACrBE,EAAWplC,KAAKyI,KAAKy8B,GACrBG,EAAQH,EAAOC,EAErB,IAAK,IAAIvf,EAAI,EAAGA,EAAIge,EAAahe,IAAK,CACpC,IAAIkf,EAAMlf,EAAIuf,EAAUhB,EAAS,GAAKY,EAASZ,EAAS,GACpDO,EAAOP,EAAS,GACpB,MAAMmB,EAAUpB,EAAUY,GAE1BA,EAAMlf,EAAIwf,EAAWjB,EAAS,GAAKY,EAASZ,EAAS,GACjDO,EAAOP,EAAS,GACpB,MAAMoB,EAAWrB,EAAUY,GAE3BA,EAAMlf,EAAIuf,EAAUhB,EAAS,GAAKa,EAAYb,EAAS,GACnDO,EAAOP,EAAS,GACpB,MAAMqB,EAAatB,EAAUY,GAE7BA,EAAMlf,EAAIwf,EAAWjB,EAAS,GAAKa,EAAYb,EAAS,GACpDO,EAAOP,EAAS,GACpB,MAEM7S,EAAMgU,GAAWC,EAAWD,GAAWD,EACvCI,EAASD,GAHKtB,EAAUY,GAGaU,GAAcH,EAEzDP,EAAMlf,EAAIplB,EAAI4jC,EAAU,GAAK7G,EAAI6G,EAAU,GAAKlgC,EAAIkgC,EAAU,GAC9DtjB,EAAO7kB,OAAO6oC,GAAOxT,GAAQmU,EAASnU,GAAO2T,SAIjD,IAAK,IAAIzkC,EAAI,EAAGA,EAAIujC,IAAavjC,EAAG,CAClC,MAAM0kC,EAAQnB,EAAY,EACtBQ,GAAMZ,EAAa,GAAKnjC,EAAIokC,EAC5B,IAAOL,EAAKE,IAAOd,EAAa,GAEpC,GAAIuB,EAAO,GAAKA,EAAOvB,EAAa,EAAG,CACrC,IAAK,IAAI/d,EAAI,EAAGA,EAAIge,EAAahe,IAAK,CACpC,MAAMkf,EACFlf,EAAIplB,EAAI4jC,EAAU,GAAK7G,EAAI6G,EAAU,GAAKlgC,EAAIkgC,EAAU,GAC5DtjB,EAAO7kB,OAAO6oC,GAAOrB,EAEvB,SAGF,MAAMiC,EAAW1lC,KAAK2lC,MAAMT,GACtBU,EAAW5lC,KAAK2lC,MAAMd,GAC5B,IAAK,IAAIjf,EAAI,EAAGA,EAAIge,EAAahe,IAAK,CACpC,MAAMigB,EAAQjgB,EAAI8f,EAAWvB,EAAS,GAAKyB,EAAWzB,EAAS,GAC3DO,EAAOP,EAAS,GACd2B,EACFlgB,EAAIplB,EAAI4jC,EAAU,GAAK7G,EAAI6G,EAAU,GAAKlgC,EAAIkgC,EAAU,GAC5DtjB,EAAO7kB,OAAO6pC,GAAU5B,EAAU2B,MAO5C,OAAOllC,EAAQ/D,eAAekkB,EAAO5kB,MAAO4kB,EAAO1lB,MAAO0lB,EAAO7kB,OACnE,GC5EO,MAAM8pC,GAA8B,CACzC5lC,WAAY6lC,UACZ3lC,YAAa,MACbC,oBA9DEC,GAEF,MAAME,OAACA,EAAME,QAAEA,EAAOyD,MAAEA,GAAS7D,GAC3BC,EAACA,GAAKC,GACNmQ,KAACA,EAAIq1B,UAAEA,EAASC,QAAEA,GAAW9hC,EAEnCzJ,EAAiB6F,EAAG,WAEpB,MAAMwQ,EAAc1U,eAAa2U,mBAAmB,CAACL,GAAOpQ,EAAEtE,MAAMY,QACpE,IAAI8xB,EAAKpuB,EACU,MAAfwQ,IACF4d,EAAK5e,GAAU,CAACvP,OAAQ,CAACD,KAAIG,UAASyD,MAAO,CAACsL,KAAMsB,MAEtD,MAAMm1B,EAAe7pC,eAAa8U,iBAAiB,EAAG5Q,EAAEtE,MAAMY,QAAQ,GAEtE,GAAIqpC,IAAiBvX,EAAG1yB,MAAMY,OAAS,EACrC,MAAM,IAAIwB,MAEN,qDAAQswB,EAAG1yB,MAAMY,OAAS,kBAAkBqpC,KAGlD,MAAMC,EAAc51B,aAAWoe,EAAGxzB,MAAO,SACnCwE,EAAO1E,OAAKmrC,mBACDnrC,OAAK0F,cAAcguB,EAAG1yB,OAAQkqC,GAEzCnlC,EAAQN,EAAQ9E,KAAKQ,IAAIuyB,EAAGpyB,QAAQP,OACpCqqC,EAAW1X,EAAG1yB,MAAM0yB,EAAG1yB,MAAMY,OAAS,GACtCypC,EAAgBL,EAClB,CAACnmC,EAAWgI,IAAchI,EAAIumC,EAAWv+B,EAAI,EAC7C,CAAChI,EAAWgI,IAAchI,EAAIgI,EAClC,IAAK,IAAIhI,EAAI,EAAGA,EAAIkB,EAAMnE,OAAQiD,GAAKumC,EACrC,IAAK,IAAIv+B,EAAI,EAAGA,EAAIu+B,EAAUv+B,IAAK,CACjC,MAAMkV,EAAMspB,EAAcxmC,EAAGgI,GAC7B,GAAU,IAANA,EACFnI,EAAKqd,GAAOgpB,EAAY,EAAIhlC,EAAMgc,OAC7B,CACL,MAAMupB,EAAUD,EAAcxmC,EAAGgI,EAAI,GACrCnI,EAAKqd,GAAOgpB,EAAYhlC,EAAMulC,GAAW5mC,EAAK4mC,GACtBvlC,EAAMgc,GAAOrd,EAAK4mC,IAKhD,MAAM/kC,EAASd,EAAQ/D,eAAegyB,EAAG1yB,MAAOkqC,EAAaxmC,GAE7D,GAAmB,MAAfoR,EAAqB,CACvB,MACMy1B,EAA0Bz2B,GAC5B,CAACvP,OAAQ,CAACD,EAAGiB,GAASd,UAASyD,MAAO,CAACsL,KAFhBpT,eAAaoqC,uBAAuB11B,MAO/D,OAHArQ,EAAQ/B,8BAA8B6C,GACtCd,EAAQ/B,8BAA8BgwB,GAE/B6X,EAGT,OAAOhlC,CACT,GCEO,MAAMklC,GAA6B,CACxCxmC,WAAYymC,SACZvmC,YAAa,MACbC,oBA9DEC,GAEF,MAAME,OAACA,EAAME,QAAEA,EAAOyD,MAAEA,GAAS7D,GAC3BC,EAACA,GAAKC,GACNmQ,KAACA,EAAIq1B,UAAEA,EAASC,QAAEA,GAAW9hC,EAEnCzJ,EAAiB6F,EAAG,UAEpB,MAAMwQ,EAAc1U,eAAa2U,mBAAmB,CAACL,GAAOpQ,EAAEtE,MAAMY,QACpE,IAAI8xB,EAAKpuB,EACU,MAAfwQ,IACF4d,EAAK5e,GAAU,CAACvP,OAAQ,CAACD,KAAIG,UAASyD,MAAO,CAACsL,KAAMsB,MAEtD,MAAMm1B,EAAe7pC,eAAa8U,iBAAiB,EAAG5Q,EAAEtE,MAAMY,QAAQ,GAEtE,GAAIqpC,IAAiBvX,EAAG1yB,MAAMY,OAAS,EACrC,MAAM,IAAIwB,MAEN,oDAAQswB,EAAG1yB,MAAMY,OAAS,kBAAkBqpC,KAGlD,MAAMC,EAAc51B,aAAWoe,EAAGxzB,MAAO,SACnCwE,EAAO1E,OAAK+H,oBACD/H,OAAK0F,cAAcguB,EAAG1yB,OAAQkqC,GAEzCnlC,EAAQN,EAAQ9E,KAAKQ,IAAIuyB,EAAGpyB,QAAQP,OACpCqqC,EAAW1X,EAAG1yB,MAAM0yB,EAAG1yB,MAAMY,OAAS,GACtCypC,EAAgBL,EAClB,CAACnmC,EAAWgI,IAAchI,EAAIumC,EAAWv+B,EAAI,EAC7C,CAAChI,EAAWgI,IAAchI,EAAIgI,EAClC,IAAK,IAAIhI,EAAI,EAAGA,EAAIkB,EAAMnE,OAAQiD,GAAKumC,EACrC,IAAK,IAAIv+B,EAAI,EAAGA,EAAIu+B,EAAUv+B,IAAK,CACjC,MAAMkV,EAAMspB,EAAcxmC,EAAGgI,GAC7B,GAAU,IAANA,EACFnI,EAAKqd,GAAOgpB,EAAY,EAAIhlC,EAAMgc,OAC7B,CACL,MAAMupB,EAAUD,EAAcxmC,EAAGgI,EAAI,GACrCnI,EAAKqd,GAAOgpB,EAAYhlC,EAAMulC,GAAW5mC,EAAK4mC,GACtBvlC,EAAMgc,GAAOrd,EAAK4mC,IAKhD,MAAM/kC,EAASd,EAAQ/D,eAAegyB,EAAG1yB,MAAOkqC,EAAaxmC,GAE7D,GAAmB,MAAfoR,EAAqB,CACvB,MACMy1B,EAA0Bz2B,GAC5B,CAACvP,OAAQ,CAACD,EAAGiB,GAASd,UAASyD,MAAO,CAACsL,KAFhBpT,eAAaoqC,uBAAuB11B,MAO/D,OAHArQ,EAAQ/B,8BAA8B6C,GACtCd,EAAQ/B,8BAA8BgwB,GAE/B6X,EAGT,OAAOhlC,CACT,GC5BO,MAAMolC,GAAoC,CAC/C1mC,WAAY2mC,gBACZzmC,YAAa,MACbC,oBAlC4BC,GAK5B,MAAME,OAACA,EAAME,QAAEA,EAAOyD,MAAEA,GAAS7D,GAC3BC,EAACA,EAACm6B,QAAEA,GAAWl6B,GACf2G,KAACA,EAAIO,aAAEA,GAAgBvD,EAE7B,GAAuB,IAAnB5D,EAAEtE,MAAMY,OAAc,CACxB,MAGMwK,EACFP,EAJUpG,EAAQ9E,KAAKQ,IAAImE,EAAEhE,QAAQP,OACrB0E,EAAQ9E,KAAKQ,IAAIs+B,EAAQn+B,QAAQP,OAGhB0+B,EAAQv/B,MAAOu/B,EAAQz+B,MAAOkL,GAEnE,OAAOzG,EAAQ/D,eAAe,CAACwK,GAAOuzB,EAAQv/B,MAAOkM,GAChD,GAAuB,IAAnB9G,EAAEtE,MAAMY,OAAc,CAC/B,MAGMgL,EAASN,EAHF7G,EAAQzC,WAA4BsC,GAC9BG,EAAQzC,WAA4By8B,GAEHvzB,EAAMO,GAE1D,OAAOhH,EAAQ/D,eAAekL,EAAO5L,MAAOy+B,EAAQv/B,MAAO0M,EAAO7L,QAGpE,MAAM,IAAIqC,MAEN,qEAAGkC,EAAEtE,MAAMY,UACjB,GCoBO,MAAMiqC,GAAmC,CAC9C5mC,WAAY6mC,eACZ3mC,YAAa,MACbC,oBArD2BC,GAK3B,MAAME,OAACA,EAAME,QAAEA,EAAOyD,MAAEA,GAAS7D,GAC3BC,EAACA,GAAKC,GACNisB,UAACA,EAAS8J,WAAEA,GAAcpyB,EAEhClJ,OAAKC,OACc,SAAfq7B,GACA,IAAM,+DACFA,MAER,MAAMjR,EAAY/kB,EAAEtE,MAAM,GACpB+qC,EAAczmC,EAAEtE,MAAM,GACtBgrC,EAAa1mC,EAAEtE,MAAM,GACrBirC,EAAa3mC,EAAEtE,MAAM,GAErBkrC,EAAeH,EAAcva,EAC7B2a,EAAcH,EAAaxa,EAC3B4a,EAAcH,GAAcza,EAAYA,GAExCiE,EAAUhwB,EAAQ9E,KAAKQ,IAAImE,EAAEhE,QAAQP,OACrCwF,EACF,IAAI3B,aAAaylB,EAAY6hB,EAAeC,EAAcC,GAE9D,IAAIC,EAAY,EAChB,IAAK,IAAIrjC,EAAI,EAAGA,EAAIqhB,IAAarhB,EAC/B,IAAK,IAAIsjC,EAAI,EAAGA,EAAIJ,IAAgBI,EAAG,CACrC,MAAMC,EAAMznC,KAAKmK,MAAMq9B,EAAI9a,GACrBgb,EAAWF,EAAI9a,EACrB,IAAK,IAAIib,EAAI,EAAGA,EAAIN,IAAeM,EAAG,CACpC,MAAMC,EAAM5nC,KAAKmK,MAAMw9B,EAAIjb,GAErBmb,GAAWH,EAAUhb,EADVib,EAAIjb,GAC6B4a,EAClD,IAAK,IAAIpqC,EAAI,EAAGA,EAAIoqC,IAAepqC,EAAG,CACpC,MACM4qC,EADM5qC,EAAI2qC,EAENV,GAAcS,EAAMV,GAAcO,EAAMR,EAAc/iC,IAChEzC,EAAO8lC,KAAe5W,EAAQmX,KAMtC,OAAOnnC,EAAQ/D,eACX,CAAC2oB,EAAW6hB,EAAcC,EAAaC,GAAc9mC,EAAEpF,MAAOqG,EACpE,YC/CgBsmC,GAAsBxnC,GAKpC,MAAME,OAACA,EAAME,QAAEA,EAAOyD,MAAEA,GAAS7D,GAC3BC,EAACA,EAAC47B,OAAEA,GAAU37B,GACduK,QAACA,EAAO8qB,IAAEA,EAAGoH,UAAEA,EAASnH,gBAAEA,GAAmB3xB,EAEnDzJ,EAAiB,CAAC6F,EAAG47B,GAAS,yBAE9B,MAAMvsB,EAAW3U,OAAKqG,eAAef,EAAEtE,OACjCshC,EAAgBtiC,OAAKqG,eAAe66B,EAAOlgC,OAEjD,IAAI8rC,EAAa9K,EACC,MAAd8K,IACFA,EAAa,CAAC,EAAG,IAGnB9sC,OAAKC,OACDmB,eAAa05B,+BAA+BhrB,EAASg9B,IACrD,IACI,gFAAkBh9B,oBAA0Bg9B,OAEpD,MAAMpX,EAAWt0B,eAAa+gC,kBAC1B78B,EAAEtE,MACFkgC,EAAOlgC,MAA2C8O,EAASg9B,EAC3DlS,EAAKC,GAAiB,IAEpBI,aAACA,EAAYD,YAAEA,EAAWlF,eAAEA,EAAcC,cAAEA,EAAaI,QAAEA,GAC7DT,EACEW,EAAUF,EAAQxK,KAClBuK,EAASC,EAAQC,IACjB2W,EAAQrX,EAASkO,YAAclO,EAASqB,WACxCsL,EAAI,IAAIthB,eAAa2U,EAAS/nB,SAAUrI,EAAEpF,OAC1C4L,EAAQrG,EAAQ9E,KAAKQ,IAAImE,EAAEhE,QAAQP,OACnCgiC,EAAQt9B,EAAQ9E,KAAKQ,IAAI+/B,EAAO5/B,QAAQP,OACxCiiC,EAAQX,EAAEthC,OAEhB,IAAK,IAAIiI,EAAI,EAAGA,EAAI0sB,EAASrL,YAAarhB,EAAG,CAC3C,MAAMi6B,EAAWj6B,EAAI2L,EAAS,GACxBuuB,EAAWl6B,EAAIq5B,EAAEvyB,QAAQ,GAC/B,IAAK,IAAIknB,EAAK,EAAGA,EAAKtB,EAASuB,YAAaD,EAAI,CAC9C,MAAMmM,EAAWD,EAAWlM,EAAKqL,EAAEvyB,QAAQ,GACrConB,EAAWF,EAAKtB,EAASE,aAAeM,EAC9C,IAAK,IAAIwC,EAAK,EAAGA,EAAKuC,IAAgBvC,EAAI,CACxC,MAAMV,EAAKd,EAAWwB,EAAK5C,EAC3B,GAAIkC,EAAK,GAAKA,GAAMtC,EAAS2B,SAC3B,SAEF,MAAM+L,EAAW1K,EAAK4J,EAAc,GAC9Be,EAAWJ,EAAWjL,EAAKrjB,EAAS,GAC1C,IAAK,IAAI4iB,EAAK,EAAGA,EAAK7B,EAAS8B,WAAYD,EAAI,CAC7C,MAAM+L,EAAWH,EAAW5L,EAAK8K,EAAEvyB,QAAQ,GACrC2nB,EAAWF,EAAK7B,EAASG,YAAcQ,EAC7C,IAAK,IAAIsC,EAAK,EAAGA,EAAKqC,IAAerC,EAAI,CACvC,MAAMT,EAAKT,EAAWkB,EAAK5C,EAC3B,GAAImC,EAAK,GAAKA,GAAMxC,EAASkC,QAC3B,SAEF,MAAM+N,EAAWvC,EAAWzK,EAAK2J,EAAc,GACzCiB,EAAWF,EAAWnL,EAAKxC,EAASqB,WAC1C,IAAI6O,EAAWtC,EACXE,EAAWmC,EACf,IAAK,IAAIlC,EAAK,EAAGA,EAAK/N,EAASqB,aAAc0M,EAAI,CAC/C,MAAMC,EAAO53B,EAAMy3B,EAAWE,GAC9B,IAAK,IAAIuJ,EAAI,EAAGA,EAAID,IAASC,EAC3BhK,EAAM4C,EAAWoH,IAAMtJ,EAAOX,EAAMS,EAAWwJ,GAEjDpH,GAAYmH,EACZvJ,GAAYuJ,OAQxB,OAAOtnC,EAAQ/D,eAAe2gC,EAAErhC,MAAOqhC,EAAEniC,MAAOmiC,EAAEthC,OACpD,CAEO,MAAMksC,GAA4C,CACvDhoC,WAAYioC,wBACZ/nC,YAAa,MACbC,WAAYynC,ICxBP,MAAMM,GAA0D,CACrEloC,WAAYmoC,sCACZjoC,YAAa,MACbC,oBA/DkDC,GAKlD,MAAME,OAACA,EAAME,QAAEA,EAAOyD,MAAEA,GAAS7D,GAC3BC,EAACA,EAACo2B,GAAEA,GAAMn2B,GACVuK,QAACA,EAAOkyB,UAAEA,EAASpH,IAAEA,EAAGC,gBAAEA,EAAeoJ,YAAEA,GAAe/6B,EAEhEzJ,EAAiB,CAAC6F,EAAGo2B,GAAK,uCAE1B,MAAMhG,EAAWt0B,eAAa+gC,kBAC1B78B,EAAEtE,MAA2CijC,EAAan0B,EAC1DkyB,EAAWpH,EAAKC,GAAiB,IAE/BjF,aAACA,EAAYC,YAAEA,EAAWoF,aAAEA,EAAYD,YAAEA,GAAetF,EAEzDwO,EAAK,IAAInjB,eAAa2U,EAASuO,YAAa,WAE5Cxc,EAAUiO,EAASS,QAAQxK,KAC3BwY,EAASzO,EAASS,QAAQC,IAC1B2W,EAAQrX,EAASkO,YAAclO,EAASqB,WAExCjrB,EAAQrG,EAAQ9E,KAAKQ,IAAImE,EAAEhE,QAAQP,OACnCwL,EAAO,IAAIwU,eAAazb,EAAEtE,MAAOsE,EAAEpF,MAAO4L,GAC1Cs4B,EAAS3+B,EAAQ9E,KAAKQ,IAAIu6B,EAAGp6B,QAAQP,OACrC+6B,EAAQ,IAAI/a,eAAa2a,EAAG16B,MAAO06B,EAAGx7B,MAAOkkC,GACnD,IAAK,IAAI1L,EAAK,EAAGA,EAAKuC,IAAgBvC,EAAI,CACxC,MAAM2L,EAAQv/B,KAAK0N,IAAI,EAAG1N,KAAKyI,MAAM42B,EAASzL,GAAM9C,IAC9C0O,EAAQx/B,KAAKoO,IACfwiB,EAASuB,WAAYvB,EAAS2B,SAAW8M,EAASzL,GAAM9C,GAE5D,IAAK,IAAI+C,EAAK,EAAGA,EAAKqC,IAAerC,EAAI,CACvC,MAAM4L,EAAQz/B,KAAK0N,IAAI,EAAG1N,KAAKyI,MAAMka,EAAUkR,GAAM9C,IAC/C2O,EAAQ1/B,KAAKoO,IACfwiB,EAAS8B,UAAW9B,EAASkC,QAAUnQ,EAAUkR,GAAM9C,GAE3D,IAAK,IAAI8N,EAAK,EAAGA,EAAKjO,EAASkO,cAAeD,EAAI,CAChD,MAAMF,EAAK3+B,KAAK6f,MAAMgf,EAAKoJ,GACrBM,EAAK1J,EAAKoJ,EAEhB,IAAI1Q,EAAU,EACd,IAAK,IAAIrzB,EAAI,EAAGA,EAAI0sB,EAASrL,YAAarhB,EACxC,IAAK,IAAIguB,EAAKqN,EAAOrN,EAAKsN,IAAStN,EAAI,CACrC,MAAMgB,EAAKU,EAAK1B,EAAKpB,EAAeuO,EACpC,IAAK,IAAI5M,EAAKgN,EAAOhN,EAAKiN,IAASjN,EAAI,CACrC,MAAMW,EAAKS,EAAKpB,EAAK1B,EAAcpO,EACnC4U,GAAY9vB,EAAKpL,IAAI6H,EAAGgvB,EAAIE,EAAIuL,GAC3B3H,EAAM36B,IAAI6H,EAAGguB,EAAIO,EAAIoM,IAIhCO,EAAG1iC,IAAI66B,EAAS3D,EAAIC,EAAI8K,EAAI4J,KAKlC,OAAO5nC,EAAQ/D,eAAewiC,EAAGljC,MAAOkjC,EAAGhkC,MAAOgkC,EAAGnjC,OACvD,GCyBO,MAAMusC,GAAyD,CACpEroC,WAAYsoC,qCACZpoC,YAAa,MACbC,oBAtFiDC,GAKjD,MAAME,OAACA,EAAME,QAAEA,EAAOyD,MAAEA,GAAS7D,GAC3Bq2B,GAACA,EAAEwF,OAAEA,GAAU37B,GACfuK,QAACA,EAAOkyB,UAAEA,EAASpH,IAAEA,EAAGC,gBAAEA,EAAe7W,WAAEA,GAAc9a,EAE/DzJ,EAAiB,CAACi8B,EAAIwF,GAAS,sCAE/B,MAAMyD,EAAY3kC,OAAKqG,eAAeq1B,EAAG16B,OACnCshC,EAAgBtiC,OAAKqG,eAAe66B,EAAOlgC,OAE3C00B,EAAWt0B,eAAa+gC,kBAC1Bne,EAAYkd,EAAOlgC,MAA2C8O,EAC9DkyB,EAAWpH,EAAKC,GAAiB,GAE/Be,EAAK,IAAI7a,eAAa2U,EAASyF,QAAS,WACxCyJ,EAAWhJ,EAAG76B,QACbqmC,EAAMC,EAAMC,GAAQ1L,EAAG9rB,QACxB+0B,EAAWp/B,EAAQ9E,KAAKQ,IAAIu6B,EAAGp6B,QAAQP,QACtCwlC,EAAMC,EAAMC,GAAQ9B,EACrBG,EAAYr/B,EAAQ9E,KAAKQ,IAAI+/B,EAAO5/B,QAAQP,QAC3CgkC,EAAOC,EAAOC,GAAS3C,GACxBjY,UACJA,EAAS4Q,aACTA,EAAYD,YACZA,EAAWjE,WACXA,EAAUM,SACVA,EAAQO,QACRA,EAAOgM,YACPA,EAAW3M,UACXA,EAASO,SACTA,EAAQ5B,aACRA,EAAYC,YACZA,GACEH,EACEyO,EAASlJ,EAAe,EAAIvF,EAASS,QAAQC,IAC7C3O,EAAUuT,EAAc,EAAItF,EAASS,QAAQxK,KAC7CohB,EAAQnJ,EAAc7M,EAE5B,IAAK,IAAI/tB,EAAI,EAAGA,EAAIqhB,IAAarhB,EAC/B,IAAK,IAAIy6B,EAAK,EAAGA,EAAK1M,IAAc0M,EAClC,IAAK,IAAIzL,EAAK,EAAGA,EAAKX,IAAYW,EAAI,CACpC,MAAMd,EAAWc,EAAKmM,EAChBhN,EAAQryB,KAAK0N,IAAI,EAAG1N,KAAKyI,KAAK2pB,EAAWtB,IACzC0O,EACFx/B,KAAKoO,IAAI+jB,GAAYgE,EAAe/D,GAAYtB,GAEpD,IAAK,IAAIsC,EAAK,EAAGA,EAAKN,IAAWM,EAAI,CACnC,MAAMT,EAAWS,EAAKzQ,EAChBiQ,EAAQ5yB,KAAK0N,IAAI,EAAG1N,KAAKyI,KAAKkqB,EAAW5B,IACzC2O,EACF1/B,KAAKoO,IAAIskB,GAAWwD,EAAcvD,GAAY5B,GAElD,IAAIwG,EAAU,EACd,IAAK,IAAIrF,EAAKG,EAAOH,EAAKsN,IAAStN,EAAI,CACrC,MAAM0B,EAAK1B,EAAKpB,EAAesB,EAE/B,IAAK,IAAIK,EAAKG,EAAOH,EAAKiN,IAASjN,EAAI,CACrC,MACM2N,EAAWqB,EAAOv9B,EAAIw9B,EAAOxP,EAAKyP,EAAOlP,EACzC4N,EAAYJ,GAAS9J,EAAe,EAAIvC,GAC1CsM,GAAShK,EAAc,GAHhBzD,EAAK1B,EAAc4B,IAGOwN,EAAQxB,EAE7C,IAAK,IAAI4J,EAAK,EAAGA,EAAKN,IAASM,EAAI,CAIjChR,GAFcwI,EAASK,GADZzB,EAAKsJ,EAAQM,IAETvI,EAAUK,EAAYkI,KAK3CzI,EAASwC,EAAOp+B,EAAIq+B,EAAOrP,EAAKsP,EAAOpP,EAAKuL,GAAMpH,GAM1D,OAAO52B,EAAQ/D,eAAek6B,EAAG56B,MAAO46B,EAAG17B,MAAO07B,EAAG76B,OACvD,GC/DO,MAAMysC,GAA2B,CACtCvoC,WAAYwoC,OACZtoC,YAAa,MACbC,oBAtBmBC,GAEnB,MAAME,OAACA,EAAME,QAAEA,GAAWJ,GACpBC,EAACA,GAAKC,EAENmP,EAAQ1U,OAAK0F,cAAcJ,EAAEtE,OAE7B8K,EAAQrG,EAAQ9E,KAAKQ,IAAImE,EAAEhE,QAAQP,OACnC6L,EAASzJ,SAAO,CAACuR,EAAOA,GAAQpP,EAAEpF,OAClCwE,EAAOkI,EAAO7L,OACpB,IAAK,IAAI8D,EAAI,EAAGA,EAAIiH,EAAMlK,OAAQiD,IAChCH,EAAKG,EAAI6P,EAAQ7P,GAAKiH,EAAMjH,GAG9B,MAAM8I,EAAW,IAAIrI,EAAEtE,SAAUsE,EAAEtE,OAEnC,OAAOyE,EAAQ/D,eAAeiM,EAAUf,EAAO1M,MAAO0M,EAAO7L,OAC/D,GCjBa2sC,GAAiC,CAC5CzoC,WAAY0oC,aACZxoC,YAAa,MACbC,WAAY,EAAEG,SAAQE,UAASyD,YAC7B,MAAM5D,EAACA,EAAC47B,OAAEA,GAAU37B,GACduK,QAACA,EAAO8qB,IAAEA,EAAGoH,UAAEA,GAAa94B,EAC5B1D,EAAaC,EAEbqG,EAAQtG,EAAW7E,KAAKQ,IAAImE,EAAEhE,QAAQP,OACtC0T,EAAQnP,EAAEtE,MAAMY,OAEhBgsC,EAAapoC,EAAW7E,KAAKQ,IAAI+/B,EAAO5/B,QAAQP,OAChD8sC,EAAa3M,EAAOlgC,MAAMY,QAE1ByoB,UACJA,EAASgN,SACTA,EAAQO,QACRA,EAAOb,WACPA,EAAUE,UACVA,EAASO,SACTA,EAAQrB,QACRA,EAAOP,aACPA,EAAYC,YACZA,EAAWoF,aACXA,EAAYD,YACZA,EAAWlF,eACXA,EAAcC,cACdA,EAAapoB,SACbA,GAEEvM,eAAa0sC,sBACTxoC,EAAEtE,MACFkgC,EAAOlgC,MAAmC8O,EAAS8qB,EACnD,OAAyBoH,GAE3B7N,EAAUn0B,OAAK0F,cAAciI,GAC7BogC,EAAUpgC,EAAS/L,OACnB60B,EAAaz2B,OAAKgN,kBAAkB1H,EAAEpF,MAAOi0B,GAMnD,IAAK,IAAInrB,EAAI,EAAGA,EAAIqhB,IAAarhB,EAC/B,IAAK,IAAIglC,EAAO,EAAGA,EAAO/W,IAAa+W,EAAM,CAC3C,MAAMC,EAAOD,EAAOpY,EAAeO,EAAQC,IAC3C,IAAK,IAAI8X,EAAO,EAAGA,EAAO1W,IAAY0W,EAAM,CAC1C,MAAMC,EAAOD,EAAOrY,EAAcM,EAAQxK,KAC1C,IAAK,IAAI3pB,EAAI,EAAGA,EAAI+0B,IAAc/0B,EAAG,CACnC,IAAIosC,EAAS37B,OAAO47B,iBACpB,IAAK,IAAI/B,EAAI,EAAGA,EAAIrR,IAAgBqR,EAAG,CACrC,MAAMgC,EAAML,EAAO3B,EAAIxW,EACvB,GAAIwY,GAAO,GAAKA,EAAMjX,EACpB,IAAK,IAAIoV,EAAI,EAAGA,EAAIzR,IAAeyR,EAAG,CACpC,MAAM8B,EAAMJ,EAAO1B,EAAI1W,EACvB,GAAIwY,GAAO,GAAKA,EAAM3W,EAAS,CAC7B,MAAM4W,EAASxuC,OAAKqH,WAChB,CAAC2B,EAAGslC,EAAKC,EAAKvsC,GAAIyS,EAAOzU,OAAKqG,eAAef,EAAEtE,QAC7CytC,EAAczuC,OAAKqH,WACrB,CAACilC,EAAGG,EAAGzqC,GAAI6rC,EACX7tC,OAAKqG,eAAe66B,EAAOlgC,QACzB0tC,EAAM5iC,EAAM0iC,GAAUZ,EAAWa,GACnCC,EAAMN,IACRA,EAASM,KAQnBjY,EAFoBz2B,OAAKqH,WACrB,CAAC2B,EAAGglC,EAAME,EAAMlsC,GAAI+rC,EAAS/tC,OAAKqG,eAAesH,KAC3BygC,IASlC,MAAO,CAAC9sC,OAHOkE,EAAW1E,MACtBd,OAAK4I,aAAa6tB,EAAYnxB,EAAEpF,OAAQyN,EAAUrI,EAAEpF,OAExCc,MAAO2M,EAAUzN,MAAOoF,EAAEpF,MAAM,GC/EvCyuC,GAA+C,CAC1D1pC,WAAY2pC,2BACZzpC,YAAa,MACbC,WAAY,EAAEG,SAAQE,UAASyD,YAC7B,MAAM5D,EAACA,EAAC47B,OAAEA,EAAMxF,GAAEA,GACdn2B,GACEuK,QAACA,EAAO8qB,IAAEA,EAAGoH,UAAEA,GAAa94B,EAC5B1D,EAAaC,EAEbiuB,EACF1zB,OAAK6uC,cACDvpC,EAAEtE,MAAOwE,EAAW7E,KAAKQ,IAAImE,EAAEhE,QAAQP,QAGzC+tC,EAAU9uC,OAAK6uC,cACD3N,EAAOlgC,MACPwE,EAAW7E,KAAKQ,IAAI+/B,EAAO5/B,QAAQP,SAGjDspB,UACJA,EAASgN,SACTA,EAAQO,QACRA,EAAOb,WACPA,EAAUE,UACVA,EAASO,SACTA,EAAQrB,QACRA,EAAOP,aACPA,EAAYC,YACZA,EAAWoF,aACXA,EAAYD,YACZA,EAAWlF,eACXA,EAAcC,cACdA,EAAapoB,SACbA,GAEEvM,eAAa0sC,sBACTxoC,EAAEtE,MACFkgC,EAAOlgC,MAAmC8O,EAAS8qB,EACnD,OAAyBoH,GAEjChiC,OAAKC,OACDy7B,EAAG1a,OAASrT,EAAS/L,QACrB,IAAM,YAAYgtC,oEACuBjhC,EAAS/L,mBAC3C85B,EAAG1a,SAEd,MAAM+tB,EACF/uC,OAAK6uC,cACDlhC,EAAUnI,EAAW7E,KAAKQ,IAAIu6B,EAAGp6B,QAAQP,QAK3CiuC,EAAYhvC,OAAKivC,0BACD/N,EAAOlgC,MAAOkgC,EAAOhhC,OAO3C,IAAK,IAAI8I,EAAI,EAAGA,EAAIqhB,IAAarhB,EAC/B,IAAK,IAAIglC,EAAO,EAAGA,EAAO/W,IAAa+W,EAAM,CAC3C,MAAMC,EAAOD,EAAOpY,EAAeO,EAAQC,IAC3C,IAAK,IAAI8X,EAAO,EAAGA,EAAO1W,IAAY0W,EAAM,CAC1C,MAAMC,EAAOD,EAAOrY,EAAcM,EAAQxK,KAC1C,IAAK,IAAI3pB,EAAI,EAAGA,EAAI+0B,IAAc/0B,EAAG,CACnC,IAAIosC,EAAS37B,OAAO47B,iBAChBa,EAAO,EACPC,EAAO,EACX,IAAK,IAAI7C,EAAI,EAAGA,EAAIrR,IAAgBqR,EAAG,CACrC,MAAMgC,EAAML,EAAO3B,EAAIxW,EACvB,GAAIwY,GAAO,GAAKA,EAAMjX,EACpB,IAAK,IAAIoV,EAAI,EAAGA,EAAIzR,IAAeyR,EAAG,CACpC,MAAM8B,EAAMJ,EAAO1B,EAAI1W,EACvB,GAAIwY,GAAO,GAAKA,EAAM3W,EAAS,CAC7B,MAAM8W,EAAMhb,EAAG1qB,GAAGslC,GAAKC,GAAKvsC,GAAK8sC,EAAQxC,GAAGG,GAAGzqC,GAC3C0sC,EAAMN,IACRA,EAASM,EACTQ,EAAO5C,EACP6C,EAAO1C,KAMjBuC,EAAUE,GAAMC,GAAMntC,IAAM+sC,EAAI/lC,GAAGglC,GAAME,GAAMlsC,KASvD,MAAO,CAACV,OAHOkE,EAAW1E,MACtBd,OAAK4I,aAAaomC,EAAW1pC,EAAEpF,OAAQghC,EAAOlgC,MAAOkgC,EAAOhhC,OAEhDc,MAAOkgC,EAAOlgC,MAAOd,MAAOghC,EAAOhhC,MAAM,GC/FhDkvC,GAA8C,CACzDnqC,WAAYoqC,0BACZlqC,YAAa,MACbC,WAAY,EAAEG,SAAQE,UAASyD,YAC7B,MAAM5D,EAACA,EAAC47B,OAAEA,EAAMxF,GAAEA,GACdn2B,GACEuK,QAACA,EAAO8qB,IAAEA,EAAGoH,UAAEA,GAAa94B,EAC5B1D,EAAaC,EAEbiuB,EACF1zB,OAAK6uC,cACDvpC,EAAEtE,MAAOwE,EAAW7E,KAAKQ,IAAImE,EAAEhE,QAAQP,QAGzC+tC,EAAU9uC,OAAK6uC,cACD3N,EAAOlgC,MACPwE,EAAW7E,KAAKQ,IAAI+/B,EAAO5/B,QAAQP,SAGjDspB,UACJA,EAASgN,SACTA,EAAQO,QACRA,EAAOb,WACPA,EAAUE,UACVA,EAASO,SACTA,EAAQrB,QACRA,EAAOP,aACPA,EAAYC,YACZA,EAAWoF,aACXA,EAAYD,YACZA,EAAWlF,eACXA,EAAcC,cACdA,EAAapoB,SACbA,GAEEvM,eAAa0sC,sBACTxoC,EAAEtE,MACFkgC,EAAOlgC,MAAmC8O,EAAS8qB,EACnD,OAAyBoH,GAEjChiC,OAAKC,OACDy7B,EAAG1a,OAASrT,EAAS/L,QACrB,IAAM,YAAYytC,mEACuB1hC,EAAS/L,mBAC3C85B,EAAG1a,SAEd,MAAM+tB,EACF/uC,OAAK6uC,cACDlhC,EAAUnI,EAAW7E,KAAKQ,IAAIu6B,EAAGp6B,QAAQP,QAK3CiuC,EACFhvC,OAAKivC,0BAA0B3pC,EAAEtE,MAAOsE,EAAEpF,OAO9C,IAAK,IAAI8I,EAAI,EAAGA,EAAIqhB,IAAarhB,EAC/B,IAAK,IAAIglC,EAAO,EAAGA,EAAO/W,IAAa+W,EAAM,CAC3C,MAAMC,EAAOD,EAAOpY,EAAeO,EAAQC,IAC3C,IAAK,IAAI8X,EAAO,EAAGA,EAAO1W,IAAY0W,EAAM,CAC1C,MAAMC,EAAOD,EAAOrY,EAAcM,EAAQxK,KAC1C,IAAK,IAAI3pB,EAAI,EAAGA,EAAI+0B,IAAc/0B,EAAG,CACnC,IAAIosC,EAAS37B,OAAO47B,iBAChBiB,EAAUrB,EAAO,EAAK,EAAIA,EAC1BsB,EAAUpB,EAAO,EAAK,EAAIA,EAC9B,IAAK,IAAI7B,EAAI,EAAGA,EAAIrR,IAAgBqR,EAAG,CACrC,MAAMgC,EAAML,EAAO3B,EAAIxW,EACvB,GAAIwY,GAAO,GAAKA,EAAMjX,EACpB,IAAK,IAAIoV,EAAI,EAAGA,EAAIzR,IAAeyR,EAAG,CACpC,MAAM8B,EAAMJ,EAAO1B,EAAI1W,EACvB,GAAIwY,GAAO,GAAKA,EAAM3W,EAAS,CAC7B,MAAM8W,EAAMhb,EAAG1qB,GAAGslC,GAAKC,GAAKvsC,GAAK8sC,EAAQxC,GAAGG,GAAGzqC,GAC3C0sC,EAAMN,IACRA,EAASM,EACTY,EAAShB,EACTiB,EAAShB,KAMnBS,EAAUhmC,GAAGsmC,GAAQC,GAAQvtC,IAAM+sC,EAAI/lC,GAAGglC,GAAME,GAAMlsC,KAS9D,MAAO,CAACV,OAHOkE,EAAW1E,MACtBd,OAAK4I,aAAaomC,EAAW1pC,EAAEpF,OAAQoF,EAAEtE,MAAOsE,EAAEpF,OAEtCc,MAAOsE,EAAEtE,MAAOd,MAAOoF,EAAEpF,MAAM,YC1FnCgyB,GACZ7sB,GAEF,MAAME,OAACA,EAAME,QAAEA,EAAOyD,MAAEA,GAAS7D,GAC3BC,EAACA,GAAKC,GACNmQ,KAACA,EAAIC,SAAEA,GAAYzM,EAIzB,IAAIwqB,EAFJj0B,EAAiB6F,EAAG,OAIlBouB,EADc,SAAZpuB,EAAEpF,MACC+I,EAAK,CAAC1D,OAAQ,CAACD,KAAIG,UAASyD,MAAO,CAAChJ,MAAO,WAE3C8H,EAAS,CAACzC,OAAQ,CAACD,KAAIG,YAG9B,MAAMgP,EAAQif,EAAG1yB,MAAMY,OACjBgU,EAAO5V,OAAK6V,eAAeH,EAAMge,EAAG1yB,OACpC8U,EAAc1U,eAAa2U,mBAAmBH,EAAMnB,GAE1D,IAAIS,EAAgBU,EAChBI,EAAY0d,EACG,MAAf5d,IACFE,EACIlB,GAAU,CAACvP,OAAQ,CAACD,EAAGouB,GAAKjuB,UAASyD,MAAO,CAACsL,KAAMsB,KACvDZ,EAAgB9T,eAAa8U,iBAAiBhB,EAActT,OAAQ6S,IAGtErT,eAAauyB,2BACT,MAAOze,EAAec,EAAUhV,MAAMY,QAE1C,MAAO+L,EAAUwH,GACb/T,eAAagU,0BAA0BY,EAAUhV,MAAOkU,GAE5D,IAAI3O,EAASuB,EAAMrC,EAASkI,EADRvM,eAAakU,WAAWU,EAAU9V,MAAO,UAE7D,MAAMqS,EAAavS,OAAK0F,cAAcyP,GAChCzQ,EAAOe,EAAQ9E,KAAKQ,IAAIoF,EAAOjF,QAAQP,OAEvCgF,EAAQN,EAAQ9E,KAAKQ,IAAI6U,EAAU1U,QAAQP,OACjD,IAAK,IAAI8D,EAAI,EAAGA,EAAIH,EAAK9C,SAAUiD,EAAG,CACpC,MAAMgJ,EAAShJ,EAAI0N,EACnB,IAAI2f,EAAM,EACV,IAAK,IAAIrlB,EAAI,EAAGA,EAAI0F,IAAc1F,EAChCqlB,GAAOnsB,EAAM8H,EAAShB,GAExBnI,EAAKG,GAAKqtB,EAGZ,GAAIvc,EAAU,CACZ,MACM65B,EAAYjpC,EAClBA,EAAS4Y,GAAQ,CAAC5Z,OAAQ,CAACD,EAAGiB,GAASd,UAASyD,MAAO,CAAClI,MAFvCI,eAAa+U,qBAAqB5P,EAAOvF,MAAO4U,MAGjEnQ,EAAQ/B,8BAA8B8rC,GASxC,OANA/pC,EAAQ/B,8BAA8BgwB,GAEnB,MAAf5d,GACFrQ,EAAQ/B,8BAA8BsS,GAGjCzP,CACT,CAEO,MAAMkpC,GAA0B,CACrCxqC,WAAYyqC,MACZvqC,YAAa,MACbC,WAAY8sB,ICGP,MAAMyd,GAA6B,CACxC1qC,WAAY2qC,SACZzqC,YAAa,MACbC,oBAzEEC,GAEF,MAAME,OAACA,EAAME,QAAEA,EAAOyD,MAAEA,GAAS7D,GAC3BwqC,SAACA,GAAY3mC,EACbkqB,EAAU7tB,GAEVuqC,QAACA,EAAOC,WAAEA,EAAUC,OAAEA,GACxB5uC,eAAa6uC,qBAAqBJ,EAAUzc,EAAQxxB,QACxDR,eAAa8uC,oBAAoBJ,EAAQluC,OAAQouC,EAAQ5c,GACzD,MAAM+c,KAACA,EAAIC,MAAEA,GAAShvC,eAAaivC,qBAAqBN,EAAYC,GAE9DM,EAASF,EAAMxuC,OACrB,IAAIoe,EAAuB,KACvBuwB,EAAmBT,EAAQluC,OAC/B,MAAM4uC,EAAiC,GACvC,IAAK,IAAI3rC,EAAI,EAAGA,EAAIyrC,IAAUzrC,EAAG,CAC/B,IAAK,MAAM4rC,KAAUL,EAAMvrC,GAAI,CAC7B,MAAO6rC,mBAAoBl8B,EAAMm8B,WAAYC,GACzCxvC,eAAayvC,qBAAqBN,EAAkBP,EAAOS,IAC/D,IAAInrC,EACAlE,eAAa0vC,sBAAsBt8B,GACrClP,EAAI8tB,EAAQqd,IAEZnrC,EAAIwP,GAAU,CAACvP,OAAQ,CAACD,EAAG8tB,EAAQqd,IAAUhrC,UAASyD,MAAO,CAACsL,UAC9Dg8B,EAAiBpgC,KAAK9K,IAExB,MAAM2e,EAAwB3e,EAAEtE,MAAMmG,QACtC,IAAK,IAAIkJ,EAAI,EAAGA,EAAIugC,EAAahvC,SAAUyO,EACzC4T,EAAY8sB,OAAOH,EAAavgC,GAAI,EAAG,GAGpCrQ,OAAKk7B,YAAY51B,EAAEtE,MAAOijB,KAC7B3e,EAAI6Z,GAAQ,CAAC5Z,OAAQ,CAACD,KAAIG,UAASyD,MAAO,CAAClI,MAAOijB,KAClDusB,EAAiBpgC,KAAK9K,IAEZ,OAAR0a,EACFA,EAAM1a,GAGN0a,EAAMxM,GAAS,CAACjO,OAAQ,CAACwD,EAAGzD,EAAG0D,EAAGgX,GAAMva,YACxC+qC,EAAiBpgC,KAAK4P,IAGtBnb,EAAIyrC,EAAS,IACXH,EAAKtrC,IAAM,IACbmb,EAAMkS,GAAI,CACR3sB,OAAQ,CAACD,EAAG0a,GACZva,UACAyD,MAAO,CACLwM,KAAMy6B,EAAKtrC,IAAMirC,EAAQluC,OAAS2uC,GAClC56B,UAAU,KAGd66B,EAAiBpgC,KAAK4P,IAExBuwB,KAKJ,IAAK,MAAM5sC,KAAc6sC,EACnB7sC,IAAeqc,GAGnBva,EAAQ/B,8BAA8BC,GAGxC,OAAOqc,CACT,GCnDO,MAAMgxB,GAA8B,CACzC/rC,WAAYgsC,UACZ9rC,YAAa,MACbC,oBAzBsBC,GAEtB,MAAME,OAACA,EAAME,QAAEA,GAAWJ,GACpBq2B,GAACA,EAAE2G,EAAEA,GAAK98B,EAEhB9F,EAAiB,CAACi8B,EAAI2G,GAAI,WAE1B,MAAM19B,EAAe,IAAIC,aAAa5E,OAAK0F,cAAc28B,EAAErhC,QACrDD,EAAS0E,EAAQ9E,KAAKQ,IAAIkhC,EAAE/gC,QAAQP,OACpC8jC,EAAWp/B,EAAQ9E,KAAKQ,IAAIu6B,EAAGp6B,QAAQP,OAC7C,IAAK,IAAI8D,EAAI,EAAGA,EAAI9D,EAAOa,SAAUiD,EAAG,CACtC,MAAMqsC,EAAInwC,EAAO8D,GAEfF,EAAaE,GADXqsC,GAAK,EACWrM,EAAShgC,GAETggC,EAAShgC,IAAMqsC,EAAI,GAIzC,OAAOzrC,EAAQ/D,eAAe2gC,EAAErhC,MAAO,UAAW2D,EACpD,GCrBMwsC,GAAI/vC,eAAagwC,MACjBC,GAAKjwC,eAAakwC,OAClBC,GAAKnwC,eAAaowC,OAClBC,GAAKrwC,eAAaswC,OAClBC,GAAKvwC,eAAawwC,OAClBC,GAAKzwC,eAAa0wC,OAEXC,GAAM9kC,EACf+kC,OACC1kC,IACC,MAAM0e,EAAOlnB,KAAKknB,KAAK1e,GACjB4jC,EAAIpsC,KAAKC,IAAIuI,GACbvN,EAAI,GAAO,EAAMoxC,GAAID,GAC3B,OAAOllB,GACF,MACK6lB,GAAK9xC,EAAI4xC,IAAM5xC,EAAK0xC,IAAM1xC,EAAIwxC,IAAMxxC,EAAIsxC,IAAMtxC,EAC/C+E,KAAK2J,KAAKyiC,EAAIA,GAAG,IAInBe,GAA0B,CACrChtC,WAAY+sC,MACZ7sC,YAAa,MACbC,WAAY2sC,aCtBEpB,GAAWtrC,GAKzB,MAAME,OAACA,EAAME,QAAEA,EAAOyD,MAAEA,GAAS7D,GAC3B8C,MAACA,GAAS5C,GACV4K,IAACA,GAAOjH,EAER4b,EAAY3c,EAAMnH,MAAMY,OACxBqE,EAAWkC,EAAMnH,MAAMmG,QAC7B,IAAI+qC,EAAO/hC,EAWX,OAVIA,EAAM,IAERnQ,OAAKC,SACC6kB,EAAY,IAAM3U,GACpB,IAAM,mCAAoC2U,EAAY,OAClDA,OACRotB,EAAOptB,EAAY3U,EAAM,GAE3BlK,EAAS8qC,OAAOmB,EAAM,EAAG,GAElB/yB,GAAQ,CAAC5Z,OAAQ,CAACD,EAAG6C,GAAQ1C,UAASyD,MAAO,CAAClI,MAAOiF,IAC9D,CAEO,MAAMksC,GAAiC,CAC5CltC,WAAYmtC,aACZjtC,YAAa,MACbC,WAAYurC,IC5BD0B,GACT1sC,GAA6B,CAACoD,EAAWC,IAAcD,EAAIC,IAClDspC,GAAM5oC,EAAiB6oC,UAASF,IAEhCG,GAA8B,CACzCvtC,WAAYstC,UACZptC,YAAa,MACbC,WAAYktC,aCKEG,GACZtqC,EAAmBuqC,EACnBltC,GACF,MAAMwe,EAAa7b,EAAMnH,MACnBqrB,EAAQrI,EAAW,GACnB2uB,EAAW3uB,EAAW,GAEtB4uB,EAAYptC,EAAW7E,KAAKQ,IAAIgH,EAAM7G,QAEtCuxC,EAASD,EAAUnwC,mBAAmBE,KACtCmwC,EAASF,EAAUnwC,mBAAmBI,KAGtCiG,EAAc,CAACujB,EAAOsmB,GACtBrsC,EAAatG,OAAK0F,cAAcoD,GAChCkC,EAAahL,OAAKwG,uBAAuB,UAAWF,GACpD2E,EAAajL,OAAKwG,uBAAuB,UAAWF,GAE1D,IAAK,IAAI0C,EAAI,EAAGA,EAAIqjB,EAAOrjB,IAAK,CAE9B,MAAMu4B,EAAIp6B,GAAM,CACd5B,OAAQ,CAACD,EAAGutC,GACZptC,QAASD,EACT0D,MAAO,CAACoY,MAAO,CAACtY,EAAG,GAAIkD,KAAM,CAAC,EAAGymC,MAE7B9tC,EAAIsC,GAAM,CACd5B,OAAQ,CAACD,EAAGwtC,GACZrtC,QAASD,EACT0D,MAAO,CAACoY,MAAO,CAACtY,EAAG,GAAIkD,KAAM,CAAC,EAAGymC,MAG7BxqC,EAAQX,EAAQ,CAACjC,OAAQ,CAAC5C,KAAM4+B,EAAG1+B,KAAMgC,GAAIY,QAASD,KAGtD7C,KAACA,EAAIE,KAAEA,GAAQkwC,GAAQ5qC,EAAOuqC,EAASltC,GACvC0O,EAAM9S,eAAa0B,uBAAuBH,EAAME,GAEtD,IAAK,IAAIb,EAAI,EAAGA,EAAI2wC,EAAU3wC,IAAK,CACjC,MAAM0oB,EAAItpB,eAAa4xC,oBAAoB9+B,EAAKlS,GAChDgJ,EAAWhC,EAAI2pC,EAAW3wC,GAAK0oB,EAAE/nB,KACjCsI,EAAWjC,EAAI2pC,EAAW3wC,GAAK0oB,EAAE7nB,KAGnC2C,EAAW9B,8BAA8B69B,GACzC/7B,EAAW9B,8BAA8BmB,GACzCW,EAAW9B,8BAA8ByE,GAG3C,MAAM8qC,EACFztC,EAAW9D,eAAeoH,EAAa,UAAWkC,GAChDkoC,EACF1tC,EAAW9D,eAAeoH,EAAa,UAAWmC,GAEhD1E,EAASiB,EACX,CAACjC,OAAQ,CAAC5C,KAAMswC,EAAWpwC,KAAMqwC,GAAYztC,QAASD,IAK1D,OAHAA,EAAW9B,8BAA8BuvC,GACzCztC,EAAW9B,8BAA8BwvC,GAElC3sC,CACT,UAEgBwsC,GACZ5qC,EAAmBuqC,EACnBltC,GACF,MAAM2tC,EAAYnzC,OAAK0F,cAAcyC,EAAMnH,OAErC4xC,EAAYptC,EAAW7E,KAAKQ,IAAIgH,EAAM7G,QAEtCmG,EACFjC,EAAW7E,KAAKQ,IAAIyxC,EAAUnwC,mBAAmBE,KAAKrB,QAAQP,OAG5D2G,EACFlC,EAAW7E,KAAKQ,IAAIyxC,EAAUnwC,mBAAmBI,KAAKvB,QAAQP,OAGlE,GAsD6B,KADRmL,EArDHinC,GAsDHjnC,EAAO,GAtDQ,CAC5B,MAAM3F,EACF6sC,GAAU3rC,EAAUC,EAAUyrC,EAAWT,EAASltC,GAEhDsD,EAAc,CAACX,EAAMnH,MAAM,GAAImH,EAAMnH,MAAM,IAEjD,GAAI0xC,EAAS,CACX,MAAMW,EACF7tC,EAAW9D,eAAeoH,EAAa,UAAWvC,EAAO5D,MACvD2wC,EACF9tC,EAAW9D,eAAeoH,EAAa,UAAWvC,EAAO1D,MAEvD0wC,EAAuB/tC,EAAW9D,eACpC,GAAI,UACJ1B,OAAK+T,kBAAkBo/B,EAAmC,YACxDK,EACFxrC,EAAS,CAACzC,OAAQ,CAACD,EAAGiuC,GAAW9tC,QAASD,IAExCiuC,EACFjB,GAAcptC,WACV,CAACG,OAAQ,CAACwD,EAAGsqC,EAAUrqC,EAAGuqC,GAAW9tC,QAASD,IAEhDkuC,EACFlB,GAAcptC,WACV,CAACG,OAAQ,CAACwD,EAAGuqC,EAAUtqC,EAAGwqC,GAAe/tC,QAASD,IAGpDmuC,EACFnuC,EAAW7E,KAAKQ,IAAIsyC,EAAYnyC,QAAQP,OACtC6yC,EACFpuC,EAAW7E,KAAKQ,IAAIuyC,EAAYpyC,QAAQP,OAS5C,OAPAyE,EAAW9B,8BAA8B2vC,GACzC7tC,EAAW9B,8BAA8B4vC,GACzC9tC,EAAW9B,8BAA8B6vC,GACzC/tC,EAAW9B,8BAA8B8vC,GACzChuC,EAAW9B,8BAA8B+vC,GACzCjuC,EAAW9B,8BAA8BgwC,GAElC,CAAC/wC,KAAMgxC,EAAa9wC,KAAM+wC,GAGnC,OAAOrtC,EACF,CACL,MAEMstC,EAiKV,SACIlzC,EAAkBuL,EAAcwmC,GAClC,MAAMoB,EAAM,IAAIlvC,aAAoB,EAAPsH,GAE7B,IAAK,IAAIq1B,EAAI,EAAGA,EAAIr1B,EAAMq1B,IAAK,CAC7B,IAAI5+B,EAAO,EACPE,EAAO,EACX,IAAK,IAAI6nB,EAAI,EAAGA,EAAIxe,EAAMwe,IAAK,CAC7B,MAAMqpB,EAAI3yC,eAAa4yC,SAASzS,EAAI7W,EAAGxe,EAAMwmC,GACvCuB,EAAO7yC,eAAa4xC,oBAAoBryC,EAAsB+pB,GACpE/nB,GAAQsxC,EAAKtxC,KAAOoxC,EAAEpxC,KAAOsxC,EAAKpxC,KAAOkxC,EAAElxC,KAC3CA,GAAQoxC,EAAKtxC,KAAOoxC,EAAElxC,KAAOoxC,EAAKpxC,KAAOkxC,EAAEpxC,KAEzC+vC,IACF/vC,GAAQuJ,EACRrJ,GAAQqJ,GAEV9K,eAAa8yC,mBAAmBJ,EAAKnxC,EAAME,EAAM0+B,GAEnD,OAAOuS,CACT,CApLQK,CAHS/yC,eAAa0B,uBAAuB2E,EAAUC,GAGxByrC,EAAWT,GAE9C,OAAOtxC,eAAagzC,uBAAuBP,GAI/C,IAAuB3nC,CAFvB,CAOA,SAASknC,GACL3rC,EAAwBC,EAAwBwE,EAChDwmC,EACAltC,GACF,GAAa,IAAT0G,EACF,MAAO,CAACvJ,KAAM8E,EAAU5E,KAAM6E,GAGhC,MAAM/G,EAAOS,eAAa0B,uBAAuB2E,EAAUC,GAErD2sC,EAAOnoC,EAAO,EAEdooC,EAAclzC,eAAamzC,qBAAqB5zC,GAEhD6zC,EAAeF,EAAY3xC,KAC3B8xC,EAAeH,EAAYzxC,KAE3B6xC,EAAY,CAACF,EAAa5yC,QAE1B+yC,EACFnvC,EAAW9D,eAAegzC,EAAW,UAAWF,GAC9CI,EACFpvC,EAAW9D,eAAegzC,EAAW,UAAWD,GAE9CI,EAAiBrtC,EACnB,CAACjC,OAAQ,CAAC5C,KAAMgyC,EAAc9xC,KAAM+xC,GAAenvC,QAASD,IAE1DsvC,EAAa1zC,eAAa2zC,oBAAoBp0C,GAE9Cq0C,EAAcF,EAAWnyC,KACzBsyC,EAAcH,EAAWjyC,KAEzBqyC,EAAW,CAACF,EAAYpzC,QAExBuzC,EACF3vC,EAAW9D,eAAewzC,EAAU,UAAWF,GAC7CI,EACF5vC,EAAW9D,eAAewzC,EAAU,UAAWD,GAE7CI,EAAgB7tC,EAClB,CAACjC,OAAQ,CAAC5C,KAAMwyC,EAAatyC,KAAMuyC,GAAc3vC,QAASD,IAGxD8vC,EACFlC,GAAUoB,EAAcC,EAAcJ,EAAM3B,EAASltC,GAEnD+vC,EAAgBD,EAAa3yC,KAC7B6yC,EAAgBF,EAAazyC,KAE7B4yC,EAAa,CAACF,EAAc3zC,QAE5B8zC,EACFlwC,EAAW9D,eAAe+zC,EAAY,UAAWF,GAC/CI,EACFnwC,EAAW9D,eAAe+zC,EAAY,UAAWD,GAE/CI,EAAkBpuC,EAAQ,CAC9BjC,OAAQ,CAAC5C,KAAM+yC,EAAe7yC,KAAM8yC,GACpClwC,QAASD,IAGLqwC,EACFzC,GAAU4B,EAAaC,EAAaZ,EAAM3B,EAASltC,GAEjDswC,EAAeD,EAAYlzC,KAC3BozC,EAAeF,EAAYhzC,KAE3BmzC,EAAY,CAACF,EAAal0C,QAE1Bq0C,EACFzwC,EAAW9D,eAAes0C,EAAW,UAAWF,GAC9CI,EACF1wC,EAAW9D,eAAes0C,EAAW,UAAWD,GAE9CI,EAAiB3uC,EACnB,CAACjC,OAAQ,CAAC5C,KAAMszC,EAAcpzC,KAAMqzC,GAAezwC,QAASD,IAE1DuuC,EAAI3yC,eAAag1C,UAAUlqC,EAAMwmC,GACjC2D,EAAS,CAACtC,EAAEpxC,KAAKf,QAEjB00C,EAAY9wC,EAAW9D,eAAe20C,EAAQ,UAAWtC,EAAEpxC,MAC3D4zC,EAAY/wC,EAAW9D,eAAe20C,EAAQ,UAAWtC,EAAElxC,MAE3D8E,EAAcH,EAChB,CAACjC,OAAQ,CAAC5C,KAAM2zC,EAAWzzC,KAAM0zC,GAAY9wC,QAASD,IAEpDgxC,EACFhjC,GACI,CAACjO,OAAQ,CAACwD,EAAGpB,EAAaqB,EAAGmtC,GAAiB1wC,QAASD,IAGzDixC,EAAU/qC,EAAI,CACFnG,OAAQ,CAACwD,EAAG6sC,EAAiB5sC,EAAGwtC,GAChC/wC,QAASD,IAErBkxC,EAAUxrB,GAAI,CACF3lB,OAAQ,CAACwD,EAAG6sC,EAAiB5sC,EAAGwtC,GAChC/wC,QAASD,IAGrBmxC,EAAch0C,EAAK,CAAC4C,OAAQ,CAAC4C,MAAOsuC,GAAUhxC,QAASD,IACvDoxC,EAAcj0C,EAAK,CAAC4C,OAAQ,CAAC4C,MAAOuuC,GAAUjxC,QAASD,IAEvDqxC,EAAch0C,GAAK,CAAC0C,OAAQ,CAAC4C,MAAOsuC,GAAUhxC,QAASD,IACvDsxC,EAAcj0C,GAAK,CAAC0C,OAAQ,CAAC4C,MAAOuuC,GAAUjxC,QAASD,IAEvDuxC,EAAQ1mB,GAAO,CACnB9qB,OAAQ,CAACoxC,EAAuBC,GAChCnxC,QAASD,EACT0D,MAAO,CAACwM,KAAM,KAEVshC,EAAQ3mB,GAAO,CACnB9qB,OAAQ,CAACsxC,EAAuBC,GAChCrxC,QAASD,EACT0D,MAAO,CAACwM,KAAM,KAGVuhC,EAAYzxC,EAAW7E,KAAKQ,IAAI41C,EAAMz1C,QAAQP,OAC9Cm2C,GAAY1xC,EAAW7E,KAAKQ,IAAI61C,EAAM11C,QAAQP,OA2BpD,OAzBAyE,EAAW9B,8BAA8BixC,GACzCnvC,EAAW9B,8BAA8BkxC,GACzCpvC,EAAW9B,8BAA8BmxC,GACzCrvC,EAAW9B,8BAA8ByxC,GACzC3vC,EAAW9B,8BAA8B0xC,GACzC5vC,EAAW9B,8BAA8B2xC,GACzC7vC,EAAW9B,8BAA8BgyC,GACzClwC,EAAW9B,8BAA8BiyC,GACzCnwC,EAAW9B,8BAA8BkyC,GACzCpwC,EAAW9B,8BAA8BuyC,GACzCzwC,EAAW9B,8BAA8BwyC,GACzC1wC,EAAW9B,8BAA8ByyC,GACzC3wC,EAAW9B,8BAA8B4yC,GACzC9wC,EAAW9B,8BAA8B6yC,GACzC/wC,EAAW9B,8BAA8BiE,GACzCnC,EAAW9B,8BAA8B8yC,GACzChxC,EAAW9B,8BAA8B+yC,GACzCjxC,EAAW9B,8BAA8BgzC,GACzClxC,EAAW9B,8BAA8BizC,GACzCnxC,EAAW9B,8BAA8BmzC,GACzCrxC,EAAW9B,8BAA8BkzC,GACzCpxC,EAAW9B,8BAA8BozC,GACzCtxC,EAAW9B,8BAA8BqzC,GACzCvxC,EAAW9B,8BAA8BszC,GAElC,CAACr0C,KAAMs0C,EAAWp0C,KAAMq0C,GACjC,CCxQO,MAAMC,GAA0B,CACrClyC,WAAYmyC,MACZjyC,YAAa,MACbC,oBA/BkBC,GAElB,MAAME,OAACA,EAAME,QAAEA,GAAWJ,GACpB8C,MAACA,GAAS5C,EAEV4tC,EAAYnzC,OAAK0F,cAAcyC,EAAMnH,OAGrCq2C,EAAqBlvC,EAAMnH,MAAMmH,EAAMnH,MAAMY,OAAS,GAGtD01C,EAAUn4B,GAAQ,CACtB5Z,OAAQ,CAACD,EAAG6C,GACZ1C,UACAyD,MAAO,CAAClI,MAAO,CALHmyC,EAAYkE,EAKDA,MAGnB9wC,EAASksC,GAAS6E,GAAS,EAAO7xC,GAElC8xC,EACFp4B,GAAQ,CAAC5Z,OAAQ,CAACD,EAAGiB,GAASd,UAASyD,MAAO,CAAClI,MAAOmH,EAAMnH,SAKhE,OAHAyE,EAAQ/B,8BAA8B4zC,GACtC7xC,EAAQ/B,8BAA8B6C,GAE/BgxC,CACT,YC5BgB1gC,GAAKxR,GAEnB,MAAMI,QAACA,EAAOyD,MAAEA,GAAS7D,GACnBrE,MAACA,EAAKqL,MAAEA,EAAKnM,MAAEA,GAASgJ,EAExBe,EAAS/J,GAASF,OAAKw3C,WAAWnrC,GAClCtL,EAASf,OAAKgN,kBAAkB/C,EAAQjK,OAAK0F,cAAc1E,IAGjE,OASF,SACID,EAAoBsL,EAAsBnM,GAEzCa,EAAoB8V,KAAKxK,EAI9B,CAlBEorC,CAAW12C,EAAQsL,GAEZ5G,EAAQ/D,eAAeV,EAAOiJ,EAAQlJ,EAC/C,CAEO,MAAM22C,GAA2B,CACtCzyC,WAAY0yC,OACZxyC,YAAa,MACbC,WAAYyR,ICdP,MAAM+gC,GAAoC,CAC/C3yC,WAAY4yC,gBACZ1yC,YAAa,MACbC,WAAY,EAAEG,SAAQ2D,QAAOzD,cAC3B,MAAMyiC,MAACA,GAAS3iC,EACVC,EAAaC,EAEbmgB,EAAS5lB,OAAKwG,uBAChB0hC,EAAMhoC,MAA0BF,OAAK0F,cAAcwiC,EAAMlnC,SACtDqrB,EAAOmc,EAAaC,EAAYC,GAAeR,EAAMlnC,MAEtDgoC,EAAYxjC,EAAW7E,KAAKQ,IAAI+mC,EAAM5mC,QAAQP,OAEpD,IAAK,IAAI2P,EAAW,EAAGA,EAAW2b,EAAO3b,IAAY,CACnD,MAAMonC,EAAcpnC,EAAW+3B,EAAaD,EAAcE,EAE1D,IAAK,IAAIz6B,EAAM,EAAGA,EAAMu6B,EAAav6B,IAAO,CAC1C,MAAM8pC,EAAY9pC,GAAOw6B,EAAaC,GAEtC,IAAK,IAAIv6B,EAAM,EAAGA,EAAMs6B,EAAYt6B,IAAO,CACzC,MAAML,EAAYK,EAAMu6B,EAExB,IAAK,IAAIvP,EAAU,EAAGA,EAAUuP,EAAavP,IAAW,CACtD,MAAM6e,EAASlzC,KAAK2lC,MAAMhC,EAAat6B,EAAM,GACvC8pC,EAASH,EAAcC,EAAYjqC,EAAYqrB,EAErD,IAAI+e,EAAclP,EAAUiP,GAE5B,GAAID,GAAU,GAAKA,EAASvP,EAAY,CAKtCyP,EAAclP,EADV8O,EAAcC,EAFOC,EAAStP,EAEevP,GAGnDvT,EAAOqyB,GAAUC,KAOzB,MAAO,CAAC52C,OADOkE,EAAW1E,MAAM8kB,EAAQsiB,EAAMlnC,MAAOknC,EAAMhoC,OAC3Cc,MAAOknC,EAAMlnC,MAAOd,MAAOgoC,EAAMhoC,MAAM,GCgCpD,MAAMi4C,GAAkC,CAC7ClzC,WAAYmzC,cACZjzC,YAAa,MACbC,oBA1E0BC,GAK1B,MAAME,OAACA,EAAME,QAAEA,EAAOyD,MAAEA,GAAS7D,GAC3BC,EAACA,EAAC47B,OAAEA,EAAM3O,KAAEA,EAAItD,uBAAEA,GAA0B1pB,GAC5CuK,QACJA,EAAO8qB,IACPA,EAAGU,WACHA,EAAU0G,UACVA,EAASnH,gBACTA,EAAe7L,WACfA,EAAUE,eACVA,GACEhmB,EAEJ,IAAI3C,EAASw7B,GAAO,CAClBx8B,OAAQ,CAACD,IAAG47B,UACZz7B,UACAyD,MAAO,CAAC4G,UAAS8qB,MAAKU,aAAY0G,YAAWnH,qBAG/C,GAAItI,EAAM,CACR,MAAM8lB,EAAY9xC,EAKlB,GAAmB,SAAf+0B,GAA+C,IAAtB/I,EAAKvxB,MAAMY,QAClB,IAAlB2wB,EAAKvxB,MAAM,GAAU,CACvB,MAAMs3C,EAAen5B,GACjB,CAAC5Z,OAAQ,CAACD,EAAGitB,GAAO9sB,UAASyD,MAAO,CAAClI,MAAO,CAACuxB,EAAKvxB,MAAM,GAAI,EAAG,MACnEuF,EACImF,EAAI,CAACnG,OAAQ,CAACwD,EAAGxC,EAAQyC,EAAGsvC,GAAe7yC,YAC/CA,EAAQ/B,8BAA8B40C,QAItC/xC,EAASmF,EAAI,CAACnG,OAAQ,CAACwD,EAAGxC,EAAQyC,EAAGupB,GAAO9sB,YAE9CA,EAAQ/B,8BAA8B20C,GAGxC,GAAIrpB,EAAY,CACd,MAAMqpB,EAAY9xC,EAKlB,GAAmB,SAAf+0B,GAAwC,UAAftM,GACe,IAAxCC,EAAuBjuB,MAAMY,QACO,IAApCqtB,EAAuBjuB,MAAM,GAAU,CACzC,MAAMu3C,EAAgBp5B,GAAQ,CAC5B5Z,OAAQ,CAACD,EAAG2pB,GACZxpB,UACAyD,MAAO,CAAClI,MAAO,CAACiuB,EAAuBjuB,MAAM,GAAI,EAAG,MAEtDuF,EAASwoB,GACLtpB,EAASc,EAAQyoB,EAAYupB,EAAerpB,GAChDzpB,EAAQ/B,8BAA8B60C,QAEtChyC,EAASwoB,GACLtpB,EAASc,EAAQyoB,EAAYC,EAAwBC,GAE3DzpB,EAAQ/B,8BAA8B20C,GAGxC,OAAO9xC,CACT,GChCO,MAAMiyC,GAA2C,CACtDvzC,WAAYwzC,uBACZtzC,YAAa,MACbC,oBAzCmCC,GAKnC,MAAME,OAACA,EAAME,QAAEA,EAAOyD,MAAEA,GAAS7D,GAC3BC,EAACA,EAAC47B,OAAEA,EAAM3O,KAAEA,EAAItD,uBAAEA,GAA0B1pB,GAC5CuK,QACJA,EAAO8qB,IACPA,EAAGU,WACHA,EAAU0G,UACVA,EAASnH,gBACTA,EAAe7L,WACfA,EAAUE,eACVA,GACEhmB,EAEJ,IAAI3C,EAASsmC,GAAsB,CACjCtnC,OAAQ,CAACD,IAAG47B,UACZz7B,UACAyD,MAAO,CAAC4G,UAAS8qB,MAAKU,aAAY0G,YAAWnH,qBAG/C,GAAItI,EAAM,CACR,MAAMid,EAAYjpC,EAClBA,EAASmF,EAAI,CAACnG,OAAQ,CAACwD,EAAGxC,EAAQyC,EAAGupB,GAAO9sB,YAC5CA,EAAQ/B,8BAA8B8rC,GAExC,GAAIxgB,EAAY,CACd,MAAMwgB,EAAYjpC,EAClBA,EAASwoB,GACLtpB,EAASc,EAAQyoB,EAAYC,EAAwBC,GACzDzpB,EAAQ/B,8BAA8B8rC,GAGxC,OAAOjpC,CACT,GCZO,MAAMmyC,GAA+B,CAC1CzzC,WAAY0zC,WACZxzC,YAAa,MACbC,oBA3BEC,GACF,MAAME,OAACA,EAAME,QAAEA,GAAWJ,GACpBuzC,OAACA,EAAMviC,QAAEA,GAAW9Q,EAEpByK,EAAahQ,OAAK0F,cAAckzC,EAAO53C,OAEvCsV,EAAeD,EAAQrV,MACvB4O,EAAY0G,EAAaA,EAAa1U,OAAS,IAE9CkH,EAAa6G,EAAWE,EAAWC,GACtC1O,eAAay3C,mBAAmBD,EAAQviC,GAC5C,GAAkB,IAAd1G,EACF,OAAOlK,EAAQ/D,eAAeoH,EAAa8vC,EAAO14C,MAAO,IAG3D,MAEM0M,EAAS4C,EAFK/J,EAAQ9E,KAAKQ,IAAIkV,EAAQ/U,QAAQP,OACnC0E,EAAQzC,WAA4B41C,GAE1BA,EAAO14C,MAAOyP,EAAWC,EAAWC,EAC5DC,EAAS8oC,EAAO53C,MAAOgP,GAE3B,OAAOvK,EAAQ/D,eAAeoH,EAAa8vC,EAAO14C,MAAO0M,EAAO7L,OAClE,GC6CO,MAAM+3C,GAA+B,CAC1C7zC,WAAY8zC,WACZ5zC,YAAa,MACbC,oBAtEuBC,GAKvB,MAAME,OAACA,EAAME,QAAEA,EAAOyD,MAAEA,GAAS7D,GAC3BC,EAACA,EAAC+Q,QAAEA,GAAW9Q,GACfmQ,KAACA,EAAIsjC,UAAEA,GAAa9vC,EAE1BzJ,EAAiB,CAAC6F,EAAG+Q,GAAU,YAG/B,MAAM4iC,EAAaj5C,OAAK6V,eAAeH,EAAMpQ,EAAEtE,OAAO,GAChDk4C,EAAczzC,EAAQ9E,KAAKQ,IAAIkV,EAAQ/U,QAAQP,OAC/Co4C,EAAU7zC,EAAEtE,MAAMi4C,GACxB,IAAK,IAAIp0C,EAAI,EAAGA,EAAIq0C,EAAYt3C,SAAUiD,EAAG,CAC3C,MAAMoL,EAAQipC,EAAYr0C,GAC1B7E,OAAKC,OACDgQ,GAASkpC,EAAU,GAAKlpC,GAAS,GACjC,IACI,6BAA6BA,mBAAuBkpC,EAAU,OAGxE,IAAIC,EAAaJ,EAEA,MAAbA,IACFI,EAAa,GAGf,MAAMC,EAAcr5C,OAAK0F,cAAc2Q,EAAQrV,OAEzCs4C,EAAYl4C,eAAam4C,aAAaC,yBACxCl0C,EAAG+Q,EAAS4iC,EAAYG,GAEtBK,EAAWt6B,GAAQ,CACvB5Z,OAAQ,CAACD,KACTG,UACAyD,MAAO,CACLlI,MAAO,CACLs4C,EAAUjvB,UAAWivB,EAAUI,UAAWJ,EAAUK,QACpDL,EAAUzpC,cAKVK,EAAeiP,GAAQ,CAC3B5Z,OAAQ,CAACD,EAAG+Q,GACZ5Q,UACAyD,MAAO,CAAClI,MAAO,CAACs4C,EAAUjvB,UAAWgvB,EAAcC,EAAUjvB,cAGzD7Z,EAAqB,CACzB8oC,EAAUjvB,UAAWivB,EAAUI,UAAWL,EAAcC,EAAUjvB,UAClEivB,EAAUzpC,WAGNU,EAAa9K,EAAQzC,WAAWkN,GAEhCtD,EAAS0D,EADF7K,EAAQzC,WAAWy2C,GACElpC,EAAYC,GAK9C,OAHA/K,EAAQ/B,8BAA8B+1C,GACtCh0C,EAAQ/B,8BAA8BwM,GAE/BzK,EAAQ/D,eACX43C,EAAU/6B,YAAa3R,EAAO1M,MAAO0M,EAAO7L,OAClD,GCtCO,MAAM64C,GAA2B,CACtC30C,WAAY40C,OACZ10C,YAAa,MACbC,oBA/BmBC,GAEnB,MAAME,OAACA,EAAME,QAAEA,GAAWJ,GACpB8C,MAACA,GAAS5C,EAEV4tC,EAAYnzC,OAAK0F,cAAcyC,EAAMnH,OAGrCq2C,EAAqBlvC,EAAMnH,MAAMmH,EAAMnH,MAAMY,OAAS,GAGtD01C,EAAUn4B,GAAQ,CACtB5Z,OAAQ,CAACD,EAAG6C,GACZ1C,UACAyD,MAAO,CAAClI,MAAO,CALHmyC,EAAYkE,EAKDA,MAGnB9wC,EAASksC,GAAS6E,GAAS,EAAM7xC,GAEjC8xC,EACFp4B,GAAQ,CAAC5Z,OAAQ,CAACD,EAAGiB,GAASd,UAASyD,MAAO,CAAClI,MAAOmH,EAAMnH,SAKhE,OAHAyE,EAAQ/B,8BAA8B4zC,GACtC7xC,EAAQ/B,8BAA8B6C,GAE/BgxC,CACT,GC5BauC,GACT7sC,EAAgB8sC,YAAWzsC,GAAOmF,OAAOqnC,SAASxsC,GAAM,EAAI,GAAG,QAEtD0sC,GAA+B,CAC1C/0C,WAAY80C,WACZ50C,YAAa,MACbC,WAAY00C,ICNDG,GACThtC,EAAgBitC,SAAQ5sC,GAAOxI,KAAKC,IAAIuI,KAAQ6sC,IAAW,EAAI,GAAG,QAEzDC,GAA4B,CACvCn1C,WAAYi1C,QACZ/0C,YAAa,MACbC,WAAY60C,ICNDvnC,GACTzF,EAAgBotC,SAAQ/sC,GAAOmF,OAAOC,MAAMpF,GAAM,EAAI,GAAG,QAEhDgtC,GAA4B,CACvCr1C,WAAYo1C,QACZl1C,YAAa,MACbC,WAAYsN,ICKP,MAAM6nC,GAA+B,CAC1Ct1C,WAAYu1C,WACZr1C,YAAa,MACbC,oBAbuBC,GAEvB,MAAMI,QAACA,EAAOyD,MAAEA,GAAS7D,GACnBxB,MAACA,EAAKkO,KAAEA,EAAIC,IAAEA,GAAO9I,EAErBkD,EAAU0F,GAAajO,EAAOkO,EAAMC,GAE1C,OAAOvM,EAAQ/D,eAAe,CAAC0K,EAAQxK,QAAS,UAAWwK,EAC7D,GCTaquC,GAAQxtC,EAAgBytC,SAAQptC,GAAOxI,KAAK21C,MAAMntC,KAElDqtC,GAA4B,CACvC11C,WAAYy1C,QACZv1C,YAAa,MACbC,WAAYq1C,ICJDG,GACTj1C,GAA6B,CAACoD,EAAWC,IAAcD,GAAKC,IACnD6xC,GAAanxC,EACtBoxC,aAAYF,GAAgB,KAAwB,QAE3CG,GAAiC,CAC5C91C,WAAY61C,aACZ31C,YAAa,MACbC,WAAYy1C,ICTDG,GACT/tC,EAAgBguC,cAAa3tC,GAAOA,EAAK,EAAI,GAAG,QAEvC4tC,GAAiC,CAC5Cj2C,WAAYg2C,aACZ91C,YAAa,MACbC,WAAY41C,ICLDG,GACTx1C,GAA6B,CAACoD,EAAWC,IAAcD,GAAKC,IACnDoyC,GACT1xC,EAAiB2xC,YAAWF,GAAe,KAAwB,QAE1DG,GAAgC,CAC3Cr2C,WAAYo2C,YACZl2C,YAAa,MACbC,WAAYg2C,ICgCP,MAAMG,GAA0B,CACrCt2C,WAAYu2C,MACZr2C,YAAa,MACbC,oBA1CEC,GAEF,MAAME,OAACA,EAAME,QAAEA,EAAOyD,MAAEA,GAAS7D,GAC3BC,EAACA,GAAKC,GACNk2C,YAACA,EAAWlpB,KAAEA,EAAItE,MAAEA,EAAKytB,KAAEA,GAAQxyC,EAEzCzJ,EAAiB6F,EAAG,OAEpB,MAAMq2C,EAAWr2C,EAAEtE,MAAM,GACnB46C,EAAOD,EAAW,EAClBlmB,EAAUhwB,EAAQ9E,KAAKQ,IAAImE,EAAEhE,QAAQP,OACrCmL,EAAOlM,OAAK0F,cAAcJ,EAAEtE,OAC5BuF,EAAS,IAAI3B,aAAasH,GAEhC,SAAS2vC,EAAkBhuC,GACzB,MAAMiuC,EAAiBjuC,EAAS8tC,EAChC,IAAII,EACAluC,EAASiuC,EAAiBh3C,KAAK0N,IAAI,EAAGspC,EAAiBL,GAC3D,MAAMO,EACFnuC,EAASiuC,EAAiBh3C,KAAKoO,IAAI4oC,EAAiBL,EAAaG,GAErE,IAAI1pB,EAAM,EACV,KAAO6pB,GAAkBC,EAAcD,IAAkB,CACvD,MAAMlwB,EAAI4J,EAAQsmB,GAClB7pB,GAAOrG,EAAIA,EAEb,OAAOqG,EAGT,IAAK,IAAIrkB,EAAS,EAAGA,EAAS3B,EAAM2B,IAAU,CAC5C,MAAMqkB,EAAM2pB,EAAkBhuC,GACxB6gC,EAAMjZ,EAAQ5nB,GAAU/I,KAAKm3C,IAAI1pB,EAAOtE,EAAQiE,GAAMwpB,GAC5Dn1C,EAAOsH,GAAU6gC,EAGnB,OAAOjpC,EAAQ/D,eAAe4D,EAAEtE,MAAOsE,EAAEpF,MAAOqG,EAClD,GCSO,MAAM21C,GAA8B,CACzCj3C,WAAYk3C,UACZh3C,YAAa,MACbC,oBAhDEC,GAGF,MAAME,OAACA,EAAME,QAAEA,EAAOyD,MAAEA,GAAS7D,GAC3BC,EAACA,EAAC+8B,EAAEA,EAAC3G,GAAEA,GAAMn2B,GACbk2C,YAACA,EAAWlpB,KAAEA,EAAItE,MAAEA,EAAKytB,KAAEA,GAAQxyC,EAEzCzJ,EAAiBi8B,EAAI,WAErB,MAAM0gB,EAASp8C,OAAK0F,cAAcg2B,EAAG16B,OAE/B26C,EAAWjgB,EAAG16B,MAAM,GACpB6jC,EAAWp/B,EAAQ9E,KAAKQ,IAAIu6B,EAAGp6B,QAAQP,OACvC00B,EAAUhwB,EAAQ9E,KAAKQ,IAAImE,EAAEhE,QAAQP,OACrCs7C,EAAU52C,EAAQ9E,KAAKQ,IAAIkhC,EAAE/gC,QAAQP,OACrCwF,EAAS,IAAI3B,aAAaw3C,GAC1BlwC,EAAOkwC,EAEb,IAAK,IAAIvuC,EAAS,EAAGA,EAAS3B,EAAM2B,IAAU,CAC5C,MAAMiuC,EAAiBjuC,EAAS8tC,EAC1BW,EACDzuC,EAASiuC,EAAkBh3C,KAAK0N,IAAI,EAAGspC,EAAiBL,GACvDc,EAAY1uC,EAASiuC,EACvBh3C,KAAKoO,IAAIyoC,EAAUG,EAAiBL,EAAc,GAEtD,IAAIe,EAAO,EACX,IAAK,IAAInsC,EAAIisC,EAAYjsC,EAAIksC,EAAUlsC,IACrCmsC,GAAQ13C,KAAKm3C,IAAIxmB,EAAQplB,GAAI,GAE/BmsC,EAAOvuB,EAAQuuB,EAAOjqB,EAEtB,IAAK,IAAIliB,EAAIisC,EAAYjsC,EAAIksC,EAAUlsC,IAAK,CAC1C,IAAIosC,GAAO,EAAIxuB,EAAQytB,EAAOjmB,EAAQplB,GAAKgsC,EAAQxuC,GAAU2uC,EACzD3uC,IAAWwC,IACbosC,GAAO33C,KAAKm3C,IAAIO,GAAOd,IAEzBe,GAAO5X,EAASh3B,GAChBtH,EAAO8J,IAAMosC,GAIjB,OAAOh3C,EAAQ/D,eAAeg6B,EAAG16B,MAAOsE,EAAEpF,MAAOqG,EACnD,YCtCgBiM,GACZnN,GAEF,MAAME,OAACA,EAAME,QAAEA,EAAOyD,MAAEA,GAAS7D,GAC3BC,EAACA,GAAKC,GACNm3C,iBAACA,EAAgB/mC,SAAEA,GAAYzM,EAC/B1D,EAAaC,EACnB,IAAImO,EAAStO,EAAEtE,MACf,MAAMyT,EAAQb,EAAOhS,OAEf4xB,EAAWxzB,OAAK6V,eAAe6mC,EAAkB9oC,GACvD,IAAIgC,EAAO4d,EACX,MAAMC,EAAeryB,eAAa2U,mBAAmBH,EAAMnB,GAC3D,IAAI3I,EAAQtG,EAAW7E,KAAKQ,IAAImE,EAAEhE,QAAQP,OAC1C,GAAoB,MAAhB0yB,EAAsB,CACxB,MAAMxtB,EAAqB,IAAIrG,MAAM6U,GACrC,IAAK,IAAI5P,EAAI,EAAGA,EAAIoB,EAASrE,OAAQiD,IACnCoB,EAASpB,GAAK+O,EAAO6f,EAAa5uB,IAGpCiH,EAAQyI,GAAczI,EAAO8H,EAAQtO,EAAEpF,MAAOuzB,EAAcxtB,GAC5D2P,EAAOxU,eAAa8U,iBAAiBN,EAAKhU,OAAQ6S,GAElDb,EAAS3N,EAGXxG,EAAiB6F,EAAG,OACpBlE,eAAauyB,2BAA2B,MAAO/d,EAAMnB,GACrD,MAAOkoC,EAAaxnC,GAChB/T,eAAagU,0BAA0BxB,EAAQgC,GAI7CrP,EAAS+L,GAAQxG,EAFJ9L,OAAK0F,cAAcyP,GAEIwnC,EAAar3C,EAAEpF,OACnDoB,EAASkE,EAAW1E,MAAMyF,EAAQo2C,EAAar3C,EAAEpF,OAEvD,IAAIyN,EAAWgvC,EACf,GAAIhnC,EAAU,CAGZhI,EADiBvM,eAAa+U,qBAAqBwmC,EAAanpB,GAIlE,MAAO,CAAClyB,SAAQN,MAAO2M,EAAUzN,MAAOoF,EAAEpF,MAC5C,CAEO,MAAM08C,GAA0B,CACrC33C,WAAY43C,MACZ13C,YAAa,MACbC,WAAYoN,ICpBP,MAAMsqC,GAA8B,CACzC73C,WAAY83C,UACZ53C,YAAa,MACbC,oBAnCEC,GAGF,MAAME,OAACA,EAAME,QAAEA,EAAOyD,MAAEA,GAAS7D,GAC3BC,EAACA,GAAKC,EACZ9F,EAAiB6F,EAAG,WACpB,MAAMq1B,WAACA,EAAU7qB,QAAEA,EAAO8qB,IAAEA,EAAGC,gBAAEA,GAAmB3xB,EAGpDlJ,OAAKC,OACDmB,eAAa05B,+BAA+BhrB,EAH9B,IAId,IACI,wEAAeA,wBAEvB,MAAM4lB,EAAWt0B,eAAa25B,kBAC1Bz1B,EAAEtE,MAA2C25B,EAAY7qB,EAR3C,EASH8qB,EAAKC,GACpB,IAAI3mB,EAEJ,GAA6B,IAAzBwhB,EAASsF,aAA+C,IAA1BtF,EAASuF,cACvCj7B,OAAKk7B,YAAYxF,EAASyF,QAASzF,EAAS/nB,UAC9CuG,EAAMlM,EAAS,CAACzC,OAAQ,CAACD,KAAIG,gBACxB,CACL,MAAMgwB,EAAUhwB,EAAQ9E,KAAKQ,IAAImE,EAAEhE,QAAQP,OACrC+O,EAAU9P,OAAKqG,eAAef,EAAEtE,OAChCmC,EAASqyB,GAAKC,EAASnwB,EAAEtE,MAAOsE,EAAEpF,MAAO4P,EAAS4lB,EAAU,OAClExhB,EAAMzO,EAAQ/D,eACVg0B,EAAS/nB,SAAUrI,EAAEpF,MAAOiD,EAAOpC,QAEzC,OAAOmT,CACT,GCTO,MAAM8oC,GAAgC,CAC3C/3C,WAAYg4C,YACZ93C,YAAa,MACbC,oBAzBwBC,GAKxB,MAAME,OAACA,EAAME,QAAEA,EAAOyD,MAAEA,GAAS7D,GAC3BC,EAACA,GAAKC,GACNo1B,WAACA,EAAU7qB,QAAEA,EAAO8qB,IAAEA,EAAGC,gBAAEA,EAAeS,WAAEA,GAAcpyB,EAEhEzJ,EAAiB6F,EAAG,aAEpB,MAAMowB,EAAWt0B,eAAam6B,kBAC1Bj2B,EAAEtE,MAAmD25B,EAAY7qB,EACjE,EAAmB8qB,EAAKC,EAAiBS,GAGvC1uB,EAASgsB,GADCnzB,EAAQ9E,KAAKQ,IAAImE,EAAEhE,QAAQP,OAE9BuE,EAAEtE,MAAOsE,EAAEpF,MAAOF,OAAKqG,eAAef,EAAEtE,OAAQ00B,EAAU,OAEvE,OAAOjwB,EAAQ/D,eAAekL,EAAO5L,MAAO,UAAW4L,EAAO7L,OAChE,GC2EO,MAAMm8C,GAAoC,CAC/Cj4C,WAAYk4C,gBACZh4C,YAAa,MACbC,oBAlG4BC,GAK5B,MAAME,OAACA,EAAME,QAAEA,EAAOyD,MAAEA,GAAS7D,GAC3Bq2B,GAACA,EAAEvzB,MAAEA,GAAS5C,GACdo1B,WAACA,EAAU7qB,QAAEA,EAAO8qB,IAAEA,EAAGC,gBAAEA,GAAmB3xB,EAEpDzJ,EAAiB,CAACi8B,EAAIvzB,GAAQ,iBAE9B,MAAMutB,EAAWt0B,eAAam6B,kBAC1BpzB,EAAMnH,MAAmD25B,EACzD7qB,EAAS,EAAmB8qB,EAAKC,GAG/BuiB,W7DgOJ7wC,EACAmpB,GACF,MAAM6C,EAAep1B,SAAOuyB,EAAS/nB,SAAU,SACzCkrB,EAAcnD,EAASmD,YACvBjD,EAAeF,EAASE,aACxBC,EAAcH,EAASG,YACvBiD,EAAgBpD,EAASoD,cACzBhD,EAAiBJ,EAASI,eAC1BC,EAAgBL,EAASK,cACzBgD,EAAuBrD,EAASqD,qBAChC/C,EAAwBN,EAASM,sBACjCC,EAAuBP,EAASO,qBAChC+C,EAAWtD,EAASS,QAAQ8C,MAC5B/C,EAASR,EAASS,QAAQC,IAC1BC,EAAUX,EAASS,QAAQxK,KAEjC,IAAK,IAAIU,EAAQ,EAAGA,EAAQqJ,EAASrL,YAAagC,EAChD,IAAK,IAAI8M,EAAU,EAAGA,EAAUzD,EAASqB,aAAcoC,EACrD,IAAK,IAAIC,EAAS,EAAGA,EAAS1D,EAAS2D,WAAYD,EAAQ,CACzD,MAAME,EAAeF,EAASP,EAAcG,EAC5C,IAAIO,EAAYD,EAChB,KAAOC,EAAY,GACjBA,GAAaT,EAEf,MAAMU,EACF10B,KAAKoO,IAAIwiB,EAAS+D,QAASV,EAAuBO,GACtD,IAAK,IAAIK,EAAO,EAAGA,EAAOjE,EAASuB,YAAa0C,EAAM,CACpD,MAAMC,EAAaD,EAAO/D,EAAeM,EACzC,IAAI2D,EAAUD,EACd,KAAOC,EAAU,GACfA,GAAW/D,EAEb,MAAMgE,EACFh1B,KAAKoO,IAAIwiB,EAAS2B,SAAUrB,EAAwB4D,GACxD,IAAK,IAAIG,EAAO,EAAGA,EAAOrE,EAAS8B,WAAYuC,EAAM,CACnD,MAAMC,EAAaD,EAAOlE,EAAcQ,EACxC,IAAI4D,EAAUD,EACd,KAAOC,EAAU,GACfA,GAAWlE,EAEb,MAAMmE,EACFp1B,KAAKoO,IAAIwiB,EAASkC,QAAS3B,EAAuB+D,GAGtD,IAAIxB,EAAW/lB,OAAO8jB,kBAClBkC,GAAe,EAEnB,IAAK,IAAI2B,EAASb,EAAWa,EAASZ,EACjCY,GAAUtB,EAAe,CAC5B,MAAMwD,EAASlC,EAASd,EACxB,IAAK,IAAIgB,EAAOT,EAASS,EAAOR,EAASQ,GAAQxE,EAAgB,CAC/D,MAAM0G,EAAOlC,EAAOV,EACpB,IAAK,IAAIY,EAAOP,EAASO,EAAON,EAC3BM,GAAQzE,EAAe,CAC1B,MAAM2G,EAAOlC,EAAOR,EACd7B,EAAQ5rB,EAAKpL,IAAIkrB,EAAO+N,EAAQE,EAAME,EACrBrB,GACnBhB,GAASK,IACXA,EAAWL,EACXM,EACI6D,EAAStG,EAAwBC,EACjCuG,EAAOxG,EAAwB0G,KAM3CnE,EAAa/2B,IAAIi3B,EAAapM,EAAO+M,EAAQO,EAAMI,EAAMZ,KAOnE,OAAOZ,CACT,C6D3SoB8kB,CADD53C,EAAQzC,WAAWmF,GACWutB,GACzCmD,EAAcnD,EAASmD,YACvBjD,EAAeF,EAASE,aACxBC,EAAcH,EAASG,YACvBiD,EAAgBpD,EAASoD,cACzBhD,EAAiBJ,EAASI,eAC1BC,EAAgBL,EAASK,cACzBgD,EAAuBrD,EAASqD,qBAChC/C,EAAwBN,EAASM,sBACjCC,EAAuBP,EAASO,qBAChC+C,EAAWD,EAAuB,EAAIrD,EAASS,QAAQ8C,MACvD5C,EAAUJ,EAAuB,EAAIP,EAASS,QAAQxK,KACtDuK,EAASF,EAAwB,EAAIN,EAASS,QAAQC,IACtDwF,EAAKz4B,SAAOgF,EAAMnH,MAAO,WAEzB86B,EAAQr2B,EAAQzC,WAA4B04B,GAElD,IAAK,IAAIrP,EAAQ,EAAGA,EAAQqJ,EAASrL,YAAagC,EAChD,IAAK,IAAI8M,EAAU,EAAGA,EAAUzD,EAASqB,aAAcoC,EACrD,IAAK,IAAI4C,EAAU,EAAGA,EAAUrG,EAAS+D,UAAWsC,EAClD,IAAK,IAAIC,EAAQ,EAAGA,EAAQtG,EAAS2B,WAAY2E,EAC/C,IAAK,IAAIC,EAAQ,EAAGA,EAAQvG,EAASkC,UAAWqE,EAAO,CAErD,MAAMC,EAAgBH,EAAU/C,EAC1BmD,EAAcH,EAAQ9F,EACtBkG,EAAcH,EAAQ5F,EAC5B,IAAIgG,EAAU,EACd,IAAK,IAAIC,EAAS,EAAGA,EAASvD,EACzBuD,GAAUxD,EAAe,CAC5B,MAAMyD,GAAWL,EAAgBI,GAAUzD,EAC3C,KAAI0D,EAAU,GAAKA,GAAW7G,EAAS2D,UACnCv0B,KAAKmK,MAAMstB,KAAaA,GAG5B,IAAK,IAAIC,EAAO,EAAGA,EAAOxG,EACrBwG,GAAQ1G,EAAgB,CAC3B,MAAM2G,GAASN,EAAcK,GAAQ5G,EACrC,KAAI6G,EAAQ,GAAKA,GAAS/G,EAASuB,WAC/BnyB,KAAKmK,MAAMwtB,KAAWA,GAG1B,IAAK,IAAIC,EAAO,EAAGA,EAAOzG,EACrByG,GAAQ3G,EAAe,CAC1B,MAAM4G,GAASP,EAAcM,GAAQ7G,EACrC,GAAI8G,EAAQ,GAAKA,GAASjH,EAAS8B,UAC/B1yB,KAAKmK,MAAM0tB,KAAWA,EACxB,SAGF,MASM2gB,EATSvkB,EAAuB/C,EAC9BC,EACJ,EACCmnB,EAAUj8C,IAAIkrB,EAAOkQ,EAASE,EAAOE,EAAOxD,KAG7CmD,EAAStG,EAAwBC,EACjCuG,EAAOvG,EAAuByG,EAED,EAAI,EACrC,GAAa,IAAT4gB,EACF,SAKFjhB,GADIP,EAAM36B,IAAIkrB,EAAOkQ,EAASE,EAAOE,EAAOxD,GACzBmkB,IAIzB1hB,EAAGp6B,IAAI66B,EAAShQ,EAAO0P,EAASC,EAAOC,EAAO9C,GAOxD,OAAO1zB,EAAQ/D,eAAek6B,EAAG56B,MAAO46B,EAAG17B,MAAO07B,EAAG76B,OACvD,GCpBO,MAAMw8C,GAAkC,CAC7Ct4C,WAAYu4C,cACZr4C,YAAa,MACbC,oBA7E0BC,GAK1B,MAAME,OAACA,EAAME,QAAEA,EAAOyD,MAAEA,GAAS7D,GAC3Bq2B,GAACA,EAAEvzB,MAAEA,EAAKyd,OAAEA,GAAUrgB,EACtBD,EAAI6C,EACV1I,EAAiB,CAAC0I,EAAOyd,GAAS,eAClC,MAAM+U,WAACA,EAAU7qB,QAAEA,EAAO8qB,IAAEA,EAAGC,gBAAEA,GAAmB3xB,EAE9CwsB,EAAWt0B,eAAa25B,kBAC1Bz1B,EAAEtE,MAA2C25B,EAAY7qB,EACzD,EAAmB8qB,EAAKC,GACtBpF,EAAUhwB,EAAQ9E,KAAKQ,IAAImE,EAAEhE,QAAQP,OACrCq8C,EAAYj6C,SACduyB,EAAS/nB,SAAUrI,EAAEpF,MACrBk4B,GAAiB3C,EAASnwB,EAAEtE,MAAOsE,EAAEpF,MAAOw1B,GAAU30B,QACpD60B,EAAeF,EAASE,aACxBC,EAAcH,EAASG,YACvBC,EAAiBJ,EAASI,eAC1BC,EAAgBL,EAASK,cACzBC,EAAwBN,EAASM,sBACjCC,EAAuBP,EAASO,qBAChCI,EAAUJ,EAAuB,EAAIP,EAASS,QAAQxK,KACtDuK,EAASF,EAAwB,EAAIN,EAASS,QAAQC,IACtDwF,EACFz4B,SAAgBmC,EAAEtE,MAA2C,WAE3D87B,EAASr3B,EAAQ9E,KAAKQ,IAAIu6B,EAAGp6B,QAAQP,OACrC+6B,EAAQ34B,SACVu4B,EAAG16B,MAA2C,UAAW87B,GAE7D,IAAK,IAAI9zB,EAAI,EAAGA,EAAI0sB,EAASrL,YAAarhB,EACxC,IAAK,IAAIhH,EAAI,EAAGA,EAAI0zB,EAASqB,aAAc/0B,EACzC,IAAK,IAAI+6B,EAAM,EAAGA,EAAMrH,EAAS2B,WAAY0F,EAC3C,IAAK,IAAIC,EAAM,EAAGA,EAAMtH,EAASkC,UAAWoF,EAAK,CAE/C,MAAMC,EAAYF,EAAM7G,EAClBgH,EAAYF,EAAM3G,EACxB,IAAIgG,EAAU,EACd,IAAK,IAAI3D,EAAK,EAAGA,EAAK1C,EAAuB0C,GAAM5C,EAAgB,CACjE,MAAMqH,GAAOF,EAAYvE,GAAM9C,EAC/B,KAAIuH,EAAM,GAAKA,GAAOzH,EAASuB,WAC3BnyB,KAAKmK,MAAMkuB,KAASA,GAGxB,IAAK,IAAIxE,EAAK,EAAGA,EAAK1C,EAAsB0C,GAAM5C,EAAe,CAC/D,MAAMqH,GAAOF,EAAYvE,GAAM9C,EAC/B,GAAIuH,EAAM,GAAKA,GAAO1H,EAAS8B,UAC3B1yB,KAAKmK,MAAMmuB,KAASA,EACtB,SAEF,MAIMkgB,EAJStnB,EAAwBC,EAAuB,EACzDmnB,EAAUj8C,IAAI6H,EAAGm0B,EAAKC,EAAKp7B,KACjB02B,EAAKzC,EAAuB0C,EAEV,EAAI,EACrC,GAAa,IAAT2kB,EACF,SAIFjhB,GADcP,EAAM36B,IAAI6H,EAAGm0B,EAAKC,EAAKp7B,GAClBs7C,GAGvB1hB,EAAGp6B,IAAI66B,EAASrzB,EAAG+zB,EAAKC,EAAKh7B,GAKrC,OAAOyD,EAAQ/D,eAAek6B,EAAG56B,MAAO46B,EAAG17B,MAAO07B,EAAG76B,OACvD,GCtEO,MAAM08C,GAAwC,CACnDx4C,WAAYy4C,oBACZv4C,YAAa,MACbC,WAAY,EAAEG,SAAQ2D,QAAOzD,cAC3B,MAAMH,EAACA,GAAKC,GACNo1B,WAACA,EAAU7qB,QAAEA,EAAO8qB,IAAEA,EAAGtC,oBAAEA,GAC7BpvB,EACE1D,EAAaC,EACnBhG,EAAiB6F,EAAG,qBAEpB,MAAMvE,EAASyE,EAAW7E,KAAKQ,IAAImE,EAAEhE,QAAQP,OACvC20B,EAAWt0B,eAAa25B,kBAC1Bz1B,EAAEtE,MAA2C25B,EAAY7qB,EACzD,CAAC,EAAG,GAAI8qB,IACL+iB,EAAQC,YClBfnoB,EAAqB7hB,EAAkB1T,EACvCo4B,EAA8B5C,GAChC,MACMmoB,EAAWroB,GAAKC,EAAS7hB,EAAQ1T,EADvBF,OAAKqG,eAAeuN,GACmB8hB,EAAU,OAC3D6C,EAAeH,GACjB3C,EAAS7hB,EAAQ1T,EAAOw1B,GAAU,EAAM4C,GAE5C,MAAO,CAACulB,EAAS98C,OAAQw3B,EAAax3B,OACxC,CDU8B+8C,CACtB/8C,EAAQuE,EAAEtE,MAAOsE,EAAEpF,MAAOo4B,EAAqB5C,GAE7CqoB,EACFv4C,EAAW1E,MAAM68C,EAAwBjoB,EAAS/nB,SAAUrI,EAAEpF,OAC5D89C,EACFx4C,EAAW1E,MAAM88C,EAAuBloB,EAAS/nB,SAAUrI,EAAEpF,OACjE,MAAO,CACL,CAACoB,OAAQy8C,EAAc/8C,MAAO00B,EAAS/nB,SAAUzN,MAAOoF,EAAEpF,OAC1D,CAACoB,OAAQ08C,EAAeh9C,MAAO00B,EAAS/nB,SAAUzN,MAAO,SAC1D,GEME,MAAM+9C,GAA2B,CACtCh5C,WAAYi5C,OACZ/4C,YAAa,MACbC,oBAhCEC,GAEF,MAAME,OAACA,EAAME,QAAEA,EAAOyD,MAAEA,GAAS7D,GAC3BC,EAACA,GAAKC,GACNmQ,KAACA,EAAIC,SAAEA,GAAYzM,EAEnB0M,EAAO5V,OAAK6V,eAAeH,EAAMpQ,EAAEtE,OAEnCmU,EADS/T,eAAagU,0BAA0B9P,EAAEtE,MAAO4U,GACpC,GACrBrD,EAAavS,OAAK0F,cAAcyP,GAChCgpC,EAAY,GACZC,EACF34C,EAAQ/D,eAAe,GAAI,UAAW,IAAIkD,aAAa,CAAC2N,KAC5D4rC,EAAU/tC,KAAKguC,GAEf,MAAM1qB,EAAKzqB,EAAK,CAAC1D,OAAQ,CAACD,KAAIG,UAASyD,MAAO,CAAChJ,MAAO,aACtDi+C,EAAU/tC,KAAKsjB,GAEf,MAAMxf,EACFo+B,GAAI,CAAC/sC,OAAQ,CAACwD,EAAG2qB,EAAI1qB,EAAGo1C,GAAmB34C,YAC/C04C,EAAU/tC,KAAK8D,GAEf,MAAM3N,EAAS2rB,GAAI,CAAC3sB,OAAQ,CAACD,EAAG4O,GAAMzO,UAASyD,MAAO,CAACwM,OAAMC,cAI7D,OAFAwoC,EAAUr+C,SAAQC,GAAK0F,EAAQ/B,8BAA8B3D,KAEtDwG,CACT,GC6BO,MAAM83C,GAA0B,CACrCp5C,WAAYq5C,MACZn5C,YAAa,MACbC,oBA3DEC,GAEF,MAAME,OAACA,EAAME,QAAEA,EAAOyD,MAAEA,GAAS7D,GAC3BC,EAACA,GAAKC,GACNmQ,KAACA,EAAIC,SAAEA,GAAYzM,EAEzBzJ,EAAiB6F,EAAG,OAEpB,MAAMkuB,EAAWxzB,OAAK6V,eAAeH,EAAMpQ,EAAEtE,OAC7C,IAAI4U,EAAO4d,EACX,MAAMC,EAAeryB,eAAa2U,mBAAmBH,EAAMtQ,EAAEtE,MAAMY,QACnE,IAAI8xB,EAAKpuB,EACW,MAAhBmuB,IACFC,EAAK5e,GAAU,CAACvP,OAAQ,CAACD,KAAIG,UAASyD,MAAO,CAACsL,KAAMif,KACpD7d,EAAOxU,eAAa8U,iBAAiBN,EAAKhU,OAAQ0D,EAAEtE,MAAMY,SAG5DR,eAAauyB,2BAA2B,MAAO/d,EAAM8d,EAAG1yB,MAAMY,QAC9D,MAAO+L,EAAUwH,GACb/T,eAAagU,0BAA0Bse,EAAG1yB,MAAO4U,GAC/CrD,EAAavS,OAAK0F,cAAcyP,GAChCzQ,EAAO1E,OAAK+H,oBAAoB/H,OAAK0F,cAAciI,GAAW+lB,EAAGxzB,OAEjE6F,EAAQN,EAAQ9E,KAAKQ,IAAIuyB,EAAGpyB,QAAQP,OAC1C,IAAK,IAAI8D,EAAI,EAAGA,EAAIH,EAAK9C,SAAUiD,EAAG,CACpC,MAAMgJ,EAAShJ,EAAI0N,EACnB,IAAIW,EAAMnN,EAAM8H,GAChB,IAAK,IAAIhB,EAAI,EAAGA,EAAI0F,IAAc1F,EAAG,CACnC,MAAMR,EAAQtG,EAAM8H,EAAShB,IACzB4F,OAAOC,MAAMrG,IACbA,EAAQ6G,KACVA,EAAM7G,GAGV3H,EAAKG,GAAKqO,EAGQ,MAAhBugB,GACFhuB,EAAQ/B,8BAA8BgwB,GAGxC,MAAMntB,EAASd,EAAQ/D,eAAeiM,EAAU+lB,EAAGxzB,MAAOwE,GAE1D,GAAIiR,EAAU,CACZ,MACMke,EACF1U,GAAQ,CAAC5Z,OAAQ,CAACD,EAAGiB,GAASd,UAASyD,MAAO,CAAClI,MAF7BI,eAAa+U,qBAAqBxI,EAAU6lB,MAMlE,OAFA/tB,EAAQ/B,8BAA8B6C,GAE/BstB,EAGT,OAAOttB,CACT,GCRO,MAAMg4C,GAAgC,CAC3Ct5C,WAAYu5C,YACZr5C,YAAa,MACbC,oBApDwBC,GAKxB,MAAME,OAACA,EAAME,QAAEA,EAAOyD,MAAEA,GAAS7D,GAC3BC,EAACA,GAAKC,GACNk5C,SAACA,EAAQC,KAAEA,GAAQx1C,EAEzBzJ,EAAiB6F,EAAG,aAEpB,MAAMqI,EAAW8wC,EAAS18C,KACtB,CAACovC,EAAGtsC,IAAMssC,EAAE,GAAqB7rC,EAAEtE,MAAM6D,GAAKssC,EAAE,KAE9CttC,EAAQ46C,EAAS18C,KAAIovC,GAAKA,EAAE,KAC5BtrB,EAAM44B,EAAS18C,KAAI,CAACovC,EAAGtsC,IAAMssC,EAAE,GAAK7rC,EAAEtE,MAAM6D,KAC5CgJ,EAAkB,YAAT6wC,EAAqB,EAAI,EAElC5yC,EAAQrG,EAAQ9E,KAAKQ,IAAImE,EAAEhE,QAAQP,OACnC0T,EAAQnP,EAAEtE,MAAMY,OAChB+S,EAAW3U,OAAKqG,eAAef,EAAEtE,OAEjCsF,EAAatG,OAAK0F,cAAciI,GAChCxH,EAAawH,EAAS/L,OACtBwE,EAAgBpG,OAAKqG,eAAesH,GACpC4jB,EACFvxB,OAAKwG,uBAAuBlB,EAAEpF,MAA0BoG,GAE5D,IAAK,IAAIzB,EAAI,EAAGA,EAAIyB,EAAYzB,IAAK,CACnC,IAAI85C,EAAS3+C,OAAKiH,WAAWpC,EAAGsB,EAAYC,GAC5C,IAAK,IAAIvB,EAAI,EAAGA,EAAIsB,EAAYtB,IAC1B85C,EAAO95C,GAAKhB,EAAMgB,GACpB85C,EAAO95C,GAAgB,EAAXhB,EAAMgB,GAAS85C,EAAO95C,GAAKgJ,EAC9B8wC,EAAO95C,IAAMghB,EAAIhhB,KAC1B85C,EAAO95C,GAAoB,GAAdghB,EAAIhhB,GAAK,GAAS85C,EAAO95C,GAAKgJ,GAG/C8wC,EAASA,EAAO58C,KAAI,CAAC2oB,EAAG7lB,IAAM6lB,EAAI7mB,EAAMgB,KAExC,MAAM+5C,EAAU5+C,OAAKqH,WAAWs3C,EAAQlqC,EAAOE,GAE/C4c,EAAQ1sB,GAAKiH,EAAM8yC,GAKrB,MAAO,CAACt9C,OAFMmE,EAAQ3E,MAAMywB,EAAS5jB,EAAUrI,EAAEpF,OAE1Bc,MAAO2M,EAAUzN,MAAOoF,EAAEpF,MACnD,GC/Ca2+C,GACTl5C,IAA+BiN,EAAgBC,KAC7C,MAAMisC,EAAMlsC,EAASC,EACrB,OAAKD,EAAS,GAAKC,EAAS,GAAOD,GAAU,GAAKC,GAAU,EACnDisC,GAECA,EAAMjsC,GAAUA,CAE3B,IAEQksC,GAAMr1C,EAAiBs1C,MAAKH,IAE5BI,GAA0B,CACrCh6C,WAAY+5C,MACZ75C,YAAa,MACbC,WAAY25C,aCTEG,GACZ75C,GAGF,MAAME,OAACA,EAAME,QAAEA,EAAOyD,MAAEA,GAAS7D,GAC3B85C,OAACA,GAAU55C,GACX4K,IAACA,GAAOjH,EAERk2C,EAAaD,EAAOn+C,MAAMY,OAEhC,IAAIswC,EAAO/hC,EAIX,IAHc,IAAV+hC,IACFA,EAAOkN,EAAa,GAElBlN,IAASkN,EAAa,EACxB,MAAMh8C,MAEF,4EAAmBg8C,iBAA0BlN,KAGnD,MAAMt8B,EAAO5V,OAAK6V,eAAe,CAACq8B,GAAOiN,EAAOn+C,OAC1Cq+C,EAAW7sC,GAAI,CACnBjN,OAAQ,CAACD,EAAG65C,GACZ15C,UACAyD,MAAO,CAACwzC,iBAAkB9mC,EAAMD,UAAU,KAEtC2pC,EAAgBl+C,eAAa+U,qBAAqBkpC,EAASr+C,MAAO4U,GAElE2pC,EACFpgC,GAAQ,CAAC5Z,OAAQ,CAACD,EAAG+5C,GAAW55C,UAASyD,MAAO,CAAClI,MAAOs+C,KACtDv2C,EACFmiB,GAAI,CAAC3lB,OAAQ,CAACwD,EAAGo2C,EAAQn2C,EAAGu2C,GAAmB95C,YAC7CuD,EAAIyF,EAAI,CAAClJ,OAAQ,CAACD,EAAGyD,GAAItD,YACzB+5C,EACFttB,GAAI,CAAC3sB,OAAQ,CAACD,EAAG0D,GAAIvD,UAASyD,MAAO,CAACwM,KAAME,EAAMD,UAAU,KAC1D8pC,EACFtgC,GAAQ,CAAC5Z,OAAQ,CAACD,EAAGk6C,GAAS/5C,UAASyD,MAAO,CAAClI,MAAOs+C,KAEpD/4C,EAAS+rC,GAAI,CAAC/sC,OAAQ,CAACwD,EAAGC,EAAGA,EAAGy2C,GAAch6C,YASpD,OAPAA,EAAQ/B,8BAA8B27C,GACtC55C,EAAQ/B,8BAA8B67C,GACtC95C,EAAQ/B,8BAA8BqF,GACtCtD,EAAQ/B,8BAA8BsF,GACtCvD,EAAQ/B,8BAA8B87C,GACtC/5C,EAAQ/B,8BAA8B+7C,GAE/Bl5C,CACT,CAEO,MAAMm5C,GAA8B,CACzCz6C,WAAY06C,UACZx6C,YAAa,MACbC,WAAY85C,ICAP,MAAMU,GAAkC,CAC7C36C,WAAY46C,cACZ16C,YAAa,MACbC,oBA3D0BC,GAK1B,MAAME,OAACA,EAAME,QAAEA,EAAOyD,MAAEA,GAAS7D,GAC3B85C,OAACA,GAAU55C,GACXu6C,WAACA,EAAUC,KAAEA,EAAIC,WAAEA,GAAc92C,EAEvCzJ,EAAiB0/C,EAAQ,eAEzB,MAAMc,EAAgBD,EAClBb,EACAD,GAAQ,CAAC35C,OAAQ,CAAC45C,UAAS15C,UAASyD,MAAO,CAACiH,KAAM,KAEhDka,EAAY41B,EAAcj/C,MAAM,GAChCk/C,EAAYD,EAAcj/C,MAAM,GAChCm/C,EAAW16C,EAAQ9E,KAAKQ,IAAI8+C,EAAc3+C,QAAQP,OAClDq/C,EAAW,CAAC/1B,EAAWy1B,GACvBvuB,EACFvxB,OAAK+H,oBAAoB/H,OAAK0F,cAAc06C,GAAW,SAE3D,IAAK,IAAIp3C,EAAI,EAAGA,EAAIqhB,IAAarhB,EAAG,CAClC,MAAM6E,EAAS7E,EAAIk3C,EAGbG,EAAM,IAAIz7C,aAAas7C,EAAY,GACzCG,EAAI,GAAKF,EAAStyC,GAClB,IAAK,IAAIyyC,EAAQ,EAAGA,EAAQD,EAAIz+C,SAAU0+C,EACxCD,EAAIC,GAASD,EAAIC,EAAQ,GAAKH,EAAStyC,EAASyyC,GAGlD,MAAMC,EAASC,EAAWC,KAAKV,EAAK1yB,YAC9BX,EAAY1jB,EAAI82C,EACtB,IAAK,IAAIY,EAAW,EAAGA,EAAWZ,IAAcY,EAAU,CACxD,MAAMnf,EAAIgf,IAGVhvB,EAAQ7E,EAAYg0B,GAAYL,EAAIz+C,OAEpC,IAAK,IAAI0+C,EAAQ,EAAGA,EAAQD,EAAIz+C,OAAQ0+C,IACtC,GAAI/e,EAAI8e,EAAIC,GAAQ,CAClB/uB,EAAQ7E,EAAYg0B,GAAYJ,EAChC,QAUR,OAJKN,GACHv6C,EAAQ/B,8BAA8Bu8C,GAGjCx6C,EAAQ/D,eAAe0+C,EAAU,QAAS7uB,EACnD,GC5DMovB,GAA0BvgD,eAAaugD,wBA0BtC,MAAMC,GAA0C,CACrD37C,WAAY47C,sBACZ17C,YAAa,MACbC,oBAxBkCC,GAKlC,MAAME,OAACA,EAAME,QAAEA,EAAOyD,MAAEA,GAAS7D,GAC3B8iC,MAACA,EAAK2Y,OAAEA,GAAUv7C,GAClBw7C,cAACA,EAAaC,aAAEA,EAAYC,eAAEA,GAAkB/3C,EAEtDzJ,EAAiB0oC,EAAO,qBAExB,MAAM+Y,EAAYz7C,EAAQ9E,KAAKQ,IAAIgnC,EAAM7mC,QAAQP,OAC3CogD,EAAa17C,EAAQ9E,KAAKQ,IAAI2/C,EAAOx/C,QAAQP,QAE7CqgD,gBAACA,GAAmBT,GACtBO,EAAWC,EAAYJ,EAAeC,EAAcC,GAExD,OAAOx7C,EAAQ/D,eACX,CAAC0/C,EAAgBx/C,QAAS,QAAS,IAAI6G,WAAW24C,GACxD,GCxBMC,GAA0BjhD,eAAaihD,wBA6BtC,MAAMC,GAA0C,CACrDr8C,WAAYs8C,sBACZp8C,YAAa,MACbC,oBA5BkCC,GAKlC,MAAME,OAACA,EAAME,QAAEA,EAAOyD,MAAEA,GAAS7D,GAC3B8iC,MAACA,EAAK2Y,OAAEA,GAAUv7C,GAClBw7C,cAACA,EAAaC,aAAEA,EAAYC,eAAEA,EAAcO,mBAAEA,GAChDt4C,EAEJzJ,EAAiB0oC,EAAO,2BAExB,MAAM+Y,EAAYz7C,EAAQ9E,KAAKQ,IAAIgnC,EAAM7mC,QAAQP,OAC3CogD,EAAa17C,EAAQ9E,KAAKQ,IAAI2/C,EAAOx/C,QAAQP,QAE7CqgD,gBAACA,EAAeK,aAAEA,GAAgBJ,GACpCH,EAAWC,EAAYJ,EAAeC,EAAcC,EACpDO,GAEJ,MAAO,CACL/7C,EAAQ/D,eACJ,CAAC0/C,EAAgBx/C,QAAS,QAAS,IAAI6G,WAAW24C,IACtD37C,EAAQ/D,eAAe,GAAI,QAAS,IAAI+G,WAAW,CAACg5C,KAExD,GC5BMC,GAA0BthD,eAAashD,wBAmCtC,MAAMC,GAA0C,CACrD18C,WAAY28C,sBACZz8C,YAAa,MACbC,oBAlCkCC,GAKlC,MAAME,OAACA,EAAME,QAAEA,EAAOyD,MAAEA,GAAS7D,GAC3B8iC,MAACA,EAAK2Y,OAAEA,GAAUv7C,GAClBw7C,cAACA,EAAaC,aAAEA,EAAYC,eAAEA,EAAcY,aAAEA,GAAgB34C,EAEpEzJ,EAAiB0oC,EAAO,8BAExB,MAAM+Y,EAAYz7C,EAAQ9E,KAAKQ,IAAIgnC,EAAM7mC,QAAQP,OAC3CogD,EAAa17C,EAAQ9E,KAAKQ,IAAI2/C,EAAOx/C,QAAQP,OAE7C+gD,EAAmBf,EACnBgB,EAAkBf,EAClBgB,EAAoBf,EACpBgB,EAAkBJ,GAElBT,gBAACA,EAAec,eAAEA,GAAkBR,GACtCR,EAAWC,EAAYW,EAAkBC,EACzCC,EAAmBC,GAEvB,MAAO,CACLx8C,EAAQ/D,eACJ,CAAC0/C,EAAgBx/C,QAAS,QAAS,IAAI6G,WAAW24C,IACtD37C,EAAQ/D,eACJ,CAACwgD,EAAetgD,QAAS,UAAW,IAAIgD,aAAas9C,IAE7D,GCNO,MAAMC,GAA6B,CACxCl9C,WAAYm9C,SACZj9C,YAAa,MACbC,oBA1BEC,GAEF,MAAME,OAACA,EAAME,QAAEA,EAAOyD,MAAEA,GAAS7D,GAC3BgR,QAACA,GAAW9Q,GACZrF,MAACA,EAAKmiD,MAAEA,EAAKC,QAAEA,EAAOC,SAAEA,GAAYr5C,EAE1CzJ,EAAiB4W,EAAS,UAE1B,MAAMgjC,EAAcr5C,OAAK0F,cAAc2Q,EAAQrV,OAEzCkT,EAAM,IAAItP,aAAay0C,EAAcgJ,GAC3CnuC,EAAI2C,KAAK0rC,GACT,MAAMC,EAAa/8C,EAAQ9E,KAAKQ,IAAIkV,EAAQ/U,QAAQP,OAEpD,IAAK,IAAIu/C,EAAQ,EAAGA,EAAQjH,IAAeiH,EACrCkC,EAAWlC,IAAU,GAAKkC,EAAWlC,GAAS+B,IAChDnuC,EAAIosC,EAAQ+B,EAAQG,EAAWlC,IAAUgC,GAI7C,OAAO78C,EAAQ/D,eAAe,IAAI2U,EAAQrV,MAAOqhD,GAAQniD,EAAOgU,EAClE,YClBgBuuC,GACZp9C,GACF,MAAME,OAACA,EAAME,QAAEA,GAAWJ,GACpBC,EAACA,GAAKC,EAEZ,GAAgB,WAAZD,EAAEpF,MACJ,MAAM,IAAIkD,MAAM,iDACX,GAAgB,cAAZkC,EAAEpF,MAAuB,CAClC,MAAMmJ,EAAW1G,EAAK,CAAC4C,OAAQ,CAAC4C,MAAO7C,GAAIG,YACrC87B,EAAIkhB,GAAU,CAACl9C,OAAQ,CAACD,EAAG+D,GAAW5D,YACtCi9C,EAAW7/C,GAAK,CAAC0C,OAAQ,CAAC4C,MAAO7C,GAAIG,YACrCZ,EAAI49C,GAAU,CAACl9C,OAAQ,CAACD,EAAGo9C,GAAWj9C,YAEtCc,EAASiB,EAAQ,CAACjC,OAAQ,CAAC5C,KAAM4+B,EAAG1+B,KAAMgC,GAAIY,YAOpD,OALAA,EAAQ/B,8BAA8B2F,GACtC5D,EAAQ/B,8BAA8B69B,GACtC97B,EAAQ/B,8BAA8Bg/C,GACtCj9C,EAAQ/B,8BAA8BmB,GAE/B0B,EAEP,OAAOsQ,GAAK,CAACpR,UAASyD,MAAO,CAAClI,MAAOsE,EAAEtE,MAAOqL,MAAO,EAAGnM,MAAOoF,EAAEpF,QAErE,CAEO,MAAMyiD,GAAgC,CAC3C19C,WAAY29C,YACZz9C,YAAa,MACbC,WAAYq9C,ICHP,MAAMI,GAA+B,CAC1C59C,WAAY69C,WACZ39C,YAAa,MACbC,oBA7Bc29C,EACZ19C,GACF,MAAME,OAACA,EAAME,QAAEA,GAAWJ,GACpBC,EAACA,GAAKC,EAEZ,GAAgB,WAAZD,EAAEpF,MACJ,MAAM,IAAIkD,MAAM,gDACX,GAAgB,cAAZkC,EAAEpF,MAAuB,CAClC,MAAMmJ,EAAW1G,EAAK,CAAC4C,OAAQ,CAAC4C,MAAO7C,GAAIG,YACrC87B,EAAIwhB,EAAS,CAACx9C,OAAQ,CAACD,EAAG+D,GAAW5D,YACrCi9C,EAAW7/C,GAAK,CAAC0C,OAAQ,CAAC4C,MAAO7C,GAAIG,YACrCZ,EAAI49C,GAAU,CAACl9C,OAAQ,CAACD,EAAGo9C,GAAWj9C,YAEtCc,EAASiB,EAAQ,CAACjC,OAAQ,CAAC5C,KAAM4+B,EAAG1+B,KAAMgC,GAAIY,YAOpD,OALAA,EAAQ/B,8BAA8B2F,GACtC5D,EAAQ/B,8BAA8B69B,GACtC97B,EAAQ/B,8BAA8Bg/C,GACtCj9C,EAAQ/B,8BAA8BmB,GAE/B0B,EAEP,OAAOsQ,GAAK,CAACpR,UAASyD,MAAO,CAAClI,MAAOsE,EAAEtE,MAAOqL,MAAO,EAAGnM,MAAOoF,EAAEpF,QAErE,YC3BgB8iD,GACZ39C,GAEF,MAAME,OAACA,EAAME,QAAEA,EAAOyD,MAAEA,GAAS7D,GAC3BqQ,KAACA,GAAQxM,EAEf,GAAsB,IAAlB3D,EAAO3D,OACT,OAAO+uC,GACH,CAACprC,OAAQ,CAAC4C,MAAO5C,EAAO,IAAKE,UAASyD,MAAO,CAACiH,IAAKuF,KAGzD,MAAM1U,EAAQuE,EAAO,GAAGvE,MAClBd,EAAQqF,EAAO,GAAGrF,MAExBqF,EAAOzF,SAAQC,IACbC,OAAKijD,kBACDjiD,EAAOjB,EAAEiB,MACT,yDACJhB,OAAKC,OACDC,IAAUH,EAAEG,OACZ,IAAM,yDAAwD,IAGpE,MAAM+V,EAAwC,GAQxC1P,EAAS8pB,GAAO,CAAC9qB,OAPCA,EAAOxD,KAAIhC,IACjC,MAAMmjD,EACFvS,GAAW,CAACprC,OAAQ,CAAC4C,MAAOpI,GAAI0F,UAASyD,MAAO,CAACiH,IAAKuF,KAE1D,OADAO,EAAwB7F,KAAK8yC,GACtBA,CAAS,IAG8Bz9C,UAASyD,MAAO,CAACwM,UAKjE,OAHAO,EAAwBnW,SACpBC,GAAK0F,EAAQ/B,8BAA8B3D,KAExCwG,CACT,CAEO,MAAM48C,GAA2B,CACtCl+C,WAAYm+C,OACZj+C,YAAa,MACbC,WAAY49C,ICDP,MAAMK,GAA4B,CACvCp+C,WAAYq+C,QACZn+C,YAAa,MACbC,oBA5CEC,GAEF,MAAME,OAACA,EAAME,QAAEA,EAAOyD,MAAEA,GAAS7D,GAC3BC,EAACA,GAAKC,GACNk5C,SAACA,EAAQ8E,cAAEA,GAAiBr6C,EAElCzJ,EAAiB6F,EAAG,OAEpB,MAAMqI,EAAW8wC,EAAS18C,KACtB,CAACovC,EAAGtsC,IAAMssC,EAAE,GAAqB7rC,EAAEtE,MAAM6D,GAAKssC,EAAE,KAE9CttC,EAAQ46C,EAAS18C,KAAIovC,GAAKA,EAAE,KAE5BrlC,EAAQrG,EAAQ9E,KAAKQ,IAAImE,EAAEhE,QAAQP,OACnC2T,EAAQ1U,OAAK0F,cAAcJ,EAAEtE,OAC7ByT,EAAQnP,EAAEtE,MAAMY,OAChB+S,EAAW3U,OAAKqG,eAAef,EAAEtE,OAEjCsF,EAAatG,OAAK0F,cAAciI,GAChCxH,EAAawH,EAAS/L,OACtBwE,EAAgBpG,OAAKqG,eAAesH,GACpC4jB,EACFvxB,OAAKwG,uBAAuBlB,EAAEpF,MAA0BoG,GAEtC,IAAlBi9C,GACFhyB,EAAQ1a,KAAK0sC,GAGf,IAAK,IAAI1+C,EAAI,EAAGA,EAAI6P,EAAO7P,IAAK,CAC9B,MACM2+C,EADSxjD,OAAKiH,WAAWpC,EAAG4P,EAAOE,GAChB5S,KAAI,CAAC2oB,EAAG7lB,IAAM6lB,EAAI7mB,EAAMgB,KAGjD0sB,EAFiBvxB,OAAKqH,WAAWm8C,EAAWr9C,EAAYC,IAEpC0F,EAAMjH,GAK5B,MAAO,CAACvD,OAFMmE,EAAQ3E,MAAMywB,EAAS5jB,EAAUrI,EAAEpF,OAE1Bc,MAAO2M,EAAUzN,MAAOoF,EAAEpF,MACnD,GCxCaujD,GACT99C,GAA6B,CAACoD,EAAWC,IAAclE,KAAKm3C,IAAIlzC,EAAGC,KAC1DizC,GAAMvyC,EAAiBg6C,MAAKD,IAE5BE,GAA0B,CACrC1+C,WAAYy+C,MACZv+C,YAAa,MACbC,WAAY62C,ICyBP,MAAM2H,GAAmC,CAC9C3+C,WAAY4+C,eACZ1+C,YAAa,MACbC,oBAlC2BC,GAK3B,MAAME,OAACA,EAAME,QAAEA,EAAOyD,MAAEA,GAAS7D,GAC3BkR,mBAACA,EAAkBsB,kBAAEA,EAAiBxB,QAAEA,GAAW9Q,EAGnDu+C,EAAsBvtC,EAAmBxU,KAC3ChC,GAAK0F,EAAQ9E,KAAKQ,IAAIpB,EAAEuB,QAAQP,SAC9BgjD,EAA4BxtC,EAAmBxU,KAAIhC,GAAKA,EAAEiB,QAC1DgjD,EACFv+C,EAAQ9E,KAAKQ,IAAI0W,EAAkBvW,QAAQP,OACzCkjD,EAAWx+C,EAAQ9E,KAAKQ,IAAIkV,EAAQ/U,QAAQP,QAE3CgY,EAAoBG,EAAmBgrC,GAC1C1rC,GACIsrC,EAAqBC,EAA2BC,EAChDnsC,EAAkB7W,MAAO6W,EAAkB3X,MAAO+jD,EAClD5tC,EAAQrV,OAEVmjD,EAA4BprC,EAAmBhX,KAChD+U,GAAWrR,EAAQ/D,eAAe,CAACoV,EAAOlV,QAAS,QAASkV,KAE3DstC,EAA0B3+C,EAAQ/D,eACpCwiD,EAAwBrsC,EAAkB3X,MAAOgZ,GAErD,OAAOirC,EAA0B9zB,OAAO,CAAC+zB,GAC3C,GCPO,MAAMC,GAAkC,CAC7Cp/C,WAAYq/C,cACZn/C,YAAa,MACbC,oBAxBEC,GAEF,MAAME,OAACA,EAAME,QAAEA,GAAWJ,GACpBgU,OAACA,EAAMG,OAAEA,EAAME,OAAEA,GAAUnU,EAE3Bg/C,EAAU9+C,EAAQ9E,KAAKQ,IAAIkY,EAAO/X,QAAQP,OAC1CyjD,EAAU/+C,EAAQ9E,KAAKQ,IAAIqY,EAAOlY,QAAQP,OAC1C0jD,EAAUh/C,EAAQ9E,KAAKQ,IAAIuY,EAAOpY,QAAQP,QAEzC2jD,EAAoBC,GAAqBvrC,GAC5CmrC,EAASlrC,EAAOrY,MAAOqY,EAAOnZ,MAAOskD,EAAShrC,EAAOxY,MAAOyjD,EAC5D/qC,EAAO1Y,OAOX,MAAO,CALgByE,EAAQ/D,eAC3B,CAACgjD,EAAmB9iD,QAAS,QAAS8iD,GACpBj/C,EAAQ/D,eAC1B,CAACijD,EAAkB/iD,QAASyX,EAAOnZ,MAAOykD,GAGhD,GCIO,MAAMC,GAA2C,CACtD3/C,WAAY4/C,uBACZ1/C,YAAa,MACbC,oBA3BmCC,GAKnC,MAAME,OAACA,EAAME,QAAEA,EAAOyD,MAAEA,GAAS7D,GAC3BrE,MAACA,EAAKD,OAAEA,EAAM2Z,aAAEA,EAAYoqC,oBAAEA,GAAuBv/C,GACrDwV,kBAACA,GAAqB7R,EAEtBimB,EAAS1pB,EAAQ9E,KAAKQ,IAAIH,EAAMM,QAAQP,OACxCgkD,EAAUt/C,EAAQ9E,KAAKQ,IAAIJ,EAAOO,QAAQP,OAC1CikD,EACFv/C,EAAQ9E,KAAKQ,IAAIuZ,EAAapZ,QAAQP,OACpCkkD,EAAsBH,EAAoB/iD,KAC5ChC,GAAK0F,EAAQ9E,KAAKQ,IAAIpB,EAAEuB,QAAQP,SAC9B8Z,EAA2BiqC,EAAoB/iD,KAAIhC,GAAKA,EAAEiB,SAEzDud,EAAaqH,GAAU3F,GAC1BkP,EAAQnuB,EAAMA,MAAO+jD,EAAShkD,EAAOC,MAAOD,EAAOb,MAAO8kD,EAC1DtqC,EAAa1Z,MAAOikD,EAAqBpqC,EACzCE,GACJ,OAAOtV,EAAQ/D,eAAe6c,EAAaxd,EAAOb,MAAO0lB,EAC3D,GCdO,MAAMs/B,GAA4B,CACvCjgD,WAAYkgD,QACZhgD,YAAa,MACbC,oBAZoBC,GAEpB,MAAMI,QAACA,EAAOyD,MAAEA,GAAS7D,GACnBxB,MAACA,EAAKkO,KAAEA,EAAI7R,MAAEA,EAAK+R,KAAEA,GAAQ/I,EAE7BnI,EAASof,GAAUtc,EAAOkO,EAAME,EAAM/R,GAC5C,OAAOuF,EAAQ/D,eAAe,CAACX,EAAOa,QAAS1B,EAAOa,EACxD,GCRaqkD,GAAan4C,EAAgBo4C,cAAa/3C,GAAO,EAAIA,IAErDg4C,GAAiC,CAC5CrgD,WAAYogD,aACZlgD,YAAa,MACbC,WAAYggD,ICgFP,MAAMG,GAAqC,CAChDtgD,WAAYugD,iBACZrgD,YAAa,MACbC,oBAvF6BC,GAK7B,MAAME,OAACA,EAAME,QAAEA,EAAOyD,MAAEA,GAAS7D,GAC3BogD,OAACA,GAAUlgD,GACXmgD,aAACA,EAAYC,iBAAEA,EAAgBz5C,KAAEA,GAAQhD,EAE/CzJ,EAAiBgmD,EAAQ,kBAEzB,MAAMG,EAAgB5lD,OAAKqG,eAAeo/C,EAAOzkD,QAC1C6kD,EAAWC,GAAY55C,GAEvBmgB,EAAO05B,EAAWC,EAAUtd,GAAe+c,EAAOzkD,MACnDy0B,EAAUhwB,EAAQ9E,KAAKQ,IAAIskD,EAAOnkD,QAAQP,OAC1CwF,EAAS,IAAI3B,aACf5E,OAAK0F,cAAc,CAAC2mB,EAAOw5B,EAAWC,EAAUpd,KAE9Cud,EAAuC,CAC1CP,GAAgBG,EAAY,EAAKE,EAAY,EAAIA,EACjDL,GAAgBI,EAAW,EAAKE,EAAW,EAAIA,GAG5CE,EAAwC,CAC3CR,GAAgBG,EAAY,EAAKA,EAAY,EAAIA,EACjDH,GAAgBI,EAAW,EAAKA,EAAW,EAAIA,GAElD,IAAIzZ,EAAY,EAChB,MAAM8Z,EAAwBF,EAAmB,GAAKC,EAAoB,GACpEE,EAAwBH,EAAmB,GAAKC,EAAoB,GAC1E,IAAK,IAAIl9C,EAAI,EAAGA,EAAIqjB,EAAOrjB,IACzB,IAAK,IAAIu4B,EAAI,EAAGA,EAAIskB,EAAWtkB,IAAK,CAClC,IAAI8kB,EAEFA,EADEV,EACcQ,GAAyB5kB,EAAI,IAAO,GAEpC4kB,EAAwB5kB,EAG1C,MAAM+kB,EAAiBxhD,KAAK0N,IAAI,EAAG1N,KAAKmK,MAAMo3C,IACxCE,EAAUF,EAAgBC,EAC1BE,EAAgB1hD,KAAKoO,IAAI6yC,EAAY,EAAGjhD,KAAKyI,KAAK84C,IAClDI,EACFz9C,EAAI48C,EAAc,GAAKU,EAAiBV,EAAc,GACpDc,EACF19C,EAAI48C,EAAc,GAAKY,EAAgBZ,EAAc,GACzD,IAAK,IAAIl7B,EAAI,EAAGA,EAAIo7B,EAAUp7B,IAAK,CACjC,IAAIi8B,EAEFA,EADEhB,EACcS,GAAyB17B,EAAI,IAAO,GAEpC07B,EAAwB17B,EAE1C,MAAMk8B,EAAiB9hD,KAAK0N,IAAI,EAAG1N,KAAKmK,MAAM03C,IACxCE,EAAUF,EAAgBC,EAC1BE,EAAgBhiD,KAAKoO,IAAI8yC,EAAW,EAAGlhD,KAAKyI,KAAKo5C,IACjDI,EAAgBN,EAAeG,EAAiBhB,EAAc,GAC9DoB,EAAgBN,EAAeE,EAAiBhB,EAAc,GAC9DqB,EAAiBR,EAAeK,EAAgBlB,EAAc,GAC9DsB,EAAiBR,EAAeI,EAAgBlB,EAAc,GACpE,IAAK,IAAI5jD,EAAI,EAAGA,EAAI0mC,EAAa1mC,IAAK,CAIpC,MAAMooC,EAAU3U,EAAQsxB,EAAgB/kD,GAClCsoC,EAAa7U,EAAQuxB,EAAgBhlD,GAIrCo0B,EAAMgU,GAHK3U,EAAQwxB,EAAiBjlD,GAGRooC,GAAWyc,EAEvCM,EAAW/wB,GADFkU,GAHK7U,EAAQyxB,EAAiBllD,GAGFsoC,GAAcuc,EACxBzwB,GAAOmwB,EAExChgD,EAAO8lC,KAAe8a,IAM9B,OAAO1hD,EAAQ/D,eACX,CAAC2qB,EAAOw5B,EAAWC,EAAUpd,GAAc,UAAWniC,EAC5D,GCOO,MAAM6gD,GAAyC,CACpDniD,WAAYoiD,qBACZliD,YAAa,MACbC,oBA5FiCC,GAKjC,MAAME,OAACA,EAAME,QAAEA,EAAOyD,MAAEA,GAAS7D,GAC3BogD,OAACA,EAAM/pB,GAAEA,GAAMn2B,GACfmgD,aAACA,GAAgBx8C,EAEvBzJ,EAAiB,CAACi8B,EAAI+pB,GAAS,sBAE/B,MAAMG,EAAgB5lD,OAAKqG,eAAeo/C,EAAOzkD,QAE1CqrB,EAAOi7B,EAASC,EAAQlF,GAASoD,EAAOzkD,QACtCwmD,EAASC,GAAU/rB,EAAG16B,MAEzB4kB,EAAS,IAAIhhB,aAAaynB,EAAQi7B,EAAUC,EAASlF,GAOrDqF,EAAmC,CACtChC,GAAgB8B,EAAU,EAAKF,EAAU,EAAIA,EAC7C5B,GAAgB+B,EAAS,EAAKF,EAAS,EAAIA,GAGxCI,EAAmC,CACtCjC,GAAgB8B,EAAU,EAAKA,EAAU,EAAIA,EAC7C9B,GAAgB+B,EAAS,EAAKA,EAAS,EAAIA,GAGxChe,EAAcie,EAAe,GAAKC,EAAe,GACjDje,EAAage,EAAe,GAAKC,EAAe,GAKhD9iB,EAAWp/B,EAAQ9E,KAAKQ,IAAIu6B,EAAGp6B,QAAQP,OAC7C,IAAI8M,EAAS,EACb,IAAK,IAAI7E,EAAI,EAAGA,EAAIqjB,EAAOrjB,IAAK,CAC9B,MAAM4+C,EAAU5+C,EAAI48C,EAAc,GAClC,IAAK,IAAIrkB,EAAI,EAAGA,EAAIimB,EAASjmB,IAAK,CAChC,MAAMxE,EAAMwE,EAAIkI,EACVoe,EAAc/iD,KAAKmK,MAAM8tB,GACzB+qB,EAAiBhjD,KAAKoO,IAAIpO,KAAKyI,KAAKwvB,GAAMuqB,EAAU,GAEpDS,EAAeH,EAAUC,EAAcjC,EAAc,GACrDoC,EAAkBJ,EAAUE,EAAiBlC,EAAc,GAE3DqC,EAAUlrB,EAAM8qB,EAChBK,EAAiB,EAAMD,EAC7B,IAAK,IAAIv9B,EAAI,EAAGA,EAAI+8B,EAAQ/8B,IAAK,CAC/B,MAAMsS,EAAMtS,EAAIgf,EACVye,EAAerjD,KAAKmK,MAAM+tB,GAC1BorB,EAAgBtjD,KAAKoO,IAAIpO,KAAKyI,KAAKyvB,GAAMuqB,EAAS,GAClDc,EAAUrrB,EAAMmrB,EAChBG,EAAiB,EAAMD,EAEvBE,EAAkBR,EAAeI,EAAevC,EAAc,GAC9D4C,EACFT,EAAeK,EAAgBxC,EAAc,GAC3C6C,EACFT,EAAkBG,EAAevC,EAAc,GAC7C8C,EACFV,EAAkBI,EAAgBxC,EAAc,GAE9C+C,EACFT,EAAiBI,EACfM,EAA6BV,EAAiBG,EAC9CQ,EAA6BZ,EAAUK,EACvCQ,EAAsBb,EAAUI,EACtC,IAAK,IAAIrmD,EAAI,EAAGA,EAAIqgD,EAAOrgD,IAAK,CAC9B,MAAM+mD,EAAQlkB,EAASh3B,KACvB+X,EAAO2iC,EAAkBvmD,IACrB+mD,EAAQJ,EACZ/iC,EAAO4iC,EAAmBxmD,IAAM+mD,EAAQH,EACxChjC,EAAO6iC,EAAqBzmD,IAAM+mD,EAAQF,EAC1CjjC,EAAO8iC,EAAsB1mD,IAAM+mD,EAAQD,KAMnD,OAAOrjD,EAAQ/D,eACX,CAAC2qB,EAAOk7B,EAAQD,EAASjF,GAAQ,UAAWz8B,EAClD,GChBO,MAAMojC,GAA4C,CACvD/jD,WAAYgkD,wBACZ9jD,YAAa,MACbC,oBA1EoCC,GAKpC,MAAME,OAACA,EAAME,QAAEA,EAAOyD,MAAEA,GAAS7D,GAC3BogD,OAACA,GAAUlgD,GACXmgD,aAACA,EAAYC,iBAAEA,EAAgBz5C,KAAEA,GAAQhD,EAE/CzJ,EAAiBgmD,EAAQ,yBAEzB,MAAMG,EAAgB5lD,OAAKqG,eAAeo/C,EAAOzkD,QAC1C6kD,EAAWC,GAAY55C,GAEvBmgB,EAAO05B,EAAWC,EAAUtd,GAAe+c,EAAOzkD,MACnDy0B,EAAUhwB,EAAQ9E,KAAKQ,IAAIskD,EAAOnkD,QAAQP,OAC1C6kB,EAAS,IAAIhhB,aAAaynB,EAAQw5B,EAAYC,EAAWpd,GAEzDud,EAAuC,CAC1CP,GAAgBG,EAAY,EAAKE,EAAY,EAAIA,EACjDL,GAAgBI,EAAW,EAAKE,EAAW,EAAIA,GAG5CE,EAAwC,CAC3CR,GAAgBG,EAAY,EAAKA,EAAY,EAAIA,EACjDH,GAAgBI,EAAW,EAAKA,EAAW,EAAIA,GAG5CK,EAAwBF,EAAmB,GAAKC,EAAoB,GACpEE,EAAwBH,EAAmB,GAAKC,EAAoB,GAE1E,IAAIgD,EAAe,EACnB,IAAK,IAAIlgD,EAAI,EAAGA,EAAIqjB,EAAOrjB,IAAK,CAC9B,MAAM8uC,EAAc9uC,EAAI48C,EAAc,GACtC,IAAK,IAAIrkB,EAAI,EAAGA,EAAIskB,EAAWtkB,IAAK,CAClC,MAAM8kB,EAAgBV,EAClBQ,GAAyB5kB,EAAI,IAC7B4kB,EAAwB5kB,EAC5B,IAAI4nB,EAAmBrkD,KAAKoO,IACxB6yC,EAAY,EACZL,EAAe5gD,KAAK2lC,MAAM4b,GAAiBvhD,KAAKmK,MAAMo3C,IACtDV,IACFwD,EAAmBrkD,KAAK0N,IAAI,EAAG22C,IAEjC,MAAMpR,EAAYD,EAAcqR,EAAmBvD,EAAc,GACjE,IAAK,IAAIl7B,EAAI,EAAGA,EAAIo7B,EAAUp7B,IAAK,CACjC,MAAMi8B,EAAgBhB,EAClBS,GAAyB17B,EAAI,IAC7B07B,EAAwB17B,EAC5B,IAAI0+B,EAAmBtkD,KAAKoO,IACxB8yC,EAAW,EACXN,EAAe5gD,KAAK2lC,MAAMkc,GACX7hD,KAAKmK,MAAM03C,IAC1BhB,IACFyD,EAAmBtkD,KAAK0N,IAAI,EAAG42C,IAEjC,MAAMt7C,EAAYiqC,EAAYqR,EAAmBxD,EAAc,GAC/D,IAAK,IAAI5jD,EAAI,EAAGA,EAAI0mC,EAAa1mC,IAAK,CAGpC,MAAMqnD,EAAS5zB,EAAQ3nB,EAAY9L,GACnC4jB,EAAOsjC,KAAkBG,KAMjC,OAAO5jD,EAAQ/D,eACX,CAAC2qB,EAAOw5B,EAAWC,EAAUpd,GAAc+c,EAAOvlD,MAAO0lB,EAC/D,GCsCO,MAAM0jC,GAAgD,CAC3DrkD,WAAYskD,4BACZpkD,YAAa,MACbC,oBA9GwCC,GAKxC,MAAME,OAACA,EAAME,QAAEA,EAAOyD,MAAEA,GAAS7D,GAC3BogD,OAACA,EAAM/pB,GAAEA,GAAMn2B,GACfmgD,aAACA,GAAgBx8C,EAEvBzJ,EAAiB,CAACi8B,EAAI+pB,GAAS,6BAE/B,MAAMG,EAAgB5lD,OAAKqG,eAAeo/C,EAAOzkD,OAC3C2jC,EAAY3kC,OAAKqG,eAAeq1B,EAAG16B,QAClCqrB,EAAOi7B,EAASC,EAAQlF,GAASoD,EAAOzkD,QACtCwmD,EAASC,GAAU/rB,EAAG16B,MAEzB4kB,EAAS,IAAIhhB,aAAaynB,EAAQi7B,EAAUC,EAASlF,GACrDxd,EAAWp/B,EAAQ9E,KAAKQ,IAAIu6B,EAAGp6B,QAAQP,OAKvC2mD,EAAmC,CACtChC,GAAgB8B,EAAU,EAAKF,EAAU,EAAIA,EAC7C5B,GAAgB+B,EAAS,EAAKF,EAAS,EAAIA,GAGxCI,EAAmC,CACtCjC,GAAgB8B,EAAU,EAAKA,EAAU,EAAIA,EAC7C9B,GAAgB+B,EAAS,EAAKA,EAAS,EAAIA,GAGxChe,EAAcie,EAAe,GAAKC,EAAe,GACjDje,EAAage,EAAe,GAAKC,EAAe,GAEhD6B,EAAiB,EAAI/f,EACrBggB,EAAgB,EAAI/f,EAIpBggB,EAAyC,EAA5B5kD,KAAKyI,KAAKi8C,GAAuB,EAC9CG,EAAuC,EAA3B7kD,KAAKyI,KAAKk8C,GAAsB,EAGlD,IAAK,IAAIzgD,EAAI,EAAGA,EAAIqjB,EAAOrjB,IAAK,CAC9B,MAAM8uC,EAAc9uC,EAAI48C,EAAc,GACtC,IAAK,IAAIrkB,EAAI,EAAGA,EAAI+lB,EAAS/lB,IAAK,CAChC,MAAMwW,EAAYD,EAAcvW,EAAIqkB,EAAc,GAG5CgE,EAAa9kD,KAAKmK,MAAMsyB,EAAIioB,GAC5BK,EAAW/kD,KAAKmK,MAAM26C,EAAcF,EAAY,GACtD,IAAK,IAAIh/B,EAAI,EAAGA,EAAI68B,EAAQ78B,IAAK,CAC/B,MAAM5c,EAAYiqC,EAAYrtB,EAAIk7B,EAAc,GAG1CkE,EAAahlD,KAAKmK,MAAMyb,EAAI++B,GAC5BM,EAAWjlD,KAAKmK,MAAM66C,EAAcH,EAAW,GAErD,IAAK,IAAI3nD,EAAI,EAAGA,EAAIqgD,EAAOrgD,IAAK,CAC9B,IAAIgoD,EAAQ,EAGZ,IAAK,IAAIC,EAAW,EAAGA,EAAWP,EAAWO,IAAY,CACvD,MAAM9sB,EAAM8sB,EAAWJ,EAEvB,GAAI1sB,EAAM,GAAKA,GAAOqqB,EACpB,SAGF,MAAM0C,EAAYpS,EAAc3a,EAAMwH,EAAU,GAC1C0hB,EAAgBlpB,EAAMsM,EAK5B,GAAIlI,IAJqBz8B,KAAKoO,IAC1Bo0C,EAAU,EACV5B,EAAe5gD,KAAK2lC,MAAM4b,GACXvhD,KAAKmK,MAAMo3C,IAI9B,IAAK,IAAI8D,EAAW,EAAGA,EAAWR,EAAUQ,IAAY,CACtD,MAAM/sB,EAAM+sB,EAAWJ,EAEvB,GAAI3sB,EAAM,GAAKA,GAAOqqB,EACpB,SAGF,MAAM2C,EAAYF,EAAY9sB,EAAMuH,EAAU,GACxCgiB,EAAgBvpB,EAAMsM,EAMxBhf,IALqB5lB,KAAKoO,IAC1Bq0C,EAAS,EACT7B,EAAe5gD,KAAK2lC,MAAMkc,GACX7hD,KAAKmK,MAAM03C,MAG5BqD,GAASnlB,EAASulB,EAAYpoD,KAIpC4jB,EAAO9X,EAAY9L,GAAKgoD,KAMhC,OAAOvkD,EAAQ/D,eAAe+jD,EAAOzkD,MAAOykD,EAAOvlD,MAAO0lB,EAC5D,GC1EO,MAAMykC,GAA8B,CACzCplD,WAAYqlD,UACZnlD,YAAa,MACbC,oBAhCEC,GAGF,MAAME,OAACA,EAAME,QAAEA,EAAOyD,MAAEA,GAAS7D,GAC3BC,EAACA,GAAKC,GACNglD,KAACA,GAAQrhD,EAEfzJ,EAAiB6F,EAAG,WAEpB,MAAMmP,EAAQnP,EAAEtE,MAAMY,OAEhB4oD,EAAQxqD,OAAK6V,eAAe00C,EAAMjlD,EAAEtE,OAC1C,GAAc,IAAVyT,EACF,OAAOzM,EAAS,CAACzC,OAAQ,CAACD,KAAIG,YAGhC,MAAMmH,EAAS,IAAImU,eAAazb,EAAEtE,MAAOsE,EAAEpF,OACrCqM,EAAO9G,EAAQzC,WAAWsC,GAEhC,IAAK,IAAIT,EAAI,EAAGA,EAAI+H,EAAOV,KAAMrH,IAAK,CACpC,MAAMgd,EAASjV,EAAO3F,WAAWpC,GAC3Bid,EAAQD,EAAO1a,QACrBqjD,EAAM1qD,SAAQkC,GAAK8f,EAAM9f,GAAKsD,EAAEtE,MAAMgB,GAAK,EAAI8f,EAAM9f,KACrD4K,EAAOpL,IAAI+K,EAAKpL,OAAO2gB,MAAWD,GAGpC,OAAOpc,EAAQ/D,eAAekL,EAAO5L,MAAO4L,EAAO1M,MAAO0M,EAAO7L,OACnE,GC7Ba0pD,GAAuC,CAClDxlD,WAAYylD,mBACZvlD,YAAa,MACbC,WAAY,EAAEG,SAAQ2D,QAAOzD,cAC3B,MAAMyiC,MAACA,GAAS3iC,GACVolD,QAACA,EAAOC,UAAEA,EAASC,OAAEA,GACzB3hD,EACI1D,EAAaC,EAEbmgB,EAAS5lB,OAAKwG,uBAChB0hC,EAAMhoC,MAA0BF,OAAK0F,cAAcwiC,EAAMlnC,SACtDqrB,EAAOmc,EAAaC,EAAYC,GAAeR,EAAMlnC,OAErD8pD,EAASC,GACZ3pD,eAAa4pD,eAAeH,EAAQriB,EAAaC,GAG/CwiB,EAAYnmD,KAAKomD,IAAIP,GACrBQ,EAAYrmD,KAAK4iC,IAAIijB,GACrB3hB,EAAYxjC,EAAW7E,KAAKQ,IAAI+mC,EAAM5mC,QAAQP,OAEpD,IAAK,IAAI2P,EAAW,EAAGA,EAAW2b,EAAO3b,IAAY,CACnD,MAAMonC,EAAcpnC,EAAW+3B,EAAaD,EAAcE,EAE1D,IAAK,IAAIz6B,EAAM,EAAGA,EAAMu6B,EAAav6B,IAAO,CAC1C,MAAM8pC,EAAY9pC,GAAOw6B,EAAaC,GAEtC,IAAK,IAAIv6B,EAAM,EAAGA,EAAMs6B,EAAYt6B,IAAO,CACzC,MAAML,EAAYK,EAAMu6B,EAExB,IAAK,IAAIvP,EAAU,EAAGA,EAAUuP,EAAavP,IAAW,CACtD,MAAMwlB,EAAS,CAACtyB,EAAOpe,EAAKE,EAAKgrB,GAE3B7zB,EAAIq5C,EAAO,GACXtc,EAAIsc,EAAO,GAGjB,IAAI3G,GAAU1yC,EAAIwlD,GAAWK,GAAa9oB,EAAI0oB,GAAWE,EACrDG,GAAU9lD,EAAIwlD,GAAWG,GAAa5oB,EAAI0oB,GAAWI,EACzDnT,EAASlzC,KAAK2lC,MAAMuN,EAAS8S,GAC7BM,EAAStmD,KAAK2lC,MAAM2gB,EAASL,GAE7B,IAAI7S,EAAc0S,EAUlB,GATyB,iBAAdA,IAEP1S,EADc,IAAZ/e,EA7BW,IAgCCyxB,EAAUzxB,IAKxB6e,GAAU,GAAKA,EAASvP,GAAc2iB,GAAU,GAChDA,EAAS5iB,EAAa,CAMxB0P,EAAclP,EADV8O,EAHqBsT,GAAU3iB,EAAaC,GACvBsP,EAAStP,EAEsBvP,GAK1DvT,EADekyB,EAAcC,EAAYjqC,EAAYqrB,GACpC+e,KAOzB,MAAO,CAAC52C,OADOkE,EAAW1E,MAAM8kB,EAAQsiB,EAAMlnC,MAAOknC,EAAMhoC,OAC3Cc,MAAOknC,EAAMlnC,MAAOd,MAAOgoC,EAAMhoC,MAAM,GCvE9CuqC,GAAQx9B,EAAgBo+C,SAAQ/9C,IAE3C,MAAMg+C,EAAOxmD,KAAKmK,MAAM3B,GACxB,OAAIA,EAAKg+C,EAAO,GACPxmD,KAAKmK,MAAM3B,GACTA,EAAKg+C,EAAO,GACdxmD,KAAKyI,KAAKD,GAEbg+C,EAAO,GAAQ,EACVA,EAEAA,EAAO,KAKPC,GAA4B,CACvCtmD,WAAYomD,QACZlmD,YAAa,MACbC,WAAYqlC,ICKP,MAAM+gB,GAAgC,CAC3CvmD,WAAYwmD,YACZtmD,YAAa,MACbC,oBA1BwBC,GAKxB,MAAME,OAACA,EAAME,QAAEA,EAAOyD,MAAEA,GAAS7D,GAC3BgR,QAACA,EAAOqK,QAAEA,GAAWnb,GACrBvE,MAACA,GAASkI,GAEV0G,UAACA,EAAS+Q,WAAEA,EAAU9Q,UAAEA,EAASC,QAAEA,EAAOyN,WAAEA,GAC9Cnc,eAAasqD,gBAAgBhrC,EAASrK,EAASrV,GAM7C4L,EAAS6T,GAHIhb,EAAQzC,WAA0BqT,GAClC5Q,EAAQzC,WAAoC0d,GAGnC1f,EAAOuc,EAAY1N,EAAW8Q,EACtD/Q,EAAWE,EAAS,GAPD,GASvB,OAAOrK,EAAQ/D,eAAeV,EAAO4L,EAAO1M,MAAO0M,EAAO7L,OAC5D,GCxBA,SAAS4qD,GAAWjgC,EAAmBrf,GACrC,IAAIsf,EAAO,EACPC,EAAQF,EAAM9pB,OACdgqD,EAAM,EACV,KAAOjgC,EAAOC,GACZggC,EAAM9mD,KAAKmK,OAAO0c,EAAOC,GAAS,GAC9BF,EAAMkgC,GAAOv/C,EACfsf,EAAOigC,EAAM,EAEbhgC,EAAQggC,EAGZ,OAAOhgC,CACT,CAEA,SAASigC,GAAWngC,EAAmBrf,GACrC,IAAIsf,EAAO,EACPC,EAAQF,EAAM9pB,OACdgqD,EAAM,EACV,KAAOjgC,EAAOC,GACZggC,EAAM9mD,KAAKmK,OAAO0c,EAAOC,GAAS,GAC9BF,EAAMkgC,IAAQv/C,EAChBsf,EAAOigC,EAAM,EAEbhgC,EAAQggC,EAGZ,OAAOhgC,CACT,CCLO,MAAMkgC,GAAmC,CAC9C7mD,WAAY8mD,eACZ5mD,YAAa,MACbC,oBAtB2BC,GAK3B,MAAME,OAACA,EAAME,QAAEA,EAAOyD,MAAEA,GAAS7D,GAC3B2mD,eAACA,EAAcjrD,OAAEA,GAAUwE,GAC3B0mD,KAACA,GAAQ/iD,EAMT0c,WDcJsmC,EAA0BnrD,EAAoBspB,EAC9C8hC,EAAmBz1C,EAAmBu1C,GACxC,MAAMrmC,EACF5lB,OAAKgN,kBAAkB,QAASqd,EAAY3T,GAChD,IAAK,IAAI1N,EAAI,EAAGA,EAAIqhB,IAAarhB,EAAG,CAClC,MAAMojD,EACFF,EAAa/kD,MAAM6B,EAAImjD,GAAYnjD,EAAI,GAAKmjD,GAC1CjD,EAAelgD,EAAI0N,EACzB,IAAK,IAAI7R,EAAI,EAAGA,EAAI6R,IAAa7R,EAC/B+gB,EAAOsjC,EAAerkD,GAAc,SAATonD,EACvBN,GAAWS,EAAmBrrD,EAAO8D,EAAIqkD,IACzC2C,GAAWO,EAAmBrrD,EAAO8D,EAAIqkD,IAGjD,OAAOtjC,CACT,CC7BiBymC,CAHX5mD,EAAQ9E,KAAKQ,IAAI6qD,EAAe1qD,QAAQP,OAC5B0E,EAAQ9E,KAAKQ,IAAIJ,EAAOO,QAAQP,OAGlBirD,EAAehrD,MAAM,GAC/CgrD,EAAehrD,MAAM,GAAID,EAAOC,MAAM,GAAIirD,GAC9C,OAAOxmD,EAAQ/D,eAAeX,EAAOC,MAAO,QAAS4kB,EACvD,GCgBO,MAAM0mC,GAA6B,CACxCrnD,WAAYsnD,SACZpnD,YAAa,MACbC,oBArCqBC,GAErB,MAAME,OAACA,EAAME,QAAEA,GAAWJ,GACpBjB,UAACA,EAASrE,EAAEA,EAACg0C,EAAEA,GAAKxuC,EAE1B9F,EAAiB,CAAC2E,EAAWrE,EAAGg0C,GAAI,UACpC,MAAMyY,EAAgBpoD,EAAUpD,MAAMY,OAEhCb,EAAS0E,EAAQ9E,KAAKQ,IAAIiD,EAAU9C,QAAQP,OAC5C0rD,EAAUhnD,EAAQ9E,KAAKQ,IAAIpB,EAAEuB,QAAQP,OACrC2rD,EAAUjnD,EAAQ9E,KAAKQ,IAAI4yC,EAAEzyC,QAAQP,OACrCmqC,EAAc51B,aAAWvV,EAAEG,MAAO6zC,EAAE7zC,OACpC6M,EACF/M,OAAK+H,oBAAoB/H,OAAK0F,cAAc3F,EAAEiB,OAAQkqC,GAE1D,IAAIj7B,EAAQ,EACZ,MAAMpC,EACgB,IAAlB2+C,GAAuBA,EAAgB,GAAwB,IAAnBzsD,EAAEiB,MAAMY,OACpD,EACA5B,OAAK0F,cAAc3F,EAAEiB,MAAMmG,MAAM,IAErC,IAAK,IAAItC,EAAI,EAAGA,EAAI9D,EAAOa,OAAQiD,IACjC,IAAK,IAAIgI,EAAI,EAAGA,EAAIgB,EAAQhB,IACR,IAAd9L,EAAO8D,GACTkI,EAAUkD,KAAWw8C,EAAQ5nD,GAE7BkI,EAAUkD,KAAWy8C,EAAQ7nD,GAKnC,OAAOY,EAAQ/D,eAAe3B,EAAEiB,MAAOkqC,EAAan+B,EACtD,GCjCM4/C,GAAavrD,eAAawrD,gBAC1BrvB,GAAQn8B,eAAayrD,WAEdC,GAAO7/C,EAAgB8/C,QAAOz/C,GACrCA,GAAM,EACDiwB,GAAQjwB,EAERq/C,IAAc7nD,KAAK2J,IAAInB,GAAM,KAI3B0/C,GAA2B,CACtC/nD,WAAY8nD,OACZ5nD,YAAa,MACbC,WAAY0nD,ICdD9gC,GAAO/e,EAAgBggD,QAAO3/C,GACrCA,EAAK,GACC,EACCA,EAAK,EACP,EAEA,IAIE4/C,GAA2B,CACtCjoD,WAAYgoD,OACZ9nD,YAAa,MACbC,WAAY4mB,ICbDk/B,GAAMj+C,EAAgBkgD,OAAM7/C,GAAOxI,KAAKomD,IAAI59C,KAE5C8/C,GAA0B,CACrCnoD,WAAYkoD,MACZhoD,YAAa,MACbC,WAAY8lD,ICLDmC,GAAOpgD,EAAgBqgD,QAAOhgD,GAAOxI,KAAKuoD,KAAK//C,KAE/CigD,GAA2B,CACtCtoD,WAAYqoD,OACZnoD,YAAa,MACbC,WAAYioD,ICCRG,GAAY1oD,KAAKqN,IADP,uBACsB,EAEzBs7C,GAAWxgD,EAAgBygD,YAAWpgD,IAGjD,MAAMqgD,EAAWrgD,GAAMkgD,GAIjBI,EAAWtgD,EAAKkgD,GAEhBK,EAAO/oD,KAAK2J,IAAInB,GACtB,IAAI/G,EASJ,OANEA,EADEqnD,EACOC,EACAF,EACArgD,EAEAxI,KAAKqN,IAAI,EAAM07C,GAEnBtnD,CAAM,IAGFunD,GAA+B,CAC1C7oD,WAAYyoD,WACZvoD,YAAa,MACbC,WAAYqoD,IC8BP,MAAMM,GAAqC,CAChD9oD,WAAY+oD,iBACZ7oD,YAAa,MACbC,oBA7D6BC,GAK7B,MAAME,OAACA,EAAME,QAAEA,EAAOyD,MAAEA,GAAS7D,GAC3BC,EAACA,GAAKC,GACNk5B,WAACA,EAAUggB,SAAEA,GAAYv1C,EAE/BzJ,EAAiB,CAAC6F,GAAI,kBAEtB,MAAMiQ,EAAOvV,OAAK0F,cAAc+4B,GAE1BwvB,EAA4C,CAAC,CAAC,EAAG,IACvDA,EAAiB79C,QAASquC,GAE1B,IAAK,IAAI55C,EAAI,EAAI45B,EAAW78B,OAAQiD,EAAIS,EAAEtE,MAAMY,SAAUiD,EACxDopD,EAAiB79C,KAAK,CAAC,EAAG,IAG5B,MAAM89C,EAAU7K,GAAYj+C,WAAW,CACrCG,OAAQ,CAACD,KACTG,UACAyD,MAAO,CAACu1C,SAAUwP,EAAkB1K,cAAe,KAG/C4K,EACF/sD,eAAaw9B,YAAYsvB,EAAQltD,MAAOy9B,EAAYlpB,GAAM,GAExD64C,EAAoChtD,eAAa09B,YACnDqvB,EAAoBvsD,OAAQ68B,EAAW78B,QAAQ,GAE7Cif,EACFzf,eAAa49B,oBAAoBkvB,EAAQltD,MAAOy9B,EAAYlpB,GAAM,GAIhE84C,EACFlvC,GAAQ,CAAC5Z,OAHwB,CAACD,EAAG4oD,GAGLzoD,UAASyD,MAFV,CAAClI,MAAOmtD,KAOrCG,EACFx5C,GAAU,CAACvP,OAJ0B,CAACD,EAAG+oD,GAIL5oD,UAASyD,MAF5B,CAACsL,KAAM45C,KAMtB7nD,EAAS4Y,GACX,CAAC5Z,OAHsC,CAACD,EAAGgpD,GAGb7oD,UAASyD,MAFF,CAAClI,MAAO6f,KAQjD,OAJApb,EAAQ/B,8BAA8BwqD,GACtCzoD,EAAQ/B,8BAA8B2qD,GACtC5oD,EAAQ/B,8BAA8B4qD,GAE/B/nD,CACT,GCXO,MAAMgoD,GAA0C,CACrDtpD,WAAYupD,sBACZrpD,YAAa,MACbC,oBAnDkCC,GAIlC,MAAME,OAACA,EAAME,QAAEA,GAAWJ,GACpBgR,QAACA,EAAOtV,OAAEA,EAAM0hB,WAAEA,EAAU/H,aAAEA,GAAgBnV,EACpD,GAAgC,IAA5Bkd,EAAWzhB,MAAMY,OACnB,MAAM,IAAIwB,MAAM,+CACVqf,EAAWzhB,SAEnB,GAA6B,IAAzBqV,EAAQrV,MAAMY,OAChB,MAAM,IAAIwB,MAAM,2CACViT,EAAQrV,SAEhB,GAA4B,IAAxBD,EAAOC,MAAMY,OACf,MAAM,IAAIwB,MAAM,0CACVrC,EAAOC,SAEf,GAAkC,IAA9B0Z,EAAa1Z,MAAMY,OACrB,MAAM,IAAIwB,MAAM,iDACVsX,EAAa1Z,SAGrB,MAAMijD,EAAWx+C,EAAQ9E,KAAKQ,IAAIkV,EAAQ/U,QAAQP,OAC5CgkD,EAAUt/C,EAAQ9E,KAAKQ,IAAIJ,EAAOO,QAAQP,OAC1C0tD,EAAchpD,EAAQ9E,KAAKQ,IAAIshB,EAAWnhB,QAAQP,OAClDikD,EACFv/C,EAAQ9E,KAAKQ,IAAIuZ,EAAapZ,QAAQP,OAAO,IAE1CuiB,EAAeorC,EAAoBnrC,EACnCX,EAAmBC,GACtBN,GACI0hC,EAAU5tC,EAAQrV,MAAOqV,EAAQnW,MAAO6kD,EAAShkD,EAAOb,MACxDuuD,EAAazJ,GACrB,MAAO,CACLv/C,EAAQ/D,eAAegtD,EAAoBr4C,EAAQnW,MAAOojB,GAC1D7d,EAAQ/D,eACJ,CAACgtD,EAAmB,IAAK3tD,EAAOb,MAAOqjB,GAC3C9d,EAAQ/D,eACJ,CAACkhB,EAAkBhhB,QAAS,OAC5B,IAAIgnB,WACAhG,EAAkB7gB,KAAKsK,GAAmBoG,OAAOpG,OACzD5G,EAAQ/D,eACJ,CAACmhB,EAAgBjhB,QAASyU,EAAQnW,MAClC,IAAIuI,WAAWoa,IAEvB,GCVO,MAAM8rC,GAAoC,CAC/C1pD,WAAY2pD,gBACZzpD,YAAa,MACbC,oBAtCEC,GAEF,MAAME,OAACA,EAAME,QAAEA,GAAWJ,GACpBwe,aAACA,EAAYG,WAAEA,EAAU/d,SAAEA,GAAYV,EAC7C,GAAkC,IAA9Bse,EAAa7iB,MAAMY,OACrB,MAAM,IAAIwB,MAAM,gEACVygB,EAAa7iB,SAErB,GAAgC,IAA5BgjB,EAAWhjB,MAAMY,OACnB,MAAM,IAAIwB,MAAM,8DACV4gB,EAAWhjB,SAGnB,GAA8B,IAA1BiF,EAASjF,MAAMY,OACjB,MAAM,IAAIwB,MACN,sDAAsD6C,EAASjF,SAGrE,MAAM6tD,EACFjvD,MAAM8I,KAAKjD,EAAQ9E,KAAKQ,IAAI6iB,EAAW1iB,QAAQP,QAC7C+tD,EACFrpD,EAAQ9E,KAAKQ,IAAI0iB,EAAaviB,QAAQP,OACpCkjB,EACFrkB,MAAM8I,KAAKjD,EAAQ9E,KAAKQ,IAAI8E,EAAS3E,QAAQP,SAE1CkkB,EAAY3O,EAAciI,GAAeqF,GAC5CkrC,EAAejrC,EAAa7iB,MAAO6iB,EAAa3jB,MAAO2uD,EACvD5qC,GACJ,MAAO,CACLxe,EAAQ/D,eAAe4U,EAAcuN,EAAa3jB,MAAO+kB,GACzDxf,EAAQ/D,eACJ,CAAC6c,EAAY3c,QAASqE,EAAS/F,MAAO,IAAIuI,WAAW8V,IAE7D,GCJO,MAAMwwC,GAAwC,CACnD9pD,WAAY+pD,oBACZ7pD,YAAa,MACbC,oBAhCEC,GAEF,MAAME,OAACA,EAAME,QAAEA,GAAWJ,GACpB1E,KAACA,EAAI0V,QAAEA,EAAO8O,WAAEA,GAAc5f,EACpC,GAAI5E,EAAKK,MAAMY,OAAS,EACtB,MAAM,IAAIwB,MACN,6DAEN,GAA6B,IAAzBiT,EAAQrV,MAAMY,OAChB,MAAM,IAAIwB,MAAM,4DACRiT,EAAQrV,SAElB,GAAgC,IAA5BmkB,EAAWnkB,MAAMY,OACnB,MAAM,IAAIwB,MAAM,gEACR+hB,EAAWnkB,SAErB,GAAIqV,EAAQrV,MAAM,KAAOmkB,EAAWnkB,MAAM,GACxC,MAAM,IAAIoC,MAAM,iDAGlB,MAAM6rD,EAAQxpD,EAAQ9E,KAAKQ,IAAIR,EAAKW,QAAQP,OACtCkjD,EAAWx+C,EAAQ9E,KAAKQ,IAAIkV,EAAQ/U,QAAQP,OAC5CmuD,EAAczpD,EAAQ9E,KAAKQ,IAAIgkB,EAAW7jB,QAAQP,QAEjDouD,EAAYC,GAAmBlqC,GAClC+pC,EAAOtuD,EAAKK,MAAOL,EAAKT,MAAO+jD,EAAUiL,GAAa,GAC1D,OAAOzpD,EAAQ/D,eAAe0tD,EAAiBzuD,EAAKT,MAAOivD,EAC7D,GCEO,MAAME,GAAuC,CAClDpqD,WAAYqqD,mBACZnqD,YAAa,MACbC,oBAhCEC,GAEF,MAAME,OAACA,EAAME,QAAEA,GAAWJ,GACpB1E,KAACA,EAAI0V,QAAEA,EAAO8O,WAAEA,GAAc5f,EACpC,GAAI5E,EAAKK,MAAMY,OAAS,EACtB,MAAM,IAAIwB,MACN,6DAEN,GAA6B,IAAzBiT,EAAQrV,MAAMY,OAChB,MAAM,IAAIwB,MAAM,2DACTiT,EAAQrV,SAEjB,GAAgC,IAA5BmkB,EAAWnkB,MAAMY,OACnB,MAAM,IAAIwB,MAAM,+DACT+hB,EAAWnkB,SAEpB,GAAIqV,EAAQrV,MAAM,KAAOmkB,EAAWnkB,MAAM,GACxC,MAAM,IAAIoC,MAAM,iDAGlB,MAAM6rD,EAAQxpD,EAAQ9E,KAAKQ,IAAIR,EAAKW,QAAQP,OACtCkjD,EAAWx+C,EAAQ9E,KAAKQ,IAAIkV,EAAQ/U,QAAQP,OAC5CmuD,EAAczpD,EAAQ9E,KAAKQ,IAAIgkB,EAAW7jB,QAAQP,QAEjDouD,EAAYC,GAAmBlqC,GAClC+pC,EAAOtuD,EAAKK,MAAOL,EAAKT,MAAO+jD,EAAUiL,GAC7C,OAAOzpD,EAAQ/D,eAAe0tD,EAAiBzuD,EAAKT,MAAOivD,EAC7D,GC8BO,MAAMI,GAAoC,CAC/CtqD,WAAYuqD,gBACZrqD,YAAa,MACbC,oBA9D4BC,GAK5B,MAAME,OAACA,EAAME,QAAEA,EAAOyD,MAAEA,GAAS7D,GAC3BoqD,cAACA,EAAaC,aAAEA,EAAYh1C,aAAEA,GAAgBnV,GAC9CgZ,YAACA,GAAerV,GAEhB0G,UAACA,EAAS+Q,WAAEA,EAAU9Q,UAAEA,EAASC,QAAEA,EAAOyN,WAAEA,GAC9Cnc,eAAasqD,gBAAgBgE,EAAcD,EAAelxC,GACxDqC,GAAiB,EAEjBrQ,EAAa9K,EAAQzC,WAA0BysD,GAErD,IAAI7iD,EACJ,OAAQ8iD,EAAaxvD,OACnB,IAAK,OAIH0M,EAAS6T,GACLlQ,EAJe9K,EAAQzC,WAAyB0sD,GAIxBnxC,EAAahB,EAAY1N,EACjD8Q,EAAY/Q,EAAWE,EAHvB6/C,QAAQlqD,EAAQ9E,KAAKQ,IAAIuZ,EAAapZ,QAAQP,OAAO,IAGN6f,GACnD,MAEF,IAAK,UAIHhU,EAAS6T,GACLlQ,EAJe9K,EAAQzC,WAA4B0sD,GAI3BnxC,EAAahB,EAAY1N,EACjD8Q,EAAY/Q,EAAWE,EAHvBrK,EAAQ9E,KAAKQ,IAAIuZ,EAAapZ,QAAQP,OAAO,GAGE6f,GACnD,MAEF,IAAK,QAIHhU,EAAS6T,GACLlQ,EAJe9K,EAAQzC,WAA0B0sD,GAIzBnxC,EAAahB,EAAY1N,EACjD8Q,EAAY/Q,EAAWE,EAHvBrK,EAAQ9E,KAAKQ,IAAIuZ,EAAapZ,QAAQP,OAAO,GAGE6f,GACnD,MAEF,IAAK,SAIHhU,EAAS6T,GACLlQ,EAJe9K,EAAQzC,WAA2B0sD,GAI1BnxC,EAAahB,EAAY1N,EACjD8Q,EAAY/Q,EAAWE,EAJL9P,OAAKkD,aACvBuC,EAAQ9E,KAAKQ,IAAIuZ,EAAapZ,QAAQP,OAAO,IAGE6f,GACnD,MAEF,QACE,MAAM,IAAIxd,MAAM,oBAAoBssD,EAAaxvD,SAErD,OAAOuF,EAAQ/D,eAAe6c,EAAa3R,EAAO1M,MAAO0M,EAAO7L,OAClE,GClCO,MAAM6uD,GAA6B,CACxC3qD,WAAY4qD,SACZ1qD,YAAa,MACbC,oBAxBEC,GAEF,MAAME,OAACA,EAAME,QAAEA,EAAOyD,MAAEA,GAAS7D,GAC3BC,EAACA,GAAKC,GACNuqD,gBAACA,EAAep6C,KAAEA,GAAQxM,EAE1B4jB,EAAQ9sB,OAAK6V,eAAeH,EAAMpQ,EAAEtE,OAAO,GAC3C+uD,EAAa3uD,eAAa4uD,iBAAiB1qD,EAAGwqD,EAAiBhjC,GAE/DxL,EAAQ,IAAI1hB,MAAM0F,EAAEtE,MAAMY,QAAQiV,KAAK,GACvC3K,EAAO5G,EAAEtE,MAAMmG,QACrB,OAAO4oD,EAAWhuD,KAAI+pB,IACpB,MAAMjc,EAAY,IAAI3D,GACtB2D,EAAUid,GAAShB,EACnB,MAAMmkC,EACF9oD,GAAM,CAAC5B,OAAQ,CAACD,KAAIG,UAASyD,MAAO,CAACoY,QAAOpV,KAAM2D,KAEtD,OADAyR,EAAMwL,IAAUhB,EACTmkC,CAAM,GAEjB,GCrBaC,GAA6B,CACxCjrD,WAAYkrD,SACZhrD,YAAa,MACbC,WAAY,EAAEG,SAAQE,cACpB,MAAMH,EAACA,GAAKC,EACNC,EAAaC,EACnBhG,EAAiB6F,EAAG,UAEpB,MAAMvE,EAASyE,EAAW7E,KAAKQ,IAAImE,EAAEhE,QAAQP,OACvCgM,EAAY,IAAInI,aAAa7D,EAAOa,QAC1C,IAAK,IAAIiD,EAAI,EAAGA,EAAI9D,EAAOa,SAAUiD,EAAG,CACtC,MAAMwH,EAAQtL,EAAO8D,GACrBkI,EAAUlI,GAAKwH,EAAQA,EAGzB,MAAO,CAAC/K,OADOkE,EAAW1E,MAAMiM,EAAWzH,EAAEtE,MAAOsE,EAAEpF,OACtCc,MAAOsE,EAAEtE,MAAOd,MAAOoF,EAAEpF,MAAM,GChBtC+R,GAAOhF,EAAgBmjD,QAAM,CAAC9iD,EAAIpE,KAC7C,MAAMmnD,EAAYnnD,EAClB,OAAIwJ,MAAMpF,GACDgjD,IAEAhjD,EAAK,EAAI,EAAI+iD,EAAUpiC,SAIrBsiC,GAA2B,CACtCtrD,WAAYmrD,OACZjrD,YAAa,MACbC,WAAY6M,ICuDP,MAAMu+C,GAAmC,CAC9CvrD,WAAYwrD,eACZtrD,YAAa,MACbC,oBAlE2BC,GAK3B,MAAME,OAACA,EAAME,QAAEA,EAAOyD,MAAEA,GAAS7D,GAC3BC,EAACA,GAAKC,GACN+b,MACJA,EAAKuE,IACLA,EAAG/V,QACHA,EAAO4gD,UACPA,EAASC,QACTA,EAAOC,aACPA,EAAYC,YACZA,EAAWC,eACXA,GACE5nD,EAEJzJ,EAAiB6F,EAAG,gBAEpB,MAAMyrD,iBACJA,EAAgBC,WAChBA,EAAUC,WACVA,EAAUC,UACVA,EAASC,cACTA,EACA7vC,MAAOW,EACP4D,IAAKurC,EACLthD,QAASuhD,GAEP7vC,aAAW8vC,UACPhsD,EAAEtE,MAAOsgB,EAAOuE,EAAK/V,EAAS4gD,EAAWC,EAASC,EAClDC,EAAaC,GAErB,IAAIvqD,EAIJ,GAAI0qD,EAEF1qD,EAAS4Y,GAAQ,CAAC5Z,OAAQ,CAACD,KAAIG,UAASyD,MAAO,CAAClI,MAAOgwD,UAClD,GAAIE,GAAaC,EAAe,CAErCnxD,OAAKC,OACDqF,EAAEtE,MAAMY,QAAU,GAClB,IAAM,yCAAyC0D,EAAEtE,MAAMY,WAE3D,MAAMsK,EAAOsV,aAAWwf,gBAAgB/e,EAAQmvC,EAAMC,GAEhDE,EAASpqD,GAAM,CAAC5B,OAAQ,CAACD,KAAIG,UAASyD,MAAO,CAACoY,MAAOW,EAAQ/V,UACnE3F,EACI4Y,GAAQ,CAAC5Z,OAAQ,CAACD,EAAGisD,GAAS9rD,UAASyD,MAAO,CAAClI,MAAOgwD,KAC1DvrD,EAAQ/B,8BAA8B6tD,OACjC,CACL,MACM3kD,EAASya,GAAiB0pC,EADnBtrD,EAAQzC,WAA4BsC,GACO+rD,EAAUpvC,GAElE1b,EAASd,EAAQ/D,eAAesvD,EAAYpkD,EAAO1M,MAAO0M,EAAO7L,QAGnE,OAAOwF,CACT,GCpCO,MAAMirD,GAAmC,CAC9CvsD,WAAYwsD,eACZtsD,YAAa,MACbC,oBA9B2BC,GAK3B,MAAME,OAACA,EAAME,QAAEA,EAAOyD,MAAEA,GAAS7D,GAC3BkiB,UACJA,EAASC,YACTA,EAAWC,QACXA,EAAOC,SACPA,EAAQC,SACRA,EAAQC,uBACRA,GACE1e,GACEvI,KAACA,EAAIipB,WAAEA,GAAcrkB,EACrB0pD,EAAQxpD,EAAQ9E,KAAKQ,IAAIR,EAAKW,QAAQP,OACtC2wD,EAAcjsD,EAAQ9E,KAAKQ,IAAIyoB,EAAWtoB,QAAQP,QAEjDyoB,EAAQF,GAAgBK,GAC3BslC,EAAOyC,EAAanqC,EAAWC,EAAaC,EAASC,EAAUC,EAC/DC,GACJ,MAAO,CACLniB,EAAQ/D,eAAe,CAAC8nB,EAAO5nB,QAAS,SAAU4nB,GAClD/jB,EAAQ/D,eAAekoB,EAAW5oB,MAAO,QAASsoB,GAEtD,GCQO,MAAMqoC,GAAkC,CAC7C1sD,WAAY2sD,cACZzsD,YAAa,MACbC,oBApC0BC,GAK1B,MAAME,OAACA,EAAME,QAAEA,EAAOyD,MAAEA,GAAS7D,GAC3B0kB,UAACA,GAAa7gB,GACdf,MAACA,EAAK6hB,UAAEA,GAAazkB,EAE3B,GAAoB,WAAhB4C,EAAMjI,MACR,MAAM,IAAIkD,MAAM,oCAElB,GAA2B,IAAvB+E,EAAMnH,MAAMY,OACd,MAAM,IAAIwB,MAAM,sCAAsC+E,EAAMnH,SAE9D,GAA+B,IAA3BgpB,EAAUhpB,MAAMY,OAClB,MAAM,IAAIwB,MACN,0CAA0C4mB,EAAUhpB,SAG1D,MAAM6wD,EAASpsD,EAAQ9E,KAAKQ,IAAIgH,EAAM7G,QAAQP,OACxC+wD,EAAarsD,EAAQ9E,KAAKQ,IAAI6oB,EAAU1oB,QAAQP,OAAO,IAEtDsV,EAAStV,EAAQC,GACpBopB,GAAgBynC,EAAQC,EAAY/nC,GAClCxM,EAAaxc,EAAOa,OAC1B,MAAO,CACL6D,EAAQ/D,eAAe,CAAC6b,EAAY,GAAI,QAASlH,GACjD5Q,EAAQ/D,eAAe,CAAC6b,GAAa,SAAUxc,GAC/C0E,EAAQ/D,eAAe,CAAC,GAAI,QAAS,IAAI+G,WAAWzH,IAExD,GCTO,MAAM+wD,GAA6C,CACxD9sD,WAAY+sD,yBACZ7sD,YAAa,MACbC,oBAzBqCC,GAKrC,MAAME,OAACA,EAAME,QAAEA,EAAOyD,MAAEA,GAAS7D,GAC3BulB,WAACA,GAAc1hB,GACff,MAACA,GAAS5C,EAEhB,GAAoB,WAAhB4C,EAAMjI,MACR,MAAM,IAAIkD,MAAM,oCAElB,GAAIwnB,GAAc,EAChB,MAAM,IAAIxnB,MAAM,wCAGlB,MAEMwiB,EAAS+E,GAFAllB,EAAQ9E,KAAKQ,IAAIgH,EAAM7G,QAAQP,OAEI6pB,GAClD,OAAOnlB,EAAQ/D,eAAeyG,EAAMnH,MAAO,QAAS4kB,EACtD,GCtBaqsC,GAAMhlD,EAAgBilD,OAAM5kD,GAAOxI,KAAKmtD,IAAI3kD,KAE5C6kD,GAA0B,CACrCltD,WAAYitD,MACZ/sD,YAAa,MACbC,WAAY6sD,ICLDG,GAAOnlD,EAAgBolD,QAAO/kD,GAAOxI,KAAKstD,KAAK9kD,KAE/CglD,GAA2B,CACtCrtD,WAAYotD,OACZltD,YAAa,MACbC,WAAYgtD,ICkBP,MAAMG,GAA0C,CACrDttD,WAAYutD,sBACZrtD,YAAa,MACbC,oBAxBkCC,GAKlC,MAAME,OAACA,EAAME,QAAEA,GAAWJ,GACpB3F,OAACA,EAAM2W,QAAEA,EAAOqK,QAAEA,GAAWnb,GAE7BqK,UAACA,EAAS+Q,WAAEA,EAAU9Q,UAAEA,EAASC,QAAEA,EAAOyN,WAAEA,GAC9Cnc,eAAasqD,gBAAgBhrC,EAASrK,EAAS3W,EAAOsB,OAGpDuP,EAAa9K,EAAQzC,WAA0BqT,GAC/Co8C,EAAahtD,EAAQzC,WAAoC0d,GACzDgyC,EAAYjtD,EAAQzC,WAAoCtD,GACxDkN,EAAS6T,GACXlQ,EAAYkiD,EAAY/yD,EAAOsB,MAAOuc,EAAY1N,EAAW8Q,EAC7D/Q,EAAWE,EAAS4iD,GAPD,GAQvB,OAAOjtD,EAAQ/D,eAAehC,EAAOsB,MAAO4L,EAAO1M,MAAO0M,EAAO7L,OACnE,GCNO,MAAM4xD,GAA2B,CACtC1tD,WAAY2tD,OACZztD,YAAa,MACbC,oBAfEC,GAEF,MAAME,OAACA,EAAME,QAAEA,EAAOyD,MAAEA,GAAS7D,GAC3BC,EAACA,GAAKC,GACN+lB,KAACA,GAAQpiB,EAEfzJ,EAAiB6F,EAAG,QACpB,MAAMsH,EAASye,GAAS5lB,EAAQzC,WAAWsC,GAAIgmB,GAE/C,OAAO7lB,EAAQ/D,eAAekL,EAAO5L,MAAO4L,EAAO1M,MAAO0M,EAAO7L,OACnE,GCUO,MAAM8xD,GAA2B,CACtC5tD,WAAY6tD,OACZ3tD,YAAa,MACbC,oBAvBEC,GAEF,MAAME,OAACA,EAAME,QAAEA,EAAOyD,MAAEA,GAAS7D,GAC3BC,EAACA,GAAKC,GACN8K,EAACA,EAAC8b,OAAEA,GAAUjjB,EAEpBzJ,EAAiB6F,EAAG,QAEpB,MAAMwG,EAAQrG,EAAQ9E,KAAKQ,IAAImE,EAAEhE,QAAQP,QAClCurB,EAAaC,GAChBL,GAASpgB,EAAOxG,EAAEtE,MAAOsE,EAAEpF,MAA0BmQ,EAAG8b,GAE5D,MAAO,CACL1mB,EAAQ/D,eACJ4qB,EAAYtrB,MAAOsrB,EAAYpsB,MAAOosB,EAAYvrB,QACtD0E,EAAQ/D,eACJ6qB,EAAevrB,MAAOurB,EAAersB,MAAOqsB,EAAexrB,QAEnE,GC2EO,MAAMgyD,GAAgC,CAC3C9tD,WAAY+tD,YACZ7tD,YAAa,MACbC,oBAnGwBC,GAKxB,MAAME,OAACA,EAAM2D,MAAEA,EAAKzD,QAAEA,GAAWJ,GAC3B6iC,MAACA,EAAK+qB,WAAEA,GAAc1tD,GACtB2tD,cAACA,EAAaC,SAAEA,EAAQvI,UAAEA,EAASrsC,YAAEA,GAAerV,GAEnDmjB,EAAOmc,EAAaC,EAAYC,GAAeR,EAAMlnC,OACrDi2B,EAAWO,GACC,MAAfjZ,EAAsBA,EAAc,CAACiqB,EAAaC,GAChD96B,EAAW,CAAC0e,EAAO4K,EAAWO,EAAUkR,GAExC0qB,EAAYpzD,OAAKqG,eAAe6hC,EAAMlnC,OACtCqyD,EAAgBD,EAAU,GAC1BE,EAAcF,EAAU,GACxBG,EAAcH,EAAU,GAExBI,EAAaxzD,OAAKqG,eAAesH,GACjC8lD,EAAiBD,EAAW,GAC5BE,EAAeF,EAAW,GAC1BG,EAAeH,EAAW,GAE1BpnD,EAAUpM,OAAKwG,uBACjB0hC,EAAMhoC,MAA0BF,OAAK0F,cAAciI,IAEvDvB,EAAQyK,KAAK+zC,GAEb,MAAM5hB,EAAYvjC,EAAQ9E,KAAKQ,IAAI+mC,EAAM5mC,QAAQP,OAC3C6yD,EACFnuD,EAAQ9E,KAAKQ,IAAI8xD,EAAW3xD,QAAQP,OAIxC,IAAK,IAAIiI,EAAI,EAAGA,EAAIqjB,IAASrjB,EAAG,CAC9B,MAAM6qD,EAAoC,IAAxBZ,EAAWjyD,MAAM,GAC/B4yD,EACAA,EAAc/zC,SAAa,EAAJ7W,EAAW,EAAJA,EAAQ,GAE1C,IAAK,IAAI8qD,EAAO,EAAGA,EAAO78B,IAAa68B,EACrC,IAAK,IAAIC,EAAO,EAAGA,EAAOv8B,IAAYu8B,EACpC,IAAK,IAAI56B,EAAU,EAAGA,EAAUuP,IAAevP,EAAS,CACtD,IAAIuV,EAEJ,MAAMslB,EAAaH,EAAU,GAAKE,EAAOF,EAAU,GAAKC,EAAO,EAE/D,GAAmB,IAAfE,EAGF,SAGF,MAAMC,GACDJ,EAAU,GAAKE,EAAOF,EAAU,GAAKC,EAAOD,EAAU,IACvDG,EACEE,GACDL,EAAU,GAAKE,EAAOF,EAAU,GAAKC,EAAOD,EAAU,IACvDG,EAEE1uD,EAAI6uD,GAASF,EAAKxrB,EAAY0qB,GAC9B9wB,EAAI8xB,GAASD,EAAK1rB,EAAa2qB,GAErC,OAAQD,GACN,IAAK,UACHxkB,EAAM0lB,GACFprB,EAAWR,EAAaC,EAAY4qB,EACpCC,EAAaC,EAAavqD,EAAGq5B,EAAG/8B,EAAG6zB,EAASyxB,GAChD,MACF,IAAK,WACHlc,EAAM2lB,GACFrrB,EAAWR,EAAaC,EAAY4qB,EACpCC,EAAaC,EAAavqD,EAAGq5B,EAAG/8B,EAAG6zB,EAASyxB,GAChD,MACF,QACE,MAAM,IAAIxnD,MAEN,+DAAuB8vD,KAO/B9mD,EAHIpD,EAAIyqD,EAAiBK,EAAOJ,EAC5BK,EAAOJ,EAAex6B,GAEXuV,EAKrB,OAAOjpC,EAAQ/D,eAAeiM,EAAUu6B,EAAMhoC,MAAOkM,GAIvD,MAAO,CAAC9K,OADOmE,EAAQ3E,MAAMsL,EAASuB,EAAUu6B,EAAMhoC,OACtCc,MAAOknC,EAAMlnC,MAAOd,MAAOgoC,EAAMhoC,MACnD,GAQA,SAASi0D,GACLG,EAAkBC,EAClB7V,GACF,OAAQA,GACN,IAAK,UACH,OAWN,SAAyB4V,EAAkBC,GAEzC,IAAIC,EAAUF,EACd,GAAIE,EAAU,EACZ,GAAID,GAAO,EACTC,EAAU,MACL,CACL,MAAMC,EAAM,EAAIF,EACZC,EAAUC,IACZD,EAAUC,EAAM3vD,KAAK6f,OAAO6vC,EAAUC,GAAOD,GAE/CA,EAAUA,GAAWD,EAAMC,EAAUC,GAAOD,EAAU,OAEnD,GAAIA,EAAUD,EAAM,EACzB,GAAIA,GAAO,EACTC,EAAU,MACL,CACL,MAAMC,EAAM,EAAIF,EAChBC,GAAWC,EAAM3vD,KAAK6f,MAAM6vC,EAAUC,GAClCD,GAAWD,IACbC,EAAUC,EAAMD,EAAU,GAMhC,OAAOx0D,OAAK00D,MAAM,EAAGF,EAASD,EAAM,EACtC,CAtCaI,CAAgBL,EAAUC,GACnC,IAAK,OACH,OAsCN,SAAsBD,EAAkBC,GAEtC,IAAIC,EAAUF,EACd,GAAIE,EAAU,EACZ,GAAID,GAAO,EACTC,EAAU,MACL,CACL,MAAMI,EAAKL,EAAM,EACjBC,GAAWD,GAAOzvD,KAAK6f,OAAO6vC,EAAUI,GAAM,QAE3C,GAAIJ,EAAUD,EAAM,EACzB,GAAIA,GAAO,EACTC,EAAU,MACL,CACL,MAAMI,EAAKL,EAAM,EACjBC,GAAWD,EAAMzvD,KAAK6f,MAAM6vC,EAAUI,GAK1C,OAAO50D,OAAK00D,MAAM,EAAGF,EAASD,EAAM,EACtC,CA3DaM,CAAaP,EAAUC,GAChC,IAAK,UACH,OA+DN,SAAyBD,EAAkBC,GACzC,OAAOv0D,OAAK00D,MAAM,EAAGJ,EAAUC,EAAM,EACvC,CAjEaO,CAAgBR,EAAUC,GAEnC,QACE,OAwDN,SAA0BD,EAAkBC,GAC1C,OAAOD,CACT,CA1DaS,CAAiBT,GAE9B,CA8DA,SAASU,GACLhsB,EAAuBR,EAAqBC,EAC5CwsB,EAAqBC,EAAmBC,EAAmB9oC,EAC3DgW,EAAW/8B,EAAW6zB,EAAiByxB,GAEzC,OAAI,GAAKvoB,GAAKA,EAAImG,GAAe,GAAKljC,GAAKA,EAAImjC,EACtCO,EAFG3c,EAAQ4oC,EAAc5yB,EAAI6yB,EAAY5vD,EAAI6vD,EAAYh8B,GAIzDyxB,CAEX,CAEA,SAASwJ,GACLprB,EAAuBR,EAAqBC,EAC5CwsB,EAAqBC,EAAmBC,EAAmB9oC,EAC3DgW,EAAW/8B,EAAW6zB,EAAiByxB,GAIzC,OAAOoK,GACHhsB,EAAWR,EAAaC,EAAYwsB,EAAaC,EAAWC,EAC5D9oC,EALOvnB,KAAK2lC,MAAMpI,GACXv9B,KAAK2lC,MAAMnlC,GAIH6zB,EAASyxB,EAC9B,CAEA,SAASyJ,GACLrrB,EAAuBR,EAAqBC,EAC5CwsB,EAAqBC,EAAmBC,EAAmB9oC,EAC3DgW,EAAW/8B,EAAW6zB,EAAiByxB,GACzC,MAAMwK,EAAStwD,KAAKmK,MAAMozB,GACpBgzB,EAASvwD,KAAKmK,MAAM3J,GACpBgwD,EAAQF,EAAS,EACjBG,EAAQF,EAAS,EAyBvB,OAAQC,EAAQjzB,KArBXkzB,EAAQjwD,GACL0vD,GACIhsB,EAAWR,EAAaC,EAAYwsB,EAAaC,EACjDC,EAAW9oC,EAAO+oC,EAAQC,EAAQl8B,EAASyxB,IAClDtlD,EAAI+vD,GACDL,GACIhsB,EAAWR,EAAaC,EAAYwsB,EAAaC,EACjDC,EAAW9oC,EAAO+oC,EAAQG,EAAOp8B,EAASyxB,KAclBvoB,EAAI+yB,KAVnCG,EAAQjwD,GACL0vD,GACIhsB,EAAWR,EAAaC,EAAYwsB,EAAaC,EACjDC,EAAW9oC,EAAOipC,EAAOD,EAAQl8B,EAASyxB,IACjDtlD,EAAI+vD,GACDL,GACIhsB,EAAWR,EAAaC,EAAYwsB,EAAaC,EACjDC,EAAW9oC,EAAOipC,EAAOC,EAAOp8B,EAASyxB,GAIvD,CCvNO,MAAM4K,GAA6B,CACxCvwD,WAAYwwD,SACZtwD,YAAa,MACbC,oBAnBEC,GAEF,MAAME,OAACA,EAAM2D,MAAEA,EAAKzD,QAAEA,GAAWJ,GAC3BqQ,KAACA,GAAQxM,GACT5D,EAACA,GAAKC,EACZ9F,EAAiB6F,EAAG,UAEpB,MAAMvE,EAAS0E,EAAQ9E,KAAKQ,IAAImE,EAAEhE,QAAQP,QACpCwiB,aAACA,EAAYhF,YAAEA,EAAWlI,QAAEA,GAC9BwW,GAAW9rB,EAAQ2U,EAAMpQ,EAAEtE,MAAOsE,EAAEpF,OACxC,MAAO,CACLuF,EAAQ/D,eAAe6c,EAAajZ,EAAEpF,MAAOqjB,GAC7C9d,EAAQ/D,eAAe,CAAC2U,EAAQzU,QAAS,QAASyU,GAEtD,GCoBO,MAAMq/C,GAA6B,CACxCzwD,WAAY0wD,SACZxwD,YAAa,MACbC,oBAtCEC,GAEF,MAAME,OAACA,EAAME,QAAEA,EAAOyD,MAAEA,GAAS7D,GAC3BgH,MAACA,GAAS9G,EAChB,IAAImQ,KAACA,GAAQxM,EAETwM,EAAO,IACTA,GAAQrJ,EAAMrL,MAAMY,QAGtB,MAAMg0D,EAAYvpD,EAAMrL,MAAMY,OAExBoQ,EAAM3F,EAAMrL,MAAM0U,GAClB/H,EAAqB,IAAI/N,MAAMg2D,EAAY,GACjD,IAAI7vC,EAAW,EACf,IAAK,IAAIlhB,EAAI,EAAGA,EAAI+wD,EAAW/wD,IACzBA,IAAM6Q,IACR/H,EAASoY,KAAc1Z,EAAMrL,MAAM6D,IAIvC,MAAMyc,EAAQ,IAAI1hB,MAAMg2D,GAAW/+C,KAAK,GAClC3K,EAAOG,EAAMrL,MAAMmG,QACzB+E,EAAKwJ,GAAQ,EACb,MAAMxB,EAAM,IAAItU,MAAMoS,GACtB,IAAK,IAAInN,EAAI,EAAGA,EAAIqP,EAAItS,OAAQiD,IAAK,CACnCyc,EAAM5L,GAAQ7Q,EACd,MAAMgxD,EAAU1uD,GAAM,CAAC5B,OAAQ,CAACD,EAAG+G,GAAQ5G,UAASyD,MAAO,CAACoY,QAAOpV,UACnEgI,EAAIrP,GAAKsa,GAAQ,CAAC5Z,OAAQ,CAACD,EAAGuwD,GAAUpwD,UAASyD,MAAO,CAAClI,MAAO2M,KAChElI,EAAQ/B,8BAA8BmyD,GAGxC,OAAO3hD,CACT,GC0BO,MAAM4hD,GAAyC,CACpD7wD,WAAY8wD,qBACZ5wD,YAAa,MACbC,oBA1DiCC,GAKjC,MAAME,OAACA,EAAME,QAAEA,EAAOyD,MAAEA,GAAS7D,GAC3BC,EAACA,EAAC6f,WAAEA,GAAc5f,GAClBywD,YAACA,GAAe9sD,EAEtBzJ,EAAiB6F,EAAG,sBAEpB,MAEM4O,EAAM,GACNye,EAA8B,GAI9BsjC,EAPQ3wD,EAAEtE,MAAMY,OACCujB,EAAWnkB,MAAMY,OAOxC,IAAIstD,EAAc/pC,EAElB,IAAK,IAAItgB,EAAI,EAAGA,EAAIoxD,IAAYpxD,EAAG,CACjC,MAAMqxD,EAAWvlB,GACb,CAACprC,OAAQ,CAAC4C,MAAO+mD,GAAczpD,UAASyD,MAAO,CAACiH,IAAKtL,EAAI,KAC7DqqD,EAAcgH,EACdvjC,EAAcviB,KAAK8lD,GAGrB,IAAK,IAAIrxD,EAAI,EAAGA,EAAImxD,IAAenxD,EAAG,CACpC,MAAMsxD,EAAcn2D,OAAK+T,kBACvBlP,EAAyB,SACrBuxD,EAAY3wD,EAAQ/D,eAAe,GAAI,QAASy0D,GAChD7Y,EACFjvC,EAAM,CAAC9I,OAAQ,CAACwD,EAAGqtD,EAAWptD,EAAGkmD,GAAczpD,YAC7C4wD,EACFptD,EAAK,CAAC1D,OAAQ,CAACD,EAAGg4C,GAAO73C,UAASyD,MAAO,CAAChJ,MAAO,aAC/Co2D,EACF9iD,GAAS,CAACjO,OAAQ,CAACwD,EAAGstD,EAAYrtD,EAAG1D,GAAIG,YACvC8wD,EACFrkC,GAAI,CAAC3sB,OAAQ,CAACD,EAAGgxD,GAAM7wD,UAASyD,MAAO,CAACwM,KAAM,EAAGC,UAAU,KAC/DzB,EAAI9D,KAAKmmD,GACT5jC,EAAcviB,KAAKgmD,GACnBzjC,EAAcviB,KAAKktC,GACnB3qB,EAAcviB,KAAKimD,GACnB1jC,EAAcviB,KAAKkmD,GACnB3jC,EAAcviB,KAAKmmD,GAGrB,MAAMhwD,EAASy8C,GAAK,CAACz9C,OAAQ2O,EAAKzO,UAASyD,MAAO,CAACwM,KAAM,KAIzD,OAFAid,EAAc7yB,SAAQC,GAAK0F,EAAQ/B,8BAA8B3D,KAE1DwG,CACT,GCgHMiwD,GAAgC,CACpCnkC,GACArtB,EACA8tB,GACAG,GACArnB,EACAsnB,GACAI,GACAQ,GACAG,GACAI,GACAK,GACAG,GACAG,GACAI,GACAG,GACAkF,GACAW,GACAI,GACAoB,GACAzK,GACAkL,GACAkB,GACAgB,GACAG,GACAl2B,EACAiE,EACA6yB,GACA14B,EACA24B,GACAsB,GACAgC,GACAE,GACAU,GACAW,GACAW,GACAmB,GACAU,GACAG,GACAC,GACA6C,GACAY,GACAE,GACAE,GACAoB,GACAE,GACAG,GACAE,GACAE,GACAiB,GACAS,GACAO,GACA5hB,GACAijB,GACAziC,EACA0jC,GACAtjC,EACAwjC,GACApjC,EACAooC,GACAO,GACAE,GACAzoC,EACAI,EACA4oC,GACAK,GACAE,GACAI,GACA7nC,GACAI,GACApJ,EACA2xC,GACAhZ,GACAoZ,GACAI,GACAE,GACApsB,GACAzc,GACAI,GACA0oC,GACAloC,GACAsoC,GACAI,GACAG,GACAI,GACAC,GACAW,GACAU,GACA5pC,GACA8pC,GACAE,GACAE,GACAK,GACAE,GACAQ,GACAI,GACAhrC,GACAkrC,GACAU,GACAW,GACAlsC,GACAM,GACA4sC,GACAU,GACAK,GACArtC,GACA6tC,GACAU,GACAM,GACAE,GACAM,GACAp1B,GACA/Y,GACAouC,GACAS,GACAO,GACAM,GACA78C,EACAmqC,GACA8S,GACA32B,GACAG,GACAS,GACAg2B,GACA6B,GACA4B,GACAM,GACAe,GACAI,GACAc,GACA/qC,GACAgrC,GACAM,GACAQ,GACAU,GACA5rC,GACA8rC,GACAE,GACAG,GACAlrC,GACAq9B,GACAoO,GACAC,GACAQ,GACAI,GACAI,GACAM,GACAE,GACAK,GACAtpC,GACA4pC,GACAvpC,GACAS,GACAmpC,GACAC,GACAgB,GACAG,GACAI,GACA3mC,GACAqkB,GACA0iB,GACAG,GACAC,GACAI,GACAE,GACAE,GACAh+C,GACAygD,GACAE,GACAI,GACAnT,IAGF,IAAK,MAAM8T,KAAgBD,GACzBE,iBAAeD,gDC5WD"}